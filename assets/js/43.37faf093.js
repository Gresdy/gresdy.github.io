(window.webpackJsonp=window.webpackJsonp||[]).push([[43],{507:function(a,t,r){"use strict";r.r(t);var s=r(9),_=Object(s.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"第一周"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#第一周"}},[a._v("#")]),a._v(" 第一周")]),a._v(" "),t("h3",{attrs:{id:"引言-introduction"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#引言-introduction"}},[a._v("#")]),a._v(" 引言(Introduction)")]),a._v(" "),t("blockquote",[t("p",[a._v("第一个视频主要讲了什么是机器学习，机器学习能做些什么事情。")])]),a._v(" "),t("h4",{attrs:{id:"_1-1-欢迎"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-欢迎"}},[a._v("#")]),a._v(" 1.1 欢迎")]),a._v(" "),t("h5",{attrs:{id:"_1-2-机器学习是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-机器学习是什么"}},[a._v("#")]),a._v(" 1.2 机器学习是什么？")]),a._v(" "),t("ul",[t("li",[a._v("第一个机器学习的定义来自于Arthur Samuel。他定义机器学习为，在进行特定编程的情况下，给予计算机学习能力的领域。Samuel的定义可以回溯到50年代，他编写了一个西洋棋程序。这程序神奇之处在于，编程者自己并不是个下棋高手。但因为他太菜了，于是就通过编程，让西洋棋程序自己跟自己下了上万盘棋。通过观察哪种布局（棋盘位置）会赢，哪种布局会输，久而久之，这西洋棋程序明白了什么是好的布局，什么样是坏的布局。")]),a._v(" "),t("li",[a._v("另一个年代近一点的定义，由Tom Mitchell提出，来自卡内基梅隆大学，Tom定义的机器学习是，一个好的学习问题定义如下，他说，一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P，当且仅当，有了经验E后，经过P评判，程序在处理T时的性能有所提升。我认为经验E 就是程序上万次的自我练习的经验而任务T 就是下棋。性能度量值P呢，就是它在与一些新的对手比赛时，赢得比赛的概率。")])]),a._v(" "),t("blockquote",[t("p",[a._v("本课中，我希望教你有关各种不同类型的学习算法。目前存在几种不同类型的学习算法。主要的两种类型被我们称之为"),t("strong",[a._v("监督学习和无监督学习")]),a._v("。监督学习这个想法是指，我们将教计算机如何去完成任务，而在无监督学习中，我们打算让它自己进行学习。我会具体介绍这两种学习算法。此外你将听到诸如，强化学习和推荐系统等各种术语。这些都是机器学习算法的一员，以后我们都将介绍到，但学习算法最常用两个类型就是监督学习、无监督学习。我会在接下来的两个视频中给出它们的定义。本课中，我们将花费最多的精力来讨论这两种学习算法。而另一个会花费大量时间的任务是了解应用学习算法的实用建议。")])]),a._v(" "),t("h5",{attrs:{id:"_1-3-监督学习"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-监督学习"}},[a._v("#")]),a._v(" 1.3 监督学习")]),a._v(" "),t("p",[a._v("常见的一些监督学习任务, 比如垃圾邮件分类, 语音识别成文本, 英语翻译成西班牙语, 根据用户信息预测用户是否会点击相关广告, 自动驾驶中根据图像、雷达等信息确定其他车辆位置, 根据图像进行工业生产线产品缺陷监测.")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/ai/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E5%9C%BA%E6%99%AF.png",alt:"监督学习场景.png"}})]),a._v(" "),t("p",[a._v("监督学习简单理解: 输入一个x和正确答案的示例(y)来训练模型, 模型从这些输入的输入x、输出y中学习之后形成一个模型, 这样再输入一个新的x时, 这是模型以前从未见过的，然后尝试生成相应的输出y。")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/ai/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.png",alt:"监督学习.png"}})]),a._v(" "),t("p",[a._v("我们用一个例子介绍什么是监督学习把正式的定义放在后面介绍。假如说你想预测房价。\n前阵子，一个学生从波特兰俄勒冈州的研究所收集了一些房价的数据。你把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，假如你有一个朋友，他有一套750平方英尺房子，现在他希望把房子卖掉，他想知道这房子能卖多少钱。")]),a._v(" "),t("p",[a._v("那么关于这个问题，机器学习算法将会怎么帮助你呢？")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/ai/img.png",alt:"img.png"}}),a._v("\n我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，拟合一条直线，根据这条线我们可以推测出，这套房子可能卖$150000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200000。稍后我们将讨论如何选择学习算法，如何决定用直线还是二次方程来拟合。两个方案中有一个能让你朋友的房子出售得更合理。这些都是学习算法里面很好的例子。以上就是监督学习的例子。")]),a._v(" "),t("p",[t("strong",[a._v("可以看出，监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成")]),a._v(" "),t("strong",[a._v("用术语来讲，这叫做回归问题。我们试着推测出一个连续值的结果，即房子的价格。")])]),a._v(" "),t("p",[a._v("在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。")]),a._v(" "),t("h2",{attrs:{id:"jupyter-示例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#jupyter-示例"}},[a._v("#")]),a._v(" Jupyter 示例")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/ai/jupyter1.png",alt:"jupyter1.png"}})]),a._v(" "),t("h4",{attrs:{id:"数据集-usa-housing-price-csv"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#数据集-usa-housing-price-csv"}},[a._v("#")]),a._v(" 数据集 "),t("a",{attrs:{href:"/img/ai/usa_housing_price.csv"}},[a._v("usa_housing_price.csv")])]),a._v(" "),t("h5",{attrs:{id:"_1-4-无监督学习"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-无监督学习"}},[a._v("#")]),a._v(" 1.4 无监督学习")]),a._v(" "),t("p",[a._v("相对于监督学习，训练集不会有人为标注的结果（无反馈），我们不会给出结果或无法得知训练集的结果是什么样，而是单纯由计算机通过无监督学习算法自行分析，从而“得出结果”。计算机可能会把特定的数据集归为几个不同的簇，故叫做聚类算法。")]),a._v(" "),t("p",[a._v("无监督学习一般分为两种：")]),a._v(" "),t("ol",[t("li",[a._v("聚类（Clustering）\n"),t("ul",[t("li",[a._v("新闻聚合")]),a._v(" "),t("li",[a._v("DNA 个体聚类")]),a._v(" "),t("li",[a._v("天文数据分析")]),a._v(" "),t("li",[a._v("市场细分")]),a._v(" "),t("li",[a._v("社交网络分析")])])]),a._v(" "),t("li",[a._v("非聚类（Non-clustering）\n"),t("ul",[t("li",[a._v("鸡尾酒问题")])])])]),a._v(" "),t("p",[a._v("在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子，即无监督学习中没有任何的标签或者是有相同的标签或者就是没标签。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法。事实证明，它能被用在很多地方。")]),a._v(" "),t("p",[a._v("聚类应用的一个例子就是在谷歌新闻中。如果你以前从来没见过它，你可以到这个URL网址news.google.com去看看。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。")]),a._v(" "),t("p",[a._v("事实证明，聚类算法和无监督学习算法同样还用在很多其它的问题上。")]),a._v(" "),t("h4",{attrs:{id:"二、单变量线性回归-linear-regression-with-one-variable"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二、单变量线性回归-linear-regression-with-one-variable"}},[a._v("#")]),a._v(" 二、单变量线性回归(Linear Regression with One Variable)")]),a._v(" "),t("h5",{attrs:{id:"_2-1-模型表示"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-模型表示"}},[a._v("#")]),a._v(" 2.1 模型表示")]),a._v(" "),t("h5",{attrs:{id:"_2-2-代价函数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-代价函数"}},[a._v("#")]),a._v(" 2.2 代价函数")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/ai/linearGresionSquredErroeCostFuction.png",alt:"linearGresionSquredErroeCostFuction.png"}})]),a._v(" "),t("h5",{attrs:{id:"_2-3-代价函数的直观理解i"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-代价函数的直观理解i"}},[a._v("#")]),a._v(" 2.3 代价函数的直观理解I")]),a._v(" "),t("h5",{attrs:{id:"_2-4-代价函数的直观理解ii"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-代价函数的直观理解ii"}},[a._v("#")]),a._v(" 2.4 代价函数的直观理解II")]),a._v(" "),t("h5",{attrs:{id:"_2-5-梯度下降"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-梯度下降"}},[a._v("#")]),a._v(" 2.5 梯度下降")]),a._v(" "),t("h5",{attrs:{id:"_2-6-梯度下降的直观理解"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-梯度下降的直观理解"}},[a._v("#")]),a._v(" 2.6 梯度下降的直观理解")]),a._v(" "),t("h5",{attrs:{id:"_2-7-梯度下降的线性回归"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-7-梯度下降的线性回归"}},[a._v("#")]),a._v(" 2.7 梯度下降的线性回归")]),a._v(" "),t("h5",{attrs:{id:"_2-8-接下来的内容"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-8-接下来的内容"}},[a._v("#")]),a._v(" 2.8 接下来的内容")]),a._v(" "),t("h5",{attrs:{id:"三、线性代数回顾-linear-algebra-review"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#三、线性代数回顾-linear-algebra-review"}},[a._v("#")]),a._v(" 三、线性代数回顾(Linear Algebra Review)")]),a._v(" "),t("h5",{attrs:{id:"_3-1-矩阵和向量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-矩阵和向量"}},[a._v("#")]),a._v(" 3.1 矩阵和向量")]),a._v(" "),t("h5",{attrs:{id:"_3-2-加法和标量乘法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-加法和标量乘法"}},[a._v("#")]),a._v(" 3.2 加法和标量乘法")]),a._v(" "),t("h5",{attrs:{id:"_3-3-矩阵向量乘法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-矩阵向量乘法"}},[a._v("#")]),a._v(" 3.3 矩阵向量乘法")]),a._v(" "),t("h5",{attrs:{id:"_3-4-矩阵乘法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-矩阵乘法"}},[a._v("#")]),a._v(" 3.4 矩阵乘法")]),a._v(" "),t("h5",{attrs:{id:"_3-5-矩阵乘法的性质"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-5-矩阵乘法的性质"}},[a._v("#")]),a._v(" 3.5 矩阵乘法的性质")]),a._v(" "),t("h5",{attrs:{id:"_3-6-逆、转置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-6-逆、转置"}},[a._v("#")]),a._v(" 3.6 逆、转置")])])}),[],!1,null,null,null);t.default=_.exports}}]);