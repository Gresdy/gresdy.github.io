(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(e){function n(n){for(var a,o,s=n[0],l=n[1],c=n[2],u=0,p=[];u<s.length;u++)o=s[u],Object.prototype.hasOwnProperty.call(r,o)&&r[o]&&p.push(r[o][0]),r[o]=0;for(a in l)Object.prototype.hasOwnProperty.call(l,a)&&(e[a]=l[a]);for(d&&d(n);p.length;)p.shift()();return i.push.apply(i,c||[]),t()}function t(){for(var e,n=0;n<i.length;n++){for(var t=i[n],a=!0,s=1;s<t.length;s++){var l=t[s];0!==r[l]&&(a=!1)}a&&(i.splice(n--,1),e=o(o.s=t[0]))}return e}var a={},r={1:0},i=[];function o(n){if(a[n])return a[n].exports;var t=a[n]={i:n,l:!1,exports:{}};return e[n].call(t.exports,t,t.exports,o),t.l=!0,t.exports}o.e=function(e){var n=[],t=r[e];if(0!==t)if(t)n.push(t[2]);else{var a=new Promise((function(n,a){t=r[e]=[n,a]}));n.push(t[2]=a);var i,s=document.createElement("script");s.charset="utf-8",s.timeout=120,o.nc&&s.setAttribute("nonce",o.nc),s.src=function(e){return o.p+"assets/js/"+({}[e]||e)+"."+{2:"294e43d0",3:"90e7f4f9",4:"35d0c84a",5:"197e9545",6:"e1ca599c",7:"ce73f7d6",8:"fc4ed1f0",9:"1c569fee",10:"c798c6b8",11:"ee2e4742",12:"02c1d8aa",13:"3deb099f",14:"8b0e3cca",15:"729baa93",16:"ea2228b8",17:"54f8d56b",18:"8295b59a",19:"80ec033a",20:"3a3150a6",21:"2cfb08e7",22:"961ef9c6",23:"af39583b",24:"b2c08c82",25:"794e8dcc",26:"cefdf367",27:"8e7d7bcb",28:"df6604a9",29:"8fc4ee82",30:"6c71ff99",31:"75827cd2",32:"305df95d",33:"d5abdfb7",34:"45ebe537",35:"d96f3878",36:"20c54cb5",37:"70b89b2b",38:"b76f1251",39:"deafc6a5",40:"9169e8bf",41:"6bd6819e",42:"1324b559",43:"37faf093",44:"116021b1",45:"54353d71",46:"9cd75d5d",47:"9f26124c",48:"b7baffbf",49:"21953821",50:"6ccefcc2",51:"5a40c934",52:"029bc53b",53:"665cf685",54:"6a915811",55:"0308b2f7",56:"99755c06",57:"732bd2f2",58:"630b7f9c",59:"7fce3d78",60:"e1e67346",61:"2e2b79f5",62:"495c41cf",63:"2bc8f152",64:"8ec76d2e",65:"3252427b",66:"d051d693",67:"d639c4e2",68:"a3f26102",69:"eafaacec",70:"9985d66c",71:"bff353d0",72:"d34bb386",73:"878497a0",74:"cde9ead1",75:"7b0e2ca8",76:"fda754f1",77:"265ae7f7",78:"67911f34",79:"cefcd8ef",80:"670edf24"}[e]+".js"}(e);var l=new Error;i=function(n){s.onerror=s.onload=null,clearTimeout(c);var t=r[e];if(0!==t){if(t){var a=n&&("load"===n.type?"missing":n.type),i=n&&n.target&&n.target.src;l.message="Loading chunk "+e+" failed.\n("+a+": "+i+")",l.name="ChunkLoadError",l.type=a,l.request=i,t[1](l)}r[e]=void 0}};var c=setTimeout((function(){i({type:"timeout",target:s})}),12e4);s.onerror=s.onload=i,document.head.appendChild(s)}return Promise.all(n)},o.m=e,o.c=a,o.d=function(e,n,t){o.o(e,n)||Object.defineProperty(e,n,{enumerable:!0,get:t})},o.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},o.t=function(e,n){if(1&n&&(e=o(e)),8&n)return e;if(4&n&&"object"==typeof e&&e&&e.__esModule)return e;var t=Object.create(null);if(o.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:e}),2&n&&"string"!=typeof e)for(var a in e)o.d(t,a,function(n){return e[n]}.bind(null,a));return t},o.n=function(e){var n=e&&e.__esModule?function(){return e.default}:function(){return e};return o.d(n,"a",n),n},o.o=function(e,n){return Object.prototype.hasOwnProperty.call(e,n)},o.p="/",o.oe=function(e){throw console.error(e),e};var s=window.webpackJsonp=window.webpackJsonp||[],l=s.push.bind(s);s.push=n,s=s.slice();for(var c=0;c<s.length;c++)n(s[c]);var d=l;i.push([105,0]),t()}([function(e,n,t){"use strict";t.r(n),t.d(n,"EffectScope",(function(){return yn})),t.d(n,"computed",(function(){return ln})),t.d(n,"customRef",(function(){return en})),t.d(n,"default",(function(){return Qa})),t.d(n,"defineAsyncComponent",(function(){return jt})),t.d(n,"defineComponent",(function(){return Gt})),t.d(n,"del",(function(){return Pe})),t.d(n,"effectScope",(function(){return wn})),t.d(n,"getCurrentInstance",(function(){return pe})),t.d(n,"getCurrentScope",(function(){return _n})),t.d(n,"h",(function(){return mt})),t.d(n,"inject",(function(){return En})),t.d(n,"isProxy",(function(){return Ue})),t.d(n,"isReactive",(function(){return Je})),t.d(n,"isReadonly",(function(){return Be})),t.d(n,"isRef",(function(){return Ge})),t.d(n,"isShallow",(function(){return Fe})),t.d(n,"markRaw",(function(){return $e})),t.d(n,"mergeDefaults",(function(){return lt})),t.d(n,"nextTick",(function(){return It})),t.d(n,"onActivated",(function(){return zt})),t.d(n,"onBeforeMount",(function(){return Lt})),t.d(n,"onBeforeUnmount",(function(){return Mt})),t.d(n,"onBeforeUpdate",(function(){return Dt})),t.d(n,"onDeactivated",(function(){return qt})),t.d(n,"onErrorCaptured",(function(){return Ht})),t.d(n,"onMounted",(function(){return Nt})),t.d(n,"onRenderTracked",(function(){return Ft})),t.d(n,"onRenderTriggered",(function(){return Bt})),t.d(n,"onScopeDispose",(function(){return xn})),t.d(n,"onServerPrefetch",(function(){return Jt})),t.d(n,"onUnmounted",(function(){return Rt})),t.d(n,"onUpdated",(function(){return Pt})),t.d(n,"provide",(function(){return kn})),t.d(n,"proxyRefs",(function(){return Qe})),t.d(n,"reactive",(function(){return Re})),t.d(n,"readonly",(function(){return an})),t.d(n,"ref",(function(){return Ke})),t.d(n,"set",(function(){return De})),t.d(n,"shallowReactive",(function(){return ze})),t.d(n,"shallowReadonly",(function(){return sn})),t.d(n,"shallowRef",(function(){return We})),t.d(n,"toRaw",(function(){return He})),t.d(n,"toRef",(function(){return tn})),t.d(n,"toRefs",(function(){return nn})),t.d(n,"triggerRef",(function(){return Ve})),t.d(n,"unref",(function(){return Ze})),t.d(n,"useAttrs",(function(){return it})),t.d(n,"useCssModule",(function(){return At})),t.d(n,"useCssVars",(function(){return Ct})),t.d(n,"useListeners",(function(){return ot})),t.d(n,"useSlots",(function(){return rt})),t.d(n,"version",(function(){return $t})),t.d(n,"watch",(function(){return vn})),t.d(n,"watchEffect",(function(){return pn})),t.d(n,"watchPostEffect",(function(){return mn})),t.d(n,"watchSyncEffect",(function(){return hn}));
/*!
 * Vue.js v2.7.16
 * (c) 2014-2023 Evan You
 * Released under the MIT License.
 */
var a=Object.freeze({}),r=Array.isArray;function i(e){return null==e}function o(e){return null!=e}function s(e){return!0===e}function l(e){return"string"==typeof e||"number"==typeof e||"symbol"==typeof e||"boolean"==typeof e}function c(e){return"function"==typeof e}function d(e){return null!==e&&"object"==typeof e}var u=Object.prototype.toString;function p(e){return"[object Object]"===u.call(e)}function m(e){return"[object RegExp]"===u.call(e)}function h(e){var n=parseFloat(String(e));return n>=0&&Math.floor(n)===n&&isFinite(e)}function f(e){return o(e)&&"function"==typeof e.then&&"function"==typeof e.catch}function g(e){return null==e?"":Array.isArray(e)||p(e)&&e.toString===u?JSON.stringify(e,v,2):String(e)}function v(e,n){return n&&n.__v_isRef?n.value:n}function b(e){var n=parseFloat(e);return isNaN(n)?e:n}function y(e,n){for(var t=Object.create(null),a=e.split(","),r=0;r<a.length;r++)t[a[r]]=!0;return n?function(e){return t[e.toLowerCase()]}:function(e){return t[e]}}y("slot,component",!0);var w=y("key,ref,slot,slot-scope,is");function _(e,n){var t=e.length;if(t){if(n===e[t-1])return void(e.length=t-1);var a=e.indexOf(n);if(a>-1)return e.splice(a,1)}}var x=Object.prototype.hasOwnProperty;function k(e,n){return x.call(e,n)}function T(e){var n=Object.create(null);return function(t){return n[t]||(n[t]=e(t))}}var E=/-(\w)/g,S=T((function(e){return e.replace(E,(function(e,n){return n?n.toUpperCase():""}))})),I=T((function(e){return e.charAt(0).toUpperCase()+e.slice(1)})),A=/\B([A-Z])/g,C=T((function(e){return e.replace(A,"-$1").toLowerCase()}));var j=Function.prototype.bind?function(e,n){return e.bind(n)}:function(e,n){function t(t){var a=arguments.length;return a?a>1?e.apply(n,arguments):e.call(n,t):e.call(n)}return t._length=e.length,t};function O(e,n){n=n||0;for(var t=e.length-n,a=new Array(t);t--;)a[t]=e[t+n];return a}function L(e,n){for(var t in n)e[t]=n[t];return e}function N(e){for(var n={},t=0;t<e.length;t++)e[t]&&L(n,e[t]);return n}function D(e,n,t){}var P=function(e,n,t){return!1},M=function(e){return e};function R(e,n){if(e===n)return!0;var t=d(e),a=d(n);if(!t||!a)return!t&&!a&&String(e)===String(n);try{var r=Array.isArray(e),i=Array.isArray(n);if(r&&i)return e.length===n.length&&e.every((function(e,t){return R(e,n[t])}));if(e instanceof Date&&n instanceof Date)return e.getTime()===n.getTime();if(r||i)return!1;var o=Object.keys(e),s=Object.keys(n);return o.length===s.length&&o.every((function(t){return R(e[t],n[t])}))}catch(e){return!1}}function z(e,n){for(var t=0;t<e.length;t++)if(R(e[t],n))return t;return-1}function q(e){var n=!1;return function(){n||(n=!0,e.apply(this,arguments))}}function J(e,n){return e===n?0===e&&1/e!=1/n:e==e||n==n}var F=["component","directive","filter"],B=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],U={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:P,isReservedAttr:P,isUnknownElement:P,getTagNamespace:D,parsePlatformTagName:M,mustUseProp:P,async:!0,_lifecycleHooks:B},H=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function $(e){var n=(e+"").charCodeAt(0);return 36===n||95===n}function G(e,n,t,a){Object.defineProperty(e,n,{value:t,enumerable:!!a,writable:!0,configurable:!0})}var K=new RegExp("[^".concat(H.source,".$_\\d]"));var W="__proto__"in{},Y="undefined"!=typeof window,V=Y&&window.navigator.userAgent.toLowerCase(),Z=V&&/msie|trident/.test(V),Q=V&&V.indexOf("msie 9.0")>0,X=V&&V.indexOf("edge/")>0;V&&V.indexOf("android");var ee=V&&/iphone|ipad|ipod|ios/.test(V);V&&/chrome\/\d+/.test(V),V&&/phantomjs/.test(V);var ne,te=V&&V.match(/firefox\/(\d+)/),ae={}.watch,re=!1;if(Y)try{var ie={};Object.defineProperty(ie,"passive",{get:function(){re=!0}}),window.addEventListener("test-passive",null,ie)}catch(e){}var oe=function(){return void 0===ne&&(ne=!Y&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),ne},se=Y&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function le(e){return"function"==typeof e&&/native code/.test(e.toString())}var ce,de="undefined"!=typeof Symbol&&le(Symbol)&&"undefined"!=typeof Reflect&&le(Reflect.ownKeys);ce="undefined"!=typeof Set&&le(Set)?Set:function(){function e(){this.set=Object.create(null)}return e.prototype.has=function(e){return!0===this.set[e]},e.prototype.add=function(e){this.set[e]=!0},e.prototype.clear=function(){this.set=Object.create(null)},e}();var ue=null;function pe(){return ue&&{proxy:ue}}function me(e){void 0===e&&(e=null),e||ue&&ue._scope.off(),ue=e,e&&e._scope.on()}var he=function(){function e(e,n,t,a,r,i,o,s){this.tag=e,this.data=n,this.children=t,this.text=a,this.elm=r,this.ns=void 0,this.context=i,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=n&&n.key,this.componentOptions=o,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(e.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),e}(),fe=function(e){void 0===e&&(e="");var n=new he;return n.text=e,n.isComment=!0,n};function ge(e){return new he(void 0,void 0,void 0,String(e))}function ve(e){var n=new he(e.tag,e.data,e.children&&e.children.slice(),e.text,e.elm,e.context,e.componentOptions,e.asyncFactory);return n.ns=e.ns,n.isStatic=e.isStatic,n.key=e.key,n.isComment=e.isComment,n.fnContext=e.fnContext,n.fnOptions=e.fnOptions,n.fnScopeId=e.fnScopeId,n.asyncMeta=e.asyncMeta,n.isCloned=!0,n}"function"==typeof SuppressedError&&SuppressedError;var be=0,ye=[],we=function(){function e(){this._pending=!1,this.id=be++,this.subs=[]}return e.prototype.addSub=function(e){this.subs.push(e)},e.prototype.removeSub=function(e){this.subs[this.subs.indexOf(e)]=null,this._pending||(this._pending=!0,ye.push(this))},e.prototype.depend=function(n){e.target&&e.target.addDep(this)},e.prototype.notify=function(e){var n=this.subs.filter((function(e){return e}));for(var t=0,a=n.length;t<a;t++){0,n[t].update()}},e}();we.target=null;var _e=[];function xe(e){_e.push(e),we.target=e}function ke(){_e.pop(),we.target=_e[_e.length-1]}var Te=Array.prototype,Ee=Object.create(Te);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(e){var n=Te[e];G(Ee,e,(function(){for(var t=[],a=0;a<arguments.length;a++)t[a]=arguments[a];var r,i=n.apply(this,t),o=this.__ob__;switch(e){case"push":case"unshift":r=t;break;case"splice":r=t.slice(2)}return r&&o.observeArray(r),o.dep.notify(),i}))}));var Se=Object.getOwnPropertyNames(Ee),Ie={},Ae=!0;function Ce(e){Ae=e}var je={notify:D,depend:D,addSub:D,removeSub:D},Oe=function(){function e(e,n,t){if(void 0===n&&(n=!1),void 0===t&&(t=!1),this.value=e,this.shallow=n,this.mock=t,this.dep=t?je:new we,this.vmCount=0,G(e,"__ob__",this),r(e)){if(!t)if(W)e.__proto__=Ee;else for(var a=0,i=Se.length;a<i;a++){G(e,s=Se[a],Ee[s])}n||this.observeArray(e)}else{var o=Object.keys(e);for(a=0;a<o.length;a++){var s;Ne(e,s=o[a],Ie,void 0,n,t)}}}return e.prototype.observeArray=function(e){for(var n=0,t=e.length;n<t;n++)Le(e[n],!1,this.mock)},e}();function Le(e,n,t){return e&&k(e,"__ob__")&&e.__ob__ instanceof Oe?e.__ob__:!Ae||!t&&oe()||!r(e)&&!p(e)||!Object.isExtensible(e)||e.__v_skip||Ge(e)||e instanceof he?void 0:new Oe(e,n,t)}function Ne(e,n,t,a,i,o,s){void 0===s&&(s=!1);var l=new we,c=Object.getOwnPropertyDescriptor(e,n);if(!c||!1!==c.configurable){var d=c&&c.get,u=c&&c.set;d&&!u||t!==Ie&&2!==arguments.length||(t=e[n]);var p=i?t&&t.__ob__:Le(t,!1,o);return Object.defineProperty(e,n,{enumerable:!0,configurable:!0,get:function(){var n=d?d.call(e):t;return we.target&&(l.depend(),p&&(p.dep.depend(),r(n)&&Me(n))),Ge(n)&&!i?n.value:n},set:function(n){var a=d?d.call(e):t;if(J(a,n)){if(u)u.call(e,n);else{if(d)return;if(!i&&Ge(a)&&!Ge(n))return void(a.value=n);t=n}p=i?n&&n.__ob__:Le(n,!1,o),l.notify()}}}),l}}function De(e,n,t){if(!Be(e)){var a=e.__ob__;return r(e)&&h(n)?(e.length=Math.max(e.length,n),e.splice(n,1,t),a&&!a.shallow&&a.mock&&Le(t,!1,!0),t):n in e&&!(n in Object.prototype)?(e[n]=t,t):e._isVue||a&&a.vmCount?t:a?(Ne(a.value,n,t,void 0,a.shallow,a.mock),a.dep.notify(),t):(e[n]=t,t)}}function Pe(e,n){if(r(e)&&h(n))e.splice(n,1);else{var t=e.__ob__;e._isVue||t&&t.vmCount||Be(e)||k(e,n)&&(delete e[n],t&&t.dep.notify())}}function Me(e){for(var n=void 0,t=0,a=e.length;t<a;t++)(n=e[t])&&n.__ob__&&n.__ob__.dep.depend(),r(n)&&Me(n)}function Re(e){return qe(e,!1),e}function ze(e){return qe(e,!0),G(e,"__v_isShallow",!0),e}function qe(e,n){if(!Be(e)){Le(e,n,oe());0}}function Je(e){return Be(e)?Je(e.__v_raw):!(!e||!e.__ob__)}function Fe(e){return!(!e||!e.__v_isShallow)}function Be(e){return!(!e||!e.__v_isReadonly)}function Ue(e){return Je(e)||Be(e)}function He(e){var n=e&&e.__v_raw;return n?He(n):e}function $e(e){return Object.isExtensible(e)&&G(e,"__v_skip",!0),e}function Ge(e){return!(!e||!0!==e.__v_isRef)}function Ke(e){return Ye(e,!1)}function We(e){return Ye(e,!0)}function Ye(e,n){if(Ge(e))return e;var t={};return G(t,"__v_isRef",!0),G(t,"__v_isShallow",n),G(t,"dep",Ne(t,"value",e,null,n,oe())),t}function Ve(e){e.dep&&e.dep.notify()}function Ze(e){return Ge(e)?e.value:e}function Qe(e){if(Je(e))return e;for(var n={},t=Object.keys(e),a=0;a<t.length;a++)Xe(n,e,t[a]);return n}function Xe(e,n,t){Object.defineProperty(e,t,{enumerable:!0,configurable:!0,get:function(){var e=n[t];if(Ge(e))return e.value;var a=e&&e.__ob__;return a&&a.dep.depend(),e},set:function(e){var a=n[t];Ge(a)&&!Ge(e)?a.value=e:n[t]=e}})}function en(e){var n=new we,t=e((function(){n.depend()}),(function(){n.notify()})),a=t.get,r=t.set,i={get value(){return a()},set value(e){r(e)}};return G(i,"__v_isRef",!0),i}function nn(e){var n=r(e)?new Array(e.length):{};for(var t in e)n[t]=tn(e,t);return n}function tn(e,n,t){var a=e[n];if(Ge(a))return a;var r={get value(){var a=e[n];return void 0===a?t:a},set value(t){e[n]=t}};return G(r,"__v_isRef",!0),r}function an(e){return rn(e,!1)}function rn(e,n){if(!p(e))return e;if(Be(e))return e;var t=n?"__v_rawToShallowReadonly":"__v_rawToReadonly",a=e[t];if(a)return a;var r=Object.create(Object.getPrototypeOf(e));G(e,t,r),G(r,"__v_isReadonly",!0),G(r,"__v_raw",e),Ge(e)&&G(r,"__v_isRef",!0),(n||Fe(e))&&G(r,"__v_isShallow",!0);for(var i=Object.keys(e),o=0;o<i.length;o++)on(r,e,i[o],n);return r}function on(e,n,t,a){Object.defineProperty(e,t,{enumerable:!0,configurable:!0,get:function(){var e=n[t];return a||!p(e)?e:an(e)},set:function(){}})}function sn(e){return rn(e,!0)}function ln(e,n){var t,a,r=c(e);r?(t=e,a=D):(t=e.get,a=e.set);var i=oe()?null:new Zt(ue,t,D,{lazy:!0});var o={effect:i,get value(){return i?(i.dirty&&i.evaluate(),we.target&&i.depend(),i.value):t()},set value(e){a(e)}};return G(o,"__v_isRef",!0),G(o,"__v_isReadonly",r),o}var cn="".concat("watcher"," callback"),dn="".concat("watcher"," getter"),un="".concat("watcher"," cleanup");function pn(e,n){return bn(e,null,n)}function mn(e,n){return bn(e,null,{flush:"post"})}function hn(e,n){return bn(e,null,{flush:"sync"})}var fn,gn={};function vn(e,n,t){return bn(e,n,t)}function bn(e,n,t){var i=void 0===t?a:t,o=i.immediate,s=i.deep,l=i.flush,d=void 0===l?"pre":l;i.onTrack,i.onTrigger;var u,p,m=ue,h=function(e,n,t){void 0===t&&(t=null);var a=ft(e,null,t,m,n);return s&&a&&a.__ob__&&a.__ob__.dep.depend(),a},f=!1,g=!1;if(Ge(e)?(u=function(){return e.value},f=Fe(e)):Je(e)?(u=function(){return e.__ob__.dep.depend(),e},s=!0):r(e)?(g=!0,f=e.some((function(e){return Je(e)||Fe(e)})),u=function(){return e.map((function(e){return Ge(e)?e.value:Je(e)?(e.__ob__.dep.depend(),Wt(e)):c(e)?h(e,dn):void 0}))}):u=c(e)?n?function(){return h(e,dn)}:function(){if(!m||!m._isDestroyed)return p&&p(),h(e,"watcher",[b])}:D,n&&s){var v=u;u=function(){return Wt(v())}}var b=function(e){p=y.onStop=function(){h(e,un)}};if(oe())return b=D,n?o&&h(n,cn,[u(),g?[]:void 0,b]):u(),D;var y=new Zt(ue,u,D,{lazy:!0});y.noRecurse=!n;var w=g?[]:gn;return y.run=function(){if(y.active)if(n){var e=y.get();(s||f||(g?e.some((function(e,n){return J(e,w[n])})):J(e,w)))&&(p&&p(),h(n,cn,[e,w===gn?void 0:w,b]),w=e)}else y.get()},"sync"===d?y.update=y.run:"post"===d?(y.post=!0,y.update=function(){return ba(y)}):y.update=function(){if(m&&m===ue&&!m._isMounted){var e=m._preWatchers||(m._preWatchers=[]);e.indexOf(y)<0&&e.push(y)}else ba(y)},n?o?y.run():w=y.get():"post"===d&&m?m.$once("hook:mounted",(function(){return y.get()})):y.get(),function(){y.teardown()}}var yn=function(){function e(e){void 0===e&&(e=!1),this.detached=e,this.active=!0,this.effects=[],this.cleanups=[],this.parent=fn,!e&&fn&&(this.index=(fn.scopes||(fn.scopes=[])).push(this)-1)}return e.prototype.run=function(e){if(this.active){var n=fn;try{return fn=this,e()}finally{fn=n}}else 0},e.prototype.on=function(){fn=this},e.prototype.off=function(){fn=this.parent},e.prototype.stop=function(e){if(this.active){var n=void 0,t=void 0;for(n=0,t=this.effects.length;n<t;n++)this.effects[n].teardown();for(n=0,t=this.cleanups.length;n<t;n++)this.cleanups[n]();if(this.scopes)for(n=0,t=this.scopes.length;n<t;n++)this.scopes[n].stop(!0);if(!this.detached&&this.parent&&!e){var a=this.parent.scopes.pop();a&&a!==this&&(this.parent.scopes[this.index]=a,a.index=this.index)}this.parent=void 0,this.active=!1}},e}();function wn(e){return new yn(e)}function _n(){return fn}function xn(e){fn&&fn.cleanups.push(e)}function kn(e,n){ue&&(Tn(ue)[e]=n)}function Tn(e){var n=e._provided,t=e.$parent&&e.$parent._provided;return t===n?e._provided=Object.create(t):n}function En(e,n,t){void 0===t&&(t=!1);var a=ue;if(a){var r=a.$parent&&a.$parent._provided;if(r&&e in r)return r[e];if(arguments.length>1)return t&&c(n)?n.call(a):n}else 0}var Sn=T((function(e){var n="&"===e.charAt(0),t="~"===(e=n?e.slice(1):e).charAt(0),a="!"===(e=t?e.slice(1):e).charAt(0);return{name:e=a?e.slice(1):e,once:t,capture:a,passive:n}}));function In(e,n){function t(){var e=t.fns;if(!r(e))return ft(e,null,arguments,n,"v-on handler");for(var a=e.slice(),i=0;i<a.length;i++)ft(a[i],null,arguments,n,"v-on handler")}return t.fns=e,t}function An(e,n,t,a,r,o){var l,c,d,u;for(l in e)c=e[l],d=n[l],u=Sn(l),i(c)||(i(d)?(i(c.fns)&&(c=e[l]=In(c,o)),s(u.once)&&(c=e[l]=r(u.name,c,u.capture)),t(u.name,c,u.capture,u.passive,u.params)):c!==d&&(d.fns=c,e[l]=d));for(l in n)i(e[l])&&a((u=Sn(l)).name,n[l],u.capture)}function Cn(e,n,t){var a;e instanceof he&&(e=e.data.hook||(e.data.hook={}));var r=e[n];function l(){t.apply(this,arguments),_(a.fns,l)}i(r)?a=In([l]):o(r.fns)&&s(r.merged)?(a=r).fns.push(l):a=In([r,l]),a.merged=!0,e[n]=a}function jn(e,n,t,a,r){if(o(n)){if(k(n,t))return e[t]=n[t],r||delete n[t],!0;if(k(n,a))return e[t]=n[a],r||delete n[a],!0}return!1}function On(e){return l(e)?[ge(e)]:r(e)?function e(n,t){var a,c,d,u,p=[];for(a=0;a<n.length;a++)i(c=n[a])||"boolean"==typeof c||(d=p.length-1,u=p[d],r(c)?c.length>0&&(Ln((c=e(c,"".concat(t||"","_").concat(a)))[0])&&Ln(u)&&(p[d]=ge(u.text+c[0].text),c.shift()),p.push.apply(p,c)):l(c)?Ln(u)?p[d]=ge(u.text+c):""!==c&&p.push(ge(c)):Ln(c)&&Ln(u)?p[d]=ge(u.text+c.text):(s(n._isVList)&&o(c.tag)&&i(c.key)&&o(t)&&(c.key="__vlist".concat(t,"_").concat(a,"__")),p.push(c)));return p}(e):void 0}function Ln(e){return o(e)&&o(e.text)&&!1===e.isComment}function Nn(e,n){var t,a,i,s,l=null;if(r(e)||"string"==typeof e)for(l=new Array(e.length),t=0,a=e.length;t<a;t++)l[t]=n(e[t],t);else if("number"==typeof e)for(l=new Array(e),t=0;t<e;t++)l[t]=n(t+1,t);else if(d(e))if(de&&e[Symbol.iterator]){l=[];for(var c=e[Symbol.iterator](),u=c.next();!u.done;)l.push(n(u.value,l.length)),u=c.next()}else for(i=Object.keys(e),l=new Array(i.length),t=0,a=i.length;t<a;t++)s=i[t],l[t]=n(e[s],s,t);return o(l)||(l=[]),l._isVList=!0,l}function Dn(e,n,t,a){var r,i=this.$scopedSlots[e];i?(t=t||{},a&&(t=L(L({},a),t)),r=i(t)||(c(n)?n():n)):r=this.$slots[e]||(c(n)?n():n);var o=t&&t.slot;return o?this.$createElement("template",{slot:o},r):r}function Pn(e){return Ma(this.$options,"filters",e,!0)||M}function Mn(e,n){return r(e)?-1===e.indexOf(n):e!==n}function Rn(e,n,t,a,r){var i=U.keyCodes[n]||t;return r&&a&&!U.keyCodes[n]?Mn(r,a):i?Mn(i,e):a?C(a)!==n:void 0===e}function zn(e,n,t,a,i){if(t)if(d(t)){r(t)&&(t=N(t));var o=void 0,s=function(r){if("class"===r||"style"===r||w(r))o=e;else{var s=e.attrs&&e.attrs.type;o=a||U.mustUseProp(n,s,r)?e.domProps||(e.domProps={}):e.attrs||(e.attrs={})}var l=S(r),c=C(r);l in o||c in o||(o[r]=t[r],i&&((e.on||(e.on={}))["update:".concat(r)]=function(e){t[r]=e}))};for(var l in t)s(l)}else;return e}function qn(e,n){var t=this._staticTrees||(this._staticTrees=[]),a=t[e];return a&&!n||Fn(a=t[e]=this.$options.staticRenderFns[e].call(this._renderProxy,this._c,this),"__static__".concat(e),!1),a}function Jn(e,n,t){return Fn(e,"__once__".concat(n).concat(t?"_".concat(t):""),!0),e}function Fn(e,n,t){if(r(e))for(var a=0;a<e.length;a++)e[a]&&"string"!=typeof e[a]&&Bn(e[a],"".concat(n,"_").concat(a),t);else Bn(e,n,t)}function Bn(e,n,t){e.isStatic=!0,e.key=n,e.isOnce=t}function Un(e,n){if(n)if(p(n)){var t=e.on=e.on?L({},e.on):{};for(var a in n){var r=t[a],i=n[a];t[a]=r?[].concat(r,i):i}}else;return e}function Hn(e,n,t,a){n=n||{$stable:!t};for(var i=0;i<e.length;i++){var o=e[i];r(o)?Hn(o,n,t):o&&(o.proxy&&(o.fn.proxy=!0),n[o.key]=o.fn)}return a&&(n.$key=a),n}function $n(e,n){for(var t=0;t<n.length;t+=2){var a=n[t];"string"==typeof a&&a&&(e[n[t]]=n[t+1])}return e}function Gn(e,n){return"string"==typeof e?n+e:e}function Kn(e){e._o=Jn,e._n=b,e._s=g,e._l=Nn,e._t=Dn,e._q=R,e._i=z,e._m=qn,e._f=Pn,e._k=Rn,e._b=zn,e._v=ge,e._e=fe,e._u=Hn,e._g=Un,e._d=$n,e._p=Gn}function Wn(e,n){if(!e||!e.length)return{};for(var t={},a=0,r=e.length;a<r;a++){var i=e[a],o=i.data;if(o&&o.attrs&&o.attrs.slot&&delete o.attrs.slot,i.context!==n&&i.fnContext!==n||!o||null==o.slot)(t.default||(t.default=[])).push(i);else{var s=o.slot,l=t[s]||(t[s]=[]);"template"===i.tag?l.push.apply(l,i.children||[]):l.push(i)}}for(var c in t)t[c].every(Yn)&&delete t[c];return t}function Yn(e){return e.isComment&&!e.asyncFactory||" "===e.text}function Vn(e){return e.isComment&&e.asyncFactory}function Zn(e,n,t,r){var i,o=Object.keys(t).length>0,s=n?!!n.$stable:!o,l=n&&n.$key;if(n){if(n._normalized)return n._normalized;if(s&&r&&r!==a&&l===r.$key&&!o&&!r.$hasNormal)return r;for(var c in i={},n)n[c]&&"$"!==c[0]&&(i[c]=Qn(e,t,c,n[c]))}else i={};for(var d in t)d in i||(i[d]=Xn(t,d));return n&&Object.isExtensible(n)&&(n._normalized=i),G(i,"$stable",s),G(i,"$key",l),G(i,"$hasNormal",o),i}function Qn(e,n,t,a){var i=function(){var n=ue;me(e);var t=arguments.length?a.apply(null,arguments):a({}),i=(t=t&&"object"==typeof t&&!r(t)?[t]:On(t))&&t[0];return me(n),t&&(!i||1===t.length&&i.isComment&&!Vn(i))?void 0:t};return a.proxy&&Object.defineProperty(n,t,{get:i,enumerable:!0,configurable:!0}),i}function Xn(e,n){return function(){return e[n]}}function et(e){return{get attrs(){if(!e._attrsProxy){var n=e._attrsProxy={};G(n,"_v_attr_proxy",!0),nt(n,e.$attrs,a,e,"$attrs")}return e._attrsProxy},get listeners(){e._listenersProxy||nt(e._listenersProxy={},e.$listeners,a,e,"$listeners");return e._listenersProxy},get slots(){return function(e){e._slotsProxy||at(e._slotsProxy={},e.$scopedSlots);return e._slotsProxy}(e)},emit:j(e.$emit,e),expose:function(n){n&&Object.keys(n).forEach((function(t){return Xe(e,n,t)}))}}}function nt(e,n,t,a,r){var i=!1;for(var o in n)o in e?n[o]!==t[o]&&(i=!0):(i=!0,tt(e,o,a,r));for(var o in e)o in n||(i=!0,delete e[o]);return i}function tt(e,n,t,a){Object.defineProperty(e,n,{enumerable:!0,configurable:!0,get:function(){return t[a][n]}})}function at(e,n){for(var t in n)e[t]=n[t];for(var t in e)t in n||delete e[t]}function rt(){return st().slots}function it(){return st().attrs}function ot(){return st().listeners}function st(){var e=ue;return e._setupContext||(e._setupContext=et(e))}function lt(e,n){var t=r(e)?e.reduce((function(e,n){return e[n]={},e}),{}):e;for(var a in n){var i=t[a];i?r(i)||c(i)?t[a]={type:i,default:n[a]}:i.default=n[a]:null===i&&(t[a]={default:n[a]})}return t}var ct=null;function dt(e,n){return(e.__esModule||de&&"Module"===e[Symbol.toStringTag])&&(e=e.default),d(e)?n.extend(e):e}function ut(e){if(r(e))for(var n=0;n<e.length;n++){var t=e[n];if(o(t)&&(o(t.componentOptions)||Vn(t)))return t}}function pt(e,n,t,a,u,p){return(r(t)||l(t))&&(u=a,a=t,t=void 0),s(p)&&(u=2),function(e,n,t,a,l){if(o(t)&&o(t.__ob__))return fe();o(t)&&o(t.is)&&(n=t.is);if(!n)return fe();0;r(a)&&c(a[0])&&((t=t||{}).scopedSlots={default:a[0]},a.length=0);2===l?a=On(a):1===l&&(a=function(e){for(var n=0;n<e.length;n++)if(r(e[n]))return Array.prototype.concat.apply([],e);return e}(a));var u,p;if("string"==typeof n){var m=void 0;p=e.$vnode&&e.$vnode.ns||U.getTagNamespace(n),u=U.isReservedTag(n)?new he(U.parsePlatformTagName(n),t,a,void 0,void 0,e):t&&t.pre||!o(m=Ma(e.$options,"components",n))?new he(n,t,a,void 0,void 0,e):Sa(m,t,e,a,n)}else u=Sa(n,t,e,a);return r(u)?u:o(u)?(o(p)&&function e(n,t,a){n.ns=t,"foreignObject"===n.tag&&(t=void 0,a=!0);if(o(n.children))for(var r=0,l=n.children.length;r<l;r++){var c=n.children[r];o(c.tag)&&(i(c.ns)||s(a)&&"svg"!==c.tag)&&e(c,t,a)}}(u,p),o(t)&&function(e){d(e.style)&&Wt(e.style);d(e.class)&&Wt(e.class)}(t),u):fe()}(e,n,t,a,u)}function mt(e,n,t){return pt(ue,e,n,t,2,!0)}function ht(e,n,t){xe();try{if(n)for(var a=n;a=a.$parent;){var r=a.$options.errorCaptured;if(r)for(var i=0;i<r.length;i++)try{if(!1===r[i].call(a,e,n,t))return}catch(e){gt(e,a,"errorCaptured hook")}}gt(e,n,t)}finally{ke()}}function ft(e,n,t,a,r){var i;try{(i=t?e.apply(n,t):e.call(n))&&!i._isVue&&f(i)&&!i._handled&&(i.catch((function(e){return ht(e,a,r+" (Promise/async)")})),i._handled=!0)}catch(e){ht(e,a,r)}return i}function gt(e,n,t){if(U.errorHandler)try{return U.errorHandler.call(null,e,n,t)}catch(n){n!==e&&vt(n,null,"config.errorHandler")}vt(e,n,t)}function vt(e,n,t){if(!Y||"undefined"==typeof console)throw e;console.error(e)}var bt,yt=!1,wt=[],_t=!1;function xt(){_t=!1;var e=wt.slice(0);wt.length=0;for(var n=0;n<e.length;n++)e[n]()}if("undefined"!=typeof Promise&&le(Promise)){var kt=Promise.resolve();bt=function(){kt.then(xt),ee&&setTimeout(D)},yt=!0}else if(Z||"undefined"==typeof MutationObserver||!le(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())bt="undefined"!=typeof setImmediate&&le(setImmediate)?function(){setImmediate(xt)}:function(){setTimeout(xt,0)};else{var Tt=1,Et=new MutationObserver(xt),St=document.createTextNode(String(Tt));Et.observe(St,{characterData:!0}),bt=function(){Tt=(Tt+1)%2,St.data=String(Tt)},yt=!0}function It(e,n){var t;if(wt.push((function(){if(e)try{e.call(n)}catch(e){ht(e,n,"nextTick")}else t&&t(n)})),_t||(_t=!0,bt()),!e&&"undefined"!=typeof Promise)return new Promise((function(e){t=e}))}function At(e){if(void 0===e&&(e="$style"),!ue)return a;var n=ue[e];return n||a}function Ct(e){if(Y){var n=ue;n&&mn((function(){var t=n.$el,a=e(n,n._setupProxy);if(t&&1===t.nodeType){var r=t.style;for(var i in a)r.setProperty("--".concat(i),a[i])}}))}}function jt(e){c(e)&&(e={loader:e});var n=e.loader,t=e.loadingComponent,a=e.errorComponent,r=e.delay,i=void 0===r?200:r,o=e.timeout,s=(e.suspensible,e.onError);var l=null,d=0,u=function(){var e;return l||(e=l=n().catch((function(e){if(e=e instanceof Error?e:new Error(String(e)),s)return new Promise((function(n,t){s(e,(function(){return n((d++,l=null,u()))}),(function(){return t(e)}),d+1)}));throw e})).then((function(n){return e!==l&&l?l:(n&&(n.__esModule||"Module"===n[Symbol.toStringTag])&&(n=n.default),n)})))};return function(){return{component:u(),delay:i,timeout:o,error:a,loading:t}}}function Ot(e){return function(n,t){if(void 0===t&&(t=ue),t)return function(e,n,t){var a=e.$options;a[n]=La(a[n],t)}(t,e,n)}}var Lt=Ot("beforeMount"),Nt=Ot("mounted"),Dt=Ot("beforeUpdate"),Pt=Ot("updated"),Mt=Ot("beforeDestroy"),Rt=Ot("destroyed"),zt=Ot("activated"),qt=Ot("deactivated"),Jt=Ot("serverPrefetch"),Ft=Ot("renderTracked"),Bt=Ot("renderTriggered"),Ut=Ot("errorCaptured");function Ht(e,n){void 0===n&&(n=ue),Ut(e,n)}var $t="2.7.16";function Gt(e){return e}var Kt=new ce;function Wt(e){return function e(n,t){var a,i,o=r(n);if(!o&&!d(n)||n.__v_skip||Object.isFrozen(n)||n instanceof he)return;if(n.__ob__){var s=n.__ob__.dep.id;if(t.has(s))return;t.add(s)}if(o)for(a=n.length;a--;)e(n[a],t);else if(Ge(n))e(n.value,t);else for(i=Object.keys(n),a=i.length;a--;)e(n[i[a]],t)}(e,Kt),Kt.clear(),e}var Yt,Vt=0,Zt=function(){function e(e,n,t,a,r){var i,o;i=this,void 0===(o=fn&&!fn._vm?fn:e?e._scope:void 0)&&(o=fn),o&&o.active&&o.effects.push(i),(this.vm=e)&&r&&(e._watcher=this),a?(this.deep=!!a.deep,this.user=!!a.user,this.lazy=!!a.lazy,this.sync=!!a.sync,this.before=a.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++Vt,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new ce,this.newDepIds=new ce,this.expression="",c(n)?this.getter=n:(this.getter=function(e){if(!K.test(e)){var n=e.split(".");return function(e){for(var t=0;t<n.length;t++){if(!e)return;e=e[n[t]]}return e}}}(n),this.getter||(this.getter=D)),this.value=this.lazy?void 0:this.get()}return e.prototype.get=function(){var e;xe(this);var n=this.vm;try{e=this.getter.call(n,n)}catch(e){if(!this.user)throw e;ht(e,n,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Wt(e),ke(),this.cleanupDeps()}return e},e.prototype.addDep=function(e){var n=e.id;this.newDepIds.has(n)||(this.newDepIds.add(n),this.newDeps.push(e),this.depIds.has(n)||e.addSub(this))},e.prototype.cleanupDeps=function(){for(var e=this.deps.length;e--;){var n=this.deps[e];this.newDepIds.has(n.id)||n.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},e.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():ba(this)},e.prototype.run=function(){if(this.active){var e=this.get();if(e!==this.value||d(e)||this.deep){var n=this.value;if(this.value=e,this.user){var t='callback for watcher "'.concat(this.expression,'"');ft(this.cb,this.vm,[e,n],this.vm,t)}else this.cb.call(this.vm,e,n)}}},e.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},e.prototype.depend=function(){for(var e=this.deps.length;e--;)this.deps[e].depend()},e.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&_(this.vm._scope.effects,this),this.active){for(var e=this.deps.length;e--;)this.deps[e].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},e}();function Qt(e,n){Yt.$on(e,n)}function Xt(e,n){Yt.$off(e,n)}function ea(e,n){var t=Yt;return function a(){var r=n.apply(null,arguments);null!==r&&t.$off(e,a)}}function na(e,n,t){Yt=e,An(n,t||{},Qt,Xt,ea,e),Yt=void 0}var ta=null;function aa(e){var n=ta;return ta=e,function(){ta=n}}function ra(e){for(;e&&(e=e.$parent);)if(e._inactive)return!0;return!1}function ia(e,n){if(n){if(e._directInactive=!1,ra(e))return}else if(e._directInactive)return;if(e._inactive||null===e._inactive){e._inactive=!1;for(var t=0;t<e.$children.length;t++)ia(e.$children[t]);oa(e,"activated")}}function oa(e,n,t,a){void 0===a&&(a=!0),xe();var r=ue,i=_n();a&&me(e);var o=e.$options[n],s="".concat(n," hook");if(o)for(var l=0,c=o.length;l<c;l++)ft(o[l],e,t||null,e,s);e._hasHookEvent&&e.$emit("hook:"+n),a&&(me(r),i&&i.on()),ke()}var sa=[],la=[],ca={},da=!1,ua=!1,pa=0;var ma=0,ha=Date.now;if(Y&&!Z){var fa=window.performance;fa&&"function"==typeof fa.now&&ha()>document.createEvent("Event").timeStamp&&(ha=function(){return fa.now()})}var ga=function(e,n){if(e.post){if(!n.post)return 1}else if(n.post)return-1;return e.id-n.id};function va(){var e,n;for(ma=ha(),ua=!0,sa.sort(ga),pa=0;pa<sa.length;pa++)(e=sa[pa]).before&&e.before(),n=e.id,ca[n]=null,e.run();var t=la.slice(),a=sa.slice();pa=sa.length=la.length=0,ca={},da=ua=!1,function(e){for(var n=0;n<e.length;n++)e[n]._inactive=!0,ia(e[n],!0)}(t),function(e){var n=e.length;for(;n--;){var t=e[n],a=t.vm;a&&a._watcher===t&&a._isMounted&&!a._isDestroyed&&oa(a,"updated")}}(a),function(){for(var e=0;e<ye.length;e++){var n=ye[e];n.subs=n.subs.filter((function(e){return e})),n._pending=!1}ye.length=0}(),se&&U.devtools&&se.emit("flush")}function ba(e){var n=e.id;if(null==ca[n]&&(e!==we.target||!e.noRecurse)){if(ca[n]=!0,ua){for(var t=sa.length-1;t>pa&&sa[t].id>e.id;)t--;sa.splice(t+1,0,e)}else sa.push(e);da||(da=!0,It(va))}}function ya(e,n){if(e){for(var t=Object.create(null),a=de?Reflect.ownKeys(e):Object.keys(e),r=0;r<a.length;r++){var i=a[r];if("__ob__"!==i){var o=e[i].from;if(o in n._provided)t[i]=n._provided[o];else if("default"in e[i]){var s=e[i].default;t[i]=c(s)?s.call(n):s}else 0}}return t}}function wa(e,n,t,i,o){var l,c=this,d=o.options;k(i,"_uid")?(l=Object.create(i))._original=i:(l=i,i=i._original);var u=s(d._compiled),p=!u;this.data=e,this.props=n,this.children=t,this.parent=i,this.listeners=e.on||a,this.injections=ya(d.inject,i),this.slots=function(){return c.$slots||Zn(i,e.scopedSlots,c.$slots=Wn(t,i)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return Zn(i,e.scopedSlots,this.slots())}}),u&&(this.$options=d,this.$slots=this.slots(),this.$scopedSlots=Zn(i,e.scopedSlots,this.$slots)),d._scopeId?this._c=function(e,n,t,a){var o=pt(l,e,n,t,a,p);return o&&!r(o)&&(o.fnScopeId=d._scopeId,o.fnContext=i),o}:this._c=function(e,n,t,a){return pt(l,e,n,t,a,p)}}function _a(e,n,t,a,r){var i=ve(e);return i.fnContext=t,i.fnOptions=a,n.slot&&((i.data||(i.data={})).slot=n.slot),i}function xa(e,n){for(var t in n)e[S(t)]=n[t]}function ka(e){return e.name||e.__name||e._componentTag}Kn(wa.prototype);var Ta={init:function(e,n){if(e.componentInstance&&!e.componentInstance._isDestroyed&&e.data.keepAlive){var t=e;Ta.prepatch(t,t)}else{(e.componentInstance=function(e,n){var t={_isComponent:!0,_parentVnode:e,parent:n},a=e.data.inlineTemplate;o(a)&&(t.render=a.render,t.staticRenderFns=a.staticRenderFns);return new e.componentOptions.Ctor(t)}(e,ta)).$mount(n?e.elm:void 0,n)}},prepatch:function(e,n){var t=n.componentOptions;!function(e,n,t,r,i){var o=r.data.scopedSlots,s=e.$scopedSlots,l=!!(o&&!o.$stable||s!==a&&!s.$stable||o&&e.$scopedSlots.$key!==o.$key||!o&&e.$scopedSlots.$key),c=!!(i||e.$options._renderChildren||l),d=e.$vnode;e.$options._parentVnode=r,e.$vnode=r,e._vnode&&(e._vnode.parent=r),e.$options._renderChildren=i;var u=r.data.attrs||a;e._attrsProxy&&nt(e._attrsProxy,u,d.data&&d.data.attrs||a,e,"$attrs")&&(c=!0),e.$attrs=u,t=t||a;var p=e.$options._parentListeners;if(e._listenersProxy&&nt(e._listenersProxy,t,p||a,e,"$listeners"),e.$listeners=e.$options._parentListeners=t,na(e,t,p),n&&e.$options.props){Ce(!1);for(var m=e._props,h=e.$options._propKeys||[],f=0;f<h.length;f++){var g=h[f],v=e.$options.props;m[g]=Ra(g,v,n,e)}Ce(!0),e.$options.propsData=n}c&&(e.$slots=Wn(i,r.context),e.$forceUpdate())}(n.componentInstance=e.componentInstance,t.propsData,t.listeners,n,t.children)},insert:function(e){var n,t=e.context,a=e.componentInstance;a._isMounted||(a._isMounted=!0,oa(a,"mounted")),e.data.keepAlive&&(t._isMounted?((n=a)._inactive=!1,la.push(n)):ia(a,!0))},destroy:function(e){var n=e.componentInstance;n._isDestroyed||(e.data.keepAlive?function e(n,t){if(!(t&&(n._directInactive=!0,ra(n))||n._inactive)){n._inactive=!0;for(var a=0;a<n.$children.length;a++)e(n.$children[a]);oa(n,"deactivated")}}(n,!0):n.$destroy())}},Ea=Object.keys(Ta);function Sa(e,n,t,l,c){if(!i(e)){var u=t.$options._base;if(d(e)&&(e=u.extend(e)),"function"==typeof e){var p;if(i(e.cid)&&void 0===(e=function(e,n){if(s(e.error)&&o(e.errorComp))return e.errorComp;if(o(e.resolved))return e.resolved;var t=ct;if(t&&o(e.owners)&&-1===e.owners.indexOf(t)&&e.owners.push(t),s(e.loading)&&o(e.loadingComp))return e.loadingComp;if(t&&!o(e.owners)){var a=e.owners=[t],r=!0,l=null,c=null;t.$on("hook:destroyed",(function(){return _(a,t)}));var u=function(e){for(var n=0,t=a.length;n<t;n++)a[n].$forceUpdate();e&&(a.length=0,null!==l&&(clearTimeout(l),l=null),null!==c&&(clearTimeout(c),c=null))},p=q((function(t){e.resolved=dt(t,n),r?a.length=0:u(!0)})),m=q((function(n){o(e.errorComp)&&(e.error=!0,u(!0))})),h=e(p,m);return d(h)&&(f(h)?i(e.resolved)&&h.then(p,m):f(h.component)&&(h.component.then(p,m),o(h.error)&&(e.errorComp=dt(h.error,n)),o(h.loading)&&(e.loadingComp=dt(h.loading,n),0===h.delay?e.loading=!0:l=setTimeout((function(){l=null,i(e.resolved)&&i(e.error)&&(e.loading=!0,u(!1))}),h.delay||200)),o(h.timeout)&&(c=setTimeout((function(){c=null,i(e.resolved)&&m(null)}),h.timeout)))),r=!1,e.loading?e.loadingComp:e.resolved}}(p=e,u)))return function(e,n,t,a,r){var i=fe();return i.asyncFactory=e,i.asyncMeta={data:n,context:t,children:a,tag:r},i}(p,n,t,l,c);n=n||{},Za(e),o(n.model)&&function(e,n){var t=e.model&&e.model.prop||"value",a=e.model&&e.model.event||"input";(n.attrs||(n.attrs={}))[t]=n.model.value;var i=n.on||(n.on={}),s=i[a],l=n.model.callback;o(s)?(r(s)?-1===s.indexOf(l):s!==l)&&(i[a]=[l].concat(s)):i[a]=l}(e.options,n);var m=function(e,n,t){var a=n.options.props;if(!i(a)){var r={},s=e.attrs,l=e.props;if(o(s)||o(l))for(var c in a){var d=C(c);jn(r,l,c,d,!0)||jn(r,s,c,d,!1)}return r}}(n,e);if(s(e.options.functional))return function(e,n,t,i,s){var l=e.options,c={},d=l.props;if(o(d))for(var u in d)c[u]=Ra(u,d,n||a);else o(t.attrs)&&xa(c,t.attrs),o(t.props)&&xa(c,t.props);var p=new wa(t,c,s,i,e),m=l.render.call(null,p._c,p);if(m instanceof he)return _a(m,t,p.parent,l,p);if(r(m)){for(var h=On(m)||[],f=new Array(h.length),g=0;g<h.length;g++)f[g]=_a(h[g],t,p.parent,l,p);return f}}(e,m,n,t,l);var h=n.on;if(n.on=n.nativeOn,s(e.options.abstract)){var g=n.slot;n={},g&&(n.slot=g)}!function(e){for(var n=e.hook||(e.hook={}),t=0;t<Ea.length;t++){var a=Ea[t],r=n[a],i=Ta[a];r===i||r&&r._merged||(n[a]=r?Ia(i,r):i)}}(n);var v=ka(e.options)||c;return new he("vue-component-".concat(e.cid).concat(v?"-".concat(v):""),n,void 0,void 0,void 0,t,{Ctor:e,propsData:m,listeners:h,tag:c,children:l},p)}}}function Ia(e,n){var t=function(t,a){e(t,a),n(t,a)};return t._merged=!0,t}var Aa=D,Ca=U.optionMergeStrategies;function ja(e,n,t){if(void 0===t&&(t=!0),!n)return e;for(var a,r,i,o=de?Reflect.ownKeys(n):Object.keys(n),s=0;s<o.length;s++)"__ob__"!==(a=o[s])&&(r=e[a],i=n[a],t&&k(e,a)?r!==i&&p(r)&&p(i)&&ja(r,i):De(e,a,i));return e}function Oa(e,n,t){return t?function(){var a=c(n)?n.call(t,t):n,r=c(e)?e.call(t,t):e;return a?ja(a,r):r}:n?e?function(){return ja(c(n)?n.call(this,this):n,c(e)?e.call(this,this):e)}:n:e}function La(e,n){var t=n?e?e.concat(n):r(n)?n:[n]:e;return t?function(e){for(var n=[],t=0;t<e.length;t++)-1===n.indexOf(e[t])&&n.push(e[t]);return n}(t):t}function Na(e,n,t,a){var r=Object.create(e||null);return n?L(r,n):r}Ca.data=function(e,n,t){return t?Oa(e,n,t):n&&"function"!=typeof n?e:Oa(e,n)},B.forEach((function(e){Ca[e]=La})),F.forEach((function(e){Ca[e+"s"]=Na})),Ca.watch=function(e,n,t,a){if(e===ae&&(e=void 0),n===ae&&(n=void 0),!n)return Object.create(e||null);if(!e)return n;var i={};for(var o in L(i,e),n){var s=i[o],l=n[o];s&&!r(s)&&(s=[s]),i[o]=s?s.concat(l):r(l)?l:[l]}return i},Ca.props=Ca.methods=Ca.inject=Ca.computed=function(e,n,t,a){if(!e)return n;var r=Object.create(null);return L(r,e),n&&L(r,n),r},Ca.provide=function(e,n){return e?function(){var t=Object.create(null);return ja(t,c(e)?e.call(this):e),n&&ja(t,c(n)?n.call(this):n,!1),t}:n};var Da=function(e,n){return void 0===n?e:n};function Pa(e,n,t){if(c(n)&&(n=n.options),function(e,n){var t=e.props;if(t){var a,i,o={};if(r(t))for(a=t.length;a--;)"string"==typeof(i=t[a])&&(o[S(i)]={type:null});else if(p(t))for(var s in t)i=t[s],o[S(s)]=p(i)?i:{type:i};else 0;e.props=o}}(n),function(e,n){var t=e.inject;if(t){var a=e.inject={};if(r(t))for(var i=0;i<t.length;i++)a[t[i]]={from:t[i]};else if(p(t))for(var o in t){var s=t[o];a[o]=p(s)?L({from:o},s):{from:s}}else 0}}(n),function(e){var n=e.directives;if(n)for(var t in n){var a=n[t];c(a)&&(n[t]={bind:a,update:a})}}(n),!n._base&&(n.extends&&(e=Pa(e,n.extends,t)),n.mixins))for(var a=0,i=n.mixins.length;a<i;a++)e=Pa(e,n.mixins[a],t);var o,s={};for(o in e)l(o);for(o in n)k(e,o)||l(o);function l(a){var r=Ca[a]||Da;s[a]=r(e[a],n[a],t,a)}return s}function Ma(e,n,t,a){if("string"==typeof t){var r=e[n];if(k(r,t))return r[t];var i=S(t);if(k(r,i))return r[i];var o=I(i);return k(r,o)?r[o]:r[t]||r[i]||r[o]}}function Ra(e,n,t,a){var r=n[e],i=!k(t,e),o=t[e],s=Fa(Boolean,r.type);if(s>-1)if(i&&!k(r,"default"))o=!1;else if(""===o||o===C(e)){var l=Fa(String,r.type);(l<0||s<l)&&(o=!0)}if(void 0===o){o=function(e,n,t){if(!k(n,"default"))return;var a=n.default;0;if(e&&e.$options.propsData&&void 0===e.$options.propsData[t]&&void 0!==e._props[t])return e._props[t];return c(a)&&"Function"!==qa(n.type)?a.call(e):a}(a,r,e);var d=Ae;Ce(!0),Le(o),Ce(d)}return o}var za=/^\s*function (\w+)/;function qa(e){var n=e&&e.toString().match(za);return n?n[1]:""}function Ja(e,n){return qa(e)===qa(n)}function Fa(e,n){if(!r(n))return Ja(n,e)?0:-1;for(var t=0,a=n.length;t<a;t++)if(Ja(n[t],e))return t;return-1}var Ba={enumerable:!0,configurable:!0,get:D,set:D};function Ua(e,n,t){Ba.get=function(){return this[n][t]},Ba.set=function(e){this[n][t]=e},Object.defineProperty(e,t,Ba)}function Ha(e){var n=e.$options;if(n.props&&function(e,n){var t=e.$options.propsData||{},a=e._props=ze({}),r=e.$options._propKeys=[];e.$parent&&Ce(!1);var i=function(i){r.push(i);var o=Ra(i,n,t,e);Ne(a,i,o,void 0,!0),i in e||Ua(e,"_props",i)};for(var o in n)i(o);Ce(!0)}(e,n.props),function(e){var n=e.$options,t=n.setup;if(t){var a=e._setupContext=et(e);me(e),xe();var r=ft(t,null,[e._props||ze({}),a],e,"setup");if(ke(),me(),c(r))n.render=r;else if(d(r))if(e._setupState=r,r.__sfc){var i=e._setupProxy={};for(var o in r)"__sfc"!==o&&Xe(i,r,o)}else for(var o in r)$(o)||Xe(e,r,o);else 0}}(e),n.methods&&function(e,n){e.$options.props;for(var t in n)e[t]="function"!=typeof n[t]?D:j(n[t],e)}(e,n.methods),n.data)!function(e){var n=e.$options.data;p(n=e._data=c(n)?function(e,n){xe();try{return e.call(n,n)}catch(e){return ht(e,n,"data()"),{}}finally{ke()}}(n,e):n||{})||(n={});var t=Object.keys(n),a=e.$options.props,r=(e.$options.methods,t.length);for(;r--;){var i=t[r];0,a&&k(a,i)||$(i)||Ua(e,"_data",i)}var o=Le(n);o&&o.vmCount++}(e);else{var t=Le(e._data={});t&&t.vmCount++}n.computed&&function(e,n){var t=e._computedWatchers=Object.create(null),a=oe();for(var r in n){var i=n[r],o=c(i)?i:i.get;0,a||(t[r]=new Zt(e,o||D,D,$a)),r in e||Ga(e,r,i)}}(e,n.computed),n.watch&&n.watch!==ae&&function(e,n){for(var t in n){var a=n[t];if(r(a))for(var i=0;i<a.length;i++)Ya(e,t,a[i]);else Ya(e,t,a)}}(e,n.watch)}var $a={lazy:!0};function Ga(e,n,t){var a=!oe();c(t)?(Ba.get=a?Ka(n):Wa(t),Ba.set=D):(Ba.get=t.get?a&&!1!==t.cache?Ka(n):Wa(t.get):D,Ba.set=t.set||D),Object.defineProperty(e,n,Ba)}function Ka(e){return function(){var n=this._computedWatchers&&this._computedWatchers[e];if(n)return n.dirty&&n.evaluate(),we.target&&n.depend(),n.value}}function Wa(e){return function(){return e.call(this,this)}}function Ya(e,n,t,a){return p(t)&&(a=t,t=t.handler),"string"==typeof t&&(t=e[t]),e.$watch(n,t,a)}var Va=0;function Za(e){var n=e.options;if(e.super){var t=Za(e.super);if(t!==e.superOptions){e.superOptions=t;var a=function(e){var n,t=e.options,a=e.sealedOptions;for(var r in t)t[r]!==a[r]&&(n||(n={}),n[r]=t[r]);return n}(e);a&&L(e.extendOptions,a),(n=e.options=Pa(t,e.extendOptions)).name&&(n.components[n.name]=e)}}return n}function Qa(e){this._init(e)}function Xa(e){e.cid=0;var n=1;e.extend=function(e){e=e||{};var t=this,a=t.cid,r=e._Ctor||(e._Ctor={});if(r[a])return r[a];var i=ka(e)||ka(t.options);var o=function(e){this._init(e)};return(o.prototype=Object.create(t.prototype)).constructor=o,o.cid=n++,o.options=Pa(t.options,e),o.super=t,o.options.props&&function(e){var n=e.options.props;for(var t in n)Ua(e.prototype,"_props",t)}(o),o.options.computed&&function(e){var n=e.options.computed;for(var t in n)Ga(e.prototype,t,n[t])}(o),o.extend=t.extend,o.mixin=t.mixin,o.use=t.use,F.forEach((function(e){o[e]=t[e]})),i&&(o.options.components[i]=o),o.superOptions=t.options,o.extendOptions=e,o.sealedOptions=L({},o.options),r[a]=o,o}}function er(e){return e&&(ka(e.Ctor.options)||e.tag)}function nr(e,n){return r(e)?e.indexOf(n)>-1:"string"==typeof e?e.split(",").indexOf(n)>-1:!!m(e)&&e.test(n)}function tr(e,n){var t=e.cache,a=e.keys,r=e._vnode,i=e.$vnode;for(var o in t){var s=t[o];if(s){var l=s.name;l&&!n(l)&&ar(t,o,a,r)}}i.componentOptions.children=void 0}function ar(e,n,t,a){var r=e[n];!r||a&&r.tag===a.tag||r.componentInstance.$destroy(),e[n]=null,_(t,n)}!function(e){e.prototype._init=function(e){var n=this;n._uid=Va++,n._isVue=!0,n.__v_skip=!0,n._scope=new yn(!0),n._scope.parent=void 0,n._scope._vm=!0,e&&e._isComponent?function(e,n){var t=e.$options=Object.create(e.constructor.options),a=n._parentVnode;t.parent=n.parent,t._parentVnode=a;var r=a.componentOptions;t.propsData=r.propsData,t._parentListeners=r.listeners,t._renderChildren=r.children,t._componentTag=r.tag,n.render&&(t.render=n.render,t.staticRenderFns=n.staticRenderFns)}(n,e):n.$options=Pa(Za(n.constructor),e||{},n),n._renderProxy=n,n._self=n,function(e){var n=e.$options,t=n.parent;if(t&&!n.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(e)}e.$parent=t,e.$root=t?t.$root:e,e.$children=[],e.$refs={},e._provided=t?t._provided:Object.create(null),e._watcher=null,e._inactive=null,e._directInactive=!1,e._isMounted=!1,e._isDestroyed=!1,e._isBeingDestroyed=!1}(n),function(e){e._events=Object.create(null),e._hasHookEvent=!1;var n=e.$options._parentListeners;n&&na(e,n)}(n),function(e){e._vnode=null,e._staticTrees=null;var n=e.$options,t=e.$vnode=n._parentVnode,r=t&&t.context;e.$slots=Wn(n._renderChildren,r),e.$scopedSlots=t?Zn(e.$parent,t.data.scopedSlots,e.$slots):a,e._c=function(n,t,a,r){return pt(e,n,t,a,r,!1)},e.$createElement=function(n,t,a,r){return pt(e,n,t,a,r,!0)};var i=t&&t.data;Ne(e,"$attrs",i&&i.attrs||a,null,!0),Ne(e,"$listeners",n._parentListeners||a,null,!0)}(n),oa(n,"beforeCreate",void 0,!1),function(e){var n=ya(e.$options.inject,e);n&&(Ce(!1),Object.keys(n).forEach((function(t){Ne(e,t,n[t])})),Ce(!0))}(n),Ha(n),function(e){var n=e.$options.provide;if(n){var t=c(n)?n.call(e):n;if(!d(t))return;for(var a=Tn(e),r=de?Reflect.ownKeys(t):Object.keys(t),i=0;i<r.length;i++){var o=r[i];Object.defineProperty(a,o,Object.getOwnPropertyDescriptor(t,o))}}}(n),oa(n,"created"),n.$options.el&&n.$mount(n.$options.el)}}(Qa),function(e){var n={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(e.prototype,"$data",n),Object.defineProperty(e.prototype,"$props",t),e.prototype.$set=De,e.prototype.$delete=Pe,e.prototype.$watch=function(e,n,t){if(p(n))return Ya(this,e,n,t);(t=t||{}).user=!0;var a=new Zt(this,e,n,t);if(t.immediate){var r='callback for immediate watcher "'.concat(a.expression,'"');xe(),ft(n,this,[a.value],this,r),ke()}return function(){a.teardown()}}}(Qa),function(e){var n=/^hook:/;e.prototype.$on=function(e,t){var a=this;if(r(e))for(var i=0,o=e.length;i<o;i++)a.$on(e[i],t);else(a._events[e]||(a._events[e]=[])).push(t),n.test(e)&&(a._hasHookEvent=!0);return a},e.prototype.$once=function(e,n){var t=this;function a(){t.$off(e,a),n.apply(t,arguments)}return a.fn=n,t.$on(e,a),t},e.prototype.$off=function(e,n){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(r(e)){for(var a=0,i=e.length;a<i;a++)t.$off(e[a],n);return t}var o,s=t._events[e];if(!s)return t;if(!n)return t._events[e]=null,t;for(var l=s.length;l--;)if((o=s[l])===n||o.fn===n){s.splice(l,1);break}return t},e.prototype.$emit=function(e){var n=this,t=n._events[e];if(t){t=t.length>1?O(t):t;for(var a=O(arguments,1),r='event handler for "'.concat(e,'"'),i=0,o=t.length;i<o;i++)ft(t[i],n,a,n,r)}return n}}(Qa),function(e){e.prototype._update=function(e,n){var t=this,a=t.$el,r=t._vnode,i=aa(t);t._vnode=e,t.$el=r?t.__patch__(r,e):t.__patch__(t.$el,e,n,!1),i(),a&&(a.__vue__=null),t.$el&&(t.$el.__vue__=t);for(var o=t;o&&o.$vnode&&o.$parent&&o.$vnode===o.$parent._vnode;)o.$parent.$el=o.$el,o=o.$parent},e.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},e.prototype.$destroy=function(){var e=this;if(!e._isBeingDestroyed){oa(e,"beforeDestroy"),e._isBeingDestroyed=!0;var n=e.$parent;!n||n._isBeingDestroyed||e.$options.abstract||_(n.$children,e),e._scope.stop(),e._data.__ob__&&e._data.__ob__.vmCount--,e._isDestroyed=!0,e.__patch__(e._vnode,null),oa(e,"destroyed"),e.$off(),e.$el&&(e.$el.__vue__=null),e.$vnode&&(e.$vnode.parent=null)}}}(Qa),function(e){Kn(e.prototype),e.prototype.$nextTick=function(e){return It(e,this)},e.prototype._render=function(){var e=this,n=e.$options,t=n.render,a=n._parentVnode;a&&e._isMounted&&(e.$scopedSlots=Zn(e.$parent,a.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&at(e._slotsProxy,e.$scopedSlots)),e.$vnode=a;var i,o=ue,s=ct;try{me(e),ct=e,i=t.call(e._renderProxy,e.$createElement)}catch(n){ht(n,e,"render"),i=e._vnode}finally{ct=s,me(o)}return r(i)&&1===i.length&&(i=i[0]),i instanceof he||(i=fe()),i.parent=a,i}}(Qa);var rr=[String,RegExp,Array],ir={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:rr,exclude:rr,max:[String,Number]},methods:{cacheVNode:function(){var e=this.cache,n=this.keys,t=this.vnodeToCache,a=this.keyToCache;if(t){var r=t.tag,i=t.componentInstance,o=t.componentOptions;e[a]={name:er(o),tag:r,componentInstance:i},n.push(a),this.max&&n.length>parseInt(this.max)&&ar(e,n[0],n,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var e in this.cache)ar(this.cache,e,this.keys)},mounted:function(){var e=this;this.cacheVNode(),this.$watch("include",(function(n){tr(e,(function(e){return nr(n,e)}))})),this.$watch("exclude",(function(n){tr(e,(function(e){return!nr(n,e)}))}))},updated:function(){this.cacheVNode()},render:function(){var e=this.$slots.default,n=ut(e),t=n&&n.componentOptions;if(t){var a=er(t),r=this.include,i=this.exclude;if(r&&(!a||!nr(r,a))||i&&a&&nr(i,a))return n;var o=this.cache,s=this.keys,l=null==n.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):n.key;o[l]?(n.componentInstance=o[l].componentInstance,_(s,l),s.push(l)):(this.vnodeToCache=n,this.keyToCache=l),n.data.keepAlive=!0}return n||e&&e[0]}}};!function(e){var n={get:function(){return U}};Object.defineProperty(e,"config",n),e.util={warn:Aa,extend:L,mergeOptions:Pa,defineReactive:Ne},e.set=De,e.delete=Pe,e.nextTick=It,e.observable=function(e){return Le(e),e},e.options=Object.create(null),F.forEach((function(n){e.options[n+"s"]=Object.create(null)})),e.options._base=e,L(e.options.components,ir),function(e){e.use=function(e){var n=this._installedPlugins||(this._installedPlugins=[]);if(n.indexOf(e)>-1)return this;var t=O(arguments,1);return t.unshift(this),c(e.install)?e.install.apply(e,t):c(e)&&e.apply(null,t),n.push(e),this}}(e),function(e){e.mixin=function(e){return this.options=Pa(this.options,e),this}}(e),Xa(e),function(e){F.forEach((function(n){e[n]=function(e,t){return t?("component"===n&&p(t)&&(t.name=t.name||e,t=this.options._base.extend(t)),"directive"===n&&c(t)&&(t={bind:t,update:t}),this.options[n+"s"][e]=t,t):this.options[n+"s"][e]}}))}(e)}(Qa),Object.defineProperty(Qa.prototype,"$isServer",{get:oe}),Object.defineProperty(Qa.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Qa,"FunctionalRenderContext",{value:wa}),Qa.version=$t;var or=y("style,class"),sr=y("input,textarea,option,select,progress"),lr=y("contenteditable,draggable,spellcheck"),cr=y("events,caret,typing,plaintext-only"),dr=y("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ur="http://www.w3.org/1999/xlink",pr=function(e){return":"===e.charAt(5)&&"xlink"===e.slice(0,5)},mr=function(e){return pr(e)?e.slice(6,e.length):""},hr=function(e){return null==e||!1===e};function fr(e){for(var n=e.data,t=e,a=e;o(a.componentInstance);)(a=a.componentInstance._vnode)&&a.data&&(n=gr(a.data,n));for(;o(t=t.parent);)t&&t.data&&(n=gr(n,t.data));return function(e,n){if(o(e)||o(n))return vr(e,br(n));return""}(n.staticClass,n.class)}function gr(e,n){return{staticClass:vr(e.staticClass,n.staticClass),class:o(e.class)?[e.class,n.class]:n.class}}function vr(e,n){return e?n?e+" "+n:e:n||""}function br(e){return Array.isArray(e)?function(e){for(var n,t="",a=0,r=e.length;a<r;a++)o(n=br(e[a]))&&""!==n&&(t&&(t+=" "),t+=n);return t}(e):d(e)?function(e){var n="";for(var t in e)e[t]&&(n&&(n+=" "),n+=t);return n}(e):"string"==typeof e?e:""}var yr={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},wr=y("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),_r=y("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),xr=function(e){return wr(e)||_r(e)};var kr=Object.create(null);var Tr=y("text,number,password,search,email,tel,url");var Er=Object.freeze({__proto__:null,createElement:function(e,n){var t=document.createElement(e);return"select"!==e||n.data&&n.data.attrs&&void 0!==n.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(e,n){return document.createElementNS(yr[e],n)},createTextNode:function(e){return document.createTextNode(e)},createComment:function(e){return document.createComment(e)},insertBefore:function(e,n,t){e.insertBefore(n,t)},removeChild:function(e,n){e.removeChild(n)},appendChild:function(e,n){e.appendChild(n)},parentNode:function(e){return e.parentNode},nextSibling:function(e){return e.nextSibling},tagName:function(e){return e.tagName},setTextContent:function(e,n){e.textContent=n},setStyleScope:function(e,n){e.setAttribute(n,"")}}),Sr={create:function(e,n){Ir(n)},update:function(e,n){e.data.ref!==n.data.ref&&(Ir(e,!0),Ir(n))},destroy:function(e){Ir(e,!0)}};function Ir(e,n){var t=e.data.ref;if(o(t)){var a=e.context,i=e.componentInstance||e.elm,s=n?null:i,l=n?void 0:i;if(c(t))ft(t,a,[s],a,"template ref function");else{var d=e.data.refInFor,u="string"==typeof t||"number"==typeof t,p=Ge(t),m=a.$refs;if(u||p)if(d){var h=u?m[t]:t.value;n?r(h)&&_(h,i):r(h)?h.includes(i)||h.push(i):u?(m[t]=[i],Ar(a,t,m[t])):t.value=[i]}else if(u){if(n&&m[t]!==i)return;m[t]=l,Ar(a,t,s)}else if(p){if(n&&t.value!==i)return;t.value=s}else 0}}}function Ar(e,n,t){var a=e._setupState;a&&k(a,n)&&(Ge(a[n])?a[n].value=t:a[n]=t)}var Cr=new he("",{},[]),jr=["create","activate","update","remove","destroy"];function Or(e,n){return e.key===n.key&&e.asyncFactory===n.asyncFactory&&(e.tag===n.tag&&e.isComment===n.isComment&&o(e.data)===o(n.data)&&function(e,n){if("input"!==e.tag)return!0;var t,a=o(t=e.data)&&o(t=t.attrs)&&t.type,r=o(t=n.data)&&o(t=t.attrs)&&t.type;return a===r||Tr(a)&&Tr(r)}(e,n)||s(e.isAsyncPlaceholder)&&i(n.asyncFactory.error))}function Lr(e,n,t){var a,r,i={};for(a=n;a<=t;++a)o(r=e[a].key)&&(i[r]=a);return i}var Nr={create:Dr,update:Dr,destroy:function(e){Dr(e,Cr)}};function Dr(e,n){(e.data.directives||n.data.directives)&&function(e,n){var t,a,r,i=e===Cr,o=n===Cr,s=Mr(e.data.directives,e.context),l=Mr(n.data.directives,n.context),c=[],d=[];for(t in l)a=s[t],r=l[t],a?(r.oldValue=a.value,r.oldArg=a.arg,zr(r,"update",n,e),r.def&&r.def.componentUpdated&&d.push(r)):(zr(r,"bind",n,e),r.def&&r.def.inserted&&c.push(r));if(c.length){var u=function(){for(var t=0;t<c.length;t++)zr(c[t],"inserted",n,e)};i?Cn(n,"insert",u):u()}d.length&&Cn(n,"postpatch",(function(){for(var t=0;t<d.length;t++)zr(d[t],"componentUpdated",n,e)}));if(!i)for(t in s)l[t]||zr(s[t],"unbind",e,e,o)}(e,n)}var Pr=Object.create(null);function Mr(e,n){var t,a,r=Object.create(null);if(!e)return r;for(t=0;t<e.length;t++){if((a=e[t]).modifiers||(a.modifiers=Pr),r[Rr(a)]=a,n._setupState&&n._setupState.__sfc){var i=a.def||Ma(n,"_setupState","v-"+a.name);a.def="function"==typeof i?{bind:i,update:i}:i}a.def=a.def||Ma(n.$options,"directives",a.name)}return r}function Rr(e){return e.rawName||"".concat(e.name,".").concat(Object.keys(e.modifiers||{}).join("."))}function zr(e,n,t,a,r){var i=e.def&&e.def[n];if(i)try{i(t.elm,e,t,a,r)}catch(a){ht(a,t.context,"directive ".concat(e.name," ").concat(n," hook"))}}var qr=[Sr,Nr];function Jr(e,n){var t=n.componentOptions;if(!(o(t)&&!1===t.Ctor.options.inheritAttrs||i(e.data.attrs)&&i(n.data.attrs))){var a,r,l=n.elm,c=e.data.attrs||{},d=n.data.attrs||{};for(a in(o(d.__ob__)||s(d._v_attr_proxy))&&(d=n.data.attrs=L({},d)),d)r=d[a],c[a]!==r&&Fr(l,a,r,n.data.pre);for(a in(Z||X)&&d.value!==c.value&&Fr(l,"value",d.value),c)i(d[a])&&(pr(a)?l.removeAttributeNS(ur,mr(a)):lr(a)||l.removeAttribute(a))}}function Fr(e,n,t,a){a||e.tagName.indexOf("-")>-1?Br(e,n,t):dr(n)?hr(t)?e.removeAttribute(n):(t="allowfullscreen"===n&&"EMBED"===e.tagName?"true":n,e.setAttribute(n,t)):lr(n)?e.setAttribute(n,function(e,n){return hr(n)||"false"===n?"false":"contenteditable"===e&&cr(n)?n:"true"}(n,t)):pr(n)?hr(t)?e.removeAttributeNS(ur,mr(n)):e.setAttributeNS(ur,n,t):Br(e,n,t)}function Br(e,n,t){if(hr(t))e.removeAttribute(n);else{if(Z&&!Q&&"TEXTAREA"===e.tagName&&"placeholder"===n&&""!==t&&!e.__ieph){var a=function(n){n.stopImmediatePropagation(),e.removeEventListener("input",a)};e.addEventListener("input",a),e.__ieph=!0}e.setAttribute(n,t)}}var Ur={create:Jr,update:Jr};function Hr(e,n){var t=n.elm,a=n.data,r=e.data;if(!(i(a.staticClass)&&i(a.class)&&(i(r)||i(r.staticClass)&&i(r.class)))){var s=fr(n),l=t._transitionClasses;o(l)&&(s=vr(s,br(l))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var $r,Gr={create:Hr,update:Hr};function Kr(e,n,t){var a=$r;return function r(){var i=n.apply(null,arguments);null!==i&&Vr(e,r,t,a)}}var Wr=yt&&!(te&&Number(te[1])<=53);function Yr(e,n,t,a){if(Wr){var r=ma,i=n;n=i._wrapper=function(e){if(e.target===e.currentTarget||e.timeStamp>=r||e.timeStamp<=0||e.target.ownerDocument!==document)return i.apply(this,arguments)}}$r.addEventListener(e,n,re?{capture:t,passive:a}:t)}function Vr(e,n,t,a){(a||$r).removeEventListener(e,n._wrapper||n,t)}function Zr(e,n){if(!i(e.data.on)||!i(n.data.on)){var t=n.data.on||{},a=e.data.on||{};$r=n.elm||e.elm,function(e){if(o(e.__r)){var n=Z?"change":"input";e[n]=[].concat(e.__r,e[n]||[]),delete e.__r}o(e.__c)&&(e.change=[].concat(e.__c,e.change||[]),delete e.__c)}(t),An(t,a,Yr,Vr,Kr,n.context),$r=void 0}}var Qr,Xr={create:Zr,update:Zr,destroy:function(e){return Zr(e,Cr)}};function ei(e,n){if(!i(e.data.domProps)||!i(n.data.domProps)){var t,a,r=n.elm,l=e.data.domProps||{},c=n.data.domProps||{};for(t in(o(c.__ob__)||s(c._v_attr_proxy))&&(c=n.data.domProps=L({},c)),l)t in c||(r[t]="");for(t in c){if(a=c[t],"textContent"===t||"innerHTML"===t){if(n.children&&(n.children.length=0),a===l[t])continue;1===r.childNodes.length&&r.removeChild(r.childNodes[0])}if("value"===t&&"PROGRESS"!==r.tagName){r._value=a;var d=i(a)?"":String(a);ni(r,d)&&(r.value=d)}else if("innerHTML"===t&&_r(r.tagName)&&i(r.innerHTML)){(Qr=Qr||document.createElement("div")).innerHTML="<svg>".concat(a,"</svg>");for(var u=Qr.firstChild;r.firstChild;)r.removeChild(r.firstChild);for(;u.firstChild;)r.appendChild(u.firstChild)}else if(a!==l[t])try{r[t]=a}catch(e){}}}}function ni(e,n){return!e.composing&&("OPTION"===e.tagName||function(e,n){var t=!0;try{t=document.activeElement!==e}catch(e){}return t&&e.value!==n}(e,n)||function(e,n){var t=e.value,a=e._vModifiers;if(o(a)){if(a.number)return b(t)!==b(n);if(a.trim)return t.trim()!==n.trim()}return t!==n}(e,n))}var ti={create:ei,update:ei},ai=T((function(e){var n={},t=/:(.+)/;return e.split(/;(?![^(]*\))/g).forEach((function(e){if(e){var a=e.split(t);a.length>1&&(n[a[0].trim()]=a[1].trim())}})),n}));function ri(e){var n=ii(e.style);return e.staticStyle?L(e.staticStyle,n):n}function ii(e){return Array.isArray(e)?N(e):"string"==typeof e?ai(e):e}var oi,si=/^--/,li=/\s*!important$/,ci=function(e,n,t){if(si.test(n))e.style.setProperty(n,t);else if(li.test(t))e.style.setProperty(C(n),t.replace(li,""),"important");else{var a=ui(n);if(Array.isArray(t))for(var r=0,i=t.length;r<i;r++)e.style[a]=t[r];else e.style[a]=t}},di=["Webkit","Moz","ms"],ui=T((function(e){if(oi=oi||document.createElement("div").style,"filter"!==(e=S(e))&&e in oi)return e;for(var n=e.charAt(0).toUpperCase()+e.slice(1),t=0;t<di.length;t++){var a=di[t]+n;if(a in oi)return a}}));function pi(e,n){var t=n.data,a=e.data;if(!(i(t.staticStyle)&&i(t.style)&&i(a.staticStyle)&&i(a.style))){var r,s,l=n.elm,c=a.staticStyle,d=a.normalizedStyle||a.style||{},u=c||d,p=ii(n.data.style)||{};n.data.normalizedStyle=o(p.__ob__)?L({},p):p;var m=function(e,n){var t,a={};if(n)for(var r=e;r.componentInstance;)(r=r.componentInstance._vnode)&&r.data&&(t=ri(r.data))&&L(a,t);(t=ri(e.data))&&L(a,t);for(var i=e;i=i.parent;)i.data&&(t=ri(i.data))&&L(a,t);return a}(n,!0);for(s in u)i(m[s])&&ci(l,s,"");for(s in m)r=m[s],ci(l,s,null==r?"":r)}}var mi={create:pi,update:pi},hi=/\s+/;function fi(e,n){if(n&&(n=n.trim()))if(e.classList)n.indexOf(" ")>-1?n.split(hi).forEach((function(n){return e.classList.add(n)})):e.classList.add(n);else{var t=" ".concat(e.getAttribute("class")||""," ");t.indexOf(" "+n+" ")<0&&e.setAttribute("class",(t+n).trim())}}function gi(e,n){if(n&&(n=n.trim()))if(e.classList)n.indexOf(" ")>-1?n.split(hi).forEach((function(n){return e.classList.remove(n)})):e.classList.remove(n),e.classList.length||e.removeAttribute("class");else{for(var t=" ".concat(e.getAttribute("class")||""," "),a=" "+n+" ";t.indexOf(a)>=0;)t=t.replace(a," ");(t=t.trim())?e.setAttribute("class",t):e.removeAttribute("class")}}function vi(e){if(e){if("object"==typeof e){var n={};return!1!==e.css&&L(n,bi(e.name||"v")),L(n,e),n}return"string"==typeof e?bi(e):void 0}}var bi=T((function(e){return{enterClass:"".concat(e,"-enter"),enterToClass:"".concat(e,"-enter-to"),enterActiveClass:"".concat(e,"-enter-active"),leaveClass:"".concat(e,"-leave"),leaveToClass:"".concat(e,"-leave-to"),leaveActiveClass:"".concat(e,"-leave-active")}})),yi=Y&&!Q,wi="transition",_i="transitionend",xi="animation",ki="animationend";yi&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(wi="WebkitTransition",_i="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(xi="WebkitAnimation",ki="webkitAnimationEnd"));var Ti=Y?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(e){return e()};function Ei(e){Ti((function(){Ti(e)}))}function Si(e,n){var t=e._transitionClasses||(e._transitionClasses=[]);t.indexOf(n)<0&&(t.push(n),fi(e,n))}function Ii(e,n){e._transitionClasses&&_(e._transitionClasses,n),gi(e,n)}function Ai(e,n,t){var a=ji(e,n),r=a.type,i=a.timeout,o=a.propCount;if(!r)return t();var s="transition"===r?_i:ki,l=0,c=function(){e.removeEventListener(s,d),t()},d=function(n){n.target===e&&++l>=o&&c()};setTimeout((function(){l<o&&c()}),i+1),e.addEventListener(s,d)}var Ci=/\b(transform|all)(,|$)/;function ji(e,n){var t,a=window.getComputedStyle(e),r=(a[wi+"Delay"]||"").split(", "),i=(a[wi+"Duration"]||"").split(", "),o=Oi(r,i),s=(a[xi+"Delay"]||"").split(", "),l=(a[xi+"Duration"]||"").split(", "),c=Oi(s,l),d=0,u=0;return"transition"===n?o>0&&(t="transition",d=o,u=i.length):"animation"===n?c>0&&(t="animation",d=c,u=l.length):u=(t=(d=Math.max(o,c))>0?o>c?"transition":"animation":null)?"transition"===t?i.length:l.length:0,{type:t,timeout:d,propCount:u,hasTransform:"transition"===t&&Ci.test(a[wi+"Property"])}}function Oi(e,n){for(;e.length<n.length;)e=e.concat(e);return Math.max.apply(null,n.map((function(n,t){return Li(n)+Li(e[t])})))}function Li(e){return 1e3*Number(e.slice(0,-1).replace(",","."))}function Ni(e,n){var t=e.elm;o(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var a=vi(e.data.transition);if(!i(a)&&!o(t._enterCb)&&1===t.nodeType){for(var r=a.css,s=a.type,l=a.enterClass,u=a.enterToClass,p=a.enterActiveClass,m=a.appearClass,h=a.appearToClass,f=a.appearActiveClass,g=a.beforeEnter,v=a.enter,y=a.afterEnter,w=a.enterCancelled,_=a.beforeAppear,x=a.appear,k=a.afterAppear,T=a.appearCancelled,E=a.duration,S=ta,I=ta.$vnode;I&&I.parent;)S=I.context,I=I.parent;var A=!S._isMounted||!e.isRootInsert;if(!A||x||""===x){var C=A&&m?m:l,j=A&&f?f:p,O=A&&h?h:u,L=A&&_||g,N=A&&c(x)?x:v,D=A&&k||y,P=A&&T||w,M=b(d(E)?E.enter:E);0;var R=!1!==r&&!Q,z=Mi(N),J=t._enterCb=q((function(){R&&(Ii(t,O),Ii(t,j)),J.cancelled?(R&&Ii(t,C),P&&P(t)):D&&D(t),t._enterCb=null}));e.data.show||Cn(e,"insert",(function(){var n=t.parentNode,a=n&&n._pending&&n._pending[e.key];a&&a.tag===e.tag&&a.elm._leaveCb&&a.elm._leaveCb(),N&&N(t,J)})),L&&L(t),R&&(Si(t,C),Si(t,j),Ei((function(){Ii(t,C),J.cancelled||(Si(t,O),z||(Pi(M)?setTimeout(J,M):Ai(t,s,J)))}))),e.data.show&&(n&&n(),N&&N(t,J)),R||z||J()}}}function Di(e,n){var t=e.elm;o(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var a=vi(e.data.transition);if(i(a)||1!==t.nodeType)return n();if(!o(t._leaveCb)){var r=a.css,s=a.type,l=a.leaveClass,c=a.leaveToClass,u=a.leaveActiveClass,p=a.beforeLeave,m=a.leave,h=a.afterLeave,f=a.leaveCancelled,g=a.delayLeave,v=a.duration,y=!1!==r&&!Q,w=Mi(m),_=b(d(v)?v.leave:v);0;var x=t._leaveCb=q((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[e.key]=null),y&&(Ii(t,c),Ii(t,u)),x.cancelled?(y&&Ii(t,l),f&&f(t)):(n(),h&&h(t)),t._leaveCb=null}));g?g(k):k()}function k(){x.cancelled||(!e.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[e.key]=e),p&&p(t),y&&(Si(t,l),Si(t,u),Ei((function(){Ii(t,l),x.cancelled||(Si(t,c),w||(Pi(_)?setTimeout(x,_):Ai(t,s,x)))}))),m&&m(t,x),y||w||x())}}function Pi(e){return"number"==typeof e&&!isNaN(e)}function Mi(e){if(i(e))return!1;var n=e.fns;return o(n)?Mi(Array.isArray(n)?n[0]:n):(e._length||e.length)>1}function Ri(e,n){!0!==n.data.show&&Ni(n)}var zi=function(e){var n,t,a={},c=e.modules,d=e.nodeOps;for(n=0;n<jr.length;++n)for(a[jr[n]]=[],t=0;t<c.length;++t)o(c[t][jr[n]])&&a[jr[n]].push(c[t][jr[n]]);function u(e){var n=d.parentNode(e);o(n)&&d.removeChild(n,e)}function p(e,n,t,r,i,l,c){if(o(e.elm)&&o(l)&&(e=l[c]=ve(e)),e.isRootInsert=!i,!function(e,n,t,r){var i=e.data;if(o(i)){var l=o(e.componentInstance)&&i.keepAlive;if(o(i=i.hook)&&o(i=i.init)&&i(e,!1),o(e.componentInstance))return m(e,n),h(t,e.elm,r),s(l)&&function(e,n,t,r){var i,s=e;for(;s.componentInstance;)if(s=s.componentInstance._vnode,o(i=s.data)&&o(i=i.transition)){for(i=0;i<a.activate.length;++i)a.activate[i](Cr,s);n.push(s);break}h(t,e.elm,r)}(e,n,t,r),!0}}(e,n,t,r)){var u=e.data,p=e.children,g=e.tag;o(g)?(e.elm=e.ns?d.createElementNS(e.ns,g):d.createElement(g,e),b(e),f(e,p,n),o(u)&&v(e,n),h(t,e.elm,r)):s(e.isComment)?(e.elm=d.createComment(e.text),h(t,e.elm,r)):(e.elm=d.createTextNode(e.text),h(t,e.elm,r))}}function m(e,n){o(e.data.pendingInsert)&&(n.push.apply(n,e.data.pendingInsert),e.data.pendingInsert=null),e.elm=e.componentInstance.$el,g(e)?(v(e,n),b(e)):(Ir(e),n.push(e))}function h(e,n,t){o(e)&&(o(t)?d.parentNode(t)===e&&d.insertBefore(e,n,t):d.appendChild(e,n))}function f(e,n,t){if(r(n)){0;for(var a=0;a<n.length;++a)p(n[a],t,e.elm,null,!0,n,a)}else l(e.text)&&d.appendChild(e.elm,d.createTextNode(String(e.text)))}function g(e){for(;e.componentInstance;)e=e.componentInstance._vnode;return o(e.tag)}function v(e,t){for(var r=0;r<a.create.length;++r)a.create[r](Cr,e);o(n=e.data.hook)&&(o(n.create)&&n.create(Cr,e),o(n.insert)&&t.push(e))}function b(e){var n;if(o(n=e.fnScopeId))d.setStyleScope(e.elm,n);else for(var t=e;t;)o(n=t.context)&&o(n=n.$options._scopeId)&&d.setStyleScope(e.elm,n),t=t.parent;o(n=ta)&&n!==e.context&&n!==e.fnContext&&o(n=n.$options._scopeId)&&d.setStyleScope(e.elm,n)}function w(e,n,t,a,r,i){for(;a<=r;++a)p(t[a],i,e,n,!1,t,a)}function _(e){var n,t,r=e.data;if(o(r))for(o(n=r.hook)&&o(n=n.destroy)&&n(e),n=0;n<a.destroy.length;++n)a.destroy[n](e);if(o(n=e.children))for(t=0;t<e.children.length;++t)_(e.children[t])}function x(e,n,t){for(;n<=t;++n){var a=e[n];o(a)&&(o(a.tag)?(k(a),_(a)):u(a.elm))}}function k(e,n){if(o(n)||o(e.data)){var t,r=a.remove.length+1;for(o(n)?n.listeners+=r:n=function(e,n){function t(){0==--t.listeners&&u(e)}return t.listeners=n,t}(e.elm,r),o(t=e.componentInstance)&&o(t=t._vnode)&&o(t.data)&&k(t,n),t=0;t<a.remove.length;++t)a.remove[t](e,n);o(t=e.data.hook)&&o(t=t.remove)?t(e,n):n()}else u(e.elm)}function T(e,n,t,a){for(var r=t;r<a;r++){var i=n[r];if(o(i)&&Or(e,i))return r}}function E(e,n,t,r,l,c){if(e!==n){o(n.elm)&&o(r)&&(n=r[l]=ve(n));var u=n.elm=e.elm;if(s(e.isAsyncPlaceholder))o(n.asyncFactory.resolved)?A(e.elm,n,t):n.isAsyncPlaceholder=!0;else if(s(n.isStatic)&&s(e.isStatic)&&n.key===e.key&&(s(n.isCloned)||s(n.isOnce)))n.componentInstance=e.componentInstance;else{var m,h=n.data;o(h)&&o(m=h.hook)&&o(m=m.prepatch)&&m(e,n);var f=e.children,v=n.children;if(o(h)&&g(n)){for(m=0;m<a.update.length;++m)a.update[m](e,n);o(m=h.hook)&&o(m=m.update)&&m(e,n)}i(n.text)?o(f)&&o(v)?f!==v&&function(e,n,t,a,r){var s,l,c,u=0,m=0,h=n.length-1,f=n[0],g=n[h],v=t.length-1,b=t[0],y=t[v],_=!r;for(0;u<=h&&m<=v;)i(f)?f=n[++u]:i(g)?g=n[--h]:Or(f,b)?(E(f,b,a,t,m),f=n[++u],b=t[++m]):Or(g,y)?(E(g,y,a,t,v),g=n[--h],y=t[--v]):Or(f,y)?(E(f,y,a,t,v),_&&d.insertBefore(e,f.elm,d.nextSibling(g.elm)),f=n[++u],y=t[--v]):Or(g,b)?(E(g,b,a,t,m),_&&d.insertBefore(e,g.elm,f.elm),g=n[--h],b=t[++m]):(i(s)&&(s=Lr(n,u,h)),i(l=o(b.key)?s[b.key]:T(b,n,u,h))?p(b,a,e,f.elm,!1,t,m):Or(c=n[l],b)?(E(c,b,a,t,m),n[l]=void 0,_&&d.insertBefore(e,c.elm,f.elm)):p(b,a,e,f.elm,!1,t,m),b=t[++m]);u>h?w(e,i(t[v+1])?null:t[v+1].elm,t,m,v,a):m>v&&x(n,u,h)}(u,f,v,t,c):o(v)?(o(e.text)&&d.setTextContent(u,""),w(u,null,v,0,v.length-1,t)):o(f)?x(f,0,f.length-1):o(e.text)&&d.setTextContent(u,""):e.text!==n.text&&d.setTextContent(u,n.text),o(h)&&o(m=h.hook)&&o(m=m.postpatch)&&m(e,n)}}}function S(e,n,t){if(s(t)&&o(e.parent))e.parent.data.pendingInsert=n;else for(var a=0;a<n.length;++a)n[a].data.hook.insert(n[a])}var I=y("attrs,class,staticClass,staticStyle,key");function A(e,n,t,a){var r,i=n.tag,l=n.data,c=n.children;if(a=a||l&&l.pre,n.elm=e,s(n.isComment)&&o(n.asyncFactory))return n.isAsyncPlaceholder=!0,!0;if(o(l)&&(o(r=l.hook)&&o(r=r.init)&&r(n,!0),o(r=n.componentInstance)))return m(n,t),!0;if(o(i)){if(o(c))if(e.hasChildNodes())if(o(r=l)&&o(r=r.domProps)&&o(r=r.innerHTML)){if(r!==e.innerHTML)return!1}else{for(var d=!0,u=e.firstChild,p=0;p<c.length;p++){if(!u||!A(u,c[p],t,a)){d=!1;break}u=u.nextSibling}if(!d||u)return!1}else f(n,c,t);if(o(l)){var h=!1;for(var g in l)if(!I(g)){h=!0,v(n,t);break}!h&&l.class&&Wt(l.class)}}else e.data!==n.text&&(e.data=n.text);return!0}return function(e,n,t,r){if(!i(n)){var l,c=!1,u=[];if(i(e))c=!0,p(n,u);else{var m=o(e.nodeType);if(!m&&Or(e,n))E(e,n,u,null,null,r);else{if(m){if(1===e.nodeType&&e.hasAttribute("data-server-rendered")&&(e.removeAttribute("data-server-rendered"),t=!0),s(t)&&A(e,n,u))return S(n,u,!0),e;l=e,e=new he(d.tagName(l).toLowerCase(),{},[],void 0,l)}var h=e.elm,f=d.parentNode(h);if(p(n,u,h._leaveCb?null:f,d.nextSibling(h)),o(n.parent))for(var v=n.parent,b=g(n);v;){for(var y=0;y<a.destroy.length;++y)a.destroy[y](v);if(v.elm=n.elm,b){for(var w=0;w<a.create.length;++w)a.create[w](Cr,v);var k=v.data.hook.insert;if(k.merged)for(var T=k.fns.slice(1),I=0;I<T.length;I++)T[I]()}else Ir(v);v=v.parent}o(f)?x([e],0,0):o(e.tag)&&_(e)}}return S(n,u,c),n.elm}o(e)&&_(e)}}({nodeOps:Er,modules:[Ur,Gr,Xr,ti,mi,Y?{create:Ri,activate:Ri,remove:function(e,n){!0!==e.data.show?Di(e,n):n()}}:{}].concat(qr)});Q&&document.addEventListener("selectionchange",(function(){var e=document.activeElement;e&&e.vmodel&&Gi(e,"input")}));var qi={inserted:function(e,n,t,a){"select"===t.tag?(a.elm&&!a.elm._vOptions?Cn(t,"postpatch",(function(){qi.componentUpdated(e,n,t)})):Ji(e,n,t.context),e._vOptions=[].map.call(e.options,Ui)):("textarea"===t.tag||Tr(e.type))&&(e._vModifiers=n.modifiers,n.modifiers.lazy||(e.addEventListener("compositionstart",Hi),e.addEventListener("compositionend",$i),e.addEventListener("change",$i),Q&&(e.vmodel=!0)))},componentUpdated:function(e,n,t){if("select"===t.tag){Ji(e,n,t.context);var a=e._vOptions,r=e._vOptions=[].map.call(e.options,Ui);if(r.some((function(e,n){return!R(e,a[n])})))(e.multiple?n.value.some((function(e){return Bi(e,r)})):n.value!==n.oldValue&&Bi(n.value,r))&&Gi(e,"change")}}};function Ji(e,n,t){Fi(e,n,t),(Z||X)&&setTimeout((function(){Fi(e,n,t)}),0)}function Fi(e,n,t){var a=n.value,r=e.multiple;if(!r||Array.isArray(a)){for(var i,o,s=0,l=e.options.length;s<l;s++)if(o=e.options[s],r)i=z(a,Ui(o))>-1,o.selected!==i&&(o.selected=i);else if(R(Ui(o),a))return void(e.selectedIndex!==s&&(e.selectedIndex=s));r||(e.selectedIndex=-1)}}function Bi(e,n){return n.every((function(n){return!R(n,e)}))}function Ui(e){return"_value"in e?e._value:e.value}function Hi(e){e.target.composing=!0}function $i(e){e.target.composing&&(e.target.composing=!1,Gi(e.target,"input"))}function Gi(e,n){var t=document.createEvent("HTMLEvents");t.initEvent(n,!0,!0),e.dispatchEvent(t)}function Ki(e){return!e.componentInstance||e.data&&e.data.transition?e:Ki(e.componentInstance._vnode)}var Wi={model:qi,show:{bind:function(e,n,t){var a=n.value,r=(t=Ki(t)).data&&t.data.transition,i=e.__vOriginalDisplay="none"===e.style.display?"":e.style.display;a&&r?(t.data.show=!0,Ni(t,(function(){e.style.display=i}))):e.style.display=a?i:"none"},update:function(e,n,t){var a=n.value;!a!=!n.oldValue&&((t=Ki(t)).data&&t.data.transition?(t.data.show=!0,a?Ni(t,(function(){e.style.display=e.__vOriginalDisplay})):Di(t,(function(){e.style.display="none"}))):e.style.display=a?e.__vOriginalDisplay:"none")},unbind:function(e,n,t,a,r){r||(e.style.display=e.__vOriginalDisplay)}}},Yi={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Vi(e){var n=e&&e.componentOptions;return n&&n.Ctor.options.abstract?Vi(ut(n.children)):e}function Zi(e){var n={},t=e.$options;for(var a in t.propsData)n[a]=e[a];var r=t._parentListeners;for(var a in r)n[S(a)]=r[a];return n}function Qi(e,n){if(/\d-keep-alive$/.test(n.tag))return e("keep-alive",{props:n.componentOptions.propsData})}var Xi=function(e){return e.tag||Vn(e)},eo=function(e){return"show"===e.name},no={name:"transition",props:Yi,abstract:!0,render:function(e){var n=this,t=this.$slots.default;if(t&&(t=t.filter(Xi)).length){0;var a=this.mode;0;var r=t[0];if(function(e){for(;e=e.parent;)if(e.data.transition)return!0}(this.$vnode))return r;var i=Vi(r);if(!i)return r;if(this._leaving)return Qi(e,r);var o="__transition-".concat(this._uid,"-");i.key=null==i.key?i.isComment?o+"comment":o+i.tag:l(i.key)?0===String(i.key).indexOf(o)?i.key:o+i.key:i.key;var s=(i.data||(i.data={})).transition=Zi(this),c=this._vnode,d=Vi(c);if(i.data.directives&&i.data.directives.some(eo)&&(i.data.show=!0),d&&d.data&&!function(e,n){return n.key===e.key&&n.tag===e.tag}(i,d)&&!Vn(d)&&(!d.componentInstance||!d.componentInstance._vnode.isComment)){var u=d.data.transition=L({},s);if("out-in"===a)return this._leaving=!0,Cn(u,"afterLeave",(function(){n._leaving=!1,n.$forceUpdate()})),Qi(e,r);if("in-out"===a){if(Vn(i))return c;var p,m=function(){p()};Cn(s,"afterEnter",m),Cn(s,"enterCancelled",m),Cn(u,"delayLeave",(function(e){p=e}))}}return r}}},to=L({tag:String,moveClass:String},Yi);function ao(e){e.elm._moveCb&&e.elm._moveCb(),e.elm._enterCb&&e.elm._enterCb()}function ro(e){e.data.newPos=e.elm.getBoundingClientRect()}function io(e){var n=e.data.pos,t=e.data.newPos,a=n.left-t.left,r=n.top-t.top;if(a||r){e.data.moved=!0;var i=e.elm.style;i.transform=i.WebkitTransform="translate(".concat(a,"px,").concat(r,"px)"),i.transitionDuration="0s"}}delete to.mode;var oo={Transition:no,TransitionGroup:{props:to,beforeMount:function(){var e=this,n=this._update;this._update=function(t,a){var r=aa(e);e.__patch__(e._vnode,e.kept,!1,!0),e._vnode=e.kept,r(),n.call(e,t,a)}},render:function(e){for(var n=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),a=this.prevChildren=this.children,r=this.$slots.default||[],i=this.children=[],o=Zi(this),s=0;s<r.length;s++){if((d=r[s]).tag)if(null!=d.key&&0!==String(d.key).indexOf("__vlist"))i.push(d),t[d.key]=d,(d.data||(d.data={})).transition=o;else;}if(a){var l=[],c=[];for(s=0;s<a.length;s++){var d;(d=a[s]).data.transition=o,d.data.pos=d.elm.getBoundingClientRect(),t[d.key]?l.push(d):c.push(d)}this.kept=e(n,null,l),this.removed=c}return e(n,null,i)},updated:function(){var e=this.prevChildren,n=this.moveClass||(this.name||"v")+"-move";e.length&&this.hasMove(e[0].elm,n)&&(e.forEach(ao),e.forEach(ro),e.forEach(io),this._reflow=document.body.offsetHeight,e.forEach((function(e){if(e.data.moved){var t=e.elm,a=t.style;Si(t,n),a.transform=a.WebkitTransform=a.transitionDuration="",t.addEventListener(_i,t._moveCb=function e(a){a&&a.target!==t||a&&!/transform$/.test(a.propertyName)||(t.removeEventListener(_i,e),t._moveCb=null,Ii(t,n))})}})))},methods:{hasMove:function(e,n){if(!yi)return!1;if(this._hasMove)return this._hasMove;var t=e.cloneNode();e._transitionClasses&&e._transitionClasses.forEach((function(e){gi(t,e)})),fi(t,n),t.style.display="none",this.$el.appendChild(t);var a=ji(t);return this.$el.removeChild(t),this._hasMove=a.hasTransform}}}};Qa.config.mustUseProp=function(e,n,t){return"value"===t&&sr(e)&&"button"!==n||"selected"===t&&"option"===e||"checked"===t&&"input"===e||"muted"===t&&"video"===e},Qa.config.isReservedTag=xr,Qa.config.isReservedAttr=or,Qa.config.getTagNamespace=function(e){return _r(e)?"svg":"math"===e?"math":void 0},Qa.config.isUnknownElement=function(e){if(!Y)return!0;if(xr(e))return!1;if(e=e.toLowerCase(),null!=kr[e])return kr[e];var n=document.createElement(e);return e.indexOf("-")>-1?kr[e]=n.constructor===window.HTMLUnknownElement||n.constructor===window.HTMLElement:kr[e]=/HTMLUnknownElement/.test(n.toString())},L(Qa.options.directives,Wi),L(Qa.options.components,oo),Qa.prototype.__patch__=Y?zi:D,Qa.prototype.$mount=function(e,n){return function(e,n,t){var a;e.$el=n,e.$options.render||(e.$options.render=fe),oa(e,"beforeMount"),a=function(){e._update(e._render(),t)},new Zt(e,a,D,{before:function(){e._isMounted&&!e._isDestroyed&&oa(e,"beforeUpdate")}},!0),t=!1;var r=e._preWatchers;if(r)for(var i=0;i<r.length;i++)r[i].run();return null==e.$vnode&&(e._isMounted=!0,oa(e,"mounted")),e}(this,e=e&&Y?function(e){if("string"==typeof e){var n=document.querySelector(e);return n||document.createElement("div")}return e}(e):void 0,n)},Y&&setTimeout((function(){U.devtools&&se&&se.emit("init",Qa)}),0)},function(e,n,t){"use strict";var a=function(e){return e&&e.Math===Math&&e};e.exports=a("object"==typeof globalThis&&globalThis)||a("object"==typeof window&&window)||a("object"==typeof self&&self)||a("object"==typeof global&&global)||a("object"==typeof this&&this)||function(){return this}()||Function("return this")()},function(e,n,t){"use strict";var a="object"==typeof document&&document.all;e.exports=void 0===a&&void 0!==a?function(e){return"function"==typeof e||e===a}:function(e){return"function"==typeof e}},function(e,n,t){"use strict";var a=t(27),r=Function.prototype,i=r.call,o=a&&r.bind.bind(i,i);e.exports=a?o:function(e){return function(){return i.apply(e,arguments)}}},function(e,n,t){"use strict";e.exports=function(e){try{return!!e()}catch(e){return!0}}},function(e,n,t){"use strict";var a=t(4);e.exports=!a((function(){return 7!==Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(e,n){var t=Array.isArray;e.exports=t},function(e,n,t){"use strict";var a=t(2);e.exports=function(e){return"object"==typeof e?null!==e:a(e)}},function(e,n,t){var a=t(69),r="object"==typeof self&&self&&self.Object===Object&&self,i=a||r||Function("return this")();e.exports=i},function(e,n,t){"use strict";function a(e,n,t,a,r,i,o,s){var l,c="function"==typeof e?e.options:e;if(n&&(c.render=n,c.staticRenderFns=t,c._compiled=!0),a&&(c.functional=!0),i&&(c._scopeId="data-v-"+i),o?(l=function(e){(e=e||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(e=__VUE_SSR_CONTEXT__),r&&r.call(this,e),e&&e._registeredComponents&&e._registeredComponents.add(o)},c._ssrRegister=l):r&&(l=s?function(){r.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:r),l)if(c.functional){c._injectStyles=l;var d=c.render;c.render=function(e,n){return l.call(n),d(e,n)}}else{var u=c.beforeCreate;c.beforeCreate=u?[].concat(u,l):[l]}return{exports:e,options:c}}t.d(n,"a",(function(){return a}))},function(e,n,t){"use strict";var a=t(3),r=t(32),i=a({}.hasOwnProperty);e.exports=Object.hasOwn||function(e,n){return i(r(e),n)}},function(e,n,t){var a=t(164),r=t(167);e.exports=function(e,n){var t=r(e,n);return a(t)?t:void 0}},function(e,n,t){"use strict";t.d(n,"e",(function(){return a})),t.d(n,"b",(function(){return i})),t.d(n,"j",(function(){return o})),t.d(n,"g",(function(){return l})),t.d(n,"h",(function(){return c})),t.d(n,"i",(function(){return d})),t.d(n,"c",(function(){return u})),t.d(n,"f",(function(){return p})),t.d(n,"l",(function(){return m})),t.d(n,"m",(function(){return h})),t.d(n,"d",(function(){return g})),t.d(n,"k",(function(){return v})),t.d(n,"n",(function(){return b})),t.d(n,"a",(function(){return w}));t(17);const a=/#.*$/,r=/\.(md|html)$/,i=/\/$/,o=/^[a-z]+:/i;function s(e){return decodeURI(e).replace(a,"").replace(r,"")}function l(e){return o.test(e)}function c(e){return/^mailto:/.test(e)}function d(e){return/^tel:/.test(e)}function u(e){if(l(e))return e;if(!e)return"404";const n=e.match(a),t=n?n[0]:"",r=s(e);return i.test(r)?e:r+".html"+t}function p(e,n){const t=e.hash,r=function(e){const n=e&&e.match(a);if(n)return n[0]}(n);if(r&&t!==r)return!1;return s(e.path)===s(n)}function m(e,n,t){if(l(n))return{type:"external",path:n};t&&(n=function(e,n,t){const a=e.charAt(0);if("/"===a)return e;if("?"===a||"#"===a)return n+e;const r=n.split("/");t&&r[r.length-1]||r.pop();const i=e.replace(/^\//,"").split("/");for(let e=0;e<i.length;e++){const n=i[e];".."===n?r.pop():"."!==n&&r.push(n)}""!==r[0]&&r.unshift("");return r.join("/")}(n,t));const a=s(n);for(let n=0;n<e.length;n++)if(s(e[n].regularPath)===a)return Object.assign({},e[n],{type:"page",path:u(e[n].path)});return console.error(`[vuepress] No matching page found for sidebar item "${n}"`),{}}function h(e,n,t,a){const{pages:r,themeConfig:i}=t,o=a&&i.locales&&i.locales[a]||i;if("auto"===(e.frontmatter.sidebar||o.sidebar||i.sidebar))return f(e);const s=o.sidebar||i.sidebar;if(s){const{base:t,config:a}=function(e,n){if(Array.isArray(n))return{base:"/",config:n};for(const a in n)if(0===(t=e,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(a)))return{base:a,config:n[a]};var t;return{}}(n,s);return"auto"===a?f(e):a?a.map(e=>function e(n,t,a,r=1){if("string"==typeof n)return m(t,n,a);if(Array.isArray(n))return Object.assign(m(t,n[0],a),{title:n[1]});{r>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const i=n.children||[];return 0===i.length&&n.path?Object.assign(m(t,n.path,a),{title:n.title}):{type:"group",path:n.path,title:n.title,sidebarDepth:n.sidebarDepth,initialOpenGroupIndex:n.initialOpenGroupIndex,children:i.map(n=>e(n,t,a,r+1)),collapsable:!1!==n.collapsable}}}(e,r,t)):[]}return[]}function f(e){const n=g(e.headers||[]);return[{type:"group",collapsable:!1,title:e.title,path:null,children:n.map(n=>({type:"auto",title:n.title,basePath:e.path,path:e.path+"#"+n.slug,children:n.children||[]}))}]}function g(e){let n;return(e=e.map(e=>Object.assign({},e))).forEach(e=>{2===e.level?n=e:n&&(n.children||(n.children=[])).push(e)}),e.filter(e=>2===e.level)}function v(e){return Object.assign(e,{type:e.items&&e.items.length?"links":"link"})}function b(e){return Object.prototype.toString.call(e).match(/\[object (.*?)\]/)[1].toLowerCase()}function y(e){let n=e.frontmatter.date||e.lastUpdated||new Date,t=new Date(n);return"Invalid Date"==t&&n&&(t=new Date(n.replace(/-/g,"/"))),t.getTime()}function w(e,n){return y(n)-y(e)}},function(e,n){e.exports=function(e){return null!=e&&"object"==typeof e}},function(e,n,t){var a=t(16),r=t(149),i=t(150),o=a?a.toStringTag:void 0;e.exports=function(e){return null==e?void 0===e?"[object Undefined]":"[object Null]":o&&o in Object(e)?r(e):i(e)}},function(e,n,t){"use strict";var a=t(5),r=t(18),i=t(35);e.exports=a?function(e,n,t){return r.f(e,n,i(1,t))}:function(e,n,t){return e[n]=t,e}},function(e,n,t){var a=t(8).Symbol;e.exports=a},function(e,n,t){"use strict";var a=t(26),r=t(32),i=t(33),o=t(143),s=t(145);a({target:"Array",proto:!0,arity:1,forced:t(4)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(e){return e instanceof TypeError}}()},{push:function(e){var n=r(this),t=i(n),a=arguments.length;s(t+a);for(var l=0;l<a;l++)n[t]=arguments[l],t++;return o(n,t),t}})},function(e,n,t){"use strict";var a=t(5),r=t(64),i=t(100),o=t(48),s=t(55),l=TypeError,c=Object.defineProperty,d=Object.getOwnPropertyDescriptor;n.f=a?i?function(e,n,t){if(o(e),n=s(n),o(t),"function"==typeof e&&"prototype"===n&&"value"in t&&"writable"in t&&!t.writable){var a=d(e,n);a&&a.writable&&(e[n]=t.value,t={configurable:"configurable"in t?t.configurable:a.configurable,enumerable:"enumerable"in t?t.enumerable:a.enumerable,writable:!1})}return c(e,n,t)}:c:function(e,n,t){if(o(e),n=s(n),o(t),r)try{return c(e,n,t)}catch(e){}if("get"in t||"set"in t)throw new l("Accessors not supported");return"value"in t&&(e[n]=t.value),e}},function(e,n,t){"use strict";var a=t(3),r=a({}.toString),i=a("".slice);e.exports=function(e){return i(r(e),8,-1)}},function(e,n,t){var a=t(154),r=t(155),i=t(156),o=t(157),s=t(158);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var a=e[n];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,e.exports=l},function(e,n,t){var a=t(71);e.exports=function(e,n){for(var t=e.length;t--;)if(a(e[t][0],n))return t;return-1}},function(e,n,t){var a=t(11)(Object,"create");e.exports=a},function(e,n,t){var a=t(176);e.exports=function(e,n){var t=e.__data__;return a(n)?t["string"==typeof n?"string":"hash"]:t.map}},function(e,n,t){var a=t(46);e.exports=function(e){if("string"==typeof e||a(e))return e;var n=e+"";return"0"==n&&1/e==-1/0?"-0":n}},function(e,n,t){var a,r;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(r="function"==typeof(a=function(){var e,n,t={version:"0.2.0"},a=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function r(e,n,t){return e<n?n:e>t?t:e}function i(e){return 100*(-1+e)}t.configure=function(e){var n,t;for(n in e)void 0!==(t=e[n])&&e.hasOwnProperty(n)&&(a[n]=t);return this},t.status=null,t.set=function(e){var n=t.isStarted();e=r(e,a.minimum,1),t.status=1===e?null:e;var l=t.render(!n),c=l.querySelector(a.barSelector),d=a.speed,u=a.easing;return l.offsetWidth,o((function(n){""===a.positionUsing&&(a.positionUsing=t.getPositioningCSS()),s(c,function(e,n,t){var r;return(r="translate3d"===a.positionUsing?{transform:"translate3d("+i(e)+"%,0,0)"}:"translate"===a.positionUsing?{transform:"translate("+i(e)+"%,0)"}:{"margin-left":i(e)+"%"}).transition="all "+n+"ms "+t,r}(e,d,u)),1===e?(s(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){s(l,{transition:"all "+d+"ms linear",opacity:0}),setTimeout((function(){t.remove(),n()}),d)}),d)):setTimeout(n,d)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var e=function(){setTimeout((function(){t.status&&(t.trickle(),e())}),a.trickleSpeed)};return a.trickle&&e(),this},t.done=function(e){return e||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(e){var n=t.status;return n?("number"!=typeof e&&(e=(1-n)*r(Math.random()*n,.1,.95)),n=r(n+e,0,.994),t.set(n)):t.start()},t.trickle=function(){return t.inc(Math.random()*a.trickleRate)},e=0,n=0,t.promise=function(a){return a&&"resolved"!==a.state()?(0===n&&t.start(),e++,n++,a.always((function(){0==--n?(e=0,t.done()):t.set((e-n)/e)})),this):this},t.render=function(e){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var n=document.createElement("div");n.id="nprogress",n.innerHTML=a.template;var r,o=n.querySelector(a.barSelector),l=e?"-100":i(t.status||0),d=document.querySelector(a.parent);return s(o,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),a.showSpinner||(r=n.querySelector(a.spinnerSelector))&&p(r),d!=document.body&&c(d,"nprogress-custom-parent"),d.appendChild(n),n},t.remove=function(){d(document.documentElement,"nprogress-busy"),d(document.querySelector(a.parent),"nprogress-custom-parent");var e=document.getElementById("nprogress");e&&p(e)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var e=document.body.style,n="WebkitTransform"in e?"Webkit":"MozTransform"in e?"Moz":"msTransform"in e?"ms":"OTransform"in e?"O":"";return n+"Perspective"in e?"translate3d":n+"Transform"in e?"translate":"margin"};var o=function(){var e=[];function n(){var t=e.shift();t&&t(n)}return function(t){e.push(t),1==e.length&&n()}}(),s=function(){var e=["Webkit","O","Moz","ms"],n={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(e,n){return n.toUpperCase()})),n[t]||(n[t]=function(n){var t=document.body.style;if(n in t)return n;for(var a,r=e.length,i=n.charAt(0).toUpperCase()+n.slice(1);r--;)if((a=e[r]+i)in t)return a;return n}(t))}function a(e,n,a){n=t(n),e.style[n]=a}return function(e,n){var t,r,i=arguments;if(2==i.length)for(t in n)void 0!==(r=n[t])&&n.hasOwnProperty(t)&&a(e,t,r);else a(e,i[1],i[2])}}();function l(e,n){return("string"==typeof e?e:u(e)).indexOf(" "+n+" ")>=0}function c(e,n){var t=u(e),a=t+n;l(t,n)||(e.className=a.substring(1))}function d(e,n){var t,a=u(e);l(e,n)&&(t=a.replace(" "+n+" "," "),e.className=t.substring(1,t.length-1))}function u(e){return(" "+(e.className||"")+" ").replace(/\s+/gi," ")}function p(e){e&&e.parentNode&&e.parentNode.removeChild(e)}return t})?a.call(n,t,n,e):a)||(e.exports=r)},function(e,n,t){"use strict";var a=t(1),r=t(53).f,i=t(15),o=t(96),s=t(38),l=t(65),c=t(124);e.exports=function(e,n){var t,d,u,p,m,h=e.target,f=e.global,g=e.stat;if(t=f?a:g?a[h]||s(h,{}):a[h]&&a[h].prototype)for(d in n){if(p=n[d],u=e.dontCallGetSet?(m=r(t,d))&&m.value:t[d],!c(f?d:h+(g?".":"#")+d,e.forced)&&void 0!==u){if(typeof p==typeof u)continue;l(p,u)}(e.sham||u&&u.sham)&&i(p,"sham",!0),o(t,d,p,e)}}},function(e,n,t){"use strict";var a=t(4);e.exports=!a((function(){var e=function(){}.bind();return"function"!=typeof e||e.hasOwnProperty("prototype")}))},function(e,n,t){"use strict";var a=t(50),r=t(36);e.exports=function(e){return a(r(e))}},function(e,n,t){"use strict";var a=t(1),r=t(2),i=function(e){return r(e)?e:void 0};e.exports=function(e,n){return arguments.length<2?i(a[e]):a[e]&&a[e][n]}},function(e,n,t){"use strict";var a=t(2),r=t(111),i=TypeError;e.exports=function(e){if(a(e))return e;throw new i(r(e)+" is not a function")}},function(e,n,t){"use strict";var a=t(1),r=t(61),i=t(10),o=t(63),s=t(59),l=t(58),c=a.Symbol,d=r("wks"),u=l?c.for||c:c&&c.withoutSetter||o;e.exports=function(e){return i(d,e)||(d[e]=s&&i(c,e)?c[e]:u("Symbol."+e)),d[e]}},function(e,n,t){"use strict";var a=t(36),r=Object;e.exports=function(e){return r(a(e))}},function(e,n,t){"use strict";var a=t(122);e.exports=function(e){return a(e.length)}},function(e,n,t){"use strict";var a=t(27),r=Function.prototype.call;e.exports=a?r.bind(r):function(){return r.apply(r,arguments)}},function(e,n,t){"use strict";e.exports=function(e,n){return{enumerable:!(1&e),configurable:!(2&e),writable:!(4&e),value:n}}},function(e,n,t){"use strict";var a=t(54),r=TypeError;e.exports=function(e){if(a(e))throw new r("Can't call method on "+e);return e}},function(e,n,t){"use strict";var a=t(62),r=t(1),i=t(38),o=e.exports=r["__core-js_shared__"]||i("__core-js_shared__",{});(o.versions||(o.versions=[])).push({version:"3.37.1",mode:a?"pure":"global",copyright:" 2014-2024 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.37.1/LICENSE",source:"https://github.com/zloirock/core-js"})},function(e,n,t){"use strict";var a=t(1),r=Object.defineProperty;e.exports=function(e,n){try{r(a,e,{value:n,configurable:!0,writable:!0})}catch(t){a[e]=n}return n}},function(e,n,t){var a=t(148),r=t(13),i=Object.prototype,o=i.hasOwnProperty,s=i.propertyIsEnumerable,l=a(function(){return arguments}())?a:function(e){return r(e)&&o.call(e,"callee")&&!s.call(e,"callee")};e.exports=l},function(e,n,t){var a=t(11)(t(8),"Map");e.exports=a},function(e,n){e.exports=function(e){var n=typeof e;return null!=e&&("object"==n||"function"==n)}},function(e,n,t){var a=t(168),r=t(175),i=t(177),o=t(178),s=t(179);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var a=e[n];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,e.exports=l},function(e,n){e.exports=function(e){var n=-1,t=Array(e.size);return e.forEach((function(e){t[++n]=e})),t}},function(e,n){e.exports=function(e){return"number"==typeof e&&e>-1&&e%1==0&&e<=9007199254740991}},function(e,n,t){var a=t(6),r=t(46),i=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,o=/^\w*$/;e.exports=function(e,n){if(a(e))return!1;var t=typeof e;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=e&&!r(e))||(o.test(e)||!i.test(e)||null!=n&&e in Object(n))}},function(e,n,t){var a=t(14),r=t(13);e.exports=function(e){return"symbol"==typeof e||r(e)&&"[object Symbol]"==a(e)}},function(e,n){e.exports=function(e){return e}},function(e,n,t){"use strict";var a=t(7),r=String,i=TypeError;e.exports=function(e){if(a(e))return e;throw new i(r(e)+" is not an object")}},function(e,n){e.exports=function(e){return e.webpackPolyfill||(e.deprecate=function(){},e.paths=[],e.children||(e.children=[]),Object.defineProperty(e,"loaded",{enumerable:!0,get:function(){return e.l}}),Object.defineProperty(e,"id",{enumerable:!0,get:function(){return e.i}}),e.webpackPolyfill=1),e}},function(e,n,t){"use strict";var a=t(3),r=t(4),i=t(19),o=Object,s=a("".split);e.exports=r((function(){return!o("z").propertyIsEnumerable(0)}))?function(e){return"String"===i(e)?s(e,""):o(e)}:o},function(e,n,t){"use strict";e.exports={}},function(e,n){var t=/^\s+|\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,r=/^0b[01]+$/i,i=/^0o[0-7]+$/i,o=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=s||l||Function("return this")(),d=Object.prototype.toString,u=Math.max,p=Math.min,m=function(){return c.Date.now()};function h(e){var n=typeof e;return!!e&&("object"==n||"function"==n)}function f(e){if("number"==typeof e)return e;if(function(e){return"symbol"==typeof e||function(e){return!!e&&"object"==typeof e}(e)&&"[object Symbol]"==d.call(e)}(e))return NaN;if(h(e)){var n="function"==typeof e.valueOf?e.valueOf():e;e=h(n)?n+"":n}if("string"!=typeof e)return 0===e?e:+e;e=e.replace(t,"");var s=r.test(e);return s||i.test(e)?o(e.slice(2),s?2:8):a.test(e)?NaN:+e}e.exports=function(e,n,t){var a,r,i,o,s,l,c=0,d=!1,g=!1,v=!0;if("function"!=typeof e)throw new TypeError("Expected a function");function b(n){var t=a,i=r;return a=r=void 0,c=n,o=e.apply(i,t)}function y(e){return c=e,s=setTimeout(_,n),d?b(e):o}function w(e){var t=e-l;return void 0===l||t>=n||t<0||g&&e-c>=i}function _(){var e=m();if(w(e))return x(e);s=setTimeout(_,function(e){var t=n-(e-l);return g?p(t,i-(e-c)):t}(e))}function x(e){return s=void 0,v&&a?b(e):(a=r=void 0,o)}function k(){var e=m(),t=w(e);if(a=arguments,r=this,l=e,t){if(void 0===s)return y(l);if(g)return s=setTimeout(_,n),b(l)}return void 0===s&&(s=setTimeout(_,n)),o}return n=f(n)||0,h(t)&&(d=!!t.leading,i=(g="maxWait"in t)?u(f(t.maxWait)||0,n):i,v="trailing"in t?!!t.trailing:v),k.cancel=function(){void 0!==s&&clearTimeout(s),c=0,a=l=r=s=void 0},k.flush=function(){return void 0===s?o:x(m())},k}},function(e,n,t){"use strict";var a=t(5),r=t(34),i=t(107),o=t(35),s=t(28),l=t(55),c=t(10),d=t(64),u=Object.getOwnPropertyDescriptor;n.f=a?u:function(e,n){if(e=s(e),n=l(n),d)try{return u(e,n)}catch(e){}if(c(e,n))return o(!r(i.f,e,n),e[n])}},function(e,n,t){"use strict";e.exports=function(e){return null==e}},function(e,n,t){"use strict";var a=t(108),r=t(56);e.exports=function(e){var n=a(e,"string");return r(n)?n:n+""}},function(e,n,t){"use strict";var a=t(29),r=t(2),i=t(57),o=t(58),s=Object;e.exports=o?function(e){return"symbol"==typeof e}:function(e){var n=a("Symbol");return r(n)&&i(n.prototype,s(e))}},function(e,n,t){"use strict";var a=t(3);e.exports=a({}.isPrototypeOf)},function(e,n,t){"use strict";var a=t(59);e.exports=a&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(e,n,t){"use strict";var a=t(60),r=t(4),i=t(1).String;e.exports=!!Object.getOwnPropertySymbols&&!r((function(){var e=Symbol("symbol detection");return!i(e)||!(Object(e)instanceof Symbol)||!Symbol.sham&&a&&a<41}))},function(e,n,t){"use strict";var a,r,i=t(1),o=t(109),s=i.process,l=i.Deno,c=s&&s.versions||l&&l.version,d=c&&c.v8;d&&(r=(a=d.split("."))[0]>0&&a[0]<4?1:+(a[0]+a[1])),!r&&o&&(!(a=o.match(/Edge\/(\d+)/))||a[1]>=74)&&(a=o.match(/Chrome\/(\d+)/))&&(r=+a[1]),e.exports=r},function(e,n,t){"use strict";var a=t(37);e.exports=function(e,n){return a[e]||(a[e]=n||{})}},function(e,n,t){"use strict";e.exports=!1},function(e,n,t){"use strict";var a=t(3),r=0,i=Math.random(),o=a(1..toString);e.exports=function(e){return"Symbol("+(void 0===e?"":e)+")_"+o(++r+i,36)}},function(e,n,t){"use strict";var a=t(5),r=t(4),i=t(99);e.exports=!a&&!r((function(){return 7!==Object.defineProperty(i("div"),"a",{get:function(){return 7}}).a}))},function(e,n,t){"use strict";var a=t(10),r=t(117),i=t(53),o=t(18);e.exports=function(e,n,t){for(var s=r(n),l=o.f,c=i.f,d=0;d<s.length;d++){var u=s[d];a(e,u)||t&&a(t,u)||l(e,u,c(n,u))}}},function(e,n,t){"use strict";var a=t(121);e.exports=function(e){var n=+e;return n!=n||0===n?0:a(n)}},function(e,n,t){"use strict";var a=t(131),r=t(7),i=t(36),o=t(132);e.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var e,n=!1,t={};try{(e=a(Object.prototype,"__proto__","set"))(t,[]),n=t instanceof Array}catch(e){}return function(t,a){return i(t),o(a),r(t)?(n?e(t,a):t.__proto__=a,t):t}}():void 0)},function(e,n){e.exports=function(e,n){for(var t=-1,a=n.length,r=e.length;++t<a;)e[r+t]=n[t];return e}},function(e,n){var t="object"==typeof global&&global&&global.Object===Object&&global;e.exports=t},function(e,n,t){var a=t(20),r=t(159),i=t(160),o=t(161),s=t(162),l=t(163);function c(e){var n=this.__data__=new a(e);this.size=n.size}c.prototype.clear=r,c.prototype.delete=i,c.prototype.get=o,c.prototype.has=s,c.prototype.set=l,e.exports=c},function(e,n){e.exports=function(e,n){return e===n||e!=e&&n!=n}},function(e,n,t){var a=t(14),r=t(41);e.exports=function(e){if(!r(e))return!1;var n=a(e);return"[object Function]"==n||"[object GeneratorFunction]"==n||"[object AsyncFunction]"==n||"[object Proxy]"==n}},function(e,n){var t=Function.prototype.toString;e.exports=function(e){if(null!=e){try{return t.call(e)}catch(e){}try{return e+""}catch(e){}}return""}},function(e,n,t){var a=t(180),r=t(13);e.exports=function e(n,t,i,o,s){return n===t||(null==n||null==t||!r(n)&&!r(t)?n!=n&&t!=t:a(n,t,i,o,e,s))}},function(e,n,t){var a=t(76),r=t(183),i=t(77);e.exports=function(e,n,t,o,s,l){var c=1&t,d=e.length,u=n.length;if(d!=u&&!(c&&u>d))return!1;var p=l.get(e),m=l.get(n);if(p&&m)return p==n&&m==e;var h=-1,f=!0,g=2&t?new a:void 0;for(l.set(e,n),l.set(n,e);++h<d;){var v=e[h],b=n[h];if(o)var y=c?o(b,v,h,n,e,l):o(v,b,h,e,n,l);if(void 0!==y){if(y)continue;f=!1;break}if(g){if(!r(n,(function(e,n){if(!i(g,n)&&(v===e||s(v,e,t,o,l)))return g.push(n)}))){f=!1;break}}else if(v!==b&&!s(v,b,t,o,l)){f=!1;break}}return l.delete(e),l.delete(n),f}},function(e,n,t){var a=t(42),r=t(181),i=t(182);function o(e){var n=-1,t=null==e?0:e.length;for(this.__data__=new a;++n<t;)this.add(e[n])}o.prototype.add=o.prototype.push=r,o.prototype.has=i,e.exports=o},function(e,n){e.exports=function(e,n){return e.has(n)}},function(e,n,t){var a=t(193),r=t(199),i=t(82);e.exports=function(e){return i(e)?a(e):r(e)}},function(e,n,t){(function(e){var a=t(8),r=t(195),i=n&&!n.nodeType&&n,o=i&&"object"==typeof e&&e&&!e.nodeType&&e,s=o&&o.exports===i?a.Buffer:void 0,l=(s?s.isBuffer:void 0)||r;e.exports=l}).call(this,t(49)(e))},function(e,n){var t=/^(?:0|[1-9]\d*)$/;e.exports=function(e,n){var a=typeof e;return!!(n=null==n?9007199254740991:n)&&("number"==a||"symbol"!=a&&t.test(e))&&e>-1&&e%1==0&&e<n}},function(e,n,t){var a=t(196),r=t(197),i=t(198),o=i&&i.isTypedArray,s=o?r(o):a;e.exports=s},function(e,n,t){var a=t(72),r=t(44);e.exports=function(e){return null!=e&&r(e.length)&&!a(e)}},function(e,n,t){var a=t(11)(t(8),"Set");e.exports=a},function(e,n,t){var a=t(41);e.exports=function(e){return e==e&&!a(e)}},function(e,n){e.exports=function(e,n){return function(t){return null!=t&&(t[e]===n&&(void 0!==n||e in Object(t)))}}},function(e,n,t){var a=t(87),r=t(24);e.exports=function(e,n){for(var t=0,i=(n=a(n,e)).length;null!=e&&t<i;)e=e[r(n[t++])];return t&&t==i?e:void 0}},function(e,n,t){var a=t(6),r=t(45),i=t(210),o=t(213);e.exports=function(e,n){return a(e)?e:r(e,n)?[e]:i(o(e))}},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){var a=t(146),r=t(151),i=t(222),o=t(230),s=t(239),l=t(104),c=i((function(e){var n=l(e);return s(n)&&(n=void 0),o(a(e,1,s,!0),r(n,2))}));e.exports=c},function(e,n,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var a=/["'&<>]/;e.exports=function(e){var n,t=""+e,r=a.exec(t);if(!r)return t;var i="",o=0,s=0;for(o=r.index;o<t.length;o++){switch(t.charCodeAt(o)){case 34:n="&quot;";break;case 38:n="&amp;";break;case 39:n="&#39;";break;case 60:n="&lt;";break;case 62:n="&gt;";break;default:continue}s!==o&&(i+=t.substring(s,o)),s=o+1,i+=n}return s!==o?i+t.substring(s,o):i}},function(e,n,t){"use strict";t.r(n);var a={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},r=(t(242),t(9)),i=Object(r.a)(a,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);n.default=i.exports},function(e,n,t){"use strict";t.r(n);var a={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(e){this.codeTabs.forEach(e=>{e.elm.classList.remove("theme-code-block__active")}),this.codeTabs[e].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(e=>Boolean(e.componentOptions)).map((e,n)=>(""===e.componentOptions.propsData.active&&(this.activeCodeTabIndex=n),{title:e.componentOptions.propsData.title,elm:e.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(e){this.activeCodeTabIndex=e}}},r=(t(243),t(9)),i=Object(r.a)(a,(function(){var e=this,n=e._self._c;return n("div",{staticClass:"theme-code-group"},[n("div",{staticClass:"theme-code-group__nav"},[n("ul",{staticClass:"theme-code-group__ul"},e._l(e.codeTabs,(function(t,a){return n("li",{key:t.title,staticClass:"theme-code-group__li"},[n("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":a===e.activeCodeTabIndex},on:{click:function(n){return e.changeCodeTab(a)}}},[e._v("\n            "+e._s(t.title)+"\n          ")])])})),0)]),e._v(" "),e._t("default"),e._v(" "),e.codeTabs.length<1?n("pre",{staticClass:"pre-blank"},[e._v("// Make sure to add code blocks to your code group")]):e._e()],2)}),[],!1,null,"2f5f1757",null);n.default=i.exports},function(e,n,t){"use strict";var a=t(2),r=t(18),i=t(101),o=t(38);e.exports=function(e,n,t,s){s||(s={});var l=s.enumerable,c=void 0!==s.name?s.name:n;if(a(t)&&i(t,c,s),s.global)l?e[n]=t:o(n,t);else{try{s.unsafe?e[n]&&(l=!0):delete e[n]}catch(e){}l?e[n]=t:r.f(e,n,{value:t,enumerable:!1,configurable:!s.nonConfigurable,writable:!s.nonWritable})}return e}},function(e,n,t){"use strict";e.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(e,n,t){"use strict";var a=t(137),r=String;e.exports=function(e){if("Symbol"===a(e))throw new TypeError("Cannot convert a Symbol value to a string");return r(e)}},function(e,n,t){"use strict";var a=t(1),r=t(7),i=a.document,o=r(i)&&r(i.createElement);e.exports=function(e){return o?i.createElement(e):{}}},function(e,n,t){"use strict";var a=t(5),r=t(4);e.exports=a&&r((function(){return 42!==Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(e,n,t){"use strict";var a=t(3),r=t(4),i=t(2),o=t(10),s=t(5),l=t(113).CONFIGURABLE,c=t(114),d=t(115),u=d.enforce,p=d.get,m=String,h=Object.defineProperty,f=a("".slice),g=a("".replace),v=a([].join),b=s&&!r((function(){return 8!==h((function(){}),"length",{value:8}).length})),y=String(String).split("String"),w=e.exports=function(e,n,t){"Symbol("===f(m(n),0,7)&&(n="["+g(m(n),/^Symbol\(([^)]*)\).*$/,"$1")+"]"),t&&t.getter&&(n="get "+n),t&&t.setter&&(n="set "+n),(!o(e,"name")||l&&e.name!==n)&&(s?h(e,"name",{value:n,configurable:!0}):e.name=n),b&&t&&o(t,"arity")&&e.length!==t.arity&&h(e,"length",{value:t.arity});try{t&&o(t,"constructor")&&t.constructor?s&&h(e,"prototype",{writable:!1}):e.prototype&&(e.prototype=void 0)}catch(e){}var a=u(e);return o(a,"source")||(a.source=v(y,"string"==typeof n?n:"")),e};Function.prototype.toString=w((function(){return i(this)&&p(this).source||c(this)}),"toString")},function(e,n,t){"use strict";var a=t(61),r=t(63),i=a("keys");e.exports=function(e){return i[e]||(i[e]=r(e))}},function(e,n,t){"use strict";var a=t(3),r=t(10),i=t(28),o=t(119).indexOf,s=t(51),l=a([].push);e.exports=function(e,n){var t,a=i(e),c=0,d=[];for(t in a)!r(s,t)&&r(a,t)&&l(d,t);for(;n.length>c;)r(a,t=n[c++])&&(~o(d,t)||l(d,t));return d}},function(e,n){e.exports=function(e){var n=null==e?0:e.length;return n?e[n-1]:void 0}},function(e,n,t){e.exports=t(248)},function(e,n,t){"use strict";var a=t(26),r=t(125).left,i=t(126),o=t(60);a({target:"Array",proto:!0,forced:!t(127)&&o>79&&o<83||!i("reduce")},{reduce:function(e){var n=arguments.length;return r(this,e,n,n>1?arguments[1]:void 0)}})},function(e,n,t){"use strict";var a={}.propertyIsEnumerable,r=Object.getOwnPropertyDescriptor,i=r&&!a.call({1:2},1);n.f=i?function(e){var n=r(this,e);return!!n&&n.enumerable}:a},function(e,n,t){"use strict";var a=t(34),r=t(7),i=t(56),o=t(110),s=t(112),l=t(31),c=TypeError,d=l("toPrimitive");e.exports=function(e,n){if(!r(e)||i(e))return e;var t,l=o(e,d);if(l){if(void 0===n&&(n="default"),t=a(l,e,n),!r(t)||i(t))return t;throw new c("Can't convert object to primitive value")}return void 0===n&&(n="number"),s(e,n)}},function(e,n,t){"use strict";e.exports="undefined"!=typeof navigator&&String(navigator.userAgent)||""},function(e,n,t){"use strict";var a=t(30),r=t(54);e.exports=function(e,n){var t=e[n];return r(t)?void 0:a(t)}},function(e,n,t){"use strict";var a=String;e.exports=function(e){try{return a(e)}catch(e){return"Object"}}},function(e,n,t){"use strict";var a=t(34),r=t(2),i=t(7),o=TypeError;e.exports=function(e,n){var t,s;if("string"===n&&r(t=e.toString)&&!i(s=a(t,e)))return s;if(r(t=e.valueOf)&&!i(s=a(t,e)))return s;if("string"!==n&&r(t=e.toString)&&!i(s=a(t,e)))return s;throw new o("Can't convert object to primitive value")}},function(e,n,t){"use strict";var a=t(5),r=t(10),i=Function.prototype,o=a&&Object.getOwnPropertyDescriptor,s=r(i,"name"),l=s&&"something"===function(){}.name,c=s&&(!a||a&&o(i,"name").configurable);e.exports={EXISTS:s,PROPER:l,CONFIGURABLE:c}},function(e,n,t){"use strict";var a=t(3),r=t(2),i=t(37),o=a(Function.toString);r(i.inspectSource)||(i.inspectSource=function(e){return o(e)}),e.exports=i.inspectSource},function(e,n,t){"use strict";var a,r,i,o=t(116),s=t(1),l=t(7),c=t(15),d=t(10),u=t(37),p=t(102),m=t(51),h=s.TypeError,f=s.WeakMap;if(o||u.state){var g=u.state||(u.state=new f);g.get=g.get,g.has=g.has,g.set=g.set,a=function(e,n){if(g.has(e))throw new h("Object already initialized");return n.facade=e,g.set(e,n),n},r=function(e){return g.get(e)||{}},i=function(e){return g.has(e)}}else{var v=p("state");m[v]=!0,a=function(e,n){if(d(e,v))throw new h("Object already initialized");return n.facade=e,c(e,v,n),n},r=function(e){return d(e,v)?e[v]:{}},i=function(e){return d(e,v)}}e.exports={set:a,get:r,has:i,enforce:function(e){return i(e)?r(e):a(e,{})},getterFor:function(e){return function(n){var t;if(!l(n)||(t=r(n)).type!==e)throw new h("Incompatible receiver, "+e+" required");return t}}}},function(e,n,t){"use strict";var a=t(1),r=t(2),i=a.WeakMap;e.exports=r(i)&&/native code/.test(String(i))},function(e,n,t){"use strict";var a=t(29),r=t(3),i=t(118),o=t(123),s=t(48),l=r([].concat);e.exports=a("Reflect","ownKeys")||function(e){var n=i.f(s(e)),t=o.f;return t?l(n,t(e)):n}},function(e,n,t){"use strict";var a=t(103),r=t(97).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(e){return a(e,r)}},function(e,n,t){"use strict";var a=t(28),r=t(120),i=t(33),o=function(e){return function(n,t,o){var s=a(n),l=i(s);if(0===l)return!e&&-1;var c,d=r(o,l);if(e&&t!=t){for(;l>d;)if((c=s[d++])!=c)return!0}else for(;l>d;d++)if((e||d in s)&&s[d]===t)return e||d||0;return!e&&-1}};e.exports={includes:o(!0),indexOf:o(!1)}},function(e,n,t){"use strict";var a=t(66),r=Math.max,i=Math.min;e.exports=function(e,n){var t=a(e);return t<0?r(t+n,0):i(t,n)}},function(e,n,t){"use strict";var a=Math.ceil,r=Math.floor;e.exports=Math.trunc||function(e){var n=+e;return(n>0?r:a)(n)}},function(e,n,t){"use strict";var a=t(66),r=Math.min;e.exports=function(e){var n=a(e);return n>0?r(n,9007199254740991):0}},function(e,n,t){"use strict";n.f=Object.getOwnPropertySymbols},function(e,n,t){"use strict";var a=t(4),r=t(2),i=/#|\.prototype\./,o=function(e,n){var t=l[s(e)];return t===d||t!==c&&(r(n)?a(n):!!n)},s=o.normalize=function(e){return String(e).replace(i,".").toLowerCase()},l=o.data={},c=o.NATIVE="N",d=o.POLYFILL="P";e.exports=o},function(e,n,t){"use strict";var a=t(30),r=t(32),i=t(50),o=t(33),s=TypeError,l="Reduce of empty array with no initial value",c=function(e){return function(n,t,c,d){var u=r(n),p=i(u),m=o(u);if(a(t),0===m&&c<2)throw new s(l);var h=e?m-1:0,f=e?-1:1;if(c<2)for(;;){if(h in p){d=p[h],h+=f;break}if(h+=f,e?h<0:m<=h)throw new s(l)}for(;e?h>=0:m>h;h+=f)h in p&&(d=t(d,p[h],h,u));return d}};e.exports={left:c(!1),right:c(!0)}},function(e,n,t){"use strict";var a=t(4);e.exports=function(e,n){var t=[][e];return!!t&&a((function(){t.call(null,n||function(){return 1},1)}))}},function(e,n,t){"use strict";var a=t(1),r=t(19);e.exports="process"===r(a.process)},function(e,n,t){"use strict";var a=t(26),r=t(1),i=t(129),o=t(130),s=r.WebAssembly,l=7!==new Error("e",{cause:7}).cause,c=function(e,n){var t={};t[e]=o(e,n,l),a({global:!0,constructor:!0,arity:1,forced:l},t)},d=function(e,n){if(s&&s[e]){var t={};t[e]=o("WebAssembly."+e,n,l),a({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:l},t)}};c("Error",(function(e){return function(n){return i(e,this,arguments)}})),c("EvalError",(function(e){return function(n){return i(e,this,arguments)}})),c("RangeError",(function(e){return function(n){return i(e,this,arguments)}})),c("ReferenceError",(function(e){return function(n){return i(e,this,arguments)}})),c("SyntaxError",(function(e){return function(n){return i(e,this,arguments)}})),c("TypeError",(function(e){return function(n){return i(e,this,arguments)}})),c("URIError",(function(e){return function(n){return i(e,this,arguments)}})),d("CompileError",(function(e){return function(n){return i(e,this,arguments)}})),d("LinkError",(function(e){return function(n){return i(e,this,arguments)}})),d("RuntimeError",(function(e){return function(n){return i(e,this,arguments)}}))},function(e,n,t){"use strict";var a=t(27),r=Function.prototype,i=r.apply,o=r.call;e.exports="object"==typeof Reflect&&Reflect.apply||(a?o.bind(i):function(){return o.apply(i,arguments)})},function(e,n,t){"use strict";var a=t(29),r=t(10),i=t(15),o=t(57),s=t(67),l=t(65),c=t(134),d=t(135),u=t(136),p=t(139),m=t(140),h=t(5),f=t(62);e.exports=function(e,n,t,g){var v=g?2:1,b=e.split("."),y=b[b.length-1],w=a.apply(null,b);if(w){var _=w.prototype;if(!f&&r(_,"cause")&&delete _.cause,!t)return w;var x=a("Error"),k=n((function(e,n){var t=u(g?n:e,void 0),a=g?new w(e):new w;return void 0!==t&&i(a,"message",t),m(a,k,a.stack,2),this&&o(_,this)&&d(a,this,k),arguments.length>v&&p(a,arguments[v]),a}));if(k.prototype=_,"Error"!==y?s?s(k,x):l(k,x,{name:!0}):h&&"stackTraceLimit"in w&&(c(k,w,"stackTraceLimit"),c(k,w,"prepareStackTrace")),l(k,w),!f)try{_.name!==y&&i(_,"name",y),_.constructor=k}catch(e){}return k}}},function(e,n,t){"use strict";var a=t(3),r=t(30);e.exports=function(e,n,t){try{return a(r(Object.getOwnPropertyDescriptor(e,n)[t]))}catch(e){}}},function(e,n,t){"use strict";var a=t(133),r=String,i=TypeError;e.exports=function(e){if(a(e))return e;throw new i("Can't set "+r(e)+" as a prototype")}},function(e,n,t){"use strict";var a=t(7);e.exports=function(e){return a(e)||null===e}},function(e,n,t){"use strict";var a=t(18).f;e.exports=function(e,n,t){t in e||a(e,t,{configurable:!0,get:function(){return n[t]},set:function(e){n[t]=e}})}},function(e,n,t){"use strict";var a=t(2),r=t(7),i=t(67);e.exports=function(e,n,t){var o,s;return i&&a(o=n.constructor)&&o!==t&&r(s=o.prototype)&&s!==t.prototype&&i(e,s),e}},function(e,n,t){"use strict";var a=t(98);e.exports=function(e,n){return void 0===e?arguments.length<2?"":n:a(e)}},function(e,n,t){"use strict";var a=t(138),r=t(2),i=t(19),o=t(31)("toStringTag"),s=Object,l="Arguments"===i(function(){return arguments}());e.exports=a?i:function(e){var n,t,a;return void 0===e?"Undefined":null===e?"Null":"string"==typeof(t=function(e,n){try{return e[n]}catch(e){}}(n=s(e),o))?t:l?i(n):"Object"===(a=i(n))&&r(n.callee)?"Arguments":a}},function(e,n,t){"use strict";var a={};a[t(31)("toStringTag")]="z",e.exports="[object z]"===String(a)},function(e,n,t){"use strict";var a=t(7),r=t(15);e.exports=function(e,n){a(n)&&"cause"in n&&r(e,"cause",n.cause)}},function(e,n,t){"use strict";var a=t(15),r=t(141),i=t(142),o=Error.captureStackTrace;e.exports=function(e,n,t,s){i&&(o?o(e,n):a(e,"stack",r(t,s)))}},function(e,n,t){"use strict";var a=t(3),r=Error,i=a("".replace),o=String(new r("zxcasd").stack),s=/\n\s*at [^:]*:[^\n]*/,l=s.test(o);e.exports=function(e,n){if(l&&"string"==typeof e&&!r.prepareStackTrace)for(;n--;)e=i(e,s,"");return e}},function(e,n,t){"use strict";var a=t(4),r=t(35);e.exports=!a((function(){var e=new Error("a");return!("stack"in e)||(Object.defineProperty(e,"stack",r(1,7)),7!==e.stack)}))},function(e,n,t){"use strict";var a=t(5),r=t(144),i=TypeError,o=Object.getOwnPropertyDescriptor,s=a&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(e){return e instanceof TypeError}}();e.exports=s?function(e,n){if(r(e)&&!o(e,"length").writable)throw new i("Cannot set read only .length");return e.length=n}:function(e,n){return e.length=n}},function(e,n,t){"use strict";var a=t(19);e.exports=Array.isArray||function(e){return"Array"===a(e)}},function(e,n,t){"use strict";var a=TypeError;e.exports=function(e){if(e>9007199254740991)throw a("Maximum allowed index exceeded");return e}},function(e,n,t){var a=t(68),r=t(147);e.exports=function e(n,t,i,o,s){var l=-1,c=n.length;for(i||(i=r),s||(s=[]);++l<c;){var d=n[l];t>0&&i(d)?t>1?e(d,t-1,i,o,s):a(s,d):o||(s[s.length]=d)}return s}},function(e,n,t){var a=t(16),r=t(39),i=t(6),o=a?a.isConcatSpreadable:void 0;e.exports=function(e){return i(e)||r(e)||!!(o&&e&&e[o])}},function(e,n,t){var a=t(14),r=t(13);e.exports=function(e){return r(e)&&"[object Arguments]"==a(e)}},function(e,n,t){var a=t(16),r=Object.prototype,i=r.hasOwnProperty,o=r.toString,s=a?a.toStringTag:void 0;e.exports=function(e){var n=i.call(e,s),t=e[s];try{e[s]=void 0;var a=!0}catch(e){}var r=o.call(e);return a&&(n?e[s]=t:delete e[s]),r}},function(e,n){var t=Object.prototype.toString;e.exports=function(e){return t.call(e)}},function(e,n,t){var a=t(152),r=t(208),i=t(47),o=t(6),s=t(219);e.exports=function(e){return"function"==typeof e?e:null==e?i:"object"==typeof e?o(e)?r(e[0],e[1]):a(e):s(e)}},function(e,n,t){var a=t(153),r=t(207),i=t(85);e.exports=function(e){var n=r(e);return 1==n.length&&n[0][2]?i(n[0][0],n[0][1]):function(t){return t===e||a(t,e,n)}}},function(e,n,t){var a=t(70),r=t(74);e.exports=function(e,n,t,i){var o=t.length,s=o,l=!i;if(null==e)return!s;for(e=Object(e);o--;){var c=t[o];if(l&&c[2]?c[1]!==e[c[0]]:!(c[0]in e))return!1}for(;++o<s;){var d=(c=t[o])[0],u=e[d],p=c[1];if(l&&c[2]){if(void 0===u&&!(d in e))return!1}else{var m=new a;if(i)var h=i(u,p,d,e,n,m);if(!(void 0===h?r(p,u,3,i,m):h))return!1}}return!0}},function(e,n){e.exports=function(){this.__data__=[],this.size=0}},function(e,n,t){var a=t(21),r=Array.prototype.splice;e.exports=function(e){var n=this.__data__,t=a(n,e);return!(t<0)&&(t==n.length-1?n.pop():r.call(n,t,1),--this.size,!0)}},function(e,n,t){var a=t(21);e.exports=function(e){var n=this.__data__,t=a(n,e);return t<0?void 0:n[t][1]}},function(e,n,t){var a=t(21);e.exports=function(e){return a(this.__data__,e)>-1}},function(e,n,t){var a=t(21);e.exports=function(e,n){var t=this.__data__,r=a(t,e);return r<0?(++this.size,t.push([e,n])):t[r][1]=n,this}},function(e,n,t){var a=t(20);e.exports=function(){this.__data__=new a,this.size=0}},function(e,n){e.exports=function(e){var n=this.__data__,t=n.delete(e);return this.size=n.size,t}},function(e,n){e.exports=function(e){return this.__data__.get(e)}},function(e,n){e.exports=function(e){return this.__data__.has(e)}},function(e,n,t){var a=t(20),r=t(40),i=t(42);e.exports=function(e,n){var t=this.__data__;if(t instanceof a){var o=t.__data__;if(!r||o.length<199)return o.push([e,n]),this.size=++t.size,this;t=this.__data__=new i(o)}return t.set(e,n),this.size=t.size,this}},function(e,n,t){var a=t(72),r=t(165),i=t(41),o=t(73),s=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,d=l.toString,u=c.hasOwnProperty,p=RegExp("^"+d.call(u).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");e.exports=function(e){return!(!i(e)||r(e))&&(a(e)?p:s).test(o(e))}},function(e,n,t){var a,r=t(166),i=(a=/[^.]+$/.exec(r&&r.keys&&r.keys.IE_PROTO||""))?"Symbol(src)_1."+a:"";e.exports=function(e){return!!i&&i in e}},function(e,n,t){var a=t(8)["__core-js_shared__"];e.exports=a},function(e,n){e.exports=function(e,n){return null==e?void 0:e[n]}},function(e,n,t){var a=t(169),r=t(20),i=t(40);e.exports=function(){this.size=0,this.__data__={hash:new a,map:new(i||r),string:new a}}},function(e,n,t){var a=t(170),r=t(171),i=t(172),o=t(173),s=t(174);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var a=e[n];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,e.exports=l},function(e,n,t){var a=t(22);e.exports=function(){this.__data__=a?a(null):{},this.size=0}},function(e,n){e.exports=function(e){var n=this.has(e)&&delete this.__data__[e];return this.size-=n?1:0,n}},function(e,n,t){var a=t(22),r=Object.prototype.hasOwnProperty;e.exports=function(e){var n=this.__data__;if(a){var t=n[e];return"__lodash_hash_undefined__"===t?void 0:t}return r.call(n,e)?n[e]:void 0}},function(e,n,t){var a=t(22),r=Object.prototype.hasOwnProperty;e.exports=function(e){var n=this.__data__;return a?void 0!==n[e]:r.call(n,e)}},function(e,n,t){var a=t(22);e.exports=function(e,n){var t=this.__data__;return this.size+=this.has(e)?0:1,t[e]=a&&void 0===n?"__lodash_hash_undefined__":n,this}},function(e,n,t){var a=t(23);e.exports=function(e){var n=a(this,e).delete(e);return this.size-=n?1:0,n}},function(e,n){e.exports=function(e){var n=typeof e;return"string"==n||"number"==n||"symbol"==n||"boolean"==n?"__proto__"!==e:null===e}},function(e,n,t){var a=t(23);e.exports=function(e){return a(this,e).get(e)}},function(e,n,t){var a=t(23);e.exports=function(e){return a(this,e).has(e)}},function(e,n,t){var a=t(23);e.exports=function(e,n){var t=a(this,e),r=t.size;return t.set(e,n),this.size+=t.size==r?0:1,this}},function(e,n,t){var a=t(70),r=t(75),i=t(184),o=t(187),s=t(203),l=t(6),c=t(79),d=t(81),u="[object Object]",p=Object.prototype.hasOwnProperty;e.exports=function(e,n,t,m,h,f){var g=l(e),v=l(n),b=g?"[object Array]":s(e),y=v?"[object Array]":s(n),w=(b="[object Arguments]"==b?u:b)==u,_=(y="[object Arguments]"==y?u:y)==u,x=b==y;if(x&&c(e)){if(!c(n))return!1;g=!0,w=!1}if(x&&!w)return f||(f=new a),g||d(e)?r(e,n,t,m,h,f):i(e,n,b,t,m,h,f);if(!(1&t)){var k=w&&p.call(e,"__wrapped__"),T=_&&p.call(n,"__wrapped__");if(k||T){var E=k?e.value():e,S=T?n.value():n;return f||(f=new a),h(E,S,t,m,f)}}return!!x&&(f||(f=new a),o(e,n,t,m,h,f))}},function(e,n){e.exports=function(e){return this.__data__.set(e,"__lodash_hash_undefined__"),this}},function(e,n){e.exports=function(e){return this.__data__.has(e)}},function(e,n){e.exports=function(e,n){for(var t=-1,a=null==e?0:e.length;++t<a;)if(n(e[t],t,e))return!0;return!1}},function(e,n,t){var a=t(16),r=t(185),i=t(71),o=t(75),s=t(186),l=t(43),c=a?a.prototype:void 0,d=c?c.valueOf:void 0;e.exports=function(e,n,t,a,c,u,p){switch(t){case"[object DataView]":if(e.byteLength!=n.byteLength||e.byteOffset!=n.byteOffset)return!1;e=e.buffer,n=n.buffer;case"[object ArrayBuffer]":return!(e.byteLength!=n.byteLength||!u(new r(e),new r(n)));case"[object Boolean]":case"[object Date]":case"[object Number]":return i(+e,+n);case"[object Error]":return e.name==n.name&&e.message==n.message;case"[object RegExp]":case"[object String]":return e==n+"";case"[object Map]":var m=s;case"[object Set]":var h=1&a;if(m||(m=l),e.size!=n.size&&!h)return!1;var f=p.get(e);if(f)return f==n;a|=2,p.set(e,n);var g=o(m(e),m(n),a,c,u,p);return p.delete(e),g;case"[object Symbol]":if(d)return d.call(e)==d.call(n)}return!1}},function(e,n,t){var a=t(8).Uint8Array;e.exports=a},function(e,n){e.exports=function(e){var n=-1,t=Array(e.size);return e.forEach((function(e,a){t[++n]=[a,e]})),t}},function(e,n,t){var a=t(188),r=Object.prototype.hasOwnProperty;e.exports=function(e,n,t,i,o,s){var l=1&t,c=a(e),d=c.length;if(d!=a(n).length&&!l)return!1;for(var u=d;u--;){var p=c[u];if(!(l?p in n:r.call(n,p)))return!1}var m=s.get(e),h=s.get(n);if(m&&h)return m==n&&h==e;var f=!0;s.set(e,n),s.set(n,e);for(var g=l;++u<d;){var v=e[p=c[u]],b=n[p];if(i)var y=l?i(b,v,p,n,e,s):i(v,b,p,e,n,s);if(!(void 0===y?v===b||o(v,b,t,i,s):y)){f=!1;break}g||(g="constructor"==p)}if(f&&!g){var w=e.constructor,_=n.constructor;w==_||!("constructor"in e)||!("constructor"in n)||"function"==typeof w&&w instanceof w&&"function"==typeof _&&_ instanceof _||(f=!1)}return s.delete(e),s.delete(n),f}},function(e,n,t){var a=t(189),r=t(190),i=t(78);e.exports=function(e){return a(e,i,r)}},function(e,n,t){var a=t(68),r=t(6);e.exports=function(e,n,t){var i=n(e);return r(e)?i:a(i,t(e))}},function(e,n,t){var a=t(191),r=t(192),i=Object.prototype.propertyIsEnumerable,o=Object.getOwnPropertySymbols,s=o?function(e){return null==e?[]:(e=Object(e),a(o(e),(function(n){return i.call(e,n)})))}:r;e.exports=s},function(e,n){e.exports=function(e,n){for(var t=-1,a=null==e?0:e.length,r=0,i=[];++t<a;){var o=e[t];n(o,t,e)&&(i[r++]=o)}return i}},function(e,n){e.exports=function(){return[]}},function(e,n,t){var a=t(194),r=t(39),i=t(6),o=t(79),s=t(80),l=t(81),c=Object.prototype.hasOwnProperty;e.exports=function(e,n){var t=i(e),d=!t&&r(e),u=!t&&!d&&o(e),p=!t&&!d&&!u&&l(e),m=t||d||u||p,h=m?a(e.length,String):[],f=h.length;for(var g in e)!n&&!c.call(e,g)||m&&("length"==g||u&&("offset"==g||"parent"==g)||p&&("buffer"==g||"byteLength"==g||"byteOffset"==g)||s(g,f))||h.push(g);return h}},function(e,n){e.exports=function(e,n){for(var t=-1,a=Array(e);++t<e;)a[t]=n(t);return a}},function(e,n){e.exports=function(){return!1}},function(e,n,t){var a=t(14),r=t(44),i=t(13),o={};o["[object Float32Array]"]=o["[object Float64Array]"]=o["[object Int8Array]"]=o["[object Int16Array]"]=o["[object Int32Array]"]=o["[object Uint8Array]"]=o["[object Uint8ClampedArray]"]=o["[object Uint16Array]"]=o["[object Uint32Array]"]=!0,o["[object Arguments]"]=o["[object Array]"]=o["[object ArrayBuffer]"]=o["[object Boolean]"]=o["[object DataView]"]=o["[object Date]"]=o["[object Error]"]=o["[object Function]"]=o["[object Map]"]=o["[object Number]"]=o["[object Object]"]=o["[object RegExp]"]=o["[object Set]"]=o["[object String]"]=o["[object WeakMap]"]=!1,e.exports=function(e){return i(e)&&r(e.length)&&!!o[a(e)]}},function(e,n){e.exports=function(e){return function(n){return e(n)}}},function(e,n,t){(function(e){var a=t(69),r=n&&!n.nodeType&&n,i=r&&"object"==typeof e&&e&&!e.nodeType&&e,o=i&&i.exports===r&&a.process,s=function(){try{var e=i&&i.require&&i.require("util").types;return e||o&&o.binding&&o.binding("util")}catch(e){}}();e.exports=s}).call(this,t(49)(e))},function(e,n,t){var a=t(200),r=t(201),i=Object.prototype.hasOwnProperty;e.exports=function(e){if(!a(e))return r(e);var n=[];for(var t in Object(e))i.call(e,t)&&"constructor"!=t&&n.push(t);return n}},function(e,n){var t=Object.prototype;e.exports=function(e){var n=e&&e.constructor;return e===("function"==typeof n&&n.prototype||t)}},function(e,n,t){var a=t(202)(Object.keys,Object);e.exports=a},function(e,n){e.exports=function(e,n){return function(t){return e(n(t))}}},function(e,n,t){var a=t(204),r=t(40),i=t(205),o=t(83),s=t(206),l=t(14),c=t(73),d=c(a),u=c(r),p=c(i),m=c(o),h=c(s),f=l;(a&&"[object DataView]"!=f(new a(new ArrayBuffer(1)))||r&&"[object Map]"!=f(new r)||i&&"[object Promise]"!=f(i.resolve())||o&&"[object Set]"!=f(new o)||s&&"[object WeakMap]"!=f(new s))&&(f=function(e){var n=l(e),t="[object Object]"==n?e.constructor:void 0,a=t?c(t):"";if(a)switch(a){case d:return"[object DataView]";case u:return"[object Map]";case p:return"[object Promise]";case m:return"[object Set]";case h:return"[object WeakMap]"}return n}),e.exports=f},function(e,n,t){var a=t(11)(t(8),"DataView");e.exports=a},function(e,n,t){var a=t(11)(t(8),"Promise");e.exports=a},function(e,n,t){var a=t(11)(t(8),"WeakMap");e.exports=a},function(e,n,t){var a=t(84),r=t(78);e.exports=function(e){for(var n=r(e),t=n.length;t--;){var i=n[t],o=e[i];n[t]=[i,o,a(o)]}return n}},function(e,n,t){var a=t(74),r=t(209),i=t(216),o=t(45),s=t(84),l=t(85),c=t(24);e.exports=function(e,n){return o(e)&&s(n)?l(c(e),n):function(t){var o=r(t,e);return void 0===o&&o===n?i(t,e):a(n,o,3)}}},function(e,n,t){var a=t(86);e.exports=function(e,n,t){var r=null==e?void 0:a(e,n);return void 0===r?t:r}},function(e,n,t){var a=t(211),r=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,i=/\\(\\)?/g,o=a((function(e){var n=[];return 46===e.charCodeAt(0)&&n.push(""),e.replace(r,(function(e,t,a,r){n.push(a?r.replace(i,"$1"):t||e)})),n}));e.exports=o},function(e,n,t){var a=t(212);e.exports=function(e){var n=a(e,(function(e){return 500===t.size&&t.clear(),e})),t=n.cache;return n}},function(e,n,t){var a=t(42);function r(e,n){if("function"!=typeof e||null!=n&&"function"!=typeof n)throw new TypeError("Expected a function");var t=function(){var a=arguments,r=n?n.apply(this,a):a[0],i=t.cache;if(i.has(r))return i.get(r);var o=e.apply(this,a);return t.cache=i.set(r,o)||i,o};return t.cache=new(r.Cache||a),t}r.Cache=a,e.exports=r},function(e,n,t){var a=t(214);e.exports=function(e){return null==e?"":a(e)}},function(e,n,t){var a=t(16),r=t(215),i=t(6),o=t(46),s=a?a.prototype:void 0,l=s?s.toString:void 0;e.exports=function e(n){if("string"==typeof n)return n;if(i(n))return r(n,e)+"";if(o(n))return l?l.call(n):"";var t=n+"";return"0"==t&&1/n==-1/0?"-0":t}},function(e,n){e.exports=function(e,n){for(var t=-1,a=null==e?0:e.length,r=Array(a);++t<a;)r[t]=n(e[t],t,e);return r}},function(e,n,t){var a=t(217),r=t(218);e.exports=function(e,n){return null!=e&&r(e,n,a)}},function(e,n){e.exports=function(e,n){return null!=e&&n in Object(e)}},function(e,n,t){var a=t(87),r=t(39),i=t(6),o=t(80),s=t(44),l=t(24);e.exports=function(e,n,t){for(var c=-1,d=(n=a(n,e)).length,u=!1;++c<d;){var p=l(n[c]);if(!(u=null!=e&&t(e,p)))break;e=e[p]}return u||++c!=d?u:!!(d=null==e?0:e.length)&&s(d)&&o(p,d)&&(i(e)||r(e))}},function(e,n,t){var a=t(220),r=t(221),i=t(45),o=t(24);e.exports=function(e){return i(e)?a(o(e)):r(e)}},function(e,n){e.exports=function(e){return function(n){return null==n?void 0:n[e]}}},function(e,n,t){var a=t(86);e.exports=function(e){return function(n){return a(n,e)}}},function(e,n,t){var a=t(47),r=t(223),i=t(225);e.exports=function(e,n){return i(r(e,n,a),e+"")}},function(e,n,t){var a=t(224),r=Math.max;e.exports=function(e,n,t){return n=r(void 0===n?e.length-1:n,0),function(){for(var i=arguments,o=-1,s=r(i.length-n,0),l=Array(s);++o<s;)l[o]=i[n+o];o=-1;for(var c=Array(n+1);++o<n;)c[o]=i[o];return c[n]=t(l),a(e,this,c)}}},function(e,n){e.exports=function(e,n,t){switch(t.length){case 0:return e.call(n);case 1:return e.call(n,t[0]);case 2:return e.call(n,t[0],t[1]);case 3:return e.call(n,t[0],t[1],t[2])}return e.apply(n,t)}},function(e,n,t){var a=t(226),r=t(229)(a);e.exports=r},function(e,n,t){var a=t(227),r=t(228),i=t(47),o=r?function(e,n){return r(e,"toString",{configurable:!0,enumerable:!1,value:a(n),writable:!0})}:i;e.exports=o},function(e,n){e.exports=function(e){return function(){return e}}},function(e,n,t){var a=t(11),r=function(){try{var e=a(Object,"defineProperty");return e({},"",{}),e}catch(e){}}();e.exports=r},function(e,n){var t=Date.now;e.exports=function(e){var n=0,a=0;return function(){var r=t(),i=16-(r-a);if(a=r,i>0){if(++n>=800)return arguments[0]}else n=0;return e.apply(void 0,arguments)}}},function(e,n,t){var a=t(76),r=t(231),i=t(236),o=t(77),s=t(237),l=t(43);e.exports=function(e,n,t){var c=-1,d=r,u=e.length,p=!0,m=[],h=m;if(t)p=!1,d=i;else if(u>=200){var f=n?null:s(e);if(f)return l(f);p=!1,d=o,h=new a}else h=n?[]:m;e:for(;++c<u;){var g=e[c],v=n?n(g):g;if(g=t||0!==g?g:0,p&&v==v){for(var b=h.length;b--;)if(h[b]===v)continue e;n&&h.push(v),m.push(g)}else d(h,v,t)||(h!==m&&h.push(v),m.push(g))}return m}},function(e,n,t){var a=t(232);e.exports=function(e,n){return!!(null==e?0:e.length)&&a(e,n,0)>-1}},function(e,n,t){var a=t(233),r=t(234),i=t(235);e.exports=function(e,n,t){return n==n?i(e,n,t):a(e,r,t)}},function(e,n){e.exports=function(e,n,t,a){for(var r=e.length,i=t+(a?1:-1);a?i--:++i<r;)if(n(e[i],i,e))return i;return-1}},function(e,n){e.exports=function(e){return e!=e}},function(e,n){e.exports=function(e,n,t){for(var a=t-1,r=e.length;++a<r;)if(e[a]===n)return a;return-1}},function(e,n){e.exports=function(e,n,t){for(var a=-1,r=null==e?0:e.length;++a<r;)if(t(n,e[a]))return!0;return!1}},function(e,n,t){var a=t(83),r=t(238),i=t(43),o=a&&1/i(new a([,-0]))[1]==1/0?function(e){return new a(e)}:r;e.exports=o},function(e,n){e.exports=function(){}},function(e,n,t){var a=t(82),r=t(13);e.exports=function(e){return r(e)&&a(e)}},function(e,n,t){},function(e,n,t){},function(e,n,t){"use strict";t(88)},function(e,n,t){"use strict";t(89)},function(e,n,t){},function(e,n,t){},function(e,n,t){"use strict";t(90)},function(e,n,t){"use strict";t(91)},function(e,n,t){"use strict";t.r(n);var a=t(0);
/*!
  * vue-router v3.6.5
  * (c) 2022 Evan You
  * @license MIT
  */function r(e,n){for(var t in n)e[t]=n[t];return e}var i=/[!'()*]/g,o=function(e){return"%"+e.charCodeAt(0).toString(16)},s=/%2C/g,l=function(e){return encodeURIComponent(e).replace(i,o).replace(s,",")};function c(e){try{return decodeURIComponent(e)}catch(e){0}return e}var d=function(e){return null==e||"object"==typeof e?e:String(e)};function u(e){var n={};return(e=e.trim().replace(/^(\?|#|&)/,""))?(e.split("&").forEach((function(e){var t=e.replace(/\+/g," ").split("="),a=c(t.shift()),r=t.length>0?c(t.join("=")):null;void 0===n[a]?n[a]=r:Array.isArray(n[a])?n[a].push(r):n[a]=[n[a],r]})),n):n}function p(e){var n=e?Object.keys(e).map((function(n){var t=e[n];if(void 0===t)return"";if(null===t)return l(n);if(Array.isArray(t)){var a=[];return t.forEach((function(e){void 0!==e&&(null===e?a.push(l(n)):a.push(l(n)+"="+l(e)))})),a.join("&")}return l(n)+"="+l(t)})).filter((function(e){return e.length>0})).join("&"):null;return n?"?"+n:""}var m=/\/?$/;function h(e,n,t,a){var r=a&&a.options.stringifyQuery,i=n.query||{};try{i=f(i)}catch(e){}var o={name:n.name||e&&e.name,meta:e&&e.meta||{},path:n.path||"/",hash:n.hash||"",query:i,params:n.params||{},fullPath:b(n,r),matched:e?v(e):[]};return t&&(o.redirectedFrom=b(t,r)),Object.freeze(o)}function f(e){if(Array.isArray(e))return e.map(f);if(e&&"object"==typeof e){var n={};for(var t in e)n[t]=f(e[t]);return n}return e}var g=h(null,{path:"/"});function v(e){for(var n=[];e;)n.unshift(e),e=e.parent;return n}function b(e,n){var t=e.path,a=e.query;void 0===a&&(a={});var r=e.hash;return void 0===r&&(r=""),(t||"/")+(n||p)(a)+r}function y(e,n,t){return n===g?e===n:!!n&&(e.path&&n.path?e.path.replace(m,"")===n.path.replace(m,"")&&(t||e.hash===n.hash&&w(e.query,n.query)):!(!e.name||!n.name)&&(e.name===n.name&&(t||e.hash===n.hash&&w(e.query,n.query)&&w(e.params,n.params))))}function w(e,n){if(void 0===e&&(e={}),void 0===n&&(n={}),!e||!n)return e===n;var t=Object.keys(e).sort(),a=Object.keys(n).sort();return t.length===a.length&&t.every((function(t,r){var i=e[t];if(a[r]!==t)return!1;var o=n[t];return null==i||null==o?i===o:"object"==typeof i&&"object"==typeof o?w(i,o):String(i)===String(o)}))}function _(e){for(var n=0;n<e.matched.length;n++){var t=e.matched[n];for(var a in t.instances){var r=t.instances[a],i=t.enteredCbs[a];if(r&&i){delete t.enteredCbs[a];for(var o=0;o<i.length;o++)r._isBeingDestroyed||i[o](r)}}}}var x={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(e,n){var t=n.props,a=n.children,i=n.parent,o=n.data;o.routerView=!0;for(var s=i.$createElement,l=t.name,c=i.$route,d=i._routerViewCache||(i._routerViewCache={}),u=0,p=!1;i&&i._routerRoot!==i;){var m=i.$vnode?i.$vnode.data:{};m.routerView&&u++,m.keepAlive&&i._directInactive&&i._inactive&&(p=!0),i=i.$parent}if(o.routerViewDepth=u,p){var h=d[l],f=h&&h.component;return f?(h.configProps&&k(f,o,h.route,h.configProps),s(f,o,a)):s()}var g=c.matched[u],v=g&&g.components[l];if(!g||!v)return d[l]=null,s();d[l]={component:v},o.registerRouteInstance=function(e,n){var t=g.instances[l];(n&&t!==e||!n&&t===e)&&(g.instances[l]=n)},(o.hook||(o.hook={})).prepatch=function(e,n){g.instances[l]=n.componentInstance},o.hook.init=function(e){e.data.keepAlive&&e.componentInstance&&e.componentInstance!==g.instances[l]&&(g.instances[l]=e.componentInstance),_(c)};var b=g.props&&g.props[l];return b&&(r(d[l],{route:c,configProps:b}),k(v,o,c,b)),s(v,o,a)}};function k(e,n,t,a){var i=n.props=function(e,n){switch(typeof n){case"undefined":return;case"object":return n;case"function":return n(e);case"boolean":return n?e.params:void 0;default:0}}(t,a);if(i){i=n.props=r({},i);var o=n.attrs=n.attrs||{};for(var s in i)e.props&&s in e.props||(o[s]=i[s],delete i[s])}}function T(e,n,t){var a=e.charAt(0);if("/"===a)return e;if("?"===a||"#"===a)return n+e;var r=n.split("/");t&&r[r.length-1]||r.pop();for(var i=e.replace(/^\//,"").split("/"),o=0;o<i.length;o++){var s=i[o];".."===s?r.pop():"."!==s&&r.push(s)}return""!==r[0]&&r.unshift(""),r.join("/")}function E(e){return e.replace(/\/(?:\s*\/)+/g,"/")}var S=Array.isArray||function(e){return"[object Array]"==Object.prototype.toString.call(e)},I=F,A=N,C=function(e,n){return P(N(e,n),n)},j=P,O=J,L=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function N(e,n){for(var t,a=[],r=0,i=0,o="",s=n&&n.delimiter||"/";null!=(t=L.exec(e));){var l=t[0],c=t[1],d=t.index;if(o+=e.slice(i,d),i=d+l.length,c)o+=c[1];else{var u=e[i],p=t[2],m=t[3],h=t[4],f=t[5],g=t[6],v=t[7];o&&(a.push(o),o="");var b=null!=p&&null!=u&&u!==p,y="+"===g||"*"===g,w="?"===g||"*"===g,_=t[2]||s,x=h||f;a.push({name:m||r++,prefix:p||"",delimiter:_,optional:w,repeat:y,partial:b,asterisk:!!v,pattern:x?R(x):v?".*":"[^"+M(_)+"]+?"})}}return i<e.length&&(o+=e.substr(i)),o&&a.push(o),a}function D(e){return encodeURI(e).replace(/[\/?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()}))}function P(e,n){for(var t=new Array(e.length),a=0;a<e.length;a++)"object"==typeof e[a]&&(t[a]=new RegExp("^(?:"+e[a].pattern+")$",q(n)));return function(n,a){for(var r="",i=n||{},o=(a||{}).pretty?D:encodeURIComponent,s=0;s<e.length;s++){var l=e[s];if("string"!=typeof l){var c,d=i[l.name];if(null==d){if(l.optional){l.partial&&(r+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(S(d)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(d)+"`");if(0===d.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var u=0;u<d.length;u++){if(c=o(d[u]),!t[s].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");r+=(0===u?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(d).replace(/[?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()})):o(d),!t[s].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');r+=l.prefix+c}}else r+=l}return r}}function M(e){return e.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function R(e){return e.replace(/([=!:$\/()])/g,"\\$1")}function z(e,n){return e.keys=n,e}function q(e){return e&&e.sensitive?"":"i"}function J(e,n,t){S(n)||(t=n||t,n=[]);for(var a=(t=t||{}).strict,r=!1!==t.end,i="",o=0;o<e.length;o++){var s=e[o];if("string"==typeof s)i+=M(s);else{var l=M(s.prefix),c="(?:"+s.pattern+")";n.push(s),s.repeat&&(c+="(?:"+l+c+")*"),i+=c=s.optional?s.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var d=M(t.delimiter||"/"),u=i.slice(-d.length)===d;return a||(i=(u?i.slice(0,-d.length):i)+"(?:"+d+"(?=$))?"),i+=r?"$":a&&u?"":"(?="+d+"|$)",z(new RegExp("^"+i,q(t)),n)}function F(e,n,t){return S(n)||(t=n||t,n=[]),t=t||{},e instanceof RegExp?function(e,n){var t=e.source.match(/\((?!\?)/g);if(t)for(var a=0;a<t.length;a++)n.push({name:a,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return z(e,n)}(e,n):S(e)?function(e,n,t){for(var a=[],r=0;r<e.length;r++)a.push(F(e[r],n,t).source);return z(new RegExp("(?:"+a.join("|")+")",q(t)),n)}(e,n,t):function(e,n,t){return J(N(e,t),n,t)}(e,n,t)}I.parse=A,I.compile=C,I.tokensToFunction=j,I.tokensToRegExp=O;var B=Object.create(null);function U(e,n,t){n=n||{};try{var a=B[e]||(B[e]=I.compile(e));return"string"==typeof n.pathMatch&&(n[0]=n.pathMatch),a(n,{pretty:!0})}catch(e){return""}finally{delete n[0]}}function H(e,n,t,a){var i="string"==typeof e?{path:e}:e;if(i._normalized)return i;if(i.name){var o=(i=r({},e)).params;return o&&"object"==typeof o&&(i.params=r({},o)),i}if(!i.path&&i.params&&n){(i=r({},i))._normalized=!0;var s=r(r({},n.params),i.params);if(n.name)i.name=n.name,i.params=s;else if(n.matched.length){var l=n.matched[n.matched.length-1].path;i.path=U(l,s,n.path)}else 0;return i}var c=function(e){var n="",t="",a=e.indexOf("#");a>=0&&(n=e.slice(a),e=e.slice(0,a));var r=e.indexOf("?");return r>=0&&(t=e.slice(r+1),e=e.slice(0,r)),{path:e,query:t,hash:n}}(i.path||""),p=n&&n.path||"/",m=c.path?T(c.path,p,t||i.append):p,h=function(e,n,t){void 0===n&&(n={});var a,r=t||u;try{a=r(e||"")}catch(e){a={}}for(var i in n){var o=n[i];a[i]=Array.isArray(o)?o.map(d):d(o)}return a}(c.query,i.query,a&&a.options.parseQuery),f=i.hash||c.hash;return f&&"#"!==f.charAt(0)&&(f="#"+f),{_normalized:!0,path:m,query:h,hash:f}}var $,G=function(){},K={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(e){var n=this,t=this.$router,a=this.$route,i=t.resolve(this.to,a,this.append),o=i.location,s=i.route,l=i.href,c={},d=t.options.linkActiveClass,u=t.options.linkExactActiveClass,p=null==d?"router-link-active":d,f=null==u?"router-link-exact-active":u,g=null==this.activeClass?p:this.activeClass,v=null==this.exactActiveClass?f:this.exactActiveClass,b=s.redirectedFrom?h(null,H(s.redirectedFrom),null,t):s;c[v]=y(a,b,this.exactPath),c[g]=this.exact||this.exactPath?c[v]:function(e,n){return 0===e.path.replace(m,"/").indexOf(n.path.replace(m,"/"))&&(!n.hash||e.hash===n.hash)&&function(e,n){for(var t in n)if(!(t in e))return!1;return!0}(e.query,n.query)}(a,b);var w=c[v]?this.ariaCurrentValue:null,_=function(e){W(e)&&(n.replace?t.replace(o,G):t.push(o,G))},x={click:W};Array.isArray(this.event)?this.event.forEach((function(e){x[e]=_})):x[this.event]=_;var k={class:c},T=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:l,route:s,navigate:_,isActive:c[g],isExactActive:c[v]});if(T){if(1===T.length)return T[0];if(T.length>1||!T.length)return 0===T.length?e():e("span",{},T)}if("a"===this.tag)k.on=x,k.attrs={href:l,"aria-current":w};else{var E=function e(n){var t;if(n)for(var a=0;a<n.length;a++){if("a"===(t=n[a]).tag)return t;if(t.children&&(t=e(t.children)))return t}}(this.$slots.default);if(E){E.isStatic=!1;var S=E.data=r({},E.data);for(var I in S.on=S.on||{},S.on){var A=S.on[I];I in x&&(S.on[I]=Array.isArray(A)?A:[A])}for(var C in x)C in S.on?S.on[C].push(x[C]):S.on[C]=_;var j=E.data.attrs=r({},E.data.attrs);j.href=l,j["aria-current"]=w}else k.on=x}return e(this.tag,k,this.$slots.default)}};function W(e){if(!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey||e.defaultPrevented||void 0!==e.button&&0!==e.button)){if(e.currentTarget&&e.currentTarget.getAttribute){var n=e.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(n))return}return e.preventDefault&&e.preventDefault(),!0}}var Y="undefined"!=typeof window;function V(e,n,t,a,r){var i=n||[],o=t||Object.create(null),s=a||Object.create(null);e.forEach((function(e){!function e(n,t,a,r,i,o){var s=r.path,l=r.name;0;var c=r.pathToRegexpOptions||{},d=function(e,n,t){t||(e=e.replace(/\/$/,""));if("/"===e[0])return e;if(null==n)return e;return E(n.path+"/"+e)}(s,i,c.strict);"boolean"==typeof r.caseSensitive&&(c.sensitive=r.caseSensitive);var u={path:d,regex:Z(d,c),components:r.components||{default:r.component},alias:r.alias?"string"==typeof r.alias?[r.alias]:r.alias:[],instances:{},enteredCbs:{},name:l,parent:i,matchAs:o,redirect:r.redirect,beforeEnter:r.beforeEnter,meta:r.meta||{},props:null==r.props?{}:r.components?r.props:{default:r.props}};r.children&&r.children.forEach((function(r){var i=o?E(o+"/"+r.path):void 0;e(n,t,a,r,u,i)}));t[u.path]||(n.push(u.path),t[u.path]=u);if(void 0!==r.alias)for(var p=Array.isArray(r.alias)?r.alias:[r.alias],m=0;m<p.length;++m){0;var h={path:p[m],children:r.children};e(n,t,a,h,i,u.path||"/")}l&&(a[l]||(a[l]=u))}(i,o,s,e,r)}));for(var l=0,c=i.length;l<c;l++)"*"===i[l]&&(i.push(i.splice(l,1)[0]),c--,l--);return{pathList:i,pathMap:o,nameMap:s}}function Z(e,n){return I(e,[],n)}function Q(e,n){var t=V(e),a=t.pathList,r=t.pathMap,i=t.nameMap;function o(e,t,o){var s=H(e,t,!1,n),c=s.name;if(c){var d=i[c];if(!d)return l(null,s);var u=d.regex.keys.filter((function(e){return!e.optional})).map((function(e){return e.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var p in t.params)!(p in s.params)&&u.indexOf(p)>-1&&(s.params[p]=t.params[p]);return s.path=U(d.path,s.params),l(d,s,o)}if(s.path){s.params={};for(var m=0;m<a.length;m++){var h=a[m],f=r[h];if(X(f.regex,s.path,s.params))return l(f,s,o)}}return l(null,s)}function s(e,t){var a=e.redirect,r="function"==typeof a?a(h(e,t,null,n)):a;if("string"==typeof r&&(r={path:r}),!r||"object"!=typeof r)return l(null,t);var s=r,c=s.name,d=s.path,u=t.query,p=t.hash,m=t.params;if(u=s.hasOwnProperty("query")?s.query:u,p=s.hasOwnProperty("hash")?s.hash:p,m=s.hasOwnProperty("params")?s.params:m,c){i[c];return o({_normalized:!0,name:c,query:u,hash:p,params:m},void 0,t)}if(d){var f=function(e,n){return T(e,n.parent?n.parent.path:"/",!0)}(d,e);return o({_normalized:!0,path:U(f,m),query:u,hash:p},void 0,t)}return l(null,t)}function l(e,t,a){return e&&e.redirect?s(e,a||t):e&&e.matchAs?function(e,n,t){var a=o({_normalized:!0,path:U(t,n.params)});if(a){var r=a.matched,i=r[r.length-1];return n.params=a.params,l(i,n)}return l(null,n)}(0,t,e.matchAs):h(e,t,a,n)}return{match:o,addRoute:function(e,n){var t="object"!=typeof e?i[e]:void 0;V([n||e],a,r,i,t),t&&t.alias.length&&V(t.alias.map((function(e){return{path:e,children:[n]}})),a,r,i,t)},getRoutes:function(){return a.map((function(e){return r[e]}))},addRoutes:function(e){V(e,a,r,i)}}}function X(e,n,t){var a=n.match(e);if(!a)return!1;if(!t)return!0;for(var r=1,i=a.length;r<i;++r){var o=e.keys[r-1];o&&(t[o.name||"pathMatch"]="string"==typeof a[r]?c(a[r]):a[r])}return!0}var ee=Y&&window.performance&&window.performance.now?window.performance:Date;function ne(){return ee.now().toFixed(3)}var te=ne();function ae(){return te}function re(e){return te=e}var ie=Object.create(null);function oe(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var e=window.location.protocol+"//"+window.location.host,n=window.location.href.replace(e,""),t=r({},window.history.state);return t.key=ae(),window.history.replaceState(t,"",n),window.addEventListener("popstate",ce),function(){window.removeEventListener("popstate",ce)}}function se(e,n,t,a){if(e.app){var r=e.options.scrollBehavior;r&&e.app.$nextTick((function(){var i=function(){var e=ae();if(e)return ie[e]}(),o=r.call(e,n,t,a?i:null);o&&("function"==typeof o.then?o.then((function(e){he(e,i)})).catch((function(e){0})):he(o,i))}))}}function le(){var e=ae();e&&(ie[e]={x:window.pageXOffset,y:window.pageYOffset})}function ce(e){le(),e.state&&e.state.key&&re(e.state.key)}function de(e){return pe(e.x)||pe(e.y)}function ue(e){return{x:pe(e.x)?e.x:window.pageXOffset,y:pe(e.y)?e.y:window.pageYOffset}}function pe(e){return"number"==typeof e}var me=/^#\d/;function he(e,n){var t,a="object"==typeof e;if(a&&"string"==typeof e.selector){var r=me.test(e.selector)?document.getElementById(e.selector.slice(1)):document.querySelector(e.selector);if(r){var i=e.offset&&"object"==typeof e.offset?e.offset:{};n=function(e,n){var t=document.documentElement.getBoundingClientRect(),a=e.getBoundingClientRect();return{x:a.left-t.left-n.x,y:a.top-t.top-n.y}}(r,i={x:pe((t=i).x)?t.x:0,y:pe(t.y)?t.y:0})}else de(e)&&(n=ue(e))}else a&&de(e)&&(n=ue(e));n&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:n.x,top:n.y,behavior:e.behavior}):window.scrollTo(n.x,n.y))}var fe,ge=Y&&((-1===(fe=window.navigator.userAgent).indexOf("Android 2.")&&-1===fe.indexOf("Android 4.0")||-1===fe.indexOf("Mobile Safari")||-1!==fe.indexOf("Chrome")||-1!==fe.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function ve(e,n){le();var t=window.history;try{if(n){var a=r({},t.state);a.key=ae(),t.replaceState(a,"",e)}else t.pushState({key:re(ne())},"",e)}catch(t){window.location[n?"replace":"assign"](e)}}function be(e){ve(e,!0)}var ye={redirected:2,aborted:4,cancelled:8,duplicated:16};function we(e,n){return xe(e,n,ye.redirected,'Redirected when going from "'+e.fullPath+'" to "'+function(e){if("string"==typeof e)return e;if("path"in e)return e.path;var n={};return ke.forEach((function(t){t in e&&(n[t]=e[t])})),JSON.stringify(n,null,2)}(n)+'" via a navigation guard.')}function _e(e,n){return xe(e,n,ye.cancelled,'Navigation cancelled from "'+e.fullPath+'" to "'+n.fullPath+'" with a new navigation.')}function xe(e,n,t,a){var r=new Error(a);return r._isRouter=!0,r.from=e,r.to=n,r.type=t,r}var ke=["params","query","hash"];function Te(e){return Object.prototype.toString.call(e).indexOf("Error")>-1}function Ee(e,n){return Te(e)&&e._isRouter&&(null==n||e.type===n)}function Se(e,n,t){var a=function(r){r>=e.length?t():e[r]?n(e[r],(function(){a(r+1)})):a(r+1)};a(0)}function Ie(e){return function(n,t,a){var r=!1,i=0,o=null;Ae(e,(function(e,n,t,s){if("function"==typeof e&&void 0===e.cid){r=!0,i++;var l,c=Oe((function(n){var r;((r=n).__esModule||je&&"Module"===r[Symbol.toStringTag])&&(n=n.default),e.resolved="function"==typeof n?n:$.extend(n),t.components[s]=n,--i<=0&&a()})),d=Oe((function(e){var n="Failed to resolve async component "+s+": "+e;o||(o=Te(e)?e:new Error(n),a(o))}));try{l=e(c,d)}catch(e){d(e)}if(l)if("function"==typeof l.then)l.then(c,d);else{var u=l.component;u&&"function"==typeof u.then&&u.then(c,d)}}})),r||a()}}function Ae(e,n){return Ce(e.map((function(e){return Object.keys(e.components).map((function(t){return n(e.components[t],e.instances[t],e,t)}))})))}function Ce(e){return Array.prototype.concat.apply([],e)}var je="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Oe(e){var n=!1;return function(){for(var t=[],a=arguments.length;a--;)t[a]=arguments[a];if(!n)return n=!0,e.apply(this,t)}}var Le=function(e,n){this.router=e,this.base=function(e){if(!e)if(Y){var n=document.querySelector("base");e=(e=n&&n.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else e="/";"/"!==e.charAt(0)&&(e="/"+e);return e.replace(/\/$/,"")}(n),this.current=g,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Ne(e,n,t,a){var r=Ae(e,(function(e,a,r,i){var o=function(e,n){"function"!=typeof e&&(e=$.extend(e));return e.options[n]}(e,n);if(o)return Array.isArray(o)?o.map((function(e){return t(e,a,r,i)})):t(o,a,r,i)}));return Ce(a?r.reverse():r)}function De(e,n){if(n)return function(){return e.apply(n,arguments)}}Le.prototype.listen=function(e){this.cb=e},Le.prototype.onReady=function(e,n){this.ready?e():(this.readyCbs.push(e),n&&this.readyErrorCbs.push(n))},Le.prototype.onError=function(e){this.errorCbs.push(e)},Le.prototype.transitionTo=function(e,n,t){var a,r=this;try{a=this.router.match(e,this.current)}catch(e){throw this.errorCbs.forEach((function(n){n(e)})),e}var i=this.current;this.confirmTransition(a,(function(){r.updateRoute(a),n&&n(a),r.ensureURL(),r.router.afterHooks.forEach((function(e){e&&e(a,i)})),r.ready||(r.ready=!0,r.readyCbs.forEach((function(e){e(a)})))}),(function(e){t&&t(e),e&&!r.ready&&(Ee(e,ye.redirected)&&i===g||(r.ready=!0,r.readyErrorCbs.forEach((function(n){n(e)}))))}))},Le.prototype.confirmTransition=function(e,n,t){var a=this,r=this.current;this.pending=e;var i,o,s=function(e){!Ee(e)&&Te(e)&&(a.errorCbs.length?a.errorCbs.forEach((function(n){n(e)})):console.error(e)),t&&t(e)},l=e.matched.length-1,c=r.matched.length-1;if(y(e,r)&&l===c&&e.matched[l]===r.matched[c])return this.ensureURL(),e.hash&&se(this.router,r,e,!1),s(((o=xe(i=r,e,ye.duplicated,'Avoided redundant navigation to current location: "'+i.fullPath+'".')).name="NavigationDuplicated",o));var d=function(e,n){var t,a=Math.max(e.length,n.length);for(t=0;t<a&&e[t]===n[t];t++);return{updated:n.slice(0,t),activated:n.slice(t),deactivated:e.slice(t)}}(this.current.matched,e.matched),u=d.updated,p=d.deactivated,m=d.activated,h=[].concat(function(e){return Ne(e,"beforeRouteLeave",De,!0)}(p),this.router.beforeHooks,function(e){return Ne(e,"beforeRouteUpdate",De)}(u),m.map((function(e){return e.beforeEnter})),Ie(m)),f=function(n,t){if(a.pending!==e)return s(_e(r,e));try{n(e,r,(function(n){!1===n?(a.ensureURL(!0),s(function(e,n){return xe(e,n,ye.aborted,'Navigation aborted from "'+e.fullPath+'" to "'+n.fullPath+'" via a navigation guard.')}(r,e))):Te(n)?(a.ensureURL(!0),s(n)):"string"==typeof n||"object"==typeof n&&("string"==typeof n.path||"string"==typeof n.name)?(s(we(r,e)),"object"==typeof n&&n.replace?a.replace(n):a.push(n)):t(n)}))}catch(e){s(e)}};Se(h,f,(function(){Se(function(e){return Ne(e,"beforeRouteEnter",(function(e,n,t,a){return function(e,n,t){return function(a,r,i){return e(a,r,(function(e){"function"==typeof e&&(n.enteredCbs[t]||(n.enteredCbs[t]=[]),n.enteredCbs[t].push(e)),i(e)}))}}(e,t,a)}))}(m).concat(a.router.resolveHooks),f,(function(){if(a.pending!==e)return s(_e(r,e));a.pending=null,n(e),a.router.app&&a.router.app.$nextTick((function(){_(e)}))}))}))},Le.prototype.updateRoute=function(e){this.current=e,this.cb&&this.cb(e)},Le.prototype.setupListeners=function(){},Le.prototype.teardown=function(){this.listeners.forEach((function(e){e()})),this.listeners=[],this.current=g,this.pending=null};var Pe=function(e){function n(n,t){e.call(this,n,t),this._startLocation=Me(this.base)}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var n=this.router,t=n.options.scrollBehavior,a=ge&&t;a&&this.listeners.push(oe());var r=function(){var t=e.current,r=Me(e.base);e.current===g&&r===e._startLocation||e.transitionTo(r,(function(e){a&&se(n,e,t,!0)}))};window.addEventListener("popstate",r),this.listeners.push((function(){window.removeEventListener("popstate",r)}))}},n.prototype.go=function(e){window.history.go(e)},n.prototype.push=function(e,n,t){var a=this,r=this.current;this.transitionTo(e,(function(e){ve(E(a.base+e.fullPath)),se(a.router,e,r,!1),n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var a=this,r=this.current;this.transitionTo(e,(function(e){be(E(a.base+e.fullPath)),se(a.router,e,r,!1),n&&n(e)}),t)},n.prototype.ensureURL=function(e){if(Me(this.base)!==this.current.fullPath){var n=E(this.base+this.current.fullPath);e?ve(n):be(n)}},n.prototype.getCurrentLocation=function(){return Me(this.base)},n}(Le);function Me(e){var n=window.location.pathname,t=n.toLowerCase(),a=e.toLowerCase();return!e||t!==a&&0!==t.indexOf(E(a+"/"))||(n=n.slice(e.length)),(n||"/")+window.location.search+window.location.hash}var Re=function(e){function n(n,t,a){e.call(this,n,t),a&&function(e){var n=Me(e);if(!/^\/#/.test(n))return window.location.replace(E(e+"/#"+n)),!0}(this.base)||ze()}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var n=this.router.options.scrollBehavior,t=ge&&n;t&&this.listeners.push(oe());var a=function(){var n=e.current;ze()&&e.transitionTo(qe(),(function(a){t&&se(e.router,a,n,!0),ge||Be(a.fullPath)}))},r=ge?"popstate":"hashchange";window.addEventListener(r,a),this.listeners.push((function(){window.removeEventListener(r,a)}))}},n.prototype.push=function(e,n,t){var a=this,r=this.current;this.transitionTo(e,(function(e){Fe(e.fullPath),se(a.router,e,r,!1),n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var a=this,r=this.current;this.transitionTo(e,(function(e){Be(e.fullPath),se(a.router,e,r,!1),n&&n(e)}),t)},n.prototype.go=function(e){window.history.go(e)},n.prototype.ensureURL=function(e){var n=this.current.fullPath;qe()!==n&&(e?Fe(n):Be(n))},n.prototype.getCurrentLocation=function(){return qe()},n}(Le);function ze(){var e=qe();return"/"===e.charAt(0)||(Be("/"+e),!1)}function qe(){var e=window.location.href,n=e.indexOf("#");return n<0?"":e=e.slice(n+1)}function Je(e){var n=window.location.href,t=n.indexOf("#");return(t>=0?n.slice(0,t):n)+"#"+e}function Fe(e){ge?ve(Je(e)):window.location.hash=e}function Be(e){ge?be(Je(e)):window.location.replace(Je(e))}var Ue=function(e){function n(n,t){e.call(this,n,t),this.stack=[],this.index=-1}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.push=function(e,n,t){var a=this;this.transitionTo(e,(function(e){a.stack=a.stack.slice(0,a.index+1).concat(e),a.index++,n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var a=this;this.transitionTo(e,(function(e){a.stack=a.stack.slice(0,a.index).concat(e),n&&n(e)}),t)},n.prototype.go=function(e){var n=this,t=this.index+e;if(!(t<0||t>=this.stack.length)){var a=this.stack[t];this.confirmTransition(a,(function(){var e=n.current;n.index=t,n.updateRoute(a),n.router.afterHooks.forEach((function(n){n&&n(a,e)}))}),(function(e){Ee(e,ye.duplicated)&&(n.index=t)}))}},n.prototype.getCurrentLocation=function(){var e=this.stack[this.stack.length-1];return e?e.fullPath:"/"},n.prototype.ensureURL=function(){},n}(Le),He=function(e){void 0===e&&(e={}),this.app=null,this.apps=[],this.options=e,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Q(e.routes||[],this);var n=e.mode||"hash";switch(this.fallback="history"===n&&!ge&&!1!==e.fallback,this.fallback&&(n="hash"),Y||(n="abstract"),this.mode=n,n){case"history":this.history=new Pe(this,e.base);break;case"hash":this.history=new Re(this,e.base,this.fallback);break;case"abstract":this.history=new Ue(this,e.base);break;default:0}},$e={currentRoute:{configurable:!0}};He.prototype.match=function(e,n,t){return this.matcher.match(e,n,t)},$e.currentRoute.get=function(){return this.history&&this.history.current},He.prototype.init=function(e){var n=this;if(this.apps.push(e),e.$once("hook:destroyed",(function(){var t=n.apps.indexOf(e);t>-1&&n.apps.splice(t,1),n.app===e&&(n.app=n.apps[0]||null),n.app||n.history.teardown()})),!this.app){this.app=e;var t=this.history;if(t instanceof Pe||t instanceof Re){var a=function(e){t.setupListeners(),function(e){var a=t.current,r=n.options.scrollBehavior;ge&&r&&"fullPath"in e&&se(n,e,a,!1)}(e)};t.transitionTo(t.getCurrentLocation(),a,a)}t.listen((function(e){n.apps.forEach((function(n){n._route=e}))}))}},He.prototype.beforeEach=function(e){return Ke(this.beforeHooks,e)},He.prototype.beforeResolve=function(e){return Ke(this.resolveHooks,e)},He.prototype.afterEach=function(e){return Ke(this.afterHooks,e)},He.prototype.onReady=function(e,n){this.history.onReady(e,n)},He.prototype.onError=function(e){this.history.onError(e)},He.prototype.push=function(e,n,t){var a=this;if(!n&&!t&&"undefined"!=typeof Promise)return new Promise((function(n,t){a.history.push(e,n,t)}));this.history.push(e,n,t)},He.prototype.replace=function(e,n,t){var a=this;if(!n&&!t&&"undefined"!=typeof Promise)return new Promise((function(n,t){a.history.replace(e,n,t)}));this.history.replace(e,n,t)},He.prototype.go=function(e){this.history.go(e)},He.prototype.back=function(){this.go(-1)},He.prototype.forward=function(){this.go(1)},He.prototype.getMatchedComponents=function(e){var n=e?e.matched?e:this.resolve(e).route:this.currentRoute;return n?[].concat.apply([],n.matched.map((function(e){return Object.keys(e.components).map((function(n){return e.components[n]}))}))):[]},He.prototype.resolve=function(e,n,t){var a=H(e,n=n||this.history.current,t,this),r=this.match(a,n),i=r.redirectedFrom||r.fullPath;return{location:a,route:r,href:function(e,n,t){var a="hash"===t?"#"+n:n;return e?E(e+"/"+a):a}(this.history.base,i,this.mode),normalizedTo:a,resolved:r}},He.prototype.getRoutes=function(){return this.matcher.getRoutes()},He.prototype.addRoute=function(e,n){this.matcher.addRoute(e,n),this.history.current!==g&&this.history.transitionTo(this.history.getCurrentLocation())},He.prototype.addRoutes=function(e){this.matcher.addRoutes(e),this.history.current!==g&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(He.prototype,$e);var Ge=He;function Ke(e,n){return e.push(n),function(){var t=e.indexOf(n);t>-1&&e.splice(t,1)}}He.install=function e(n){if(!e.installed||$!==n){e.installed=!0,$=n;var t=function(e){return void 0!==e},a=function(e,n){var a=e.$options._parentVnode;t(a)&&t(a=a.data)&&t(a=a.registerRouteInstance)&&a(e,n)};n.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),n.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,a(this,this)},destroyed:function(){a(this)}}),Object.defineProperty(n.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(n.prototype,"$route",{get:function(){return this._routerRoot._route}}),n.component("RouterView",x),n.component("RouterLink",K);var r=n.config.optionMergeStrategies;r.beforeRouteEnter=r.beforeRouteLeave=r.beforeRouteUpdate=r.created}},He.version="3.6.5",He.isNavigationFailure=Ee,He.NavigationFailureType=ye,He.START_LOCATION=g,Y&&window.Vue&&window.Vue.use(He);t(106);t(128),t(17);var We={NotFound:()=>Promise.all([t.e(0),t.e(7)]).then(t.bind(null,470)),Layout:()=>Promise.all([t.e(0),t.e(3)]).then(t.bind(null,469))},Ye={"v-f415ebc0":()=>t.e(8).then(t.bind(null,472)),"v-a6c35a82":()=>t.e(9).then(t.bind(null,473)),"v-998835bc":()=>t.e(10).then(t.bind(null,474)),"v-78bcb4bc":()=>t.e(11).then(t.bind(null,475)),"v-1f0ca540":()=>t.e(12).then(t.bind(null,476)),"v-a6c16d9c":()=>t.e(13).then(t.bind(null,477)),"v-5a234d0e":()=>t.e(14).then(t.bind(null,478)),"v-2dd572b2":()=>t.e(15).then(t.bind(null,479)),"v-31d26f3c":()=>t.e(16).then(t.bind(null,480)),"v-4ad5cd7c":()=>t.e(17).then(t.bind(null,481)),"v-676002b2":()=>t.e(18).then(t.bind(null,482)),"v-f4d1815c":()=>t.e(19).then(t.bind(null,483)),"v-38ca00b8":()=>t.e(20).then(t.bind(null,484)),"v-51cd5ef8":()=>t.e(21).then(t.bind(null,485)),"v-497d7762":()=>t.e(22).then(t.bind(null,486)),"v-6280d5a2":()=>t.e(23).then(t.bind(null,487)),"v-abc39610":()=>t.e(24).then(t.bind(null,488)),"v-79bcd990":()=>t.e(25).then(t.bind(null,489)),"v-1ccb3574":()=>t.e(26).then(t.bind(null,490)),"v-4bad8eff":()=>t.e(27).then(t.bind(null,491)),"v-6ef6bf36":()=>t.e(28).then(t.bind(null,492)),"v-c290b01e":()=>t.e(29).then(t.bind(null,493)),"v-e70761c4":()=>t.e(30).then(t.bind(null,494)),"v-660b1f27":()=>t.e(32).then(t.bind(null,495)),"v-80aef426":()=>t.e(33).then(t.bind(null,496)),"v-639a0f7a":()=>t.e(31).then(t.bind(null,497)),"v-03a6f1e0":()=>t.e(34).then(t.bind(null,498)),"v-4e919d70":()=>t.e(35).then(t.bind(null,499)),"v-4f7e5a56":()=>t.e(36).then(t.bind(null,500)),"v-f7980a44":()=>t.e(37).then(t.bind(null,501)),"v-039b7178":()=>t.e(38).then(t.bind(null,502)),"v-5459eecd":()=>t.e(39).then(t.bind(null,503)),"v-27c64bc0":()=>t.e(40).then(t.bind(null,504)),"v-cd219960":()=>t.e(41).then(t.bind(null,505)),"v-0b12933a":()=>t.e(42).then(t.bind(null,506)),"v-7b9db9b6":()=>t.e(43).then(t.bind(null,507)),"v-098edc32":()=>t.e(44).then(t.bind(null,508)),"v-3fa091ca":()=>t.e(45).then(t.bind(null,509)),"v-54077827":()=>t.e(46).then(t.bind(null,510)),"v-1c067b47":()=>t.e(47).then(t.bind(null,511)),"v-54a5a8f1":()=>t.e(49).then(t.bind(null,512)),"v-4b206a0f":()=>t.e(48).then(t.bind(null,513)),"v-10f613aa":()=>t.e(50).then(t.bind(null,514)),"v-0c164253":()=>t.e(52).then(t.bind(null,515)),"v-65b952f2":()=>t.e(53).then(t.bind(null,516)),"v-672547f2":()=>t.e(51).then(t.bind(null,517)),"v-21a1b472":()=>t.e(54).then(t.bind(null,518)),"v-24c0bbfe":()=>t.e(55).then(t.bind(null,519)),"v-558dc8ba":()=>t.e(57).then(t.bind(null,520)),"v-c8daa3f2":()=>t.e(58).then(t.bind(null,521)),"v-0c46eaa7":()=>t.e(59).then(t.bind(null,522)),"v-20feecc7":()=>t.e(60).then(t.bind(null,523)),"v-1deb9607":()=>t.e(56).then(t.bind(null,524)),"v-ce147052":()=>t.e(61).then(t.bind(null,525)),"v-79dbae07":()=>t.e(62).then(t.bind(null,526)),"v-686ae17b":()=>t.e(64).then(t.bind(null,527)),"v-0a9184e7":()=>t.e(63).then(t.bind(null,528)),"v-a0880f96":()=>t.e(65).then(t.bind(null,529)),"v-6592916c":()=>t.e(66).then(t.bind(null,530)),"v-778ac29c":()=>t.e(68).then(t.bind(null,531)),"v-6c528997":()=>t.e(67).then(t.bind(null,532)),"v-b6061afe":()=>t.e(69).then(t.bind(null,533)),"v-4c28040b":()=>t.e(70).then(t.bind(null,534)),"v-7280ffb2":()=>t.e(71).then(t.bind(null,535)),"v-01725947":()=>t.e(72).then(t.bind(null,536)),"v-3f973327":()=>t.e(73).then(t.bind(null,537)),"v-30230c72":()=>t.e(74).then(t.bind(null,538)),"v-26d51feb":()=>t.e(76).then(t.bind(null,539)),"v-03d9b432":()=>t.e(75).then(t.bind(null,540)),"v-d6f86d32":()=>t.e(77).then(t.bind(null,541)),"v-6ea4444b":()=>t.e(78).then(t.bind(null,542)),"v-a493dd52":()=>t.e(79).then(t.bind(null,543)),"v-d7570fb0":()=>t.e(80).then(t.bind(null,544)),"v-49cf9efe":()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,545))};function Ve(e){const n=Object.create(null);return function(t){return n[t]||(n[t]=e(t))}}const Ze=/-(\w)/g,Qe=Ve(e=>e.replace(Ze,(e,n)=>n?n.toUpperCase():"")),Xe=/\B([A-Z])/g,en=Ve(e=>e.replace(Xe,"-$1").toLowerCase()),nn=Ve(e=>e.charAt(0).toUpperCase()+e.slice(1));function tn(e,n){if(!n)return;if(e(n))return e(n);return n.includes("-")?e(nn(Qe(n))):e(nn(n))||e(en(n))}const an=Object.assign({},We,Ye),rn=e=>an[e],on=e=>Ye[e],sn=e=>We[e],ln=e=>a.default.component(e);function cn(e){return tn(on,e)}function dn(e){return tn(sn,e)}function un(e){return tn(rn,e)}function pn(e){return tn(ln,e)}function mn(...e){return Promise.all(e.filter(e=>e).map(async e=>{if(!pn(e)&&un(e)){const n=await un(e)();a.default.component(e,n.default)}}))}function hn(e,n){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[e]=n)}var fn=t(92),gn=t.n(fn),vn=t(93),bn=t.n(vn),yn={created(){if(this.siteMeta=this.$site.headTags.filter(([e])=>"meta"===e).map(([e,n])=>n),this.$ssrContext){const n=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(e=n)?e.map(e=>{let n="<meta";return Object.keys(e).forEach(t=>{n+=` ${t}="${bn()(e[t])}"`}),n+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=_n(this.$canonicalUrl)}var e},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const e=this.getMergedMetaTags();this.currentMetaTags=xn(e,this.currentMetaTags)},getMergedMetaTags(){const e=this.$page.frontmatter.meta||[];return gn()([{name:"description",content:this.$description}],e,this.siteMeta,kn)},updateCanonicalLink(){wn(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",_n(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){xn(null,this.currentMetaTags),wn()}};function wn(){const e=document.querySelector("link[rel='canonical']");e&&e.remove()}function _n(e=""){return e?`<link href="${e}" rel="canonical" />`:""}function xn(e,n){if(n&&[...n].filter(e=>e.parentNode===document.head).forEach(e=>document.head.removeChild(e)),e)return e.map(e=>{const n=document.createElement("meta");return Object.keys(e).forEach(t=>{n.setAttribute(t,e[t])}),document.head.appendChild(n),n})}function kn(e){for(const n of["name","property","itemprop"])if(e.hasOwnProperty(n))return e[n]+n;return JSON.stringify(e)}var Tn=t(52),En={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(Tn)()((function(){this.setActiveHash()}),300),setActiveHash(){const e=[].slice.call(document.querySelectorAll(".sidebar-link")),n=[].slice.call(document.querySelectorAll(".header-anchor")).filter(n=>e.some(e=>e.hash===n.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),a=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),r=window.innerHeight+t;for(let e=0;e<n.length;e++){const i=n[e],o=n[e+1],s=0===e&&0===t||t>=i.parentElement.offsetTop+10&&(!o||t<o.parentElement.offsetTop-10),l=decodeURIComponent(this.$route.hash);if(s&&l!==decodeURIComponent(i.hash)){const t=i;if(r===a)for(let t=e+1;t<n.length;t++)if(l===decodeURIComponent(n[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},Sn=t(25),In=t.n(Sn),An={mounted(){In.a.configure({showSpinner:!1}),this.$router.beforeEach((e,n,t)=>{e.path===n.path||a.default.component(e.name)||In.a.start(),t()}),this.$router.afterEach(()=>{In.a.done(),this.isSidebarOpen=!1})}};t(240),t(241);class Cn{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:e="",duration:n=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${e}</div>\n    `,this.containerEl.appendChild(t),n>0&&setTimeout(()=>{this.close(t)},n)}close(e){e.className=e.className.replace("move-in",""),e.className+="move-out",e.addEventListener("animationend",()=>{e.remove()})}}var jn={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(e=>{document.querySelectorAll(e).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(e){if(e.classList.contains("codecopy-enabled"))return;const n=document.createElement("i");n.className="code-copy",n.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',n.title="Copy to clipboard",n.addEventListener("click",()=>{this.copyToClipboard(e.innerText)}),e.appendChild(n),e.classList.add("codecopy-enabled")},copyToClipboard(e){const n=document.createElement("textarea");n.value=e,n.setAttribute("readonly",""),n.style.position="absolute",n.style.left="-9999px",document.body.appendChild(n);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);n.select(),document.execCommand("copy");(new Cn).show({text:"",duration:1e3}),document.body.removeChild(n),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(e,n){void 0===n&&(n={});var t=n.insertAt;if(e&&"undefined"!=typeof document){var a=document.head||document.getElementsByTagName("head")[0],r=document.createElement("style");r.type="text/css","top"===t&&a.firstChild?a.insertBefore(r,a.firstChild):a.appendChild(r),r.styleSheet?r.styleSheet.cssText=e:r.appendChild(document.createTextNode(e))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var On={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Ln={},Nn=function(e){return'<div id="app">\n'.concat(e,"\n</div>")},Dn=function(e){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[e]?window.$VUEPRESS_DEMO_BLOCK[e]:On[e]},Pn=function e(n,t,a){var r=document.createElement(n);return t&&Object.keys(t).forEach((function(e){if(e.indexOf("data"))r[e]=t[e];else{var n=e.replace("data","");r.dataset[n]=t[e]}})),a&&a.forEach((function(n){var t=n.tag,a=n.attrs,i=n.children;r.appendChild(e(t,a,i))})),r},Mn=function(e,n,t){var a,r=(a=e.querySelectorAll(".".concat(n)),Array.prototype.slice.call(a));return 1!==r.length||t?r:r[0]},Rn=function(e,n){var t,a,r=e.match(/<style>([\s\S]+)<\/style>/),i=e.match(/<template>([\s\S]+)<\/template>/),o=e.match(/<script>([\s\S]+)<\/script>/),s={css:r&&r[1].replace(/^\n|\n$/g,""),html:i&&i[1].replace(/^\n|\n$/g,""),js:o&&o[1].replace(/^\n|\n$/g,""),jsLib:n.jsLib||[],cssLib:n.cssLib||[]};s.htmlTpl=Nn(s.html),s.jsTpl=(t=s.js,a=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(a,"\n})")),s.script=function(e,n){var t=e.split(/export\s+default/),a="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),r=window.Babel?window.Babel.transform(a,{presets:["es2015"]}).code:a,i=[eval][0](r);return i.template=n,i}(s.js,s.html);var l=Dn("vue");return s.jsLib.unshift(l),s},zn=function(e,n){var t,a=e.match(/<style>([\s\S]+)<\/style>/),r=e.match(/<html>([\s\S]+)<\/html>/),i=e.match(/<script>([\s\S]+)<\/script>/),o={css:a&&a[1].replace(/^\n|\n$/g,""),html:r&&r[1].replace(/^\n|\n$/g,""),js:i&&i[1].replace(/^\n|\n$/g,""),jsLib:n.jsLib||[],cssLib:n.cssLib||[]};return o.htmlTpl=o.html,o.jsTpl=o.js,o.script=(t=o.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),o},qn=function(e){return e=e.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),e+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function Jn(){var e=Mn(document,"vuepress-plugin-demo-block__wrapper",!0);e.length?e.forEach((function(e){if("true"!==e.dataset.created){e.style.display="block";var n=Mn(e,"vuepress-plugin-demo-block__code"),t=Mn(e,"vuepress-plugin-demo-block__display"),a=Mn(e,"vuepress-plugin-demo-block__footer"),r=Mn(t,"vuepress-plugin-demo-block__app"),i=decodeURIComponent(e.dataset.code),o=decodeURIComponent(e.dataset.config),s=decodeURIComponent(e.dataset.type);o=o?JSON.parse(o):{};var l=n.querySelector("div").clientHeight,c="react"===s?function(e,n){var t=(0,window.Babel.transform)(e,{presets:["es2015","react"]}).code,a="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),r=new Function("return ".concat(a))(),i={js:r,css:r.__style__||"",jsLib:n.jsLib||[],cssLib:n.cssLib||[],jsTpl:qn(e),htmlTpl:Nn("")},o=Dn("react"),s=Dn("reactDOM");return i.jsLib.unshift(o,s),i}(i,o):"vanilla"===s?zn(i,o):Rn(i,o),d=Pn("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(a.appendChild(d),d.addEventListener("click",Fn.bind(null,d,l,n,a)),Dn("jsfiddle")&&a.appendChild(function(e){var n=e.css,t=e.htmlTpl,a=e.jsTpl,r=e.jsLib,i=e.cssLib,o=r.concat(i).concat(Dn("cssLib")).concat(Dn("jsLib")).join(",");return Pn("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:n}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:a}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:o}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(c)),Dn("codepen")&&a.appendChild(function(e){var n=e.css,t=e.htmlTpl,a=e.jsTpl,r=e.jsLib,i=e.cssLib,o=JSON.stringify({css:n,html:t,js:a,js_external:r.concat(Dn("jsLib")).join(";"),css_external:i.concat(Dn("cssLib")).join(";"),layout:Dn("codepenLayout"),js_pre_processor:Dn("codepenJsProcessor"),editors:Dn("codepenEditors")});return Pn("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:o}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(c)),void 0!==o.horizontal?o.horizontal:Dn("horizontal")){e.classList.add("vuepress-plugin-demo-block__horizontal");var u=n.firstChild.cloneNode(!0);u.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(u)}if(c.css&&function(e){if(!Ln[e]){var n=Pn("style",{innerHTML:e});document.body.appendChild(n),Ln[e]=!0}}(c.css),"react"===s)ReactDOM.render(React.createElement(c.js),r);else if("vue"===s){var p=(new(Vue.extend(c.script))).$mount();r.appendChild(p.$el)}else"vanilla"===s&&(r.innerHTML=c.html,new Function("return (function(){".concat(c.script,"})()"))());e.dataset.created="true"}})):setTimeout((function(e){Jn()}),300)}function Fn(e,n,t,a){var r="1"!==e.dataset.isExpand;t.style.height=r?"".concat(n,"px"):0,r?a.classList.add("vuepress-plugin-demo-block__show-link"):a.classList.remove("vuepress-plugin-demo-block__show-link"),e.dataset.isExpand=r?"1":"0"}var Bn={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},Jn()},updated:function(){Jn()}},Un="auto",Hn="zoom-in",$n="zoom-out",Gn="grab",Kn="move";function Wn(e,n,t){var a=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],r={passive:!1};a?e.addEventListener(n,t,r):e.removeEventListener(n,t,r)}function Yn(e,n){if(e){var t=new Image;t.onload=function(){n&&n(t)},t.src=e}}function Vn(e){return e.dataset.original?e.dataset.original:"A"===e.parentNode.tagName?e.parentNode.getAttribute("href"):null}function Zn(e,n,t){!function(e){var n=Qn,t=Xn;if(e.transition){var a=e.transition;delete e.transition,e[n]=a}if(e.transform){var r=e.transform;delete e.transform,e[t]=r}}(n);var a=e.style,r={};for(var i in n)t&&(r[i]=a[i]||""),a[i]=n[i];return r}var Qn="transition",Xn="transform",et="transform",nt="transitionend";var tt=function(){},at={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:tt,onClose:tt,onGrab:tt,onMove:tt,onRelease:tt,onBeforeOpen:tt,onBeforeClose:tt,onBeforeGrab:tt,onBeforeRelease:tt,onImageLoading:tt,onImageLoaded:tt},rt={init:function(e){var n,t;n=this,t=e,Object.getOwnPropertyNames(Object.getPrototypeOf(n)).forEach((function(e){n[e]=n[e].bind(t)}))},click:function(e){if(e.preventDefault(),ot(e))return window.open(this.target.srcOriginal||e.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(e.currentTarget)},scroll:function(){var e=document.documentElement||document.body.parentNode||document.body,n=window.pageXOffset||e.scrollLeft,t=window.pageYOffset||e.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:n,y:t});var a=this.lastScrollPosition.x-n,r=this.lastScrollPosition.y-t,i=this.options.scrollThreshold;(Math.abs(r)>=i||Math.abs(a)>=i)&&(this.lastScrollPosition=null,this.close())},keydown:function(e){(function(e){return"Escape"===(e.key||e.code)||27===e.keyCode})(e)&&(this.released?this.close():this.release(this.close))},mousedown:function(e){if(it(e)&&!ot(e)){e.preventDefault();var n=e.clientX,t=e.clientY;this.pressTimer=setTimeout(function(){this.grab(n,t)}.bind(this),200)}},mousemove:function(e){this.released||this.move(e.clientX,e.clientY)},mouseup:function(e){it(e)&&!ot(e)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(e){e.preventDefault();var n=e.touches[0],t=n.clientX,a=n.clientY;this.pressTimer=setTimeout(function(){this.grab(t,a)}.bind(this),200)},touchmove:function(e){if(!this.released){var n=e.touches[0],t=n.clientX,a=n.clientY;this.move(t,a)}},touchend:function(e){(function(e){e.targetTouches.length})(e)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function it(e){return 0===e.button}function ot(e){return e.metaKey||e.ctrlKey}var st={init:function(e){this.el=document.createElement("div"),this.instance=e,this.parent=document.body,Zn(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(e.options),Wn(this.el,"click",e.handler.clickOverlay.bind(e))},updateStyle:function(e){Zn(this.el,{zIndex:e.zIndex,backgroundColor:e.bgColor,transition:"opacity\n        "+e.transitionDuration+"s\n        "+e.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},lt="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},ct=function(){function e(e,n){for(var t=0;t<n.length;t++){var a=n[t];a.enumerable=a.enumerable||!1,a.configurable=!0,"value"in a&&(a.writable=!0),Object.defineProperty(e,a.key,a)}}return function(n,t,a){return t&&e(n.prototype,t),a&&e(n,a),n}}(),dt=Object.assign||function(e){for(var n=1;n<arguments.length;n++){var t=arguments[n];for(var a in t)Object.prototype.hasOwnProperty.call(t,a)&&(e[a]=t[a])}return e},ut={init:function(e,n){this.el=e,this.instance=n,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Vn(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var e=this.instance.options,n=e.zIndex,t=e.enableGrab,a=e.transitionDuration,r=e.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:n+1,cursor:t?Gn:$n,transition:et+"\n        "+a+"s\n        "+r,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Zn(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Zn(this.el,{transform:"none"})},grab:function(e,n,t){var a=pt(),r=a.x-e,i=a.y-n;Zn(this.el,{cursor:Kn,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(e,n,t){var a=pt(),r=a.x-e,i=a.y-n;Zn(this.el,{transition:et,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Zn(this.el,this.styleClose)},restoreOpenStyle:function(){Zn(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var e=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var n=this.el.cloneNode(!1);n.setAttribute("src",this.srcOriginal),n.style.position="fixed",n.style.visibility="hidden",e.appendChild(n),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),e.removeChild(n)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var e=pt(),n=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:e.x-n,y:e.y-t}},calculateScale:function(){var e=this.el.dataset,n=e.zoomingHeight,t=e.zoomingWidth,a=this.instance.options,r=a.customSize,i=a.scaleBase;if(!r&&n&&t)return{x:t/this.rect.width,y:n/this.rect.height};if(r&&"object"===(void 0===r?"undefined":lt(r)))return{x:r.width/this.rect.width,y:r.height/this.rect.height};var o=this.rect.width/2,s=this.rect.height/2,l=pt(),c={x:l.x-o,y:l.y-s},d=c.x/o,u=c.y/s,p=i+Math.min(d,u);if(r&&"string"==typeof r){var m=t||this.el.naturalWidth,h=n||this.el.naturalHeight,f=parseFloat(r)*m/(100*this.rect.width),g=parseFloat(r)*h/(100*this.rect.height);if(p>f||p>g)return{x:f,y:g}}return{x:p,y:p}}};function pt(){var e=document.documentElement;return{x:Math.min(e.clientWidth,window.innerWidth)/2,y:Math.min(e.clientHeight,window.innerHeight)/2}}function mt(e,n,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(a){Wn(e,a,n[a],t)}))}var ht=function(){function e(n){!function(e,n){if(!(e instanceof n))throw new TypeError("Cannot call a class as a function")}(this,e),this.target=Object.create(ut),this.overlay=Object.create(st),this.handler=Object.create(rt),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=dt({},at,n),this.overlay.init(this),this.handler.init(this)}return ct(e,[{key:"listen",value:function(e){if("string"==typeof e)for(var n=document.querySelectorAll(e),t=n.length;t--;)this.listen(n[t]);else"IMG"===e.tagName&&(e.style.cursor=Hn,Wn(e,"click",this.handler.click),this.options.preloadImage&&Yn(Vn(e)));return this}},{key:"config",value:function(e){return e?(dt(this.options,e),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(e){var n=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var a="string"==typeof e?document.querySelector(e):e;if("IMG"===a.tagName){if(this.options.onBeforeOpen(a),this.target.init(a,this),!this.options.preloadImage){var r=this.target.srcOriginal;null!=r&&(this.options.onImageLoading(a),Yn(r,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Wn(document,"scroll",this.handler.scroll),Wn(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Wn(window,"resize",this.handler.resizeWindow);var i=function e(){Wn(a,nt,e,!1),n.lock=!1,n.target.upgradeSource(),n.options.enableGrab&&mt(document,n.handler,!0),t(a)};return Wn(a,nt,i),this}}}},{key:"close",value:function(){var e=this,n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Un,this.overlay.fadeOut(),this.target.zoomOut(),Wn(document,"scroll",this.handler.scroll,!1),Wn(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Wn(window,"resize",this.handler.resizeWindow,!1);var a=function a(){Wn(t,nt,a,!1),e.shown=!1,e.lock=!1,e.target.downgradeSource(),e.options.enableGrab&&mt(document,e.handler,!1),e.target.restoreCloseStyle(),e.overlay.remove(),n(t)};return Wn(t,nt,a),this}}},{key:"grab",value:function(e,n){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,a=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var r=this.target.el;this.options.onBeforeGrab(r),this.released=!1,this.target.grab(e,n,t);var i=function e(){Wn(r,nt,e,!1),a(r)};return Wn(r,nt,i),this}}},{key:"move",value:function(e,n){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,a=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=Kn,this.target.move(e,n,t);var r=this.target.el,i=function e(){Wn(r,nt,e,!1),a(r)};return Wn(r,nt,i),this}}},{key:"release",value:function(){var e=this,n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Un,this.target.restoreOpenStyle();var a=function a(){Wn(t,nt,a,!1),e.lock=!1,e.released=!0,n(t)};return Wn(t,nt,a),this}}}]),e}();const ft=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),gt=Number("500");class vt{constructor(){this.instance=new ht(ft)}update(e=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(e)}updateDelay(e=".theme-vdoing-content img:not(.no-zoom)",n=gt){setTimeout(()=>this.update(e),n)}}var bt=[yn,En,An,jn,Bn,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new vt,this.$vuepress.zooming.updateDelay()}}],yt={name:"GlobalLayout",computed:{layout(){const e=this.getLayout();return hn("layout",e),a.default.component(e)}},methods:{getLayout(){if(this.$page.path){const e=this.$page.frontmatter.layout;return e&&(this.$vuepress.getLayoutAsyncComponent(e)||this.$vuepress.getVueComponent(e))?e:"Layout"}return"NotFound"}}},wt=t(9),_t=Object(wt.a)(yt,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(e,n,t){switch(n){case"components":e[n]||(e[n]={}),Object.assign(e[n],t);break;case"mixins":e[n]||(e[n]=[]),e[n].push(...t);break;default:throw new Error("Unknown option name.")}}(_t,"mixins",bt);const xt=[{name:"v-f415ebc0",path:"/pages/155b65/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-f415ebc0").then(t)}},{path:"/pages/155b65/index.html",redirect:"/pages/155b65/"},{path:"/01.Java/01./01..html",redirect:"/pages/155b65/"},{name:"v-a6c35a82",path:"/pages/77d4e2/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-a6c35a82").then(t)}},{path:"/pages/77d4e2/index.html",redirect:"/pages/77d4e2/"},{path:"/01.Java/02.IO/01.IO.html",redirect:"/pages/77d4e2/"},{name:"v-998835bc",path:"/pages/49acab/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-998835bc").then(t)}},{path:"/pages/49acab/index.html",redirect:"/pages/49acab/"},{path:"/01.Java/02.IO/02.IO.html",redirect:"/pages/49acab/"},{name:"v-78bcb4bc",path:"/pages/a3d832/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-78bcb4bc").then(t)}},{path:"/pages/a3d832/index.html",redirect:"/pages/a3d832/"},{path:"/01.Java/02.IO/03.IO.html",redirect:"/pages/a3d832/"},{name:"v-1f0ca540",path:"/pages/42be26/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-1f0ca540").then(t)}},{path:"/pages/42be26/index.html",redirect:"/pages/42be26/"},{path:"/01.Java/02.IO/04.NIO.html",redirect:"/pages/42be26/"},{name:"v-a6c16d9c",path:"/pages/cd056d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-a6c16d9c").then(t)}},{path:"/pages/cd056d/index.html",redirect:"/pages/cd056d/"},{path:"/01.Java/05./01.java8-common-new-features.html",redirect:"/pages/cd056d/"},{name:"v-5a234d0e",path:"/pages/b610cd/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-5a234d0e").then(t)}},{path:"/pages/b610cd/index.html",redirect:"/pages/b610cd/"},{path:"/01.Java/05./02.java8-tutorial-translate.html",redirect:"/pages/b610cd/"},{name:"v-2dd572b2",path:"/pages/1091ad/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-2dd572b2").then(t)}},{path:"/pages/1091ad/index.html",redirect:"/pages/1091ad/"},{path:"/01.Java/05./03.java9.html",redirect:"/pages/1091ad/"},{name:"v-31d26f3c",path:"/pages/e43406/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-31d26f3c").then(t)}},{path:"/pages/e43406/index.html",redirect:"/pages/e43406/"},{path:"/01.Java/05./04.java10.html",redirect:"/pages/e43406/"},{name:"v-4ad5cd7c",path:"/pages/f37c60/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4ad5cd7c").then(t)}},{path:"/pages/f37c60/index.html",redirect:"/pages/f37c60/"},{path:"/01.Java/05./05.java11.html",redirect:"/pages/f37c60/"},{name:"v-676002b2",path:"/pages/79a5f6/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-676002b2").then(t)}},{path:"/pages/79a5f6/index.html",redirect:"/pages/79a5f6/"},{path:"/01.Java/05./06.java12-13.html",redirect:"/pages/79a5f6/"},{name:"v-f4d1815c",path:"/pages/683a03/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-f4d1815c").then(t)}},{path:"/pages/683a03/index.html",redirect:"/pages/683a03/"},{path:"/01.Java/05./07.java14-15.html",redirect:"/pages/683a03/"},{name:"v-38ca00b8",path:"/pages/fa2c73/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-38ca00b8").then(t)}},{path:"/pages/fa2c73/index.html",redirect:"/pages/fa2c73/"},{path:"/01.Java/05./08.java16.html",redirect:"/pages/fa2c73/"},{name:"v-51cd5ef8",path:"/pages/245aa2/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-51cd5ef8").then(t)}},{path:"/pages/245aa2/index.html",redirect:"/pages/245aa2/"},{path:"/01.Java/05./09.java17.html",redirect:"/pages/245aa2/"},{name:"v-497d7762",path:"/pages/ce76de/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-497d7762").then(t)}},{path:"/pages/ce76de/index.html",redirect:"/pages/ce76de/"},{path:"/01.Java/05./10.java18.html",redirect:"/pages/ce76de/"},{name:"v-6280d5a2",path:"/pages/42d550/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6280d5a2").then(t)}},{path:"/pages/42d550/index.html",redirect:"/pages/42d550/"},{path:"/01.Java/05./11.java19.html",redirect:"/pages/42d550/"},{name:"v-abc39610",path:"/pages/d5208b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-abc39610").then(t)}},{path:"/pages/d5208b/index.html",redirect:"/pages/d5208b/"},{path:"/01.Java/05./12.java20.html",redirect:"/pages/d5208b/"},{name:"v-79bcd990",path:"/pages/54087b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-79bcd990").then(t)}},{path:"/pages/54087b/index.html",redirect:"/pages/54087b/"},{path:"/01.Java/05./13.java21.html",redirect:"/pages/54087b/"},{name:"v-1ccb3574",path:"/pages/be9ac8/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-1ccb3574").then(t)}},{path:"/pages/be9ac8/index.html",redirect:"/pages/be9ac8/"},{path:"/01.Java/06.SpringBoot/01.Spring.html",redirect:"/pages/be9ac8/"},{name:"v-4bad8eff",path:"/pages/5b4265/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4bad8eff").then(t)}},{path:"/pages/5b4265/index.html",redirect:"/pages/5b4265/"},{path:"/01.Java/06.SpringBoot/02..html",redirect:"/pages/5b4265/"},{name:"v-6ef6bf36",path:"/pages/c6bced/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6ef6bf36").then(t)}},{path:"/pages/c6bced/index.html",redirect:"/pages/c6bced/"},{path:"/01.Java/06.SpringBoot/03.Cookie-Session-Token-JWT.html",redirect:"/pages/c6bced/"},{name:"v-c290b01e",path:"/pages/3c4623/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-c290b01e").then(t)}},{path:"/pages/3c4623/index.html",redirect:"/pages/3c4623/"},{path:"/03./01.-coursera.html",redirect:"/pages/3c4623/"},{name:"v-e70761c4",path:"/pages/cb2190/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-e70761c4").then(t)}},{path:"/pages/cb2190/index.html",redirect:"/pages/cb2190/"},{path:"/03./02..html",redirect:"/pages/cb2190/"},{name:"v-660b1f27",path:"/pages/8448ab/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-660b1f27").then(t)}},{path:"/pages/8448ab/index.html",redirect:"/pages/8448ab/"},{path:"/04./02./01..html",redirect:"/pages/8448ab/"},{name:"v-80aef426",path:"/pages/372b2d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-80aef426").then(t)}},{path:"/pages/372b2d/index.html",redirect:"/pages/372b2d/"},{path:"/04./02./02.Program.html",redirect:"/pages/372b2d/"},{name:"v-639a0f7a",path:"/pages/f8be69/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-639a0f7a").then(t)}},{path:"/pages/f8be69/index.html",redirect:"/pages/f8be69/"},{path:"/04./01./01..html",redirect:"/pages/f8be69/"},{name:"v-03a6f1e0",path:"/pages/cb2fbc/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-03a6f1e0").then(t)}},{path:"/pages/cb2fbc/index.html",redirect:"/pages/cb2fbc/"},{path:"/04./02./03.WebApplication.html",redirect:"/pages/cb2fbc/"},{name:"v-4e919d70",path:"/pages/78c443/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4e919d70").then(t)}},{path:"/pages/78c443/index.html",redirect:"/pages/78c443/"},{path:"/04./02./04.Host.html",redirect:"/pages/78c443/"},{name:"v-4f7e5a56",path:"/pages/840f86/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4f7e5a56").then(t)}},{path:"/pages/840f86/index.html",redirect:"/pages/840f86/"},{path:"/04./02./05.WebHost.html",redirect:"/pages/840f86/"},{name:"v-f7980a44",path:"/pages/0d115d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-f7980a44").then(t)}},{path:"/pages/0d115d/index.html",redirect:"/pages/0d115d/"},{path:"/04./02./06..html",redirect:"/pages/0d115d/"},{name:"v-039b7178",path:"/pages/e2d1de/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-039b7178").then(t)}},{path:"/pages/e2d1de/index.html",redirect:"/pages/e2d1de/"},{path:"/04./02./07.Autofac.html",redirect:"/pages/e2d1de/"},{name:"v-5459eecd",path:"/pages/899977/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-5459eecd").then(t)}},{path:"/pages/899977/index.html",redirect:"/pages/899977/"},{path:"/04./02./08.Middleware.html",redirect:"/pages/899977/"},{name:"v-27c64bc0",path:"/pages/5991be/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-27c64bc0").then(t)}},{path:"/pages/5991be/index.html",redirect:"/pages/5991be/"},{path:"/04./02./09.RateLimiter.html",redirect:"/pages/5991be/"},{name:"v-cd219960",path:"/pages/bacc57/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-cd219960").then(t)}},{path:"/pages/bacc57/index.html",redirect:"/pages/bacc57/"},{path:"/04./02./10..html",redirect:"/pages/bacc57/"},{name:"v-0b12933a",path:"/pages/e50dff/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-0b12933a").then(t)}},{path:"/pages/e50dff/index.html",redirect:"/pages/e50dff/"},{path:"/05.&/01.Docker/01..html",redirect:"/pages/e50dff/"},{name:"v-7b9db9b6",path:"/pages/f1d3fb/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-7b9db9b6").then(t)}},{path:"/pages/f1d3fb/index.html",redirect:"/pages/f1d3fb/"},{path:"/05.&/01.Docker/02.-coursera.html",redirect:"/pages/f1d3fb/"},{name:"v-098edc32",path:"/pages/fbe42b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-098edc32").then(t)}},{path:"/pages/fbe42b/index.html",redirect:"/pages/fbe42b/"},{path:"/05.&/01.Docker/03.Apisix.html",redirect:"/pages/fbe42b/"},{name:"v-3fa091ca",path:"/pages/272684/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-3fa091ca").then(t)}},{path:"/pages/272684/index.html",redirect:"/pages/272684/"},{path:"/05.&/01.Docker/04.Apollo.html",redirect:"/pages/272684/"},{name:"v-54077827",path:"/pages/01958e/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-54077827").then(t)}},{path:"/pages/01958e/index.html",redirect:"/pages/01958e/"},{path:"/05.&/01.Docker/05.Cassandra.html",redirect:"/pages/01958e/"},{name:"v-1c067b47",path:"/pages/7e58c5/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-1c067b47").then(t)}},{path:"/pages/7e58c5/index.html",redirect:"/pages/7e58c5/"},{path:"/05.&/01.Docker/06.Cerebro.html",redirect:"/pages/7e58c5/"},{name:"v-54a5a8f1",path:"/pages/3d230b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-54a5a8f1").then(t)}},{path:"/pages/3d230b/index.html",redirect:"/pages/3d230b/"},{path:"/05.&/01.Docker/08.Consul.html",redirect:"/pages/3d230b/"},{name:"v-4b206a0f",path:"/pages/3b4977/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4b206a0f").then(t)}},{path:"/pages/3b4977/index.html",redirect:"/pages/3b4977/"},{path:"/05.&/01.Docker/07.ClickHouse.html",redirect:"/pages/3b4977/"},{name:"v-10f613aa",path:"/pages/ca4b88/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-10f613aa").then(t)}},{path:"/pages/ca4b88/index.html",redirect:"/pages/ca4b88/"},{path:"/05.&/01.Docker/09.EasyMock.html",redirect:"/pages/ca4b88/"},{name:"v-0c164253",path:"/pages/d93c0b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-0c164253").then(t)}},{path:"/pages/d93c0b/index.html",redirect:"/pages/d93c0b/"},{path:"/05.&/01.Docker/11.Emqx.html",redirect:"/pages/d93c0b/"},{name:"v-65b952f2",path:"/pages/7bfded/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-65b952f2").then(t)}},{path:"/pages/7bfded/index.html",redirect:"/pages/7bfded/"},{path:"/05.&/01.Docker/12.FastDFS.html",redirect:"/pages/7bfded/"},{name:"v-672547f2",path:"/pages/18fff0/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-672547f2").then(t)}},{path:"/pages/18fff0/index.html",redirect:"/pages/18fff0/"},{path:"/05.&/01.Docker/10.Elasticsearch.html",redirect:"/pages/18fff0/"},{name:"v-21a1b472",path:"/pages/53b154/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-21a1b472").then(t)}},{path:"/pages/53b154/index.html",redirect:"/pages/53b154/"},{path:"/05.&/01.Docker/13.Flink.html",redirect:"/pages/53b154/"},{name:"v-24c0bbfe",path:"/pages/83a3e2/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-24c0bbfe").then(t)}},{path:"/pages/83a3e2/index.html",redirect:"/pages/83a3e2/"},{path:"/05.&/01.Docker/14.Gitlab.html",redirect:"/pages/83a3e2/"},{name:"v-558dc8ba",path:"/pages/8e9d93/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-558dc8ba").then(t)}},{path:"/pages/8e9d93/index.html",redirect:"/pages/8e9d93/"},{path:"/05.&/01.Docker/16.Jrebel.html",redirect:"/pages/8e9d93/"},{name:"v-c8daa3f2",path:"/pages/ee069d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-c8daa3f2").then(t)}},{path:"/pages/ee069d/index.html",redirect:"/pages/ee069d/"},{path:"/05.&/01.Docker/17.MariaDB.html",redirect:"/pages/ee069d/"},{name:"v-0c46eaa7",path:"/pages/cff07b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-0c46eaa7").then(t)}},{path:"/pages/cff07b/index.html",redirect:"/pages/cff07b/"},{path:"/05.&/01.Docker/18.MySQL.html",redirect:"/pages/cff07b/"},{name:"v-20feecc7",path:"/pages/862a97/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-20feecc7").then(t)}},{path:"/pages/862a97/index.html",redirect:"/pages/862a97/"},{path:"/05.&/01.Docker/19.Percona.html",redirect:"/pages/862a97/"},{name:"v-1deb9607",path:"/pages/f90f99/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-1deb9607").then(t)}},{path:"/pages/f90f99/index.html",redirect:"/pages/f90f99/"},{path:"/05.&/01.Docker/15.Jenkins.html",redirect:"/pages/f90f99/"},{name:"v-ce147052",path:"/pages/a560de/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-ce147052").then(t)}},{path:"/pages/a560de/index.html",redirect:"/pages/a560de/"},{path:"/05.&/01.Docker/20.Phpmyadmin.html",redirect:"/pages/a560de/"},{name:"v-79dbae07",path:"/pages/230ca1/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-79dbae07").then(t)}},{path:"/pages/230ca1/index.html",redirect:"/pages/230ca1/"},{path:"/05.&/01.Docker/21.PostgreSQL.html",redirect:"/pages/230ca1/"},{name:"v-686ae17b",path:"/pages/aa794b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-686ae17b").then(t)}},{path:"/pages/aa794b/index.html",redirect:"/pages/aa794b/"},{path:"/05.&/02.Linux/01.Linux.html",redirect:"/pages/aa794b/"},{name:"v-0a9184e7",path:"/pages/be7f5d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-0a9184e7").then(t)}},{path:"/pages/be7f5d/index.html",redirect:"/pages/be7f5d/"},{path:"/05.&/01.Docker/22.Redis.html",redirect:"/pages/be7f5d/"},{name:"v-a0880f96",path:"/pages/2cbf35/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-a0880f96").then(t)}},{path:"/pages/2cbf35/index.html",redirect:"/pages/2cbf35/"},{path:"/05.&/02.Linux/02.CentOS7.html",redirect:"/pages/2cbf35/"},{name:"v-6592916c",path:"/pages/42cda4/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6592916c").then(t)}},{path:"/pages/42cda4/index.html",redirect:"/pages/42cda4/"},{path:"/05.&/02.Linux/03.IO.html",redirect:"/pages/42cda4/"},{name:"v-778ac29c",path:"/pages/6db179/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-778ac29c").then(t)}},{path:"/pages/6db179/index.html",redirect:"/pages/6db179/"},{path:"/05.&/02.Linux/05.CentOS7mysql5.7.html",redirect:"/pages/6db179/"},{name:"v-6c528997",path:"/pages/71dd10/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6c528997").then(t)}},{path:"/pages/71dd10/index.html",redirect:"/pages/71dd10/"},{path:"/05.&/02.Linux/04.LinuxCockpit.html",redirect:"/pages/71dd10/"},{name:"v-b6061afe",path:"/pages/518cfa/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-b6061afe").then(t)}},{path:"/pages/518cfa/index.html",redirect:"/pages/518cfa/"},{path:"/05.&/02.Linux/06.Linux.html",redirect:"/pages/518cfa/"},{name:"v-4c28040b",path:"/pages/86a4e2/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4c28040b").then(t)}},{path:"/pages/86a4e2/index.html",redirect:"/pages/86a4e2/"},{path:"/06./01.AspNetCore/01.AspNetCore.html",redirect:"/pages/86a4e2/"},{name:"v-7280ffb2",path:"/pages/868a19/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-7280ffb2").then(t)}},{path:"/pages/868a19/index.html",redirect:"/pages/868a19/"},{path:"/06./01.AspNetCore/02.Net.html",redirect:"/pages/868a19/"},{name:"v-01725947",path:"/pages/a567cd/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-01725947").then(t)}},{path:"/pages/a567cd/index.html",redirect:"/pages/a567cd/"},{path:"/06./02.Elasticsearch/01.Elasticsearch.html",redirect:"/pages/a567cd/"},{name:"v-3f973327",path:"/pages/5201b9/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-3f973327").then(t)}},{path:"/pages/5201b9/index.html",redirect:"/pages/5201b9/"},{path:"/06./03.MongoDB/01.MongoDB.html",redirect:"/pages/5201b9/"},{name:"v-30230c72",path:"/pages/43b4dd/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-30230c72").then(t)}},{path:"/pages/43b4dd/index.html",redirect:"/pages/43b4dd/"},{path:"/06./04.MySql/01.MySql.html",redirect:"/pages/43b4dd/"},{name:"v-26d51feb",path:"/pages/d74e41/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-26d51feb").then(t)}},{path:"/pages/d74e41/index.html",redirect:"/pages/d74e41/"},{path:"/06./06.RabbitMQ/01.RabbitMQ.html",redirect:"/pages/d74e41/"},{name:"v-03d9b432",path:"/pages/27153d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-03d9b432").then(t)}},{path:"/pages/27153d/index.html",redirect:"/pages/27153d/"},{path:"/06./05.Nginx/01.Nginx.html",redirect:"/pages/27153d/"},{name:"v-d6f86d32",path:"/pages/97e5f1/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-d6f86d32").then(t)}},{path:"/pages/97e5f1/index.html",redirect:"/pages/97e5f1/"},{path:"/06./07.Redis/01.Redis.html",redirect:"/pages/97e5f1/"},{name:"v-6ea4444b",path:"/pages/51830e/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6ea4444b").then(t)}},{path:"/pages/51830e/index.html",redirect:"/pages/51830e/"},{path:"/06./08./01..html",redirect:"/pages/51830e/"},{name:"v-a493dd52",path:"/pages/11e99f/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-a493dd52").then(t)}},{path:"/pages/11e99f/index.html",redirect:"/pages/11e99f/"},{path:"/06./09./01..html",redirect:"/pages/11e99f/"},{name:"v-d7570fb0",path:"/blog/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-d7570fb0").then(t)}},{path:"/blog/index.html",redirect:"/blog/"},{path:"/@pages/archivesPage.html",redirect:"/blog/"},{name:"v-49cf9efe",path:"/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-49cf9efe").then(t)}},{path:"/index.html",redirect:"/"},{path:"*",component:_t}],kt={title:"ZYHCODE",description:"Java ",base:"/",headTags:[["link",{rel:"icon",href:"/img/favicon.ico"}],["meta",{name:"keywords",content:".net,doc,easy,tool"}],["meta",{name:"theme-color",content:"#11a8cd"}]],pages:[{title:"",frontmatter:{title:"",date:"2024-08-21T22:56:40.000Z",permalink:"/pages/155b65/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/01.%E9%9B%86%E5%90%88/01.%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2.html",relativePath:"01.Java/01./01..md",key:"v-f415ebc0",path:"/pages/155b65/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"Java IO ",frontmatter:{title:"Java IO ",category:"Java",tag:["Java IO","Java"],date:"2024-08-21T22:31:13.000Z",permalink:"/pages/77d4e2/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/02.IO%E6%B5%81/01.IO%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html",relativePath:"01.Java/02.IO/01.IO.md",key:"v-a6c35a82",path:"/pages/77d4e2/",headers:[{level:2,title:"IO ",slug:"io-",normalizedTitle:"io ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:139},{level:3,title:"InputStream",slug:"inputstream-",normalizedTitle:"inputstream",charIndex:305},{level:3,title:"OutputStream",slug:"outputstream-",normalizedTitle:"outputstream",charIndex:2746},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:143},{level:3,title:"Reader",slug:"reader-",normalizedTitle:"reader",charIndex:4797},{level:3,title:"Writer",slug:"writer-",normalizedTitle:"writer",charIndex:5927},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:6940},{level:3,title:"BufferedInputStream",slug:"bufferedinputstream-",normalizedTitle:"bufferedinputstream",charIndex:7077},{level:3,title:"BufferedOutputStream",slug:"bufferedoutputstream-",normalizedTitle:"bufferedoutputstream",charIndex:11216},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:11665},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:11824},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:12229}],headersStr:"IO   InputStream OutputStream  Reader Writer  BufferedInputStream BufferedOutputStream   ",content:'# IO \n\nIO  Input/Output IO IO  Java \n\nJava IO  40  4 \n\n * InputStream/Reader: \n * OutputStream/Writer: \n\n\n# \n\n\n# InputStream\n\nInputStreamjava.io.InputStream\n\nInputStream \n\n * read() 0  255  -1 \n * read(byte b[ ]) :  b  b  -1 b.length   read(b, 0, b.length)\n * read(byte b[], int off, int len)read(byte b[ ])  off  len \n * skip(long n) n  ,\n * available()\n * close()\n\n Java 9 InputStream \n\n * readAllBytes()\n * readNBytes(byte[] b, int off, int len) len \n * transferTo(OutputStream out)\n\nFileInputStream \n\nFileInputStream \n\ntry (InputStream fis = new FileInputStream("input.txt")) {\n    System.out.println("Number of remaining bytes:"\n            + fis.available());\n    int content;\n    long skip = fis.skip(2);\n    System.out.println("The actual number of bytes skipped:" + skip);\n    System.out.print("The content read from file:");\n    while ((content = fis.read()) != -1) {\n        System.out.print((char) content);\n    }\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\ninput.txt \n\n\n\n\n\nNumber of remaining bytes:11\nThe actual number of bytes skipped:2\nThe content read from file:JavaGuide\n\n\n FileInputStream  BufferedInputStream\n\n readAllBytes()  String \n\n//  BufferedInputStream \nBufferedInputStream bufferedInputStream = new BufferedInputStream(new FileInputStream("input.txt"));\n//  String \nString result = new String(bufferedInputStream.readAllBytes());\nSystem.out.println(result);\n\n\nDataInputStream  FileInputStream \n\nFileInputStream fileInputStream = new FileInputStream("input.txt");\n//fileInputStream\nDataInputStream dataInputStream = new DataInputStream(fileInputStream);\n//\ndataInputStream.readBoolean();\ndataInputStream.readInt();\ndataInputStream.readUTF();\n\n\nObjectInputStream  Java ObjectOutputStream ()\n\nObjectInputStream input = new ObjectInputStream(new FileInputStream("object.data"));\nMyClass object = (MyClass) input.readObject();\ninput.close();\n\n\n Serializable  transient \n\n\n# OutputStream\n\nOutputStreamjava.io.OutputStream\n\nOutputStream \n\n * write(int b)\n * write(byte b[ ]) : b  write(b, 0, b.length) \n * write(byte[] b, int off, int len) : write(byte b[ ])  off  len \n * flush()\n * close()\n\nFileOutputStream \n\nFileOutputStream \n\ntry (FileOutputStream output = new FileOutputStream("output.txt")) {\n    byte[] array = "JavaGuide".getBytes();\n    output.write(array);\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\n\n\n\n\n FileInputStreamFileOutputStream  BufferedOutputStream\n\nFileOutputStream fileOutputStream = new FileOutputStream("output.txt");\nBufferedOutputStream bos = new BufferedOutputStream(fileOutputStream)\n\n\nDataOutputStream  FileOutputStream \n\n// \nFileOutputStream fileOutputStream = new FileOutputStream("out.txt");\nDataOutputStream dataOutputStream = new DataOutputStream(fileOutputStream);\n// \ndataOutputStream.writeBoolean(true);\ndataOutputStream.writeByte(1);\n\n\nObjectInputStream  Java ObjectInputStream,ObjectOutputStream(ObjectOutputStream)\n\nObjectOutputStream output = new ObjectOutputStream(new FileOutputStream("file.txt")\nPerson person = new Person("Guide", "JavaGuide");\noutput.writeObject(person);\n\n\n\n# \n\n  I/O \n\n\n\n *  Java \n * \n\n FileInputStream  input.txt \n\n\n\n\n\nNumber of remaining bytes:9\nThe actual number of bytes skipped:2\nThe content read from file:\n\n\n\n\nI/O \n\n Unicode utf8 : 1  3 unicode 2 gbk 1  2 \n\n\n# Reader\n\nReaderjava.io.Reader\n\nReader  InputStream \n\nReader \n\n * read() : \n * read(char[] cbuf) :  cbuf read(cbuf, 0, cbuf.length) \n * read(char[] cbuf, int off, int len)read(char[] cbuf)  off  len \n * skip(long n) n  ,\n * close() : \n\nInputStreamReader  FileReader \n\n// \npublic class InputStreamReader extends Reader {\n}\n// \npublic class FileReader extends InputStreamReader {\n}\n\n\nFileReader \n\ntry (FileReader fileReader = new FileReader("input.txt");) {\n    int content;\n    long skip = fileReader.skip(3);\n    System.out.println("The actual number of bytes skipped:" + skip);\n    System.out.print("The content read from file:");\n    while ((content = fileReader.read()) != -1) {\n        System.out.print((char) content);\n    }\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\ninput.txt \n\n\n\n\n\nThe actual number of bytes skipped:3\nThe content read from file:Guide\n\n\n\n# Writer\n\nWriterjava.io.Writer\n\nWriter \n\n * write(int c) : \n * write(char[] cbuf) cbufwrite(cbuf, 0, cbuf.length)\n * write(char[] cbuf, int off, int len)write(char[] cbuf)  off  len \n * write(String str) write(str, 0, str.length()) \n * write(String str, int off, int len)write(String str)  off  len \n * append(CharSequence csq) Writer  Writer \n * append(char c) Writer  Writer \n * flush()\n * close():\n\nOutputStreamWriter  FileWriter \n\n// \npublic class OutputStreamWriter extends Writer {\n}\n// \npublic class FileWriter extends OutputStreamWriter {\n}\n\n\nFileWriter \n\ntry (Writer output = new FileWriter("output.txt")) {\n    output.write("Guide");\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\n\n\n\n\n\n# \n\nIO / IO \n\n InputStream OutputStream\n\n BufferedInputStream FileInputStream \n\n//  BufferedInputStream \nBufferedInputStream bufferedInputStream = new BufferedInputStream(new FileInputStream("input.txt"));\n\n\n write(int b)  read()  IO \n\n write(int b)  read()  524.9 mb  PDF \n\nPDF:15428 \nPDF:2555062 \n\n\n 1/165\n\n:\n\n@Test\nvoid copy_pdf_to_another_pdf_buffer_stream() {\n    // \n    long start = System.currentTimeMillis();\n    try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(".pdf"));\n         BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream("-.pdf"))) {\n        int content;\n        while ((content = bis.read()) != -1) {\n            bos.write(content);\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    // \n    long end = System.currentTimeMillis();\n    System.out.println("PDF:" + (end - start) + " ");\n}\n\n@Test\nvoid copy_pdf_to_another_pdf_stream() {\n    // \n    long start = System.currentTimeMillis();\n    try (FileInputStream fis = new FileInputStream(".pdf");\n         FileOutputStream fos = new FileOutputStream("-.pdf")) {\n        int content;\n        while ((content = fis.read()) != -1) {\n            fos.write(content);\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    // \n    long end = System.currentTimeMillis();\n    System.out.println("PDF:" + (end - start) + " ");\n}\n\n\n read(byte b[])  write(byte b[], int off, int len) \n\n read(byte b[])  write(byte b[], int off, int len)  524.9 mb  PDF \n\nPDF:695 \nPDF:989 \n\n\n\n\n\n\n@Test\nvoid copy_pdf_to_another_pdf_with_byte_array_buffer_stream() {\n    // \n    long start = System.currentTimeMillis();\n    try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(".pdf"));\n         BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream("-.pdf"))) {\n        int len;\n        byte[] bytes = new byte[4 * 1024];\n        while ((len = bis.read(bytes)) != -1) {\n            bos.write(bytes, 0, len);\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    // \n    long end = System.currentTimeMillis();\n    System.out.println("PDF:" + (end - start) + " ");\n}\n\n@Test\nvoid copy_pdf_to_another_pdf_with_byte_array_stream() {\n    // \n    long start = System.currentTimeMillis();\n    try (FileInputStream fis = new FileInputStream(".pdf");\n         FileOutputStream fos = new FileOutputStream("-.pdf")) {\n        int len;\n        byte[] bytes = new byte[4 * 1024];\n        while ((len = fis.read(bytes)) != -1) {\n            fos.write(bytes, 0, len);\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    // \n    long end = System.currentTimeMillis();\n    System.out.println("PDF:" + (end - start) + " ");\n}\n\n\n\n# BufferedInputStream\n\nBufferedInputStream  IO \n\nBufferedInputStream  BufferedInputStream \n\npublic\nclass BufferedInputStream extends FilterInputStream {\n    // \n    protected volatile byte buf[];\n    // \n    private static int DEFAULT_BUFFER_SIZE = 8192;\n    // \n    public BufferedInputStream(InputStream in) {\n        this(in, DEFAULT_BUFFER_SIZE);\n    }\n    // \n    public BufferedInputStream(InputStream in, int size) {\n        super(in);\n        if (size <= 0) {\n            throw new IllegalArgumentException("Buffer size <= 0");\n        }\n        buf = new byte[size];\n    }\n}\n\n\n 8192  BufferedInputStream(InputStream in, int size) \n\n\n# BufferedOutputStream\n\nBufferedOutputStream  IO \n\ntry (BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream("output.txt"))) {\n    byte[] array = "JavaGuide".getBytes();\n    bos.write(array);\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\n BufferedInputStream BufferedOutputStream  8192 \n\n\n# \n\nBufferedReader  BufferedWriter BufferedInputStreamBufferedOutputStream\n\n\n# \n\n\n\nSystem.out.print("Hello");\nSystem.out.println("Hello");\n\n\nSystem.out  PrintStream print PrintStream  write \n\nPrintStream  PrintWriter PrintStream  OutputStream PrintWriter  Writer \n\npublic class PrintStream extends FilterOutputStream\n    implements Appendable, Closeable {\n}\npublic class PrintWriter extends Writer {\n}\n\n\n\n# \n\n RandomAccessFile \n\nRandomAccessFile  mode\n\n// openAndDelete  false \npublic RandomAccessFile(File file, String mode)\n    throws FileNotFoundException {\n    this(file, mode, false);\n}\n// \nprivate RandomAccessFile(File file, String mode, boolean openAndDelete)  throws FileNotFoundException{\n  // \n}\n\n\n\n\n * r : \n * rw: \n * rws:  rwrws \n * rwd :  rwrwd \n\n\n\nRandomAccessFile  RandomAccessFile  seek(long pos)  pos  getFilePointer() \n\nRandomAccessFile \n\nRandomAccessFile randomAccessFile = new RandomAccessFile(new File("input.txt"), "rw");\nSystem.out.println("" + randomAccessFile.getFilePointer() + "," + (char) randomAccessFile.read() + "" + randomAccessFile.getFilePointer());\n//  6\nrandomAccessFile.seek(6);\nSystem.out.println("" + randomAccessFile.getFilePointer() + "," + (char) randomAccessFile.read() + "" + randomAccessFile.getFilePointer());\n//  7 \nrandomAccessFile.write(new byte[]{\'H\', \'I\', \'J\', \'K\'});\n//  0\nrandomAccessFile.seek(0);\nSystem.out.println("" + randomAccessFile.getFilePointer() + "," + (char) randomAccessFile.read() + "" + randomAccessFile.getFilePointer());\n\n\ninput.txt \n\n\n\n\n\n0,A1\n6,G7\n0,A1\n\n\ninput.txt  ABCDEFGHIJK \n\nRandomAccessFile  write \n\nRandomAccessFile randomAccessFile = new RandomAccessFile(new File("input.txt"), "rw");\nrandomAccessFile.write(new byte[]{\'H\', \'I\', \'J\', \'K\'});\n\n\n input.txt  ABCD  HIJK \n\nRandomAccessFile   \n\nRandomAccessFile \n\n\n\nJava \n\n\n\nRandomAccessFile  FileDescriptor ()  FileChannel ',normalizedContent:'# io \n\nio  input/output io io  java \n\njava io  40  4 \n\n * inputstream/reader: \n * outputstream/writer: \n\n\n# \n\n\n# inputstream\n\ninputstreamjava.io.inputstream\n\ninputstream \n\n * read() 0  255  -1 \n * read(byte b[ ]) :  b  b  -1 b.length   read(b, 0, b.length)\n * read(byte b[], int off, int len)read(byte b[ ])  off  len \n * skip(long n) n  ,\n * available()\n * close()\n\n java 9 inputstream \n\n * readallbytes()\n * readnbytes(byte[] b, int off, int len) len \n * transferto(outputstream out)\n\nfileinputstream \n\nfileinputstream \n\ntry (inputstream fis = new fileinputstream("input.txt")) {\n    system.out.println("number of remaining bytes:"\n            + fis.available());\n    int content;\n    long skip = fis.skip(2);\n    system.out.println("the actual number of bytes skipped:" + skip);\n    system.out.print("the content read from file:");\n    while ((content = fis.read()) != -1) {\n        system.out.print((char) content);\n    }\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\ninput.txt \n\n\n\n\n\nnumber of remaining bytes:11\nthe actual number of bytes skipped:2\nthe content read from file:javaguide\n\n\n fileinputstream  bufferedinputstream\n\n readallbytes()  string \n\n//  bufferedinputstream \nbufferedinputstream bufferedinputstream = new bufferedinputstream(new fileinputstream("input.txt"));\n//  string \nstring result = new string(bufferedinputstream.readallbytes());\nsystem.out.println(result);\n\n\ndatainputstream  fileinputstream \n\nfileinputstream fileinputstream = new fileinputstream("input.txt");\n//fileinputstream\ndatainputstream datainputstream = new datainputstream(fileinputstream);\n//\ndatainputstream.readboolean();\ndatainputstream.readint();\ndatainputstream.readutf();\n\n\nobjectinputstream  java objectoutputstream ()\n\nobjectinputstream input = new objectinputstream(new fileinputstream("object.data"));\nmyclass object = (myclass) input.readobject();\ninput.close();\n\n\n serializable  transient \n\n\n# outputstream\n\noutputstreamjava.io.outputstream\n\noutputstream \n\n * write(int b)\n * write(byte b[ ]) : b  write(b, 0, b.length) \n * write(byte[] b, int off, int len) : write(byte b[ ])  off  len \n * flush()\n * close()\n\nfileoutputstream \n\nfileoutputstream \n\ntry (fileoutputstream output = new fileoutputstream("output.txt")) {\n    byte[] array = "javaguide".getbytes();\n    output.write(array);\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\n\n\n\n\n fileinputstreamfileoutputstream  bufferedoutputstream\n\nfileoutputstream fileoutputstream = new fileoutputstream("output.txt");\nbufferedoutputstream bos = new bufferedoutputstream(fileoutputstream)\n\n\ndataoutputstream  fileoutputstream \n\n// \nfileoutputstream fileoutputstream = new fileoutputstream("out.txt");\ndataoutputstream dataoutputstream = new dataoutputstream(fileoutputstream);\n// \ndataoutputstream.writeboolean(true);\ndataoutputstream.writebyte(1);\n\n\nobjectinputstream  java objectinputstream,objectoutputstream(objectoutputstream)\n\nobjectoutputstream output = new objectoutputstream(new fileoutputstream("file.txt")\nperson person = new person("guide", "javaguide");\noutput.writeobject(person);\n\n\n\n# \n\n  i/o \n\n\n\n *  java \n * \n\n fileinputstream  input.txt \n\n\n\n\n\nnumber of remaining bytes:9\nthe actual number of bytes skipped:2\nthe content read from file:aa\n\n\n\n\ni/o \n\n unicode utf8 : 1  3 unicode 2 gbk 1  2 \n\n\n# reader\n\nreaderjava.io.reader\n\nreader  inputstream \n\nreader \n\n * read() : \n * read(char[] cbuf) :  cbuf read(cbuf, 0, cbuf.length) \n * read(char[] cbuf, int off, int len)read(char[] cbuf)  off  len \n * skip(long n) n  ,\n * close() : \n\ninputstreamreader  filereader \n\n// \npublic class inputstreamreader extends reader {\n}\n// \npublic class filereader extends inputstreamreader {\n}\n\n\nfilereader \n\ntry (filereader filereader = new filereader("input.txt");) {\n    int content;\n    long skip = filereader.skip(3);\n    system.out.println("the actual number of bytes skipped:" + skip);\n    system.out.print("the content read from file:");\n    while ((content = filereader.read()) != -1) {\n        system.out.print((char) content);\n    }\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\ninput.txt \n\n\n\n\n\nthe actual number of bytes skipped:3\nthe content read from file:guide\n\n\n\n# writer\n\nwriterjava.io.writer\n\nwriter \n\n * write(int c) : \n * write(char[] cbuf) cbufwrite(cbuf, 0, cbuf.length)\n * write(char[] cbuf, int off, int len)write(char[] cbuf)  off  len \n * write(string str) write(str, 0, str.length()) \n * write(string str, int off, int len)write(string str)  off  len \n * append(charsequence csq) writer  writer \n * append(char c) writer  writer \n * flush()\n * close():\n\noutputstreamwriter  filewriter \n\n// \npublic class outputstreamwriter extends writer {\n}\n// \npublic class filewriter extends outputstreamwriter {\n}\n\n\nfilewriter \n\ntry (writer output = new filewriter("output.txt")) {\n    output.write("guide");\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\n\n\n\n\n\n# \n\nio / io \n\n inputstream outputstream\n\n bufferedinputstream fileinputstream \n\n//  bufferedinputstream \nbufferedinputstream bufferedinputstream = new bufferedinputstream(new fileinputstream("input.txt"));\n\n\n write(int b)  read()  io \n\n write(int b)  read()  524.9 mb  pdf \n\npdf:15428 \npdf:2555062 \n\n\n 1/165\n\n:\n\n@test\nvoid copy_pdf_to_another_pdf_buffer_stream() {\n    // \n    long start = system.currenttimemillis();\n    try (bufferedinputstream bis = new bufferedinputstream(new fileinputstream(".pdf"));\n         bufferedoutputstream bos = new bufferedoutputstream(new fileoutputstream("-.pdf"))) {\n        int content;\n        while ((content = bis.read()) != -1) {\n            bos.write(content);\n        }\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n    // \n    long end = system.currenttimemillis();\n    system.out.println("pdf:" + (end - start) + " ");\n}\n\n@test\nvoid copy_pdf_to_another_pdf_stream() {\n    // \n    long start = system.currenttimemillis();\n    try (fileinputstream fis = new fileinputstream(".pdf");\n         fileoutputstream fos = new fileoutputstream("-.pdf")) {\n        int content;\n        while ((content = fis.read()) != -1) {\n            fos.write(content);\n        }\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n    // \n    long end = system.currenttimemillis();\n    system.out.println("pdf:" + (end - start) + " ");\n}\n\n\n read(byte b[])  write(byte b[], int off, int len) \n\n read(byte b[])  write(byte b[], int off, int len)  524.9 mb  pdf \n\npdf:695 \npdf:989 \n\n\n\n\n\n\n@test\nvoid copy_pdf_to_another_pdf_with_byte_array_buffer_stream() {\n    // \n    long start = system.currenttimemillis();\n    try (bufferedinputstream bis = new bufferedinputstream(new fileinputstream(".pdf"));\n         bufferedoutputstream bos = new bufferedoutputstream(new fileoutputstream("-.pdf"))) {\n        int len;\n        byte[] bytes = new byte[4 * 1024];\n        while ((len = bis.read(bytes)) != -1) {\n            bos.write(bytes, 0, len);\n        }\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n    // \n    long end = system.currenttimemillis();\n    system.out.println("pdf:" + (end - start) + " ");\n}\n\n@test\nvoid copy_pdf_to_another_pdf_with_byte_array_stream() {\n    // \n    long start = system.currenttimemillis();\n    try (fileinputstream fis = new fileinputstream(".pdf");\n         fileoutputstream fos = new fileoutputstream("-.pdf")) {\n        int len;\n        byte[] bytes = new byte[4 * 1024];\n        while ((len = fis.read(bytes)) != -1) {\n            fos.write(bytes, 0, len);\n        }\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n    // \n    long end = system.currenttimemillis();\n    system.out.println("pdf:" + (end - start) + " ");\n}\n\n\n\n# bufferedinputstream\n\nbufferedinputstream  io \n\nbufferedinputstream  bufferedinputstream \n\npublic\nclass bufferedinputstream extends filterinputstream {\n    // \n    protected volatile byte buf[];\n    // \n    private static int default_buffer_size = 8192;\n    // \n    public bufferedinputstream(inputstream in) {\n        this(in, default_buffer_size);\n    }\n    // \n    public bufferedinputstream(inputstream in, int size) {\n        super(in);\n        if (size <= 0) {\n            throw new illegalargumentexception("buffer size <= 0");\n        }\n        buf = new byte[size];\n    }\n}\n\n\n 8192  bufferedinputstream(inputstream in, int size) \n\n\n# bufferedoutputstream\n\nbufferedoutputstream  io \n\ntry (bufferedoutputstream bos = new bufferedoutputstream(new fileoutputstream("output.txt"))) {\n    byte[] array = "javaguide".getbytes();\n    bos.write(array);\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\n bufferedinputstream bufferedoutputstream  8192 \n\n\n# \n\nbufferedreader  bufferedwriter bufferedinputstreambufferedoutputstream\n\n\n# \n\n\n\nsystem.out.print("hello");\nsystem.out.println("hello");\n\n\nsystem.out  printstream print printstream  write \n\nprintstream  printwriter printstream  outputstream printwriter  writer \n\npublic class printstream extends filteroutputstream\n    implements appendable, closeable {\n}\npublic class printwriter extends writer {\n}\n\n\n\n# \n\n randomaccessfile \n\nrandomaccessfile  mode\n\n// openanddelete  false \npublic randomaccessfile(file file, string mode)\n    throws filenotfoundexception {\n    this(file, mode, false);\n}\n// \nprivate randomaccessfile(file file, string mode, boolean openanddelete)  throws filenotfoundexception{\n  // \n}\n\n\n\n\n * r : \n * rw: \n * rws:  rwrws \n * rwd :  rwrwd \n\n\n\nrandomaccessfile  randomaccessfile  seek(long pos)  pos  getfilepointer() \n\nrandomaccessfile \n\nrandomaccessfile randomaccessfile = new randomaccessfile(new file("input.txt"), "rw");\nsystem.out.println("" + randomaccessfile.getfilepointer() + "," + (char) randomaccessfile.read() + "" + randomaccessfile.getfilepointer());\n//  6\nrandomaccessfile.seek(6);\nsystem.out.println("" + randomaccessfile.getfilepointer() + "," + (char) randomaccessfile.read() + "" + randomaccessfile.getfilepointer());\n//  7 \nrandomaccessfile.write(new byte[]{\'h\', \'i\', \'j\', \'k\'});\n//  0\nrandomaccessfile.seek(0);\nsystem.out.println("" + randomaccessfile.getfilepointer() + "," + (char) randomaccessfile.read() + "" + randomaccessfile.getfilepointer());\n\n\ninput.txt \n\n\n\n\n\n0,a1\n6,g7\n0,a1\n\n\ninput.txt  abcdefghijk \n\nrandomaccessfile  write \n\nrandomaccessfile randomaccessfile = new randomaccessfile(new file("input.txt"), "rw");\nrandomaccessfile.write(new byte[]{\'h\', \'i\', \'j\', \'k\'});\n\n\n input.txt  abcd  hijk \n\nrandomaccessfile   \n\nrandomaccessfile \n\n\n\njava \n\n\n\nrandomaccessfile  filedescriptor ()  filechannel ',charsets:{cjk:!0}},{title:"Java IO ",frontmatter:{title:"Java IO ",category:"Java",tag:["Java IO","Java"],date:"2024-08-21T22:33:13.000Z",permalink:"/pages/49acab/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/02.IO%E6%B5%81/02.IO%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java/02.IO/02.IO.md",key:"v-998835bc",path:"/pages/49acab/",headers:[{level:2,title:"",slug:"",normalizedTitle:"",charIndex:39},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:2389},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:5642},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:5917},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:8313}],headersStr:"    ",content:' IO \n\n\n# \n\nDecorator \n\nIO \n\n FilterInputStream FilterOutputStream InputStream OutputStream\n\nBufferedInputStream()DataInputStream FilterInputStream BufferedOutputStreamDataOutputStreamFilterOutputStream\n\n BufferedInputStream FileInputStream \n\nBufferedInputStream \n\npublic BufferedInputStream(InputStream in) {\n    this(in, DEFAULT_BUFFER_SIZE);\n}\n\npublic BufferedInputStream(InputStream in, int size) {\n    super(in);\n    if (size <= 0) {\n        throw new IllegalArgumentException("Buffer size <= 0");\n    }\n    buf = new byte[size];\n}\n\n\nBufferedInputStream  InputStream \n\nBufferedInputStream \n\ntry (BufferedInputStream bis = new BufferedInputStream(new FileInputStream("input.txt"))) {\n    int content;\n    long skip = bis.skip(2);\n    while ((content = bis.read()) != -1) {\n        System.out.print((char) content);\n    }\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\nBufferedFileInputStream\n\nBufferedFileInputStream bfis = new BufferedFileInputStream("input.txt");\n\n\n InputStream InputStream\n\n IO ZipInputStream ZipOutputStream  BufferedInputStream  BufferedOutputStream \n\nBufferedInputStream bis = new BufferedInputStream(new FileInputStream(fileName));\nZipInputStream zis = new ZipInputStream(bis);\n\nBufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(fileName));\nZipOutputStream zipOut = new ZipOutputStream(bos);\n\n\nZipInputStream ZipOutputStream InflaterInputStream DeflaterOutputStream\n\npublic\nclass InflaterInputStream extends FilterInputStream {\n}\n\npublic\nclass DeflaterOutputStream extends FilterOutputStream {\n}\n\n\n\n\n\n IO  InputStream OutputStream\n\nBufferedReader  Reader BufferedWriter  Writer \n\nBufferedWriter bw = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(fileName), "UTF-8"));\n\n\nIO \n\n\n# \n\nAdapter Pattern \n\n (Adaptee) (Adapter) \n\nIO \n\nInputStreamReader  OutputStreamWriter (Adapter) InputStreamReader  StreamDecoder  OutputStreamWriter StreamEncoder\n\nInputStream  OutputStream  InputStreamReader  OutputStreamWriter\n\n// InputStreamReader FileInputStream \nInputStreamReader isr = new InputStreamReader(new FileInputStream(fileName), "UTF-8");\n// BufferedReader  InputStreamReader \nBufferedReader bufferedReader = new BufferedReader(isr);\n\n\njava.io.InputStreamReader \n\npublic class InputStreamReader extends Reader {\n //\n private final StreamDecoder sd;\n    public InputStreamReader(InputStream in) {\n        super(in);\n        try {\n            //  StreamDecoder \n            sd = StreamDecoder.forInputStreamReader(in, this, (String)null);\n        } catch (UnsupportedEncodingException e) {\n            throw new Error(e);\n        }\n    }\n    //  StreamDecoder \n public int read() throws IOException {\n        return sd.read();\n    }\n}\n\n\njava.io.OutputStreamWriter \n\npublic class OutputStreamWriter extends Writer {\n    // \n    private final StreamEncoder se;\n    public OutputStreamWriter(OutputStream out) {\n        super(out);\n        try {\n           //  StreamEncoder \n            se = StreamEncoder.forOutputStreamWriter(out, this, (String)null);\n        } catch (UnsupportedEncodingException e) {\n            throw new Error(e);\n        }\n    }\n    //  StreamEncoder \n    public void write(int c) throws IOException {\n        se.write(c);\n    }\n}\n\n\n\n\n \n\n  StreamDecoder StreamEncoder InputStream  OutputStream  FileChannel read  write \n\nStreamDecoder(InputStream in, Object lock, CharsetDecoder dec) {\n    // \n    //  InputStream  FileChannel \n    ch = getChannel((FileInputStream)in);\n}\n\n\n\n\nFutureTask Executors  RunnableAdapter  Runnable  Callable\n\nFutureTask Runnable \n\npublic FutureTask(Runnable runnable, V result) {\n    //  Executors  callable \n    this.callable = Executors.callable(runnable, result);\n    this.state = NEW;\n}\n\n\nExecutors\n\n//  Executors  RunnableAdapter \npublic static <T> Callable<T> callable(Runnable task, T result) {\n    if (task == null)\n        throw new NullPointerException();\n    return new RunnableAdapter<T>(task, result);\n}\n// \nstatic final class RunnableAdapter<T> implements Callable<T> {\n    final Runnable task;\n    final T result;\n    RunnableAdapter(Runnable task, T result) {\n        this.task = task;\n        this.result = result;\n    }\n    public T call() {\n        task.run();\n        return result;\n    }\n}\n\n\n\n# \n\nNIO  Files  newInputStream  InputStream  Paths  get  Path ZipFileSystem sun.nio java.nio  getPath  Path \n\nInputStream is = Files.newInputStream(Paths.get(generatorLogoPath))\n\n\n\n# \n\nNIO \n\nNIO  WatchService  Watchable WatchService Watchable \n\nWatchable  WatchService  register \n\npublic interface Path\n    extends Comparable<Path>, Iterable<Path>, Watchable{\n}\n\npublic interface Watchable {\n    WatchKey register(WatchService watcher,\n                      WatchEvent.Kind<?>[] events,\n                      WatchEvent.Modifier... modifiers)\n        throws IOException;\n}\n\n\nWatchService  WatchService \n\n//  WatchService \nWatchService watchService = FileSystems.getDefault().newWatchService();\n\n//  Path :\nPath path = Paths.get("workingDirectory");\n//  path  WatchService \nWatchKey watchKey = path.register(\nwatchService, StandardWatchEventKinds...);\n\n\nPath  register  events \n\nWatchKey register(WatchService watcher,\n                  WatchEvent.Kind<?>... events)\n    throws IOException;\n\n\n 3 \n\n * StandardWatchEventKinds.ENTRY_CREATE\n * StandardWatchEventKinds.ENTRY_DELETE : \n * StandardWatchEventKinds.ENTRY_MODIFY : \n\nregister  WatchKey WatchKey \n\nWatchKey key;\nwhile ((key = watchService.take()) != null) {\n    for (WatchEvent<?> event : key.pollEvents()) {\n      //  WatchEvent \n    }\n    key.reset();\n}\n\n\nWatchService  daemon thread\n\nclass PollingWatchService\n    extends AbstractWatchService\n{\n    //  daemon thread\n    private final ScheduledExecutorService scheduledExecutor;\n\n    PollingWatchService() {\n        scheduledExecutor = Executors\n            .newSingleThreadScheduledExecutor(new ThreadFactory() {\n                 @Override\n                 public Thread newThread(Runnable r) {\n                     Thread t = new Thread(r);\n                     t.setDaemon(true);\n                     return t;\n                 }});\n    }\n\n  void enable(Set<? extends WatchEvent.Kind<?>> events, long period) {\n    synchronized (this) {\n      // \n      this.events = events;\n\n        // \n      Runnable thunk = new Runnable() { public void run() { poll(); }};\n      this.poller = scheduledExecutor\n        .scheduleAtFixedRate(thunk, period, period, TimeUnit.SECONDS);\n    }\n  }\n}\n\n\n\n# \n\n * Patterns in Java APIshttp://cecs.wright.edu/~tkprasad/courses/ceg860/paper/node26.html\n *  Java IO https://time.geekbang.org/column/article/204845\n * sun.nio  java  - RednaxelaFX https://www.zhihu.com/question/29237781/answer/43653953',normalizedContent:' io \n\n\n# \n\ndecorator \n\nio \n\n filterinputstream filteroutputstream inputstream outputstream\n\nbufferedinputstream()datainputstream filterinputstream bufferedoutputstreamdataoutputstreamfilteroutputstream\n\n bufferedinputstream fileinputstream \n\nbufferedinputstream \n\npublic bufferedinputstream(inputstream in) {\n    this(in, default_buffer_size);\n}\n\npublic bufferedinputstream(inputstream in, int size) {\n    super(in);\n    if (size <= 0) {\n        throw new illegalargumentexception("buffer size <= 0");\n    }\n    buf = new byte[size];\n}\n\n\nbufferedinputstream  inputstream \n\nbufferedinputstream \n\ntry (bufferedinputstream bis = new bufferedinputstream(new fileinputstream("input.txt"))) {\n    int content;\n    long skip = bis.skip(2);\n    while ((content = bis.read()) != -1) {\n        system.out.print((char) content);\n    }\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\nbufferedfileinputstream\n\nbufferedfileinputstream bfis = new bufferedfileinputstream("input.txt");\n\n\n inputstream inputstream\n\n io zipinputstream zipoutputstream  bufferedinputstream  bufferedoutputstream \n\nbufferedinputstream bis = new bufferedinputstream(new fileinputstream(filename));\nzipinputstream zis = new zipinputstream(bis);\n\nbufferedoutputstream bos = new bufferedoutputstream(new fileoutputstream(filename));\nzipoutputstream zipout = new zipoutputstream(bos);\n\n\nzipinputstream zipoutputstream inflaterinputstream deflateroutputstream\n\npublic\nclass inflaterinputstream extends filterinputstream {\n}\n\npublic\nclass deflateroutputstream extends filteroutputstream {\n}\n\n\n\n\n\n io  inputstream outputstream\n\nbufferedreader  reader bufferedwriter  writer \n\nbufferedwriter bw = new bufferedwriter(new outputstreamwriter(new fileoutputstream(filename), "utf-8"));\n\n\nio \n\n\n# \n\nadapter pattern \n\n (adaptee) (adapter) \n\nio \n\ninputstreamreader  outputstreamwriter (adapter) inputstreamreader  streamdecoder  outputstreamwriter streamencoder\n\ninputstream  outputstream  inputstreamreader  outputstreamwriter\n\n// inputstreamreader fileinputstream \ninputstreamreader isr = new inputstreamreader(new fileinputstream(filename), "utf-8");\n// bufferedreader  inputstreamreader \nbufferedreader bufferedreader = new bufferedreader(isr);\n\n\njava.io.inputstreamreader \n\npublic class inputstreamreader extends reader {\n //\n private final streamdecoder sd;\n    public inputstreamreader(inputstream in) {\n        super(in);\n        try {\n            //  streamdecoder \n            sd = streamdecoder.forinputstreamreader(in, this, (string)null);\n        } catch (unsupportedencodingexception e) {\n            throw new error(e);\n        }\n    }\n    //  streamdecoder \n public int read() throws ioexception {\n        return sd.read();\n    }\n}\n\n\njava.io.outputstreamwriter \n\npublic class outputstreamwriter extends writer {\n    // \n    private final streamencoder se;\n    public outputstreamwriter(outputstream out) {\n        super(out);\n        try {\n           //  streamencoder \n            se = streamencoder.foroutputstreamwriter(out, this, (string)null);\n        } catch (unsupportedencodingexception e) {\n            throw new error(e);\n        }\n    }\n    //  streamencoder \n    public void write(int c) throws ioexception {\n        se.write(c);\n    }\n}\n\n\n\n\n \n\n  streamdecoder streamencoder inputstream  outputstream  filechannel read  write \n\nstreamdecoder(inputstream in, object lock, charsetdecoder dec) {\n    // \n    //  inputstream  filechannel \n    ch = getchannel((fileinputstream)in);\n}\n\n\n\n\nfuturetask executors  runnableadapter  runnable  callable\n\nfuturetask runnable \n\npublic futuretask(runnable runnable, v result) {\n    //  executors  callable \n    this.callable = executors.callable(runnable, result);\n    this.state = new;\n}\n\n\nexecutors\n\n//  executors  runnableadapter \npublic static <t> callable<t> callable(runnable task, t result) {\n    if (task == null)\n        throw new nullpointerexception();\n    return new runnableadapter<t>(task, result);\n}\n// \nstatic final class runnableadapter<t> implements callable<t> {\n    final runnable task;\n    final t result;\n    runnableadapter(runnable task, t result) {\n        this.task = task;\n        this.result = result;\n    }\n    public t call() {\n        task.run();\n        return result;\n    }\n}\n\n\n\n# \n\nnio  files  newinputstream  inputstream  paths  get  path zipfilesystem sun.nio java.nio  getpath  path \n\ninputstream is = files.newinputstream(paths.get(generatorlogopath))\n\n\n\n# \n\nnio \n\nnio  watchservice  watchable watchservice watchable \n\nwatchable  watchservice  register \n\npublic interface path\n    extends comparable<path>, iterable<path>, watchable{\n}\n\npublic interface watchable {\n    watchkey register(watchservice watcher,\n                      watchevent.kind<?>[] events,\n                      watchevent.modifier... modifiers)\n        throws ioexception;\n}\n\n\nwatchservice  watchservice \n\n//  watchservice \nwatchservice watchservice = filesystems.getdefault().newwatchservice();\n\n//  path :\npath path = paths.get("workingdirectory");\n//  path  watchservice \nwatchkey watchkey = path.register(\nwatchservice, standardwatcheventkinds...);\n\n\npath  register  events \n\nwatchkey register(watchservice watcher,\n                  watchevent.kind<?>... events)\n    throws ioexception;\n\n\n 3 \n\n * standardwatcheventkinds.entry_create\n * standardwatcheventkinds.entry_delete : \n * standardwatcheventkinds.entry_modify : \n\nregister  watchkey watchkey \n\nwatchkey key;\nwhile ((key = watchservice.take()) != null) {\n    for (watchevent<?> event : key.pollevents()) {\n      //  watchevent \n    }\n    key.reset();\n}\n\n\nwatchservice  daemon thread\n\nclass pollingwatchservice\n    extends abstractwatchservice\n{\n    //  daemon thread\n    private final scheduledexecutorservice scheduledexecutor;\n\n    pollingwatchservice() {\n        scheduledexecutor = executors\n            .newsinglethreadscheduledexecutor(new threadfactory() {\n                 @override\n                 public thread newthread(runnable r) {\n                     thread t = new thread(r);\n                     t.setdaemon(true);\n                     return t;\n                 }});\n    }\n\n  void enable(set<? extends watchevent.kind<?>> events, long period) {\n    synchronized (this) {\n      // \n      this.events = events;\n\n        // \n      runnable thunk = new runnable() { public void run() { poll(); }};\n      this.poller = scheduledexecutor\n        .scheduleatfixedrate(thunk, period, period, timeunit.seconds);\n    }\n  }\n}\n\n\n\n# \n\n * patterns in java apishttp://cecs.wright.edu/~tkprasad/courses/ceg860/paper/node26.html\n *  java io https://time.geekbang.org/column/article/204845\n * sun.nio  java  - rednaxelafx https://www.zhihu.com/question/29237781/answer/43653953',charsets:{cjk:!0}},{title:"Java IO ",frontmatter:{title:"Java IO ",category:"Java",tag:["Java IO","Java"],date:"2024-08-21T22:33:21.000Z",permalink:"/pages/a3d832/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/02.IO%E6%B5%81/03.IO%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93.html",relativePath:"01.Java/02.IO/03.IO.md",key:"v-78bcb4bc",path:"/pages/a3d832/",headers:[{level:2,title:"",slug:"",normalizedTitle:"",charIndex:154},{level:2,title:"I/O",slug:"i-o",normalizedTitle:"i/o",charIndex:158},{level:3,title:" I/O?",slug:"-i-o",normalizedTitle:" i/o?",charIndex:227},{level:3,title:" IO ?",slug:"-io-",normalizedTitle:" io ?",charIndex:1038},{level:2,title:"Java  3  IO ",slug:"java--3--io-",normalizedTitle:"java  3  io ",charIndex:1149},{level:3,title:"BIO (Blocking I/O)",slug:"bio-blocking-i-o",normalizedTitle:"bio (blocking i/o)",charIndex:1172},{level:3,title:"NIO (Non-blocking/New I/O)",slug:"nio-non-blocking-new-i-o",normalizedTitle:"nio (non-blocking/new i/o)",charIndex:1359},{level:3,title:"AIO (Asynchronous I/O)",slug:"aio-asynchronous-i-o",normalizedTitle:"aio (asynchronous i/o)",charIndex:2321},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:2607}],headersStr:" I/O  I/O?  IO ? Java  3  IO  BIO (Blocking I/O) NIO (Non-blocking/New I/O) AIO (Asynchronous I/O) ",content:"IO !UNIX ~\n\n//\n\n\n# \n\nI/O  I/O \n\n\n# I/O\n\n\n#  I/O?\n\nI/OInput/Output  \n\n I/O\n\n. 5 \n\n\n\n\n\n\n\n I/O \n\n I/O\n\n User space  Kernel space  \n\n IO \n\n\n\n IO \n\n IO   \n\n  IO   IO\n\n IO  IO  IO  IO \n\n I/O \n\n 1.  I/O \n 2. \n\n\n#  IO ?\n\nUNIX  IO  5  I/O I/OI/O  I/O  I/O\n\n 5  IO \n\n\n# Java  3  IO \n\n\n# BIO (Blocking I/O)\n\nBIO  IO  \n\n IO  read \n\n\n\n BIO  I/O \n\n\n# NIO (Non-blocking/New I/O)\n\nJava  NIO  Java 1.4  java.nio  Channel , SelectorBuffer NIO  N  Non-blocking New I/O   NIO \n\nJava  NIO  I/O Java  NIO  IO \n\n\n\n  IO \n\n\n\n IO  read \n\n IO  IO \n\n IO  I/O  CPU \n\nI/O  \n\n\n\nIO  select  read read  -> \n\n>  IO  selectepoll select \n> \n>  * select \n>  * epoll linux 2.6  select  IO \n\nIO  CPU \n\nJava  NIO  ( Selector )  \n\n\n\n\n# AIO (Asynchronous I/O)\n\nAIO  NIO 2Java 7  NIO  NIO 2, IO \n\n IO \n\n\n\n AIO Netty  AIONetty  AIO  Linux \n\n Java  BIONIOAIO\n\n\n\n\n# \n\n *  Tomcat & Jetty\n *  IOhttps://llc687.top/126.html\n *  IOhttps://www.jianshu.com/p/fa7bdc4f3de7\n * 10  Java NIO https://www.cnblogs.com/crazymakercircle/p/10225159.html\n * IO  | https://www.cnblogs.com/sheng-jie/p/how-much-you-know-about-io-models.html\n * UNIX   1 API 6.2  IO ",normalizedContent:"io !unix ~\n\n//\n\n\n# \n\ni/o  i/o \n\n\n# i/o\n\n\n#  i/o?\n\ni/oinput/output  \n\n i/o\n\n. 5 \n\n\n\n\n\n\n\n i/o \n\n i/o\n\n user space  kernel space  \n\n io \n\n\n\n io \n\n io   \n\n  io   io\n\n io  io  io  io \n\n i/o \n\n 1.  i/o \n 2. \n\n\n#  io ?\n\nunix  io  5  i/o i/oi/o  i/o  i/o\n\n 5  io \n\n\n# java  3  io \n\n\n# bio (blocking i/o)\n\nbio  io  \n\n io  read \n\n\n\n bio  i/o \n\n\n# nio (non-blocking/new i/o)\n\njava  nio  java 1.4  java.nio  channel , selectorbuffer nio  n  non-blocking new i/o   nio \n\njava  nio  i/o java  nio  io \n\n\n\n  io \n\n\n\n io  read \n\n io  io \n\n io  i/o  cpu \n\ni/o  \n\n\n\nio  select  read read  -> \n\n>  io  selectepoll select \n> \n>  * select \n>  * epoll linux 2.6  select  io \n\nio  cpu \n\njava  nio  ( selector )  \n\n\n\n\n# aio (asynchronous i/o)\n\naio  nio 2java 7  nio  nio 2, io \n\n io \n\n\n\n aio netty  aionetty  aio  linux \n\n java  bionioaio\n\n\n\n\n# \n\n *  tomcat & jetty\n *  iohttps://llc687.top/126.html\n *  iohttps://www.jianshu.com/p/fa7bdc4f3de7\n * 10  java nio https://www.cnblogs.com/crazymakercircle/p/10225159.html\n * io  | https://www.cnblogs.com/sheng-jie/p/how-much-you-know-about-io-models.html\n * unix   1 api 6.2  io ",charsets:{cjk:!0}},{title:"Java NIO ",frontmatter:{title:"Java NIO ",category:"Java",tag:["Java IO","Java"],date:"2024-08-21T22:33:27.000Z",permalink:"/pages/42be26/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/02.IO%E6%B5%81/04.NIO%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93.html",relativePath:"01.Java/02.IO/04.NIO.md",key:"v-1f0ca540",path:"/pages/42be26/",headers:[{level:2,title:"NIO ",slug:"nio-",normalizedTitle:"nio ",charIndex:73},{level:2,title:"NIO ",slug:"nio-",normalizedTitle:"nio ",charIndex:562},{level:3,title:"Buffer",slug:"buffer-",normalizedTitle:"buffer",charIndex:594},{level:3,title:"Channel",slug:"channel-",normalizedTitle:"channel",charIndex:696},{level:3,title:"Selector",slug:"selector-",normalizedTitle:"selector",charIndex:800},{level:2,title:"NIO ",slug:"nio-",normalizedTitle:"nio ",charIndex:9693},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:11180},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:45}],headersStr:"NIO  NIO  Buffer Channel Selector NIO   ",content:' NIO  I/O Java IO \n\n\n# NIO \n\n Java I/O BIOI/O  I/O \n\n Java1.4  I/O   NIO New IO Non-blocking IO NIO  I/O  Java  I/O I/O \n\n BIONIO  AIO  AIO Java IO \n\n\n\n NIO NIO  BIO \n\n\n# NIO \n\nNIO \n\n * BufferNIO  Channel  Buffer  Buffer  Channel \n * ChannelChannel NIO  Channel \n * Selector Channel I/O  Channel  Selector  Selector \n\n\n\n\n\n\n\n\n# Buffer\n\n BIO  \n\n Java 1.4  NIO  BIO  BIO NIO   NIO \n\nBuffer  ByteBuffer\n\n\n\n Buffer IntBufferFloatBufferCharBuffer  int[]float[]char[] \n\nBuffer \n\npublic abstract class Buffer {\n    // Invariants: mark <= position <= limit <= capacity\n    private int mark = -1;\n    private int position = 0;\n    private int limit;\n    private int capacity;\n}\n\n\n\n\n 1. capacityBufferBuffer\n 2. limitBuffer /limit  capacitylimit(int newLimit)limit  Buffer \n 3. positionflipposition \n 4. markBuffer\n\n0 <= mark <= position <= limit <= capacity \n\nBuffer  Buffer  Buffer Buffer  flip()  clear()  compact() \n\n\n\n\n\nBuffer  new   Buffer\n\n ByteBuffer\n\n// \npublic static ByteBuffer allocate(int capacity);\n// \npublic static ByteBuffer allocateDirect(int capacity);\n\n\nBuffer \n\n 1. get : \n 2. put \n\n\n\n * flip  limit  position  position  0\n * clear:  position  0 limit  capacity \n * \n\nBuffer \n\nimport java.nio.*;\n\npublic class CharBufferDemo {\n    public static void main(String[] args) {\n        // 8CharBuffer\n        CharBuffer buffer = CharBuffer.allocate(8);\n        System.out.println("");\n        printState(buffer);\n\n        // buffer3\n        buffer.put(\'a\').put(\'b\').put(\'c\');\n        System.out.println("3");\n        printState(buffer);\n\n        // flip()buffer position  0,limit  3\n        buffer.flip();\n        System.out.println("flip()");\n        printState(buffer);\n\n        // \n        while (buffer.hasRemaining()) {\n            System.out.print(buffer.get());\n        }\n\n        // clear() position  0 limit  capacity \n        buffer.clear();\n        System.out.println("clear()");\n        printState(buffer);\n\n    }\n\n    // buffercapacitylimitpositionmark\n    private static void printState(CharBuffer buffer) {\n        System.out.print("capacity: " + buffer.capacity());\n        System.out.print(", limit: " + buffer.limit());\n        System.out.print(", position: " + buffer.position());\n        System.out.print(", mark : " + buffer.mark());\n        System.out.println("\\n");\n    }\n}\n\n\n:\n\n\ncapacity: 8, limit: 8, position: 0\n\n3\ncapacity: 8, limit: 8, position: 3\n\nbuffer\n\nflip()\ncapacity: 8, limit: 3, position: 0\n\nabc\n\nclear()\ncapacity: 8, limit: 8, position: 0\n\n\n capacitylimitposition\n\n\n\n\n# Channel\n\nChannel  Channel \n\nBIO  InputStream OutputStream\n\nChannel  Buffer  Channel  Buffer  Buffer  Channel \n\n\n\n Channel  API UNIX \n\nChannel \n\n\n\n\n\n * FileChannel\n * SocketChannelServerSocketChannelTCP \n * DatagramChannelUDP \n\n\n\nChannel \n\n 1. read  Buffer \n 2. write  Buffer  Channel \n\n FileChannel \n\nRandomAccessFile reader = new RandomAccessFile("/Users/guide/Documents/test_read.in", "r"))\nFileChannel channel = reader.getChannel();\nByteBuffer buffer = ByteBuffer.allocate(1024);\nchannel.read(buffer);\n\n\n\n# Selector\n\nSelector  NIO  ChannelSelector  I/O  Selector Selector  Channel Channel  TCP  Channel  Selector Selector  Channel  SelectionKey  Channel  Channel  I/O \n\n\n\n Selector  Channel JDK  epoll()  select  1024/2048  Selector \n\nSelector \n\n 1. SelectionKey.OP_ACCEPT ServerSocketChannel\n 2. SelectionKey.OP_CONNECT SocketChannel\n 3. SelectionKey.OP_READ\n 4. SelectionKey.OP_WRITE\n\nSelector open()  Selector Selector  SelectableChannel  IO  IO \n\n Selector  SelectionKey \n\n 1.  SelectionKey  Selector  Channel keys() \n 2.  SelectionKey  select()  IO  Channel selectedKeys() \n 3.  SelectionKey  Channel select()  Channel  SelectionKey \n\n SelectionKey \n\nSet<SelectionKey> selectedKeys = selector.selectedKeys();\nIterator<SelectionKey> keyIterator = selectedKeys.iterator();\nwhile (keyIterator.hasNext()) {\n    SelectionKey key = keyIterator.next();\n    if (key != null) {\n        if (key.isAcceptable()) {\n            // ServerSocketChannel \n        } else if (key.isConnectable()) {\n            // \n        } else if (key.isReadable()) {\n            // Channel \n        } else if (key.isWritable()) {\n            // Channel  Buffer\n        }\n    }\n    keyIterator.remove();\n}\n\n\nSelector  select() \n\n * int select() Channel IO  SelectionKey  SelectionKey  Channel \n * int select(long timeout) select() \n * int selectNow() select()  select() \n * Selector wakeup() select() \n * \n\n Selector \n\nimport java.io.IOException;\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.SelectionKey;\nimport java.nio.channels.Selector;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.util.Iterator;\nimport java.util.Set;\n\npublic class NioSelectorExample {\n\n  public static void main(String[] args) {\n    try {\n      ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n      serverSocketChannel.configureBlocking(false);\n      serverSocketChannel.socket().bind(new InetSocketAddress(8080));\n\n      Selector selector = Selector.open();\n      //  ServerSocketChannel  Selector  OP_ACCEPT \n      serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n\n      while (true) {\n        int readyChannels = selector.select();\n\n        if (readyChannels == 0) {\n          continue;\n        }\n\n        Set<SelectionKey> selectedKeys = selector.selectedKeys();\n        Iterator<SelectionKey> keyIterator = selectedKeys.iterator();\n\n        while (keyIterator.hasNext()) {\n          SelectionKey key = keyIterator.next();\n\n          if (key.isAcceptable()) {\n            // \n            ServerSocketChannel server = (ServerSocketChannel) key.channel();\n            SocketChannel client = server.accept();\n            client.configureBlocking(false);\n\n            //  Selector  OP_READ \n            client.register(selector, SelectionKey.OP_READ);\n          } else if (key.isReadable()) {\n            // \n            SocketChannel client = (SocketChannel) key.channel();\n            ByteBuffer buffer = ByteBuffer.allocate(1024);\n            int bytesRead = client.read(buffer);\n\n            if (bytesRead > 0) {\n              buffer.flip();\n              System.out.println("" +new String(buffer.array(), 0, bytesRead));\n              //  Selector  OP_WRITE \n              client.register(selector, SelectionKey.OP_WRITE);\n            } else if (bytesRead < 0) {\n              // \n              client.close();\n            }\n          } else if (key.isWritable()) {\n            // \n            SocketChannel client = (SocketChannel) key.channel();\n            ByteBuffer buffer = ByteBuffer.wrap("Hello, Client!".getBytes());\n            client.write(buffer);\n\n            //  Selector  OP_READ \n            client.register(selector, SelectionKey.OP_READ);\n          }\n\n          keyIterator.remove();\n        }\n      }\n    } catch (IOException e) {\n      e.printStackTrace();\n    }\n  }\n}\n\n\n 8080  Selector  "Hello, Client!"\n\n\n# NIO \n\n IO  ActiveMQKafka RocketMQQMQNetty \n\n IO CPU  CPU  I/O  mmap+writesendfile sendfile + DMA gather copy \n\n\n\n                             CPU    DMA             \n                         2        2        read+write   4\nmmap+write                   1        2        mmap+write   4\nsendfile                     1        2        sendfile     2\nsendfile + DMA gather copy   0        2        sendfile     2\n\n I/O 2  DMA(Direct Memory Access)  DMA  CPU \n\nJava \n\n * MappedByteBuffer  NIO mmap Linux  mmap \n * FileChannel transferTo()/transferFrom() NIO sendfile Linux  sendfileFileChannelJava NIO  FileChannel \n\n\n\nprivate void loadFileIntoMemory(File xmlFile) throws IOException {\n  FileInputStream fis = new FileInputStream(xmlFile);\n  //  FileChannel \n  FileChannel fc = fis.getChannel();\n  // FileChannel.map()  MappedByteBuffer \n  MappedByteBuffer mmb = fc.map(FileChannel.MapMode.READ_ONLY, 0, fc.size());\n  xmlFileBuffer = new byte[(int)fc.size()];\n  mmb.get(xmlFileBuffer);\n  fis.close();\n}\n\n\n\n# \n\n NIO  NIO \n\n NIO  NIO NIO  NettyNetty  NIO  SSL/TLS \n\n\n# \n\n * Java NIO https://tech.meituan.com/2016/11/04/nio.html\n\n * Java NIO https://mp.weixin.qq.com/s/mZobf-U8OSYQfHfYBEB6KA\n\n * Java NIOBufferChannel  Selectorhttps://www.javadoop.com/post/java-nio',normalizedContent:' nio  i/o java io \n\n\n# nio \n\n java i/o bioi/o  i/o \n\n java1.4  i/o   nio new io non-blocking io nio  i/o  java  i/o i/o \n\n bionio  aio  aio java io \n\n\n\n nio nio  bio \n\n\n# nio \n\nnio \n\n * buffernio  channel  buffer  buffer  channel \n * channelchannel nio  channel \n * selector channel i/o  channel  selector  selector \n\n\n\n\n\n\n\n\n# buffer\n\n bio  \n\n java 1.4  nio  bio  bio nio   nio \n\nbuffer  bytebuffer\n\n\n\n buffer intbufferfloatbuffercharbuffer  int[]float[]char[] \n\nbuffer \n\npublic abstract class buffer {\n    // invariants: mark <= position <= limit <= capacity\n    private int mark = -1;\n    private int position = 0;\n    private int limit;\n    private int capacity;\n}\n\n\n\n\n 1. capacitybufferbuffer\n 2. limitbuffer /limit  capacitylimit(int newlimit)limit  buffer \n 3. positionflipposition \n 4. markbuffer\n\n0 <= mark <= position <= limit <= capacity \n\nbuffer  buffer  buffer buffer  flip()  clear()  compact() \n\n\n\n\n\nbuffer  new   buffer\n\n bytebuffer\n\n// \npublic static bytebuffer allocate(int capacity);\n// \npublic static bytebuffer allocatedirect(int capacity);\n\n\nbuffer \n\n 1. get : \n 2. put \n\n\n\n * flip  limit  position  position  0\n * clear:  position  0 limit  capacity \n * \n\nbuffer \n\nimport java.nio.*;\n\npublic class charbufferdemo {\n    public static void main(string[] args) {\n        // 8charbuffer\n        charbuffer buffer = charbuffer.allocate(8);\n        system.out.println("");\n        printstate(buffer);\n\n        // buffer3\n        buffer.put(\'a\').put(\'b\').put(\'c\');\n        system.out.println("3");\n        printstate(buffer);\n\n        // flip()buffer position  0,limit  3\n        buffer.flip();\n        system.out.println("flip()");\n        printstate(buffer);\n\n        // \n        while (buffer.hasremaining()) {\n            system.out.print(buffer.get());\n        }\n\n        // clear() position  0 limit  capacity \n        buffer.clear();\n        system.out.println("clear()");\n        printstate(buffer);\n\n    }\n\n    // buffercapacitylimitpositionmark\n    private static void printstate(charbuffer buffer) {\n        system.out.print("capacity: " + buffer.capacity());\n        system.out.print(", limit: " + buffer.limit());\n        system.out.print(", position: " + buffer.position());\n        system.out.print(", mark : " + buffer.mark());\n        system.out.println("\\n");\n    }\n}\n\n\n:\n\n\ncapacity: 8, limit: 8, position: 0\n\n3\ncapacity: 8, limit: 8, position: 3\n\nbuffer\n\nflip()\ncapacity: 8, limit: 3, position: 0\n\nabc\n\nclear()\ncapacity: 8, limit: 8, position: 0\n\n\n capacitylimitposition\n\n\n\n\n# channel\n\nchannel  channel \n\nbio  inputstream outputstream\n\nchannel  buffer  channel  buffer  buffer  channel \n\n\n\n channel  api unix \n\nchannel \n\n\n\n\n\n * filechannel\n * socketchannelserversocketchanneltcp \n * datagramchanneludp \n\n\n\nchannel \n\n 1. read  buffer \n 2. write  buffer  channel \n\n filechannel \n\nrandomaccessfile reader = new randomaccessfile("/users/guide/documents/test_read.in", "r"))\nfilechannel channel = reader.getchannel();\nbytebuffer buffer = bytebuffer.allocate(1024);\nchannel.read(buffer);\n\n\n\n# selector\n\nselector  nio  channelselector  i/o  selector selector  channel channel  tcp  channel  selector selector  channel  selectionkey  channel  channel  i/o \n\n\n\n selector  channel jdk  epoll()  select  1024/2048  selector \n\nselector \n\n 1. selectionkey.op_accept serversocketchannel\n 2. selectionkey.op_connect socketchannel\n 3. selectionkey.op_read\n 4. selectionkey.op_write\n\nselector open()  selector selector  selectablechannel  io  io \n\n selector  selectionkey \n\n 1.  selectionkey  selector  channel keys() \n 2.  selectionkey  select()  io  channel selectedkeys() \n 3.  selectionkey  channel select()  channel  selectionkey \n\n selectionkey \n\nset<selectionkey> selectedkeys = selector.selectedkeys();\niterator<selectionkey> keyiterator = selectedkeys.iterator();\nwhile (keyiterator.hasnext()) {\n    selectionkey key = keyiterator.next();\n    if (key != null) {\n        if (key.isacceptable()) {\n            // serversocketchannel \n        } else if (key.isconnectable()) {\n            // \n        } else if (key.isreadable()) {\n            // channel \n        } else if (key.iswritable()) {\n            // channel  buffer\n        }\n    }\n    keyiterator.remove();\n}\n\n\nselector  select() \n\n * int select() channel io  selectionkey  selectionkey  channel \n * int select(long timeout) select() \n * int selectnow() select()  select() \n * selector wakeup() select() \n * \n\n selector \n\nimport java.io.ioexception;\nimport java.net.inetsocketaddress;\nimport java.nio.bytebuffer;\nimport java.nio.channels.selectionkey;\nimport java.nio.channels.selector;\nimport java.nio.channels.serversocketchannel;\nimport java.nio.channels.socketchannel;\nimport java.util.iterator;\nimport java.util.set;\n\npublic class nioselectorexample {\n\n  public static void main(string[] args) {\n    try {\n      serversocketchannel serversocketchannel = serversocketchannel.open();\n      serversocketchannel.configureblocking(false);\n      serversocketchannel.socket().bind(new inetsocketaddress(8080));\n\n      selector selector = selector.open();\n      //  serversocketchannel  selector  op_accept \n      serversocketchannel.register(selector, selectionkey.op_accept);\n\n      while (true) {\n        int readychannels = selector.select();\n\n        if (readychannels == 0) {\n          continue;\n        }\n\n        set<selectionkey> selectedkeys = selector.selectedkeys();\n        iterator<selectionkey> keyiterator = selectedkeys.iterator();\n\n        while (keyiterator.hasnext()) {\n          selectionkey key = keyiterator.next();\n\n          if (key.isacceptable()) {\n            // \n            serversocketchannel server = (serversocketchannel) key.channel();\n            socketchannel client = server.accept();\n            client.configureblocking(false);\n\n            //  selector  op_read \n            client.register(selector, selectionkey.op_read);\n          } else if (key.isreadable()) {\n            // \n            socketchannel client = (socketchannel) key.channel();\n            bytebuffer buffer = bytebuffer.allocate(1024);\n            int bytesread = client.read(buffer);\n\n            if (bytesread > 0) {\n              buffer.flip();\n              system.out.println("" +new string(buffer.array(), 0, bytesread));\n              //  selector  op_write \n              client.register(selector, selectionkey.op_write);\n            } else if (bytesread < 0) {\n              // \n              client.close();\n            }\n          } else if (key.iswritable()) {\n            // \n            socketchannel client = (socketchannel) key.channel();\n            bytebuffer buffer = bytebuffer.wrap("hello, client!".getbytes());\n            client.write(buffer);\n\n            //  selector  op_read \n            client.register(selector, selectionkey.op_read);\n          }\n\n          keyiterator.remove();\n        }\n      }\n    } catch (ioexception e) {\n      e.printstacktrace();\n    }\n  }\n}\n\n\n 8080  selector  "hello, client!"\n\n\n# nio \n\n io  activemqkafka rocketmqqmqnetty \n\n io cpu  cpu  i/o  mmap+writesendfile sendfile + dma gather copy \n\n\n\n                             cpu    dma             \n                         2        2        read+write   4\nmmap+write                   1        2        mmap+write   4\nsendfile                     1        2        sendfile     2\nsendfile + dma gather copy   0        2        sendfile     2\n\n i/o 2  dma(direct memory access)  dma  cpu \n\njava \n\n * mappedbytebuffer  nio mmap linux  mmap \n * filechannel transferto()/transferfrom() nio sendfile linux  sendfilefilechanneljava nio  filechannel \n\n\n\nprivate void loadfileintomemory(file xmlfile) throws ioexception {\n  fileinputstream fis = new fileinputstream(xmlfile);\n  //  filechannel \n  filechannel fc = fis.getchannel();\n  // filechannel.map()  mappedbytebuffer \n  mappedbytebuffer mmb = fc.map(filechannel.mapmode.read_only, 0, fc.size());\n  xmlfilebuffer = new byte[(int)fc.size()];\n  mmb.get(xmlfilebuffer);\n  fis.close();\n}\n\n\n\n# \n\n nio  nio \n\n nio  nio nio  nettynetty  nio  ssl/tls \n\n\n# \n\n * java nio https://tech.meituan.com/2016/11/04/nio.html\n\n * java nio https://mp.weixin.qq.com/s/mzobf-u8osyqfhfybeb6ka\n\n * java niobufferchannel  selectorhttps://www.javadoop.com/post/java-nio',charsets:{cjk:!0}},{title:"Java8 ",frontmatter:{title:"Java8 ",category:"Java",tag:["Java"],date:"2024-08-21T23:05:46.000Z",permalink:"/pages/cd056d/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/01.java8-common-new-features.html",relativePath:"01.Java/05./01.java8-common-new-features.md",key:"v-a6c16d9c",path:"/pages/cd056d/",headers:[{level:2,title:"Interface",slug:"interface",normalizedTitle:"interface",charIndex:353},{level:2,title:"functional interface ",slug:"functional-interface-",normalizedTitle:"functional interface ",charIndex:2143},{level:2,title:"Lambda ",slug:"lambda-",normalizedTitle:"lambda ",charIndex:268},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:2667},{level:3,title:"Lambda ",slug:"lambda-",normalizedTitle:"lambda ",charIndex:2738},{level:4,title:"",slug:"",normalizedTitle:"",charIndex:2777},{level:4,title:"",slug:"",normalizedTitle:"",charIndex:4297},{level:4,title:"",slug:"",normalizedTitle:"",charIndex:4742},{level:4,title:"",slug:"",normalizedTitle:"",charIndex:5493},{level:2,title:"Stream",slug:"stream",normalizedTitle:"stream",charIndex:5644},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:5917},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:5971},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:2745},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:9307},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:10594},{level:2,title:"Optional",slug:"optional",normalizedTitle:"optional",charIndex:10759},{level:3,title:" Optional",slug:"-optional",normalizedTitle:" optional",charIndex:11799},{level:3,title:" value  null",slug:"-value--null",normalizedTitle:" value  null",charIndex:15458},{level:3,title:" value",slug:"-value",normalizedTitle:" value",charIndex:15707},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:16533},{level:3,title:"",slug:"-2",normalizedTitle:"",charIndex:10594},{level:2,title:"Date-Time API",slug:"date-time-api",normalizedTitle:"date-time api",charIndex:17060},{level:3,title:"java.time ",slug:"java-time-",normalizedTitle:"java.time ",charIndex:17280},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:17145},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:18779},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:19328},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:21076},{level:3,title:"JDBC  java8",slug:"jdbc--java8",normalizedTitle:"jdbc  java8",charIndex:22718},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:17132},{level:3,title:"",slug:"-3",normalizedTitle:"",charIndex:10594},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:160}],headersStr:"Interface functional interface  Lambda   Lambda      Stream      Optional  Optional  value  null  value   Date-Time API java.time      JDBC  java8   ",content:'> cowbi~\n\nOracle  2014  Java8jdk1.8 jdk  7  Java8 \n\n jdk.7  interface java.util.HashMap  Lambda  Java8 \n\n\n# Interface\n\ninterface Interface \n\n interface default  static\n\n interface  2 \n\n 1. defaultthis\n 2. staticInterface\n\n\n\npublic interface InterfaceNew {\n    static void sm() {\n        System.out.println("interface");\n    }\n    static void sm2() {\n        System.out.println("interface");\n    }\n\n    default void def() {\n        System.out.println("interface default");\n    }\n    default void def2() {\n        System.out.println("interface default2");\n    }\n    //\n    void f();\n}\n\npublic interface InterfaceNew1 {\n    default void def() {\n        System.out.println("InterfaceNew1 default");\n    }\n}\n\n\n InterfaceNew  InterfaceNew1def() InterfaceNew  InterfaceNew1def()\n\npublic class InterfaceNewImpl implements InterfaceNew , InterfaceNew1{\n    public static void main(String[] args) {\n        InterfaceNewImpl interfaceNew = new InterfaceNewImpl();\n        interfaceNew.def();\n    }\n\n    @Override\n    public void def() {\n        InterfaceNew1.super.def();\n    }\n\n    @Override\n    public void f() {\n    }\n}\n\n\n Java 8 \n\n interface  abstract class \n\n\n\n 1. interface  class \n    \n    * \n    *  public abstract  public static final  abstract class \n\n 2. interface  abstract class \n\ninterface defaultstaticabstract class abstract class  abstract class interface \n\n\n\n\n# functional interface \n\n SAM  Single Abstract Method interfaces\n\n java 8 java.util.function @FunctionalInterface \n\n@FunctionalInterface \n\n@FunctionalInterface Lambda \n\n\n# Lambda \n\n Lambda  Java 8 (Generics)(Annotation)\n\n Lambda  java \n\n> Lambda java 8 \n\n\n# \n\n(parameters) -> expression \n(parameters) ->{ statements; }\n\n\n\n# Lambda \n\n Lambda \n\n# \n\n\n\n1.Runnable \n\nnew Thread(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println("The runable now is using!");\n            }\n}).start();\n//lambda\nnew Thread(() -> System.out.println("It\'s a lambda function!")).start();\n\n\n2.Comparator \n\nList<Integer> strings = Arrays.asList(1, 2, 3);\n\nCollections.sort(strings, new Comparator<Integer>() {\n@Override\npublic int compare(Integer o1, Integer o2) {\n    return o1 - o2;}\n});\n\n//Lambda\nCollections.sort(strings, (Integer o1, Integer o2) -> o1 - o2);\n//\nComparator<Integer> comparator = (Integer o1, Integer o2) -> o1 - o2;\nCollections.sort(strings, comparator);\n\n\n3.Listener \n\nJButton button = new JButton();\nbutton.addItemListener(new ItemListener() {\n@Override\npublic void itemStateChanged(ItemEvent e) {\n   e.getItem();\n}\n});\n//lambda\nbutton.addItemListener(e -> e.getItem());\n\n\n4.\n\n 3  Lambda  Lambda \n\n@FunctionalInterface\npublic interface Comparator<T>{}\n\n@FunctionalInterface\npublic interface Runnable{}\n\n\n\n\n@FunctionalInterface\npublic interface LambdaInterface {\n void f();\n}\n//\npublic class LambdaClass {\n    public static void forEg() {\n        lambdaInterfaceDemo(()-> System.out.println(""));\n    }\n    //\n    static void lambdaInterfaceDemo(LambdaInterface i){\n        i.f();\n    }\n}\n\n\n# \n\nvoid lamndaFor() {\n        List<String> strings = Arrays.asList("1", "2", "3");\n        //foreach\n        for (String s : strings) {\n            System.out.println(s);\n        }\n        //Lambda foreach\n        strings.forEach((s) -> System.out.println(s));\n        //or\n        strings.forEach(System.out::println);\n     //map\n        Map<Integer, String> map = new HashMap<>();\n        map.forEach((k,v)->System.out.println(v));\n}\n\n\n# \n\nJava 8  ::  functional-interface\n\npublic class LambdaClassSuper {\n    LambdaInterface sf(){\n        return null;\n    }\n}\n\npublic class LambdaClass extends LambdaClassSuper {\n    public static LambdaInterface staticF() {\n        return null;\n    }\n\n    public LambdaInterface f() {\n        return null;\n    }\n\n    void show() {\n        //1.functional-interface\n        LambdaInterface t = LambdaClass::staticF;\n\n        //2.\n        LambdaClass lambdaClass = new LambdaClass();\n        LambdaInterface lambdaInterface = lambdaClass::f;\n\n        //3.\n        LambdaInterface superf = super::sf;\n\n        //4. \n        LambdaInterface tt = LambdaClassSuper::new;\n    }\n}\n\n\n# \n\nint i = 0;\nCollections.sort(strings, (Integer o1, Integer o2) -> o1 - i);\n//i =3;\n\n\nlambda  final \n\n\n# Stream\n\njava  java.util.stream java.io.FileInputStreamCRUD\n\nStream(Retrieve) Sql \n\n CollectionArray  Lambda \n\n\n# \n\n 1. stream \n 2. parallelStream \n\n\n# \n\njava.util.stream.Stream\n\n/**\n* \n*/\ndefault Stream<E> stream()\n\n/**\n* \n*/\ndefault Stream<E> parallelStream()\n\n/**\n* T\n*/\npublic static<T> Stream<T> of(T t)\n\n/**\n* \n*/\npublic static<T> Stream<T> of(T... values) {\n    return Arrays.stream(values);\n}\n\n\n/**\n* predicate\n*/\nStream<T> filter(Predicate<? super T> predicate);\n\n/**\n* predicate\n*/\nboolean allMatch(Predicate<? super T> predicate)\n\n/**\n* predicate\n*/\nboolean anyMatch(Predicate<? super T> predicate);\n\n/**\n*  Stream\n*/\npublic static<T> Builder<T> builder();\n\n/**\n*  Collector\n*/\n<R, A> R collect(Collector<? super T, A, R> collector);\n\n/**\n * \n*/\nlong count();\n\n/**\n*  Object.equals(Object) \n*/\nStream<T> distinct();\n\n/**\n * \n*/\nvoid forEach(Consumer<? super T> action);\n\n/**\n*  maxSize \n*/\nStream<T> limit(long maxSize);\n\n/**\n* \n*/\n<R> Stream<R> map(Function<? super T, ? extends R> mapper);\n\n/**\n*  Comparator\n*/\nStream<T> sorted(Comparator<? super T> comparator);\n\n/**\n*  n n\n*/\nStream<T> skip(long n);\n\n/**\n* \n*/\nObject[] toArray();\n\n/**\n*  generator\n*/\n<A> A[] toArray(IntFunction<A[]> generator);\n\n/**\n* \n*/\npublic static <T> Stream<T> concat(Stream<? extends T> a, Stream<? extends T> b)\n\n\n\n# \n\n Stream  Api\n\n@Test\npublic void test() {\n  List<String> strings = Arrays.asList("abc", "def", "gkh", "abc");\n    //stream\n    Stream<String> stringStream = strings.stream().filter(s -> "abc".equals(s));\n    //\n    long count = stringStream.count();\n\n    //forEach->\n    strings.stream().forEach(System.out::println);\n\n    //limit 1stream\n    Stream<String> limit = strings.stream().limit(1);\n    //toArray limitStreamString[],\n    String[] array = limit.toArray(String[]::new);\n\n    //map \n    Stream<String> map = strings.stream().map(s -> s + "22");\n\n    //sorted \n    strings.stream().sorted().forEach(System.out::println);\n\n    //Collectors collect abc\n    List<String> collect = strings.stream().filter(string -> "abc".equals(string)).collect(Collectors.toList());\n    //liststring\n    String mergedString = strings.stream().filter(string -> !string.isEmpty()).collect(Collectors.joining(","));\n\n    //\n    List<Integer> number = Arrays.asList(1, 2, 5, 4);\n\n    IntSummaryStatistics statistics = number.stream().mapToInt((x) -> x).summaryStatistics();\n    System.out.println(" : "+statistics.getMax());\n    System.out.println(" : "+statistics.getMin());\n    System.out.println(" : "+statistics.getAverage());\n    System.out.println(" : "+statistics.getSum());\n\n    //concat \n    List<String> strings2 = Arrays.asList("xyz", "jqx");\n    Stream.concat(strings2.stream(),strings.stream()).count();\n\n    // Stream\n    Stream stream = strings.stream();\n    //\n    stream.limit(2);\n    //\n    stream.forEach(System.out::println);\n    // java.lang.IllegalStateException: stream has already been operated upon or closed\n\n    //, \n    stream.limit(2).forEach(System.out::println);\n}\n\n\n\n# \n\n Stream  Stream  Stream  Stream 2 \n\n filter \n\n@Test\npublic void laziness(){\n  List<String> strings = Arrays.asList("abc", "def", "gkh", "abc");\n  Stream<Integer> stream = strings.stream().filter(new Predicate() {\n      @Override\n      public boolean test(Object o) {\n        System.out.println("Predicate.test ");\n        return true;\n        }\n      });\n\n   System.out.println("count ");\n   stream.count();\n}\n/*---------------*/\ncount \nPredicate.test \nPredicate.test \nPredicate.test \nPredicate.test \n\n\n 4 Predicate.test count  filter count()\n\n Stream  parallelStream  parallelStream  ForkJoin  ForkJoin  ForkJoinPool\n\n@Test\npublic void parallelStreamTest(){\n   List<Integer> numbers = Arrays.asList(1, 2, 5, 4);\n   numbers.parallelStream() .forEach(num->System.out.println(Thread.currentThread().getName()+">>"+num));\n}\n//\nmain>>5\nForkJoinPool.commonPool-worker-2>>4\nForkJoinPool.commonPool-worker-11>>1\nForkJoinPool.commonPool-worker-9>>2\n\n\nfor-each \n\n\n# \n\n stream \n\n 1. \n 2. \n 3.  Stream  stream \n 4. Stream \n\n\n# Optional\n\n Optional \n\n>  NPE NPE \n> \n> 1 return  NPE\n> \n> public int f() { return Integer }  null NPE\n> \n> 2  null\n> \n> 3  isNotEmpty null\n> \n> 4  NPE\n> \n> 5  Session  NPE \n> \n> 6  obj.getA().getB().getC() NPE\n> \n>  JDK8  Optional  NPE \n\n Optional  NPEjava.lang.NullPointerException NPE  Optional \n\n Zoo  Dog Dog  age\n\nclass Zoo {\n   private Dog dog;\n}\n\nclass Dog {\n   private int age;\n}\n\n\n NPE \n\nZoo zoo = getZoo();\nif(zoo != null){\n   Dog dog = zoo.getDog();\n   if(dog != null){\n      int age = dog.getAge();\n      System.out.println(age);\n   }\n}\n\n\n\n\nOptional \n\nOptional.ofNullable(zoo).map(o -> o.getDog()).map(d -> d.getAge()).ifPresent(age ->\n    System.out.println(age)\n);\n\n\n\n\n\n#  Optional\n\nOptional.ofNullable Optional  Optional \n\n/**\n* Common instance for {@code empty()}. EMPTY\n*/\nprivate static final Optional<?> EMPTY = new Optional<>();\n\n/**\n* Optional\n*/\nprivate final T value;\n\n/**\n* valuenullEMPTYof(T)\n*/\npublic static <T> Optional<T> ofNullable(T value) {\n   return value == null ? empty() : of(value);\n}\n/**\n*  EMPTY \n*/\npublic static<T> Optional<T> empty() {\n   Optional<T> t = (Optional<T>) EMPTY;\n   return t;\n}\n/**\n* Optional\n*/\npublic static <T> Optional<T> of(T value) {\n    return new Optional<>(value);\n}\n/**\n* value\n*/\nprivate Optional(T value) {\n  this.value = Objects.requireNonNull(value);\n}\n/**\n* of(T value) valuenullNullPointerExceptionNPE\n*/\npublic static <T> T requireNonNull(T obj) {\n  if (obj == null)\n         throw new NullPointerException();\n  return obj;\n}\n\n\nofNullable of value  null ofNullable EMPTYof  NullPointerException  NullPointerException  of ofNullable\n\nmap()  flatMap() \n\nmap  flatMap mapflatMap\n\nmapflatMap\n\npublic class MapAndFlatMapExample {\n    public static void main(String[] args) {\n        List<String[]> listOfArrays = Arrays.asList(\n                new String[]{"apple", "banana", "cherry"},\n                new String[]{"orange", "grape", "pear"},\n                new String[]{"kiwi", "melon", "pineapple"}\n        );\n\n        List<String[]> mapResult = listOfArrays.stream()\n                .map(array -> Arrays.stream(array).map(String::toUpperCase).toArray(String[]::new))\n                .collect(Collectors.toList());\n\n        System.out.println("Using map:");\n        mapResult.forEach(arrays-> System.out.println(Arrays.toString(arrays)));\n\n        List<String> flatMapResult = listOfArrays.stream()\n                .flatMap(array -> Arrays.stream(array).map(String::toUpperCase))\n                .collect(Collectors.toList());\n\n        System.out.println("Using flatMap:");\n        System.out.println(flatMapResult);\n    }\n}\n\n\n\n:\n\nUsing map:\n[[APPLE, BANANA, CHERRY], [ORANGE, GRAPE, PEAR], [KIWI, MELON, PINEAPPLE]]\n\nUsing flatMap:\n[APPLE, BANANA, CHERRY, ORANGE, GRAPE, PEAR, KIWI, MELON, PINEAPPLE]\n\n\nflatMap()map()\n\nOptionalmap()OptionalflatMapOptionalOptionalOptional\n\n\n\npublic static void main(String[] args) {\n        int userId = 1;\n\n        // flatMap\n        String cityUsingFlatMap = getUserById(userId)\n                .flatMap(OptionalExample::getAddressByUser)\n                .map(Address::getCity)\n                .orElse("Unknown");\n\n        System.out.println("User\'s city using flatMap: " + cityUsingFlatMap);\n\n        // flatMap\n        Optional<Optional<Address>> optionalAddress = getUserById(userId)\n                .map(OptionalExample::getAddressByUser);\n\n        String cityWithoutFlatMap;\n        if (optionalAddress.isPresent()) {\n            Optional<Address> addressOptional = optionalAddress.get();\n            if (addressOptional.isPresent()) {\n                Address address = addressOptional.get();\n                cityWithoutFlatMap = address.getCity();\n            } else {\n                cityWithoutFlatMap = "Unknown";\n            }\n        } else {\n            cityWithoutFlatMap = "Unknown";\n        }\n\n        System.out.println("User\'s city without flatMap: " + cityWithoutFlatMap);\n    }\n\n\nStreamOptionalflatMap\n\n\n#  value  null\n\n/**\n* valuenull\n*/\npublic boolean isPresent() {\n    return value != null;\n}\n/**\n* valuenullconsumer.accept\n*/\npublic void ifPresent(Consumer<? super T> consumer) {\n   if (value != null)\n    consumer.accept(value);\n}\n\n\n\n#  value\n\n/**\n* Return the value if present, otherwise invoke {@code other} and return\n* the result of that invocation.\n* value != null valueother\n*/\npublic T orElseGet(Supplier<? extends T> other) {\n    return value != null ? value : other.get();\n}\n\n/**\n* value != null valueT\n*/\npublic T orElse(T other) {\n    return value != null ? value : other;\n}\n\n/**\n* value != null value\n*/\npublic <X extends Throwable> T orElseThrow(Supplier<? extends X> exceptionSupplier) throws X {\n        if (value != null) {\n            return value;\n        } else {\n            throw exceptionSupplier.get();\n        }\n}\n/**\n* valuenullNoSuchElementExceptionvalue\n*/\npublic T get() {\n  if (value == null) {\n      throw new NoSuchElementException("No value present");\n  }\n  return value;\n}\n\n\n\n# \n\n/**\n* 1. emptyempty\n* 2. predicate.test(value)==true thisempty\n*/\npublic Optional<T> filter(Predicate<? super T> predicate) {\n        Objects.requireNonNull(predicate);\n        if (!isPresent())\n            return this;\n        else\n            return predicate.test(value) ? this : empty();\n}\n\n\n\n# \n\n Optional Optional  NPE of() get()flatMap(..) Optional \n\nOptional.ofNullable(zoo).map(o -> o.getDog()).map(d -> d.getAge()).filter(v->v==1).orElse(3);\n\n\n\n# Date-Time API\n\njava.util.Date Date \n\n 1. \n 2. \n 3. \n 4. Date  java.sql.Date\n\n java.util.Date  Date java.util.Date\n\n\n# java.time \n\njava.util.Date  java.time \n\nLocalDateTime.class //+ format: yyyy-MM-ddTHH:mm:ss.SSS\nLocalDate.class // format: yyyy-MM-dd\nLocalTime.class // format: HH:mm:ss\n\n\n\n# \n\nJava 8 :\n\npublic void oldFormat(){\n    Date now = new Date();\n    //format yyyy-MM-dd\n    SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd");\n    String date  = sdf.format(now);\n    System.out.println(String.format("date format : %s", date));\n\n    //format HH:mm:ss\n    SimpleDateFormat sdft = new SimpleDateFormat("HH:mm:ss");\n    String time = sdft.format(now);\n    System.out.println(String.format("time format : %s", time));\n\n    //format yyyy-MM-dd HH:mm:ss\n    SimpleDateFormat sdfdt = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");\n    String datetime = sdfdt.format(now);\n    System.out.println(String.format("dateTime format : %s", datetime));\n}\n\n\nJava 8 :\n\npublic void newFormat(){\n    //format yyyy-MM-dd\n    LocalDate date = LocalDate.now();\n    System.out.println(String.format("date format : %s", date));\n\n    //format HH:mm:ss\n    LocalTime time = LocalTime.now().withNano(0);\n    System.out.println(String.format("time format : %s", time));\n\n    //format yyyy-MM-dd HH:mm:ss\n    LocalDateTime dateTime = LocalDateTime.now();\n    DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");\n    String dateTimeStr = dateTime.format(dateTimeFormatter);\n    System.out.println(String.format("dateTime format : %s", dateTimeStr));\n}\n\n\n\n# \n\nJava 8 :\n\n//\nDate date = new Date("2021-01-26");\n//\nSimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd");\nDate date1 = sdf.parse("2021-01-26");\n\n\nJava 8 :\n\nLocalDate date = LocalDate.of(2021, 1, 26);\nLocalDate.parse("2021-01-26");\n\nLocalDateTime dateTime = LocalDateTime.of(2021, 1, 26, 12, 12, 22);\nLocalDateTime.parse("2021-01-26 12:12:22");\n\nLocalTime time = LocalTime.of(12, 12, 22);\nLocalTime.parse("12:12:22");\n\n\nJava 8   SimpleDateFormat Java 8  LocalDateLocalTimeLocalDateTime of  parse \n\n\n# \n\n1/2  java.time.temporal.ChronoUnit \n\nJava 8 :\n\npublic void afterDay(){\n     //\n     SimpleDateFormat formatDate = new SimpleDateFormat("yyyy-MM-dd");\n     Calendar ca = Calendar.getInstance();\n     ca.add(Calendar.DATE, 7);\n     Date d = ca.getTime();\n     String after = formatDate.format(d);\n     System.out.println("" + after);\n\n   //\n     String dates1 = "2021-12-23";\n   String dates2 = "2021-02-26";\n     SimpleDateFormat format = new SimpleDateFormat("yyyy-MM-dd");\n     Date date1 = format.parse(dates1);\n     Date date2 = format.parse(dates2);\n     int day = (int) ((date1.getTime() - date2.getTime()) / (1000 * 3600 * 24));\n     System.out.println(dates1 + "" + dates2 + "" + day + "");\n     //2021-02-262021-12-23300\n}\n\n\nJava 8 :\n\npublic void pushWeek(){\n     //\n     LocalDate localDate = LocalDate.now();\n     //1\n     LocalDate after = localDate.plus(1, ChronoUnit.WEEKS);\n     //2\n     LocalDate after2 = localDate.plusWeeks(1);\n     System.out.println("" + after);\n\n     //\n     LocalDate date1 = LocalDate.parse("2021-02-26");\n     LocalDate date2 = LocalDate.parse("2021-12-23");\n     Period period = Period.between(date1, date2);\n     System.out.println("date1  date2 "\n                + period.getYears() + ""\n                + period.getMonths() + ""\n                + period.getDays() + "");\n   // date1  date2 0927\n     //period.getDays()\n     //\n     long day = date2.toEpochDay() - date1.toEpochDay();\n     System.out.println(date1 + "" + date2 + "" + day + "");\n     //2021-02-262021-12-23300\n}\n\n\n\n# \n\n\n\nJava 8 :\n\npublic void getDay() {\n\n        SimpleDateFormat format = new SimpleDateFormat("yyyy-MM-dd");\n        //\n        Calendar c = Calendar.getInstance();\n        c.set(Calendar.DAY_OF_MONTH, 1);\n        String first = format.format(c.getTime());\n        System.out.println("first day:" + first);\n\n        //\n        Calendar ca = Calendar.getInstance();\n        ca.set(Calendar.DAY_OF_MONTH, ca.getActualMaximum(Calendar.DAY_OF_MONTH));\n        String last = format.format(ca.getTime());\n        System.out.println("last day:" + last);\n\n        //\n        Calendar currCal = Calendar.getInstance();\n        Calendar calendar = Calendar.getInstance();\n        calendar.clear();\n        calendar.set(Calendar.YEAR, currCal.get(Calendar.YEAR));\n        calendar.roll(Calendar.DAY_OF_YEAR, -1);\n        Date time = calendar.getTime();\n        System.out.println("last day:" + format.format(time));\n}\n\n\nJava 8 :\n\npublic void getDayNew() {\n    LocalDate today = LocalDate.now();\n    //\n    LocalDate firstDayOfThisMonth = today.with(TemporalAdjusters.firstDayOfMonth());\n    // \n    LocalDate lastDayOfThisMonth = today.with(TemporalAdjusters.lastDayOfMonth());\n    //\n    LocalDate nextDay = lastDayOfThisMonth.plusDays(1);\n    //\n    LocalDate lastday = today.with(TemporalAdjusters.lastDayOfYear());\n    //2021Calendar\n    LocalDate lastMondayOf2021 = LocalDate.parse("2021-12-31").with(TemporalAdjusters.lastInMonth(DayOfWeek.SUNDAY));\n}\n\n\njava.time.temporal.TemporalAdjusters  Api \n\n\n# JDBC  java8\n\n jdbc  java8 \n\n 1. Date ---\x3e LocalDate\n 2. Time ---\x3e LocalTime\n 3. Timestamp ---\x3e LocalDateTime\n\n Date Date\n\n\n# \n\n>  15  24  1  1  1  5 \n\njava.util.Date  1970  1  1  0  GMT Date  new Datejava.util.Date  TimeZone\n\n//Wed Jan 27 14:05:29 CST 2021\nDate date = new Date();\n\nSimpleDateFormat bjSdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");\n//\nbjSdf.setTimeZone(TimeZone.getTimeZone("Asia/Shanghai"));\nSystem.out.println(":" + date.getTime() + ", :" + bjSdf.format(date));\n\n//\nSimpleDateFormat tokyoSdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");\ntokyoSdf.setTimeZone(TimeZone.getTimeZone("Asia/Tokyo"));  // \nSystem.out.println(":" + date.getTime() + ", :" + tokyoSdf.format(date));\n\n//print\nSystem.out.println(date);\n//Wed Jan 27 14:05:29 CST 2021\n\n\n java.time.ZonedDateTime  LocalDateTime + ZoneId\n\n//\nZonedDateTime zonedDateTime = ZonedDateTime.now();\nSystem.out.println(": " + zonedDateTime);\n\n//\nZoneId zoneId = ZoneId.of(ZoneId.SHORT_IDS.get("JST"));\nZonedDateTime tokyoTime = zonedDateTime.withZoneSameInstant(zoneId);\nSystem.out.println(": " + tokyoTime);\n\n// ZonedDateTime  LocalDateTime\nLocalDateTime localDateTime = tokyoTime.toLocalDateTime();\nSystem.out.println(": " + localDateTime);\n\n//LocalDateTime  ZonedDateTime\nZonedDateTime localZoned = localDateTime.atZone(ZoneId.systemDefault());\nSystem.out.println(": " + localZoned);\n\n//\n: 2021-01-27T14:43:58.735+08:00[Asia/Shanghai]\n: 2021-01-27T15:43:58.735+09:00[Asia/Tokyo]\n: 2021-01-27T15:43:58.735\n: 2021-01-27T15:53:35.618+08:00[Asia/Shanghai]\n\n\n\n# \n\n Date  date-time-api  date  date-time-api Date\n\n\n# \n\n java 8 \n\n * Interface & functional Interface\n * Lambda\n * Stream\n * Optional\n * Date time-api\n\n java 8 35 ',normalizedContent:'> cowbi~\n\noracle  2014  java8jdk1.8 jdk  7  java8 \n\n jdk.7  interface java.util.hashmap  lambda  java8 \n\n\n# interface\n\ninterface interface \n\n interface default  static\n\n interface  2 \n\n 1. defaultthis\n 2. staticinterface\n\n\n\npublic interface interfacenew {\n    static void sm() {\n        system.out.println("interface");\n    }\n    static void sm2() {\n        system.out.println("interface");\n    }\n\n    default void def() {\n        system.out.println("interface default");\n    }\n    default void def2() {\n        system.out.println("interface default2");\n    }\n    //\n    void f();\n}\n\npublic interface interfacenew1 {\n    default void def() {\n        system.out.println("interfacenew1 default");\n    }\n}\n\n\n interfacenew  interfacenew1def() interfacenew  interfacenew1def()\n\npublic class interfacenewimpl implements interfacenew , interfacenew1{\n    public static void main(string[] args) {\n        interfacenewimpl interfacenew = new interfacenewimpl();\n        interfacenew.def();\n    }\n\n    @override\n    public void def() {\n        interfacenew1.super.def();\n    }\n\n    @override\n    public void f() {\n    }\n}\n\n\n java 8 \n\n interface  abstract class \n\n\n\n 1. interface  class \n    \n    * \n    *  public abstract  public static final  abstract class \n\n 2. interface  abstract class \n\ninterface defaultstaticabstract class abstract class  abstract class interface \n\n\n\n\n# functional interface \n\n sam  single abstract method interfaces\n\n java 8 java.util.function @functionalinterface \n\n@functionalinterface \n\n@functionalinterface lambda \n\n\n# lambda \n\n lambda  java 8 (generics)(annotation)\n\n lambda  java \n\n> lambda java 8 \n\n\n# \n\n(parameters) -> expression \n(parameters) ->{ statements; }\n\n\n\n# lambda \n\n lambda \n\n# \n\n\n\n1.runnable \n\nnew thread(new runnable() {\n            @override\n            public void run() {\n                system.out.println("the runable now is using!");\n            }\n}).start();\n//lambda\nnew thread(() -> system.out.println("it\'s a lambda function!")).start();\n\n\n2.comparator \n\nlist<integer> strings = arrays.aslist(1, 2, 3);\n\ncollections.sort(strings, new comparator<integer>() {\n@override\npublic int compare(integer o1, integer o2) {\n    return o1 - o2;}\n});\n\n//lambda\ncollections.sort(strings, (integer o1, integer o2) -> o1 - o2);\n//\ncomparator<integer> comparator = (integer o1, integer o2) -> o1 - o2;\ncollections.sort(strings, comparator);\n\n\n3.listener \n\njbutton button = new jbutton();\nbutton.additemlistener(new itemlistener() {\n@override\npublic void itemstatechanged(itemevent e) {\n   e.getitem();\n}\n});\n//lambda\nbutton.additemlistener(e -> e.getitem());\n\n\n4.\n\n 3  lambda  lambda \n\n@functionalinterface\npublic interface comparator<t>{}\n\n@functionalinterface\npublic interface runnable{}\n\n\n\n\n@functionalinterface\npublic interface lambdainterface {\n void f();\n}\n//\npublic class lambdaclass {\n    public static void foreg() {\n        lambdainterfacedemo(()-> system.out.println(""));\n    }\n    //\n    static void lambdainterfacedemo(lambdainterface i){\n        i.f();\n    }\n}\n\n\n# \n\nvoid lamndafor() {\n        list<string> strings = arrays.aslist("1", "2", "3");\n        //foreach\n        for (string s : strings) {\n            system.out.println(s);\n        }\n        //lambda foreach\n        strings.foreach((s) -> system.out.println(s));\n        //or\n        strings.foreach(system.out::println);\n     //map\n        map<integer, string> map = new hashmap<>();\n        map.foreach((k,v)->system.out.println(v));\n}\n\n\n# \n\njava 8  ::  functional-interface\n\npublic class lambdaclasssuper {\n    lambdainterface sf(){\n        return null;\n    }\n}\n\npublic class lambdaclass extends lambdaclasssuper {\n    public static lambdainterface staticf() {\n        return null;\n    }\n\n    public lambdainterface f() {\n        return null;\n    }\n\n    void show() {\n        //1.functional-interface\n        lambdainterface t = lambdaclass::staticf;\n\n        //2.\n        lambdaclass lambdaclass = new lambdaclass();\n        lambdainterface lambdainterface = lambdaclass::f;\n\n        //3.\n        lambdainterface superf = super::sf;\n\n        //4. \n        lambdainterface tt = lambdaclasssuper::new;\n    }\n}\n\n\n# \n\nint i = 0;\ncollections.sort(strings, (integer o1, integer o2) -> o1 - i);\n//i =3;\n\n\nlambda  final \n\n\n# stream\n\njava  java.util.stream java.io.fileinputstreamcrud\n\nstream(retrieve) sql \n\n collectionarray  lambda \n\n\n# \n\n 1. stream \n 2. parallelstream \n\n\n# \n\njava.util.stream.stream\n\n/**\n* \n*/\ndefault stream<e> stream()\n\n/**\n* \n*/\ndefault stream<e> parallelstream()\n\n/**\n* t\n*/\npublic static<t> stream<t> of(t t)\n\n/**\n* \n*/\npublic static<t> stream<t> of(t... values) {\n    return arrays.stream(values);\n}\n\n\n/**\n* predicate\n*/\nstream<t> filter(predicate<? super t> predicate);\n\n/**\n* predicate\n*/\nboolean allmatch(predicate<? super t> predicate)\n\n/**\n* predicate\n*/\nboolean anymatch(predicate<? super t> predicate);\n\n/**\n*  stream\n*/\npublic static<t> builder<t> builder();\n\n/**\n*  collector\n*/\n<r, a> r collect(collector<? super t, a, r> collector);\n\n/**\n * \n*/\nlong count();\n\n/**\n*  object.equals(object) \n*/\nstream<t> distinct();\n\n/**\n * \n*/\nvoid foreach(consumer<? super t> action);\n\n/**\n*  maxsize \n*/\nstream<t> limit(long maxsize);\n\n/**\n* \n*/\n<r> stream<r> map(function<? super t, ? extends r> mapper);\n\n/**\n*  comparator\n*/\nstream<t> sorted(comparator<? super t> comparator);\n\n/**\n*  n n\n*/\nstream<t> skip(long n);\n\n/**\n* \n*/\nobject[] toarray();\n\n/**\n*  generator\n*/\n<a> a[] toarray(intfunction<a[]> generator);\n\n/**\n* \n*/\npublic static <t> stream<t> concat(stream<? extends t> a, stream<? extends t> b)\n\n\n\n# \n\n stream  api\n\n@test\npublic void test() {\n  list<string> strings = arrays.aslist("abc", "def", "gkh", "abc");\n    //stream\n    stream<string> stringstream = strings.stream().filter(s -> "abc".equals(s));\n    //\n    long count = stringstream.count();\n\n    //foreach->\n    strings.stream().foreach(system.out::println);\n\n    //limit 1stream\n    stream<string> limit = strings.stream().limit(1);\n    //toarray limitstreamstring[],\n    string[] array = limit.toarray(string[]::new);\n\n    //map \n    stream<string> map = strings.stream().map(s -> s + "22");\n\n    //sorted \n    strings.stream().sorted().foreach(system.out::println);\n\n    //collectors collect abc\n    list<string> collect = strings.stream().filter(string -> "abc".equals(string)).collect(collectors.tolist());\n    //liststring\n    string mergedstring = strings.stream().filter(string -> !string.isempty()).collect(collectors.joining(","));\n\n    //\n    list<integer> number = arrays.aslist(1, 2, 5, 4);\n\n    intsummarystatistics statistics = number.stream().maptoint((x) -> x).summarystatistics();\n    system.out.println(" : "+statistics.getmax());\n    system.out.println(" : "+statistics.getmin());\n    system.out.println(" : "+statistics.getaverage());\n    system.out.println(" : "+statistics.getsum());\n\n    //concat \n    list<string> strings2 = arrays.aslist("xyz", "jqx");\n    stream.concat(strings2.stream(),strings.stream()).count();\n\n    // stream\n    stream stream = strings.stream();\n    //\n    stream.limit(2);\n    //\n    stream.foreach(system.out::println);\n    // java.lang.illegalstateexception: stream has already been operated upon or closed\n\n    //, \n    stream.limit(2).foreach(system.out::println);\n}\n\n\n\n# \n\n stream  stream  stream  stream 2 \n\n filter \n\n@test\npublic void laziness(){\n  list<string> strings = arrays.aslist("abc", "def", "gkh", "abc");\n  stream<integer> stream = strings.stream().filter(new predicate() {\n      @override\n      public boolean test(object o) {\n        system.out.println("predicate.test ");\n        return true;\n        }\n      });\n\n   system.out.println("count ");\n   stream.count();\n}\n/*---------------*/\ncount \npredicate.test \npredicate.test \npredicate.test \npredicate.test \n\n\n 4 predicate.test count  filter count()\n\n stream  parallelstream  parallelstream  forkjoin  forkjoin  forkjoinpool\n\n@test\npublic void parallelstreamtest(){\n   list<integer> numbers = arrays.aslist(1, 2, 5, 4);\n   numbers.parallelstream() .foreach(num->system.out.println(thread.currentthread().getname()+">>"+num));\n}\n//\nmain>>5\nforkjoinpool.commonpool-worker-2>>4\nforkjoinpool.commonpool-worker-11>>1\nforkjoinpool.commonpool-worker-9>>2\n\n\nfor-each \n\n\n# \n\n stream \n\n 1. \n 2. \n 3.  stream  stream \n 4. stream \n\n\n# optional\n\n optional \n\n>  npe npe \n> \n> 1 return  npe\n> \n> public int f() { return integer }  null npe\n> \n> 2  null\n> \n> 3  isnotempty null\n> \n> 4  npe\n> \n> 5  session  npe \n> \n> 6  obj.geta().getb().getc() npe\n> \n>  jdk8  optional  npe \n\n optional  npejava.lang.nullpointerexception npe  optional \n\n zoo  dog dog  age\n\nclass zoo {\n   private dog dog;\n}\n\nclass dog {\n   private int age;\n}\n\n\n npe \n\nzoo zoo = getzoo();\nif(zoo != null){\n   dog dog = zoo.getdog();\n   if(dog != null){\n      int age = dog.getage();\n      system.out.println(age);\n   }\n}\n\n\n\n\noptional \n\noptional.ofnullable(zoo).map(o -> o.getdog()).map(d -> d.getage()).ifpresent(age ->\n    system.out.println(age)\n);\n\n\n\n\n\n#  optional\n\noptional.ofnullable optional  optional \n\n/**\n* common instance for {@code empty()}. empty\n*/\nprivate static final optional<?> empty = new optional<>();\n\n/**\n* optional\n*/\nprivate final t value;\n\n/**\n* valuenullemptyof(t)\n*/\npublic static <t> optional<t> ofnullable(t value) {\n   return value == null ? empty() : of(value);\n}\n/**\n*  empty \n*/\npublic static<t> optional<t> empty() {\n   optional<t> t = (optional<t>) empty;\n   return t;\n}\n/**\n* optional\n*/\npublic static <t> optional<t> of(t value) {\n    return new optional<>(value);\n}\n/**\n* value\n*/\nprivate optional(t value) {\n  this.value = objects.requirenonnull(value);\n}\n/**\n* of(t value) valuenullnullpointerexceptionnpe\n*/\npublic static <t> t requirenonnull(t obj) {\n  if (obj == null)\n         throw new nullpointerexception();\n  return obj;\n}\n\n\nofnullable of value  null ofnullable emptyof  nullpointerexception  nullpointerexception  of ofnullable\n\nmap()  flatmap() \n\nmap  flatmap mapflatmap\n\nmapflatmap\n\npublic class mapandflatmapexample {\n    public static void main(string[] args) {\n        list<string[]> listofarrays = arrays.aslist(\n                new string[]{"apple", "banana", "cherry"},\n                new string[]{"orange", "grape", "pear"},\n                new string[]{"kiwi", "melon", "pineapple"}\n        );\n\n        list<string[]> mapresult = listofarrays.stream()\n                .map(array -> arrays.stream(array).map(string::touppercase).toarray(string[]::new))\n                .collect(collectors.tolist());\n\n        system.out.println("using map:");\n        mapresult.foreach(arrays-> system.out.println(arrays.tostring(arrays)));\n\n        list<string> flatmapresult = listofarrays.stream()\n                .flatmap(array -> arrays.stream(array).map(string::touppercase))\n                .collect(collectors.tolist());\n\n        system.out.println("using flatmap:");\n        system.out.println(flatmapresult);\n    }\n}\n\n\n\n:\n\nusing map:\n[[apple, banana, cherry], [orange, grape, pear], [kiwi, melon, pineapple]]\n\nusing flatmap:\n[apple, banana, cherry, orange, grape, pear, kiwi, melon, pineapple]\n\n\nflatmap()map()\n\noptionalmap()optionalflatmapoptionaloptionaloptional\n\n\n\npublic static void main(string[] args) {\n        int userid = 1;\n\n        // flatmap\n        string cityusingflatmap = getuserbyid(userid)\n                .flatmap(optionalexample::getaddressbyuser)\n                .map(address::getcity)\n                .orelse("unknown");\n\n        system.out.println("user\'s city using flatmap: " + cityusingflatmap);\n\n        // flatmap\n        optional<optional<address>> optionaladdress = getuserbyid(userid)\n                .map(optionalexample::getaddressbyuser);\n\n        string citywithoutflatmap;\n        if (optionaladdress.ispresent()) {\n            optional<address> addressoptional = optionaladdress.get();\n            if (addressoptional.ispresent()) {\n                address address = addressoptional.get();\n                citywithoutflatmap = address.getcity();\n            } else {\n                citywithoutflatmap = "unknown";\n            }\n        } else {\n            citywithoutflatmap = "unknown";\n        }\n\n        system.out.println("user\'s city without flatmap: " + citywithoutflatmap);\n    }\n\n\nstreamoptionalflatmap\n\n\n#  value  null\n\n/**\n* valuenull\n*/\npublic boolean ispresent() {\n    return value != null;\n}\n/**\n* valuenullconsumer.accept\n*/\npublic void ifpresent(consumer<? super t> consumer) {\n   if (value != null)\n    consumer.accept(value);\n}\n\n\n\n#  value\n\n/**\n* return the value if present, otherwise invoke {@code other} and return\n* the result of that invocation.\n* value != null valueother\n*/\npublic t orelseget(supplier<? extends t> other) {\n    return value != null ? value : other.get();\n}\n\n/**\n* value != null valuet\n*/\npublic t orelse(t other) {\n    return value != null ? value : other;\n}\n\n/**\n* value != null value\n*/\npublic <x extends throwable> t orelsethrow(supplier<? extends x> exceptionsupplier) throws x {\n        if (value != null) {\n            return value;\n        } else {\n            throw exceptionsupplier.get();\n        }\n}\n/**\n* valuenullnosuchelementexceptionvalue\n*/\npublic t get() {\n  if (value == null) {\n      throw new nosuchelementexception("no value present");\n  }\n  return value;\n}\n\n\n\n# \n\n/**\n* 1. emptyempty\n* 2. predicate.test(value)==true thisempty\n*/\npublic optional<t> filter(predicate<? super t> predicate) {\n        objects.requirenonnull(predicate);\n        if (!ispresent())\n            return this;\n        else\n            return predicate.test(value) ? this : empty();\n}\n\n\n\n# \n\n optional optional  npe of() get()flatmap(..) optional \n\noptional.ofnullable(zoo).map(o -> o.getdog()).map(d -> d.getage()).filter(v->v==1).orelse(3);\n\n\n\n# date-time api\n\njava.util.date date \n\n 1. \n 2. \n 3. \n 4. date  java.sql.date\n\n java.util.date  date java.util.date\n\n\n# java.time \n\njava.util.date  java.time \n\nlocaldatetime.class //+ format: yyyy-mm-ddthh:mm:ss.sss\nlocaldate.class // format: yyyy-mm-dd\nlocaltime.class // format: hh:mm:ss\n\n\n\n# \n\njava 8 :\n\npublic void oldformat(){\n    date now = new date();\n    //format yyyy-mm-dd\n    simpledateformat sdf = new simpledateformat("yyyy-mm-dd");\n    string date  = sdf.format(now);\n    system.out.println(string.format("date format : %s", date));\n\n    //format hh:mm:ss\n    simpledateformat sdft = new simpledateformat("hh:mm:ss");\n    string time = sdft.format(now);\n    system.out.println(string.format("time format : %s", time));\n\n    //format yyyy-mm-dd hh:mm:ss\n    simpledateformat sdfdt = new simpledateformat("yyyy-mm-dd hh:mm:ss");\n    string datetime = sdfdt.format(now);\n    system.out.println(string.format("datetime format : %s", datetime));\n}\n\n\njava 8 :\n\npublic void newformat(){\n    //format yyyy-mm-dd\n    localdate date = localdate.now();\n    system.out.println(string.format("date format : %s", date));\n\n    //format hh:mm:ss\n    localtime time = localtime.now().withnano(0);\n    system.out.println(string.format("time format : %s", time));\n\n    //format yyyy-mm-dd hh:mm:ss\n    localdatetime datetime = localdatetime.now();\n    datetimeformatter datetimeformatter = datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss");\n    string datetimestr = datetime.format(datetimeformatter);\n    system.out.println(string.format("datetime format : %s", datetimestr));\n}\n\n\n\n# \n\njava 8 :\n\n//\ndate date = new date("2021-01-26");\n//\nsimpledateformat sdf = new simpledateformat("yyyy-mm-dd");\ndate date1 = sdf.parse("2021-01-26");\n\n\njava 8 :\n\nlocaldate date = localdate.of(2021, 1, 26);\nlocaldate.parse("2021-01-26");\n\nlocaldatetime datetime = localdatetime.of(2021, 1, 26, 12, 12, 22);\nlocaldatetime.parse("2021-01-26 12:12:22");\n\nlocaltime time = localtime.of(12, 12, 22);\nlocaltime.parse("12:12:22");\n\n\njava 8   simpledateformat java 8  localdatelocaltimelocaldatetime of  parse \n\n\n# \n\n1/2  java.time.temporal.chronounit \n\njava 8 :\n\npublic void afterday(){\n     //\n     simpledateformat formatdate = new simpledateformat("yyyy-mm-dd");\n     calendar ca = calendar.getinstance();\n     ca.add(calendar.date, 7);\n     date d = ca.gettime();\n     string after = formatdate.format(d);\n     system.out.println("" + after);\n\n   //\n     string dates1 = "2021-12-23";\n   string dates2 = "2021-02-26";\n     simpledateformat format = new simpledateformat("yyyy-mm-dd");\n     date date1 = format.parse(dates1);\n     date date2 = format.parse(dates2);\n     int day = (int) ((date1.gettime() - date2.gettime()) / (1000 * 3600 * 24));\n     system.out.println(dates1 + "" + dates2 + "" + day + "");\n     //2021-02-262021-12-23300\n}\n\n\njava 8 :\n\npublic void pushweek(){\n     //\n     localdate localdate = localdate.now();\n     //1\n     localdate after = localdate.plus(1, chronounit.weeks);\n     //2\n     localdate after2 = localdate.plusweeks(1);\n     system.out.println("" + after);\n\n     //\n     localdate date1 = localdate.parse("2021-02-26");\n     localdate date2 = localdate.parse("2021-12-23");\n     period period = period.between(date1, date2);\n     system.out.println("date1  date2 "\n                + period.getyears() + ""\n                + period.getmonths() + ""\n                + period.getdays() + "");\n   // date1  date2 0927\n     //period.getdays()\n     //\n     long day = date2.toepochday() - date1.toepochday();\n     system.out.println(date1 + "" + date2 + "" + day + "");\n     //2021-02-262021-12-23300\n}\n\n\n\n# \n\n\n\njava 8 :\n\npublic void getday() {\n\n        simpledateformat format = new simpledateformat("yyyy-mm-dd");\n        //\n        calendar c = calendar.getinstance();\n        c.set(calendar.day_of_month, 1);\n        string first = format.format(c.gettime());\n        system.out.println("first day:" + first);\n\n        //\n        calendar ca = calendar.getinstance();\n        ca.set(calendar.day_of_month, ca.getactualmaximum(calendar.day_of_month));\n        string last = format.format(ca.gettime());\n        system.out.println("last day:" + last);\n\n        //\n        calendar currcal = calendar.getinstance();\n        calendar calendar = calendar.getinstance();\n        calendar.clear();\n        calendar.set(calendar.year, currcal.get(calendar.year));\n        calendar.roll(calendar.day_of_year, -1);\n        date time = calendar.gettime();\n        system.out.println("last day:" + format.format(time));\n}\n\n\njava 8 :\n\npublic void getdaynew() {\n    localdate today = localdate.now();\n    //\n    localdate firstdayofthismonth = today.with(temporaladjusters.firstdayofmonth());\n    // \n    localdate lastdayofthismonth = today.with(temporaladjusters.lastdayofmonth());\n    //\n    localdate nextday = lastdayofthismonth.plusdays(1);\n    //\n    localdate lastday = today.with(temporaladjusters.lastdayofyear());\n    //2021calendar\n    localdate lastmondayof2021 = localdate.parse("2021-12-31").with(temporaladjusters.lastinmonth(dayofweek.sunday));\n}\n\n\njava.time.temporal.temporaladjusters  api \n\n\n# jdbc  java8\n\n jdbc  java8 \n\n 1. date ---\x3e localdate\n 2. time ---\x3e localtime\n 3. timestamp ---\x3e localdatetime\n\n date date\n\n\n# \n\n>  15  24  1  1  1  5 \n\njava.util.date  1970  1  1  0  gmt date  new datejava.util.date  timezone\n\n//wed jan 27 14:05:29 cst 2021\ndate date = new date();\n\nsimpledateformat bjsdf = new simpledateformat("yyyy-mm-dd hh:mm:ss");\n//\nbjsdf.settimezone(timezone.gettimezone("asia/shanghai"));\nsystem.out.println(":" + date.gettime() + ", :" + bjsdf.format(date));\n\n//\nsimpledateformat tokyosdf = new simpledateformat("yyyy-mm-dd hh:mm:ss");\ntokyosdf.settimezone(timezone.gettimezone("asia/tokyo"));  // \nsystem.out.println(":" + date.gettime() + ", :" + tokyosdf.format(date));\n\n//print\nsystem.out.println(date);\n//wed jan 27 14:05:29 cst 2021\n\n\n java.time.zoneddatetime  localdatetime + zoneid\n\n//\nzoneddatetime zoneddatetime = zoneddatetime.now();\nsystem.out.println(": " + zoneddatetime);\n\n//\nzoneid zoneid = zoneid.of(zoneid.short_ids.get("jst"));\nzoneddatetime tokyotime = zoneddatetime.withzonesameinstant(zoneid);\nsystem.out.println(": " + tokyotime);\n\n// zoneddatetime  localdatetime\nlocaldatetime localdatetime = tokyotime.tolocaldatetime();\nsystem.out.println(": " + localdatetime);\n\n//localdatetime  zoneddatetime\nzoneddatetime localzoned = localdatetime.atzone(zoneid.systemdefault());\nsystem.out.println(": " + localzoned);\n\n//\n: 2021-01-27t14:43:58.735+08:00[asia/shanghai]\n: 2021-01-27t15:43:58.735+09:00[asia/tokyo]\n: 2021-01-27t15:43:58.735\n: 2021-01-27t15:53:35.618+08:00[asia/shanghai]\n\n\n\n# \n\n date  date-time-api  date  date-time-api date\n\n\n# \n\n java 8 \n\n * interface & functional interface\n * lambda\n * stream\n * optional\n * date time-api\n\n java 8 35 ',charsets:{cjk:!0}},{title:"java8-tutorial-translate",frontmatter:{title:"java8-tutorial-translate",date:"2024-08-21T23:05:51.000Z",permalink:"/pages/b610cd/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/02.java8-tutorial-translate.html",relativePath:"01.Java/05./02.java8-tutorial-translate.md",key:"v-5a234d0e",path:"/pages/b610cd/",headers:[{level:2,title:"(Default Methods for Interfaces)",slug:"-default-methods-for-interfaces",normalizedTitle:"(default methods for interfaces)",charIndex:441},{level:2,title:"Lambda (Lambda expressions)",slug:"lambda--lambda-expressions",normalizedTitle:"lambda (lambda expressions)",charIndex:1393},{level:2,title:"(Functional Interfaces)",slug:"-functional-interfaces",normalizedTitle:"(functional interfaces)",charIndex:363},{level:2,title:"(Method and Constructor References)",slug:"-method-and-constructor-references",normalizedTitle:"(method and constructor references)",charIndex:3019},{level:2,title:"Lambda (Lambda Scopes)",slug:"lambda--lambda-scopes",normalizedTitle:"lambda (lambda scopes)",charIndex:4260},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:4293},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:4872},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:5341},{level:2,title:"(Built-in Functional Interfaces)",slug:"-built-in-functional-interfaces",normalizedTitle:"(built-in functional interfaces)",charIndex:5525},{level:3,title:"Predicate",slug:"predicate",normalizedTitle:"predicate",charIndex:5802},{level:3,title:"Function",slug:"function",normalizedTitle:"function",charIndex:369},{level:3,title:"Supplier",slug:"supplier",normalizedTitle:"supplier",charIndex:8104},{level:3,title:"Consumer",slug:"consumer",normalizedTitle:"consumer",charIndex:8263},{level:3,title:"Comparator",slug:"comparator",normalizedTitle:"comparator",charIndex:1552},{level:2,title:"Optional",slug:"optional",normalizedTitle:"optional",charIndex:8766},{level:2,title:"Streams()",slug:"streams-",normalizedTitle:"streams()",charIndex:9477},{level:3,title:"Filter()",slug:"filter-",normalizedTitle:"filter()",charIndex:10085},{level:3,title:"Sorted()",slug:"sorted-",normalizedTitle:"sorted()",charIndex:10506},{level:3,title:"Map()",slug:"map-",normalizedTitle:"map()",charIndex:10945},{level:3,title:"Match()",slug:"match-",normalizedTitle:"match()",charIndex:11361},{level:3,title:"Count()",slug:"count-",normalizedTitle:"count()",charIndex:12134},{level:3,title:"Reduce()",slug:"reduce-",normalizedTitle:"reduce()",charIndex:12445},{level:2,title:"Parallel Streams()",slug:"parallel-streams-",normalizedTitle:"parallel streams()",charIndex:13838},{level:3,title:"Sequential Sort()",slug:"sequential-sort-",normalizedTitle:"sequential sort()",charIndex:14191},{level:3,title:"Parallel Sort()",slug:"parallel-sort-",normalizedTitle:"parallel sort()",charIndex:14538},{level:2,title:"Maps",slug:"maps",normalizedTitle:"maps",charIndex:14960},{level:2,title:"Date API( API)",slug:"date-api--api",normalizedTitle:"date api( api)",charIndex:16285},{level:3,title:"Clock",slug:"clock",normalizedTitle:"clock",charIndex:16436},{level:3,title:"Timezones()",slug:"timezones-",normalizedTitle:"timezones()",charIndex:17361},{level:3,title:"LocalTime()",slug:"localtime-",normalizedTitle:"localtime()",charIndex:17814},{level:3,title:"LocalDate()",slug:"localdate-",normalizedTitle:"localdate()",charIndex:18656},{level:3,title:"LocalDateTime()",slug:"localdatetime-",normalizedTitle:"localdatetime()",charIndex:20959},{level:2,title:"Annotations()",slug:"annotations-",normalizedTitle:"annotations()",charIndex:22183},{level:2,title:"Where to go from here?",slug:"where-to-go-from-here",normalizedTitle:"where to go from here?",charIndex:23252}],headersStr:"(Default Methods for Interfaces) Lambda (Lambda expressions) (Functional Interfaces) (Method and Constructor References) Lambda (Lambda Scopes)    (Built-in Functional Interfaces) Predicate Function Supplier Consumer Comparator Optional Streams() Filter() Sorted() Map() Match() Count() Reduce() Parallel Streams() Sequential Sort() Parallel Sort() Maps Date API( API) Clock Timezones() LocalTime() LocalDate() LocalDateTime() Annotations() Where to go from here?",content:'# Java8 \n\n Java 8  Java 8  GitHub  https://github.com/winterbe/java8-tutorial\n\n----------------------------------------\n\n Java 8  lambda   API (Functional Interfaces)Map  Date API \n\n\n# (Default Methods for Interfaces)\n\nJava 8  default  \n\n\n\ninterface Formula{\n\n    double calculate(int a);\n\n    default double sqrt(int a) {\n        return Math.sqrt(a);\n    }\n\n}\n\n\nFormula  sqrt  calculate sqrt \n\npublic class Main {\n\n  public static void main(String[] args) {\n    // \n    Formula formula = new Formula() {\n        @Override\n        public double calculate(int a) {\n            return sqrt(a * 100);\n        }\n    };\n\n    System.out.println(formula.calculate(100));     // 100.0\n    System.out.println(formula.sqrt(16));           // 4.0\n\n  }\n\n}\n\n\nformula 6  sqrt(a * 100) Java 8 \n\n \n\n\n# Lambda (Lambda expressions)\n\n Java \n\nList<String> names = Arrays.asList("peter", "anna", "mike", "xenia");\n\nCollections.sort(names, new Comparator<String>() {\n    @Override\n    public int compare(String a, String b) {\n        return b.compareTo(a);\n    }\n});\n\n\nCollections.sort  List  sort \n\n Java 8 Java 8 lambda \n\nCollections.sort(names, (String a, String b) -> {\n    return b.compareTo(a);\n});\n\n\n\n\nCollections.sort(names, (String a, String b) -> b.compareTo(a));\n\n\n{} return \n\nnames.sort((a, b) -> b.compareTo(a));\n\n\nList  sort  Java  lambda \n\n\n# (Functional Interfaces)\n\n \n\nJava  Lambda,()  lambda java.lang.Runnable  java.util.concurrent.Callable Java 8 @FunctionalInterface,()@FunctionalInterface \n\n\n\n\n\n@FunctionalInterface\npublic interface Converter<F, T> {\n  T convert(F from);\n}\n\n\n    // TODO \n    Converter<String, Integer> converter = (from) -> Integer.valueOf(from);\n    Integer converted = converter.convert("123");\n    System.out.println(converted.getClass()); //class java.lang.Integer\n\n\n Java8  java.util.function \n\n\n# (Method and Constructor References)\n\n\n\n    Converter<String, Integer> converter = Integer::valueOf;\n    Integer converted = converter.convert("123");\n    System.out.println(converted.getClass());   //class java.lang.Integer\n\n\nJava 8 ::  \n\nclass Something {\n    String startsWith(String s) {\n        return String.valueOf(s.charAt(0));\n    }\n}\n\n\nSomething something = new Something();\nConverter<String, String> converter = something::startsWith;\nString converted = converter.convert("Java");\nSystem.out.println(converted);    // "J"\n\n\n::\n\nclass Person {\n    String firstName;\n    String lastName;\n\n    Person() {}\n\n    Person(String firstName, String lastName) {\n        this.firstName = firstName;\n        this.lastName = lastName;\n    }\n}\n\n\n Person \n\ninterface PersonFactory<P extends Person> {\n    P create(String firstName, String lastName);\n}\n\n\n\n\nPersonFactory<Person> personFactory = Person::new;\nPerson person = personFactory.create("Peter", "Parker");\n\n\n Person::new  Person Java PersonFactory.create\n\n\n# Lambda (Lambda Scopes)\n\n\n# \n\n lambda \n\nfinal int num = 1;\nConverter<Integer, String> stringConverter =\n        (from) -> String.valueOf(from + num);\n\nstringConverter.convert(2);     // 3\n\n\n num  final\n\nint num = 1;\nConverter<Integer, String> stringConverter =\n        (from) -> String.valueOf(from + num);\n\nstringConverter.convert(2);     // 3\n\n\n num  final \n\nint num = 1;\nConverter<Integer, String> stringConverter =\n        (from) -> String.valueOf(from + num);\nnum = 3;//lambdanum\n\n\n\n# \n\n lambda  \n\nclass Lambda4 {\n    static int outerStaticNum;\n    int outerNum;\n\n    void testScopes() {\n        Converter<Integer, String> stringConverter1 = (from) -> {\n            outerNum = 23;\n            return String.valueOf(from);\n        };\n\n        Converter<Integer, String> stringConverter2 = (from) -> {\n            outerStaticNum = 72;\n            return String.valueOf(from);\n        };\n    }\n}\n\n\n\n# \n\n formula  Formula sqrt formula   lambda \n\n lambda ,\n\nFormula formula = (a) -> sqrt(a * 100);\n\n\n\n# (Built-in Functional Interfaces)\n\nJDK 1.8 API   Java Comparator Runnable@FunctionalInterface lambda \n\n Java 8 API  Google Guava  lambda \n\n\n# Predicate\n\nPredicate    Predicate \n\n Predicate \n\npackage java.util.function;\nimport java.util.Objects;\n\n@FunctionalInterface\npublic interface Predicate<T> {\n\n    // ,..\n    boolean test(T t);\n\n    //and"&&"true\n    default Predicate<T> and(Predicate<? super T> other) {\n        Objects.requireNonNull(other);\n        return (t) -> test(t) && other.test(t);\n    }\n    // "!"\n    default Predicate<T> negate() {\n        return (t) -> !test(t);\n    }\n    //or"||"true\n    default Predicate<T> or(Predicate<? super T> other) {\n        Objects.requireNonNull(other);\n        return (t) -> test(t) || other.test(t);\n    }\n   // Object,Predicate.testtest(equal).\n    static <T> Predicate<T> isEqual(Object targetRef) {\n        return (null == targetRef)\n                ? Objects::isNull\n                : object -> targetRef.equals(object);\n    }\n\n\n\n\nPredicate<String> predicate = (s) -> s.length() > 0;\n\npredicate.test("foo");              // true\npredicate.negate().test("foo");     // false\n\nPredicate<Boolean> nonNull = Objects::nonNull;\nPredicate<Boolean> isNull = Objects::isNull;\n\nPredicate<String> isEmpty = String::isEmpty;\nPredicate<String> isNotEmpty = isEmpty.negate();\n\n\n\n# Function\n\nFunction compose, andThen\n\n Function \n\n\npackage java.util.function;\n\nimport java.util.Objects;\n\n@FunctionalInterface\npublic interface Function<T, R> {\n\n    //Function\n    R apply(T t);\n    //FunctionFunctionFunction\n    default <V> Function<V, R> compose(Function<? super V, ? extends T> before) {\n        Objects.requireNonNull(before);\n        return (V v) -> apply(before.apply(v));\n    }\n    //\n    default <V> Function<T, V> andThen(Function<? super R, ? extends V> after) {\n        Objects.requireNonNull(after);\n        return (T t) -> after.apply(apply(t));\n    }\n\n    static <T> Function<T, T> identity() {\n        return t -> t;\n    }\n}\n\n\nFunction<String, Integer> toInteger = Integer::valueOf;\nFunction<String, String> backToString = toInteger.andThen(String::valueOf);\nbackToString.apply("123");     // "123"\n\n\n\n# Supplier\n\nSupplier   Function Supplier \n\nSupplier<Person> personSupplier = Person::new;\npersonSupplier.get();   // new Person\n\n\n\n# Consumer\n\nConsumer \n\nConsumer<Person> greeter = (p) -> System.out.println("Hello, " + p.firstName);\ngreeter.accept(new Person("Luke", "Skywalker"));\n\n\n\n# Comparator\n\nComparator  Java  Java 8 \n\nComparator<Person> comparator = (p1, p2) -> p1.firstName.compareTo(p2.firstName);\n\nPerson p1 = new Person("John", "Doe");\nPerson p2 = new Person("Alice", "Wonderland");\n\ncomparator.compare(p1, p2);             // > 0\ncomparator.reversed().compare(p1, p2);  // < 0\n\n\n\n# Optional\n\nOptional  NullPointerException  Optional \n\nOptional  null  null Java 8  Java 8  Optional  null\n\n\n\n//of()nullOptional\nOptional<String> optional = Optional.of("bam");\n// isPresent()truefalse\noptional.isPresent();           // true\n//get()OptionalNoSuchElementException\noptional.get();                 // "bam"\n//orElse()\noptional.orElse("fallback");    // "bam"\n//ifPresent()Optionalconsumer\noptional.ifPresent((s) -> System.out.println(s.charAt(0)));     // "b"\n\n\n[Java8] Optional\n\n\n# Streams()\n\njava.util.Stream Stream  Stream Stream java.util.Collection List  Set Map Stream \n\n Stream  List\n\nList<String> stringList = new ArrayList<>();\nstringList.add("ddd2");\nstringList.add("aaa2");\nstringList.add("bbb1");\nstringList.add("aaa1");\nstringList.add("bbb3");\nstringList.add("ccc");\nstringList.add("bbb2");\nstringList.add("ddd1");\n\n\nJava 8  Collection.stream()  Collection.parallelStream()  Stream Stream \n\n\n# Filter()\n\n predicate  Stream  forEachforEach forEach  forEach  Stream \n\n        //  Filter()\n        stringList\n                .stream()\n                .filter((s) -> s.startsWith("a"))\n                .forEach(System.out::println);//aaa2 aaa1\n\n\nforEach  Lambda  Lambda \n\n\n# Sorted()\n\n  Stream Comparator \n\n        //  Sort ()\n        stringList\n                .stream()\n                .sorted()\n                .filter((s) -> s.startsWith("a"))\n                .forEach(System.out::println);// aaa1 aaa2\n\n\n Stream stringList \n\n    System.out.println(stringList);// ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1\n\n\n\n# Map()\n\n map  Function \n\n map map  Stream  map \n\n        //  Map \n        stringList\n                .stream()\n                .map(String::toUpperCase)\n                .sorted((a, b) -> b.compareTo(a))\n                .forEach(System.out::println);// "DDD2", "DDD1", "CCC", "BBB3", "BBB2", "BBB1", "AAA2", "AAA1"\n\n\n\n# Match()\n\nStream  Predicate  Stream   boolean \n\n        //  Match ()\n        boolean anyStartsWithA =\n                stringList\n                        .stream()\n                        .anyMatch((s) -> s.startsWith("a"));\n        System.out.println(anyStartsWithA);      // true\n\n        boolean allStartsWithA =\n                stringList\n                        .stream()\n                        .allMatch((s) -> s.startsWith("a"));\n\n        System.out.println(allStartsWithA);      // false\n\n        boolean noneStartsWithZ =\n                stringList\n                        .stream()\n                        .noneMatch((s) -> s.startsWith("z"));\n\n        System.out.println(noneStartsWithZ);      // true\n\n\n\n# Count()\n\n  Stream  long\n\n      // Count ()\n        long startsWithB =\n                stringList\n                        .stream()\n                        .filter((s) -> s.startsWith("b"))\n                        .count();\n        System.out.println(startsWithB);    // 3\n\n\n\n# Reduce()\n\n   stream  Optional \n\n        // Reduce ()\n        Optional<String> reduced =\n                stringList\n                        .stream()\n                        .sorted()\n                        .reduce((s1, s2) -> s1 + "#" + s2);\n\n        reduced.ifPresent(System.out::println);//aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2\n\n\n  Stream BinaryOperator Stream  n  summinmaxaverage  reduce Stream  sum Integer sum = integers.reduce(0, (a, b) -> a+b); Stream  Optional\n\n// concat = "ABCD"\nString concat = Stream.of("A", "B", "C", "D").reduce("", String::concat);\n// minValue = -3.0\ndouble minValue = Stream.of(-1.5, 1.0, -3.0, -2.0).reduce(Double.MAX_VALUE, Double::min);\n// sumValue = 10, \nint sumValue = Stream.of(1, 2, 3, 4).reduce(0, Integer::sum);\n// sumValue = 10, \nsumValue = Stream.of(1, 2, 3, 4).reduce(Integer::sum).get();\n// concat = "ace"\nconcat = Stream.of("a", "B", "c", "D", "e", "F").\n filter(x -> x.compareTo("Z") > 0).\n reduce("", String::concat);\n\n\n reduce()String::concat BinaryOperator reduce()  reduce() OptionalIBMJava 8  Streams API \n\n\n# Parallel Streams()\n\n Stream  Stream  Stream \n\n Stream \n\n\n\nint max = 1000000;\nList<String> values = new ArrayList<>(max);\nfor (int i = 0; i < max; i++) {\n    UUID uuid = UUID.randomUUID();\n    values.add(uuid.toString());\n}\n\n\n\n\n\n# Sequential Sort()\n\n//\nlong t0 = System.nanoTime();\nlong count = values.stream().sorted().count();\nSystem.out.println(count);\n\nlong t1 = System.nanoTime();\n\nlong millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);\nSystem.out.println(String.format("sequential sort took: %d ms", millis));\n\n\n1000000\nsequential sort took: 709 ms//\n\n\n\n# Parallel Sort()\n\n//\nlong t0 = System.nanoTime();\n\nlong count = values.parallelStream().sorted().count();\nSystem.out.println(count);\n\nlong t1 = System.nanoTime();\n\nlong millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);\nSystem.out.println(String.format("parallel sort took: %d ms", millis));\n\n\n\n1000000\nparallel sort took: 475 ms//\n\n\n 50%  stream() parallelStream()\n\n\n# Maps\n\nMap  streams Map Map  stream() map.keySet().stream(),map.values().stream()map.entrySet().stream()\n\n,Maps \n\nMap<Integer, String> map = new HashMap<>();\n\nfor (int i = 0; i < 10; i++) {\n    map.putIfAbsent(i, "val" + i);\n}\n\nmap.forEach((id, val) -> System.out.println(val));//val0 val1 val2 val3 val4 val5 val6 val7 val8 val9\n\n\nputIfAbsent  null ;forEach consumer  map \n\n map \n\nmap.computeIfPresent(3, (num, val) -> val + num);\nmap.get(3);             // val33\n\nmap.computeIfPresent(9, (num, val) -> null);\nmap.containsKey(9);     // false\n\nmap.computeIfAbsent(23, num -> "val" + num);\nmap.containsKey(23);    // true\n\nmap.computeIfAbsent(3, num -> "bam");\nmap.get(3);             // val33\n\n\n Map \n\nmap.remove(3, "val3");\nmap.get(3);             // val33\nmap.remove(3, "val33");\nmap.get(3);             // null\n\n\n\n\nmap.getOrDefault(42, "not found");  // not found\n\n\n Map \n\nmap.merge(9, "val9", (value, newValue) -> value.concat(newValue));\nmap.get(9);             // val9\nmap.merge(9, "concat", (value, newValue) -> value.concat(newValue));\nmap.get(9);             // val9concat\n\n\nMerge  map \n\n\n# Date API( API)\n\nJava 8  java.time  API Date API  Joda-Time  API \n\n()\n\n * Clock Clock  System.currentTimeMillis()  Instant Instant java.util.Date \n\n *  API  ZoneId  of  ZoneIdjava.time getAvailableZoneIds\n\n * jdk1.8  LocalDate  LocalDateTime  DateTimeFormatter  Instant  DateLocalDateTime  CalendarDateTimeFormatter  SimpleDateFormat\n\n\n# Clock\n\nClock Clock  System.currentTimeMillis()  Instant Instant java.util.Date \n\nClock clock = Clock.systemDefaultZone();\nlong millis = clock.millis();\nSystem.out.println(millis);//1552379579043\nInstant instant = clock.instant();\nSystem.out.println(instant);\nDate legacyDate = Date.from(instant); //2019-03-12T08:46:42.588Z\nSystem.out.println(legacyDate);//Tue Mar 12 16:32:59 CST 2019\n\n\n\n# Timezones()\n\n API  ZoneId  of  ZoneIdjava.time getAvailableZoneIds\n\n//\nSystem.out.println(ZoneId.getAvailableZoneIds());\n\nZoneId zone1 = ZoneId.of("Europe/Berlin");\nZoneId zone2 = ZoneId.of("Brazil/East");\nSystem.out.println(zone1.getRules());// ZoneRules[currentStandardOffset=+01:00]\nSystem.out.println(zone2.getRules());// ZoneRules[currentStandardOffset=-03:00]\n\n\n\n# LocalTime()\n\nLocalTime   10  17:30:15\n\nLocalTime now1 = LocalTime.now(zone1);\nLocalTime now2 = LocalTime.now(zone2);\nSystem.out.println(now1.isBefore(now2));  // false\n\nlong hoursBetween = ChronoUnit.HOURS.between(now1, now2);\nlong minutesBetween = ChronoUnit.MINUTES.between(now1, now2);\n\nSystem.out.println(hoursBetween);       // -3\nSystem.out.println(minutesBetween);     // -239\n\n\nLocalTime .\n\nLocalTime late = LocalTime.of(23, 59, 59);\nSystem.out.println(late);       // 23:59:59\nDateTimeFormatter germanFormatter =\n    DateTimeFormatter\n        .ofLocalizedTime(FormatStyle.SHORT)\n        .withLocale(Locale.GERMAN);\n\nLocalTime leetTime = LocalTime.parse("13:37", germanFormatter);\nSystem.out.println(leetTime);   // 13:37\n\n\n\n# LocalDate()\n\nLocalDate  2014-03-11 LocalTime  Date //\n\nLocalDate today = LocalDate.now();//\nSystem.out.println(": "+today);//2019-03-12\nLocalDate tomorrow = today.plus(1, ChronoUnit.DAYS);\nSystem.out.println(": "+tomorrow);//2019-03-13\nLocalDate yesterday = tomorrow.minusDays(2);\nSystem.out.println(": "+yesterday);//2019-03-11\nLocalDate independenceDay = LocalDate.of(2019, Month.MARCH, 12);\nDayOfWeek dayOfWeek = independenceDay.getDayOfWeek();\nSystem.out.println(":"+dayOfWeek);//TUESDAY\n\n\n LocalDate  LocalTime , DateTimeFormatter \n\n    String str1 = "2014==04==12 010609";\n        // \n        DateTimeFormatter fomatter1 = DateTimeFormatter\n                .ofPattern("yyyy==MM==dd HHmmss");\n\n        LocalDateTime dt1 = LocalDateTime.parse(str1, fomatter1);\n        System.out.println(dt1); //  2014-04-12T01:06:09\n\n        String str2 = "2014$$$$$$13 20";\n        DateTimeFormatter fomatter2 = DateTimeFormatter\n                .ofPattern("yyy$$$MMM$$$dd HH");\n        LocalDateTime dt2 = LocalDateTime.parse(str2, fomatter2);\n        System.out.println(dt2); //  2014-04-13T20:00\n\n\n\n DateTimeFormatter \n\nLocalDateTime rightNow=LocalDateTime.now();\nString date=DateTimeFormatter.ISO_LOCAL_DATE_TIME.format(rightNow);\nSystem.out.println(date);//2019-03-12T16:26:48.29\nDateTimeFormatter formatter=DateTimeFormatter.ofPattern("YYYY-MM-dd HH:mm:ss");\nSystem.out.println(formatter.format(rightNow));//2019-03-12 16:26:48\n\n\n issue#1157 YYYY  yyyy\n\n\n\nLocalDateTime rightNow = LocalDateTime.of(2020, 12, 31, 12, 0, 0);\nString date= DateTimeFormatter.ISO_LOCAL_DATE_TIME.format(rightNow);\n// 2020-12-31T12:00:00\nSystem.out.println(date);\nDateTimeFormatter formatterOfYYYY = DateTimeFormatter.ofPattern("YYYY-MM-dd HH:mm:ss");\n// 2021-12-31 12:00:00\nSystem.out.println(formatterOfYYYY.format(rightNow));\n\nDateTimeFormatter formatterOfYyyy = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");\n// 2020-12-31 12:00:00\nSystem.out.println(formatterOfYyyy.format(rightNow));\n\n\n IDEA  yyyy  YYYY \n\n\n\n\n# LocalDateTime()\n\nLocalDateTime LocalDateTime  LocalTime  LocalDate LocalDateTime \n\nLocalDateTime sylvester = LocalDateTime.of(2014, Month.DECEMBER, 31, 23, 59, 59);\n\nDayOfWeek dayOfWeek = sylvester.getDayOfWeek();\nSystem.out.println(dayOfWeek);      // WEDNESDAY\n\nMonth month = sylvester.getMonth();\nSystem.out.println(month);          // DECEMBER\n\nlong minuteOfDay = sylvester.getLong(ChronoField.MINUTE_OF_DAY);\nSystem.out.println(minuteOfDay);    // 1439\n\n\n Instant Instant java.util.Date\n\nInstant instant = sylvester\n        .atZone(ZoneId.systemDefault())\n        .toInstant();\n\nDate legacyDate = Date.from(instant);\nSystem.out.println(legacyDate);     // Wed Dec 31 23:59:59 CET 2014\n\n\n LocalDateTime \n\nDateTimeFormatter formatter =\n    DateTimeFormatter\n        .ofPattern("MMM dd, yyyy - HH:mm");\nLocalDateTime parsed = LocalDateTime.parse("Nov 03, 2014 - 07:13", formatter);\nString string = formatter.format(parsed);\nSystem.out.println(string);     // Nov 03, 2014 - 07:13\n\n\n java.text.NumberFormat  DateTimeFormatter  \n\n\n# Annotations()\n\n Java 8   Hints  Hint \n\n@Retention(RetentionPolicy.RUNTIME)\n@interface Hints {\n    Hint[] value();\n}\n@Repeatable(Hints.class)\n@interface Hint {\n    String value();\n}\n\n\nJava 8 @Repeatable\n\n 1: \n\n@Hints({@Hint("hint1"), @Hint("hint2")})\nclass Person {}\n\n\n 2\n\n@Hint("hint1")\n@Hint("hint2")\nclass Person {}\n\n\n java @Hints \n\nHint hint = Person.class.getAnnotation(Hint.class);\nSystem.out.println(hint);                   // null\nHints hints1 = Person.class.getAnnotation(Hints.class);\nSystem.out.println(hints1.value().length);  // 2\n\nHint[] hints2 = Person.class.getAnnotationsByType(Hint.class);\nSystem.out.println(hints2.length);          // 2\n\n\n Person @Hints getAnnotation(Hints.class) @Hints getAnnotationsByType @Hint  Java 8  target \n\n@Target({ElementType.TYPE_PARAMETER, ElementType.TYPE_USE})\n@interface MyAnnotation {}\n\n\n\n# Where to go from here?\n\n Java 8 JDK 1.8 Arrays.parallelSort, StampedLockCompletableFuture',normalizedContent:'# java8 \n\n java 8  java 8  github  https://github.com/winterbe/java8-tutorial\n\n----------------------------------------\n\n java 8  lambda   api (functional interfaces)map  date api \n\n\n# (default methods for interfaces)\n\njava 8  default  \n\n\n\ninterface formula{\n\n    double calculate(int a);\n\n    default double sqrt(int a) {\n        return math.sqrt(a);\n    }\n\n}\n\n\nformula  sqrt  calculate sqrt \n\npublic class main {\n\n  public static void main(string[] args) {\n    // \n    formula formula = new formula() {\n        @override\n        public double calculate(int a) {\n            return sqrt(a * 100);\n        }\n    };\n\n    system.out.println(formula.calculate(100));     // 100.0\n    system.out.println(formula.sqrt(16));           // 4.0\n\n  }\n\n}\n\n\nformula 6  sqrt(a * 100) java 8 \n\n \n\n\n# lambda (lambda expressions)\n\n java \n\nlist<string> names = arrays.aslist("peter", "anna", "mike", "xenia");\n\ncollections.sort(names, new comparator<string>() {\n    @override\n    public int compare(string a, string b) {\n        return b.compareto(a);\n    }\n});\n\n\ncollections.sort  list  sort \n\n java 8 java 8 lambda \n\ncollections.sort(names, (string a, string b) -> {\n    return b.compareto(a);\n});\n\n\n\n\ncollections.sort(names, (string a, string b) -> b.compareto(a));\n\n\n{} return \n\nnames.sort((a, b) -> b.compareto(a));\n\n\nlist  sort  java  lambda \n\n\n# (functional interfaces)\n\n \n\njava  lambda,()  lambda java.lang.runnable  java.util.concurrent.callable java 8 @functionalinterface,()@functionalinterface \n\n\n\n\n\n@functionalinterface\npublic interface converter<f, t> {\n  t convert(f from);\n}\n\n\n    // todo \n    converter<string, integer> converter = (from) -> integer.valueof(from);\n    integer converted = converter.convert("123");\n    system.out.println(converted.getclass()); //class java.lang.integer\n\n\n java8  java.util.function \n\n\n# (method and constructor references)\n\n\n\n    converter<string, integer> converter = integer::valueof;\n    integer converted = converter.convert("123");\n    system.out.println(converted.getclass());   //class java.lang.integer\n\n\njava 8 ::  \n\nclass something {\n    string startswith(string s) {\n        return string.valueof(s.charat(0));\n    }\n}\n\n\nsomething something = new something();\nconverter<string, string> converter = something::startswith;\nstring converted = converter.convert("java");\nsystem.out.println(converted);    // "j"\n\n\n::\n\nclass person {\n    string firstname;\n    string lastname;\n\n    person() {}\n\n    person(string firstname, string lastname) {\n        this.firstname = firstname;\n        this.lastname = lastname;\n    }\n}\n\n\n person \n\ninterface personfactory<p extends person> {\n    p create(string firstname, string lastname);\n}\n\n\n\n\npersonfactory<person> personfactory = person::new;\nperson person = personfactory.create("peter", "parker");\n\n\n person::new  person java personfactory.create\n\n\n# lambda (lambda scopes)\n\n\n# \n\n lambda \n\nfinal int num = 1;\nconverter<integer, string> stringconverter =\n        (from) -> string.valueof(from + num);\n\nstringconverter.convert(2);     // 3\n\n\n num  final\n\nint num = 1;\nconverter<integer, string> stringconverter =\n        (from) -> string.valueof(from + num);\n\nstringconverter.convert(2);     // 3\n\n\n num  final \n\nint num = 1;\nconverter<integer, string> stringconverter =\n        (from) -> string.valueof(from + num);\nnum = 3;//lambdanum\n\n\n\n# \n\n lambda  \n\nclass lambda4 {\n    static int outerstaticnum;\n    int outernum;\n\n    void testscopes() {\n        converter<integer, string> stringconverter1 = (from) -> {\n            outernum = 23;\n            return string.valueof(from);\n        };\n\n        converter<integer, string> stringconverter2 = (from) -> {\n            outerstaticnum = 72;\n            return string.valueof(from);\n        };\n    }\n}\n\n\n\n# \n\n formula  formula sqrt formula   lambda \n\n lambda ,\n\nformula formula = (a) -> sqrt(a * 100);\n\n\n\n# (built-in functional interfaces)\n\njdk 1.8 api   java comparator runnable@functionalinterface lambda \n\n java 8 api  google guava  lambda \n\n\n# predicate\n\npredicate    predicate \n\n predicate \n\npackage java.util.function;\nimport java.util.objects;\n\n@functionalinterface\npublic interface predicate<t> {\n\n    // ,..\n    boolean test(t t);\n\n    //and"&&"true\n    default predicate<t> and(predicate<? super t> other) {\n        objects.requirenonnull(other);\n        return (t) -> test(t) && other.test(t);\n    }\n    // "!"\n    default predicate<t> negate() {\n        return (t) -> !test(t);\n    }\n    //or"||"true\n    default predicate<t> or(predicate<? super t> other) {\n        objects.requirenonnull(other);\n        return (t) -> test(t) || other.test(t);\n    }\n   // object,predicate.testtest(equal).\n    static <t> predicate<t> isequal(object targetref) {\n        return (null == targetref)\n                ? objects::isnull\n                : object -> targetref.equals(object);\n    }\n\n\n\n\npredicate<string> predicate = (s) -> s.length() > 0;\n\npredicate.test("foo");              // true\npredicate.negate().test("foo");     // false\n\npredicate<boolean> nonnull = objects::nonnull;\npredicate<boolean> isnull = objects::isnull;\n\npredicate<string> isempty = string::isempty;\npredicate<string> isnotempty = isempty.negate();\n\n\n\n# function\n\nfunction compose, andthen\n\n function \n\n\npackage java.util.function;\n\nimport java.util.objects;\n\n@functionalinterface\npublic interface function<t, r> {\n\n    //function\n    r apply(t t);\n    //functionfunctionfunction\n    default <v> function<v, r> compose(function<? super v, ? extends t> before) {\n        objects.requirenonnull(before);\n        return (v v) -> apply(before.apply(v));\n    }\n    //\n    default <v> function<t, v> andthen(function<? super r, ? extends v> after) {\n        objects.requirenonnull(after);\n        return (t t) -> after.apply(apply(t));\n    }\n\n    static <t> function<t, t> identity() {\n        return t -> t;\n    }\n}\n\n\nfunction<string, integer> tointeger = integer::valueof;\nfunction<string, string> backtostring = tointeger.andthen(string::valueof);\nbacktostring.apply("123");     // "123"\n\n\n\n# supplier\n\nsupplier   function supplier \n\nsupplier<person> personsupplier = person::new;\npersonsupplier.get();   // new person\n\n\n\n# consumer\n\nconsumer \n\nconsumer<person> greeter = (p) -> system.out.println("hello, " + p.firstname);\ngreeter.accept(new person("luke", "skywalker"));\n\n\n\n# comparator\n\ncomparator  java  java 8 \n\ncomparator<person> comparator = (p1, p2) -> p1.firstname.compareto(p2.firstname);\n\nperson p1 = new person("john", "doe");\nperson p2 = new person("alice", "wonderland");\n\ncomparator.compare(p1, p2);             // > 0\ncomparator.reversed().compare(p1, p2);  // < 0\n\n\n\n# optional\n\noptional  nullpointerexception  optional \n\noptional  null  null java 8  java 8  optional  null\n\n\n\n//of()nulloptional\noptional<string> optional = optional.of("bam");\n// ispresent()truefalse\noptional.ispresent();           // true\n//get()optionalnosuchelementexception\noptional.get();                 // "bam"\n//orelse()\noptional.orelse("fallback");    // "bam"\n//ifpresent()optionalconsumer\noptional.ifpresent((s) -> system.out.println(s.charat(0)));     // "b"\n\n\n[java8] optional\n\n\n# streams()\n\njava.util.stream stream  stream stream java.util.collection list  set map stream \n\n stream  list\n\nlist<string> stringlist = new arraylist<>();\nstringlist.add("ddd2");\nstringlist.add("aaa2");\nstringlist.add("bbb1");\nstringlist.add("aaa1");\nstringlist.add("bbb3");\nstringlist.add("ccc");\nstringlist.add("bbb2");\nstringlist.add("ddd1");\n\n\njava 8  collection.stream()  collection.parallelstream()  stream stream \n\n\n# filter()\n\n predicate  stream  foreachforeach foreach  foreach  stream \n\n        //  filter()\n        stringlist\n                .stream()\n                .filter((s) -> s.startswith("a"))\n                .foreach(system.out::println);//aaa2 aaa1\n\n\nforeach  lambda  lambda \n\n\n# sorted()\n\n  stream comparator \n\n        //  sort ()\n        stringlist\n                .stream()\n                .sorted()\n                .filter((s) -> s.startswith("a"))\n                .foreach(system.out::println);// aaa1 aaa2\n\n\n stream stringlist \n\n    system.out.println(stringlist);// ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1\n\n\n\n# map()\n\n map  function \n\n map map  stream  map \n\n        //  map \n        stringlist\n                .stream()\n                .map(string::touppercase)\n                .sorted((a, b) -> b.compareto(a))\n                .foreach(system.out::println);// "ddd2", "ddd1", "ccc", "bbb3", "bbb2", "bbb1", "aaa2", "aaa1"\n\n\n\n# match()\n\nstream  predicate  stream   boolean \n\n        //  match ()\n        boolean anystartswitha =\n                stringlist\n                        .stream()\n                        .anymatch((s) -> s.startswith("a"));\n        system.out.println(anystartswitha);      // true\n\n        boolean allstartswitha =\n                stringlist\n                        .stream()\n                        .allmatch((s) -> s.startswith("a"));\n\n        system.out.println(allstartswitha);      // false\n\n        boolean nonestartswithz =\n                stringlist\n                        .stream()\n                        .nonematch((s) -> s.startswith("z"));\n\n        system.out.println(nonestartswithz);      // true\n\n\n\n# count()\n\n  stream  long\n\n      // count ()\n        long startswithb =\n                stringlist\n                        .stream()\n                        .filter((s) -> s.startswith("b"))\n                        .count();\n        system.out.println(startswithb);    // 3\n\n\n\n# reduce()\n\n   stream  optional \n\n        // reduce ()\n        optional<string> reduced =\n                stringlist\n                        .stream()\n                        .sorted()\n                        .reduce((s1, s2) -> s1 + "#" + s2);\n\n        reduced.ifpresent(system.out::println);//aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2\n\n\n  stream binaryoperator stream  n  summinmaxaverage  reduce stream  sum integer sum = integers.reduce(0, (a, b) -> a+b); stream  optional\n\n// concat = "abcd"\nstring concat = stream.of("a", "b", "c", "d").reduce("", string::concat);\n// minvalue = -3.0\ndouble minvalue = stream.of(-1.5, 1.0, -3.0, -2.0).reduce(double.max_value, double::min);\n// sumvalue = 10, \nint sumvalue = stream.of(1, 2, 3, 4).reduce(0, integer::sum);\n// sumvalue = 10, \nsumvalue = stream.of(1, 2, 3, 4).reduce(integer::sum).get();\n// concat = "ace"\nconcat = stream.of("a", "b", "c", "d", "e", "f").\n filter(x -> x.compareto("z") > 0).\n reduce("", string::concat);\n\n\n reduce()string::concat binaryoperator reduce()  reduce() optionalibmjava 8  streams api \n\n\n# parallel streams()\n\n stream  stream  stream \n\n stream \n\n\n\nint max = 1000000;\nlist<string> values = new arraylist<>(max);\nfor (int i = 0; i < max; i++) {\n    uuid uuid = uuid.randomuuid();\n    values.add(uuid.tostring());\n}\n\n\n\n\n\n# sequential sort()\n\n//\nlong t0 = system.nanotime();\nlong count = values.stream().sorted().count();\nsystem.out.println(count);\n\nlong t1 = system.nanotime();\n\nlong millis = timeunit.nanoseconds.tomillis(t1 - t0);\nsystem.out.println(string.format("sequential sort took: %d ms", millis));\n\n\n1000000\nsequential sort took: 709 ms//\n\n\n\n# parallel sort()\n\n//\nlong t0 = system.nanotime();\n\nlong count = values.parallelstream().sorted().count();\nsystem.out.println(count);\n\nlong t1 = system.nanotime();\n\nlong millis = timeunit.nanoseconds.tomillis(t1 - t0);\nsystem.out.println(string.format("parallel sort took: %d ms", millis));\n\n\n\n1000000\nparallel sort took: 475 ms//\n\n\n 50%  stream() parallelstream()\n\n\n# maps\n\nmap  streams map map  stream() map.keyset().stream(),map.values().stream()map.entryset().stream()\n\n,maps \n\nmap<integer, string> map = new hashmap<>();\n\nfor (int i = 0; i < 10; i++) {\n    map.putifabsent(i, "val" + i);\n}\n\nmap.foreach((id, val) -> system.out.println(val));//val0 val1 val2 val3 val4 val5 val6 val7 val8 val9\n\n\nputifabsent  null ;foreach consumer  map \n\n map \n\nmap.computeifpresent(3, (num, val) -> val + num);\nmap.get(3);             // val33\n\nmap.computeifpresent(9, (num, val) -> null);\nmap.containskey(9);     // false\n\nmap.computeifabsent(23, num -> "val" + num);\nmap.containskey(23);    // true\n\nmap.computeifabsent(3, num -> "bam");\nmap.get(3);             // val33\n\n\n map \n\nmap.remove(3, "val3");\nmap.get(3);             // val33\nmap.remove(3, "val33");\nmap.get(3);             // null\n\n\n\n\nmap.getordefault(42, "not found");  // not found\n\n\n map \n\nmap.merge(9, "val9", (value, newvalue) -> value.concat(newvalue));\nmap.get(9);             // val9\nmap.merge(9, "concat", (value, newvalue) -> value.concat(newvalue));\nmap.get(9);             // val9concat\n\n\nmerge  map \n\n\n# date api( api)\n\njava 8  java.time  api date api  joda-time  api \n\n()\n\n * clock clock  system.currenttimemillis()  instant instant java.util.date \n\n *  api  zoneid  of  zoneidjava.time getavailablezoneids\n\n * jdk1.8  localdate  localdatetime  datetimeformatter  instant  datelocaldatetime  calendardatetimeformatter  simpledateformat\n\n\n# clock\n\nclock clock  system.currenttimemillis()  instant instant java.util.date \n\nclock clock = clock.systemdefaultzone();\nlong millis = clock.millis();\nsystem.out.println(millis);//1552379579043\ninstant instant = clock.instant();\nsystem.out.println(instant);\ndate legacydate = date.from(instant); //2019-03-12t08:46:42.588z\nsystem.out.println(legacydate);//tue mar 12 16:32:59 cst 2019\n\n\n\n# timezones()\n\n api  zoneid  of  zoneidjava.time getavailablezoneids\n\n//\nsystem.out.println(zoneid.getavailablezoneids());\n\nzoneid zone1 = zoneid.of("europe/berlin");\nzoneid zone2 = zoneid.of("brazil/east");\nsystem.out.println(zone1.getrules());// zonerules[currentstandardoffset=+01:00]\nsystem.out.println(zone2.getrules());// zonerules[currentstandardoffset=-03:00]\n\n\n\n# localtime()\n\nlocaltime   10  17:30:15\n\nlocaltime now1 = localtime.now(zone1);\nlocaltime now2 = localtime.now(zone2);\nsystem.out.println(now1.isbefore(now2));  // false\n\nlong hoursbetween = chronounit.hours.between(now1, now2);\nlong minutesbetween = chronounit.minutes.between(now1, now2);\n\nsystem.out.println(hoursbetween);       // -3\nsystem.out.println(minutesbetween);     // -239\n\n\nlocaltime .\n\nlocaltime late = localtime.of(23, 59, 59);\nsystem.out.println(late);       // 23:59:59\ndatetimeformatter germanformatter =\n    datetimeformatter\n        .oflocalizedtime(formatstyle.short)\n        .withlocale(locale.german);\n\nlocaltime leettime = localtime.parse("13:37", germanformatter);\nsystem.out.println(leettime);   // 13:37\n\n\n\n# localdate()\n\nlocaldate  2014-03-11 localtime  date //\n\nlocaldate today = localdate.now();//\nsystem.out.println(": "+today);//2019-03-12\nlocaldate tomorrow = today.plus(1, chronounit.days);\nsystem.out.println(": "+tomorrow);//2019-03-13\nlocaldate yesterday = tomorrow.minusdays(2);\nsystem.out.println(": "+yesterday);//2019-03-11\nlocaldate independenceday = localdate.of(2019, month.march, 12);\ndayofweek dayofweek = independenceday.getdayofweek();\nsystem.out.println(":"+dayofweek);//tuesday\n\n\n localdate  localtime , datetimeformatter \n\n    string str1 = "2014==04==12 010609";\n        // \n        datetimeformatter fomatter1 = datetimeformatter\n                .ofpattern("yyyy==mm==dd hhmmss");\n\n        localdatetime dt1 = localdatetime.parse(str1, fomatter1);\n        system.out.println(dt1); //  2014-04-12t01:06:09\n\n        string str2 = "2014$$$$$$13 20";\n        datetimeformatter fomatter2 = datetimeformatter\n                .ofpattern("yyy$$$mmm$$$dd hh");\n        localdatetime dt2 = localdatetime.parse(str2, fomatter2);\n        system.out.println(dt2); //  2014-04-13t20:00\n\n\n\n datetimeformatter \n\nlocaldatetime rightnow=localdatetime.now();\nstring date=datetimeformatter.iso_local_date_time.format(rightnow);\nsystem.out.println(date);//2019-03-12t16:26:48.29\ndatetimeformatter formatter=datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss");\nsystem.out.println(formatter.format(rightnow));//2019-03-12 16:26:48\n\n\n issue#1157 yyyy  yyyy\n\n\n\nlocaldatetime rightnow = localdatetime.of(2020, 12, 31, 12, 0, 0);\nstring date= datetimeformatter.iso_local_date_time.format(rightnow);\n// 2020-12-31t12:00:00\nsystem.out.println(date);\ndatetimeformatter formatterofyyyy = datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss");\n// 2021-12-31 12:00:00\nsystem.out.println(formatterofyyyy.format(rightnow));\n\ndatetimeformatter formatterofyyyy = datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss");\n// 2020-12-31 12:00:00\nsystem.out.println(formatterofyyyy.format(rightnow));\n\n\n idea  yyyy  yyyy \n\n\n\n\n# localdatetime()\n\nlocaldatetime localdatetime  localtime  localdate localdatetime \n\nlocaldatetime sylvester = localdatetime.of(2014, month.december, 31, 23, 59, 59);\n\ndayofweek dayofweek = sylvester.getdayofweek();\nsystem.out.println(dayofweek);      // wednesday\n\nmonth month = sylvester.getmonth();\nsystem.out.println(month);          // december\n\nlong minuteofday = sylvester.getlong(chronofield.minute_of_day);\nsystem.out.println(minuteofday);    // 1439\n\n\n instant instant java.util.date\n\ninstant instant = sylvester\n        .atzone(zoneid.systemdefault())\n        .toinstant();\n\ndate legacydate = date.from(instant);\nsystem.out.println(legacydate);     // wed dec 31 23:59:59 cet 2014\n\n\n localdatetime \n\ndatetimeformatter formatter =\n    datetimeformatter\n        .ofpattern("mmm dd, yyyy - hh:mm");\nlocaldatetime parsed = localdatetime.parse("nov 03, 2014 - 07:13", formatter);\nstring string = formatter.format(parsed);\nsystem.out.println(string);     // nov 03, 2014 - 07:13\n\n\n java.text.numberformat  datetimeformatter  \n\n\n# annotations()\n\n java 8   hints  hint \n\n@retention(retentionpolicy.runtime)\n@interface hints {\n    hint[] value();\n}\n@repeatable(hints.class)\n@interface hint {\n    string value();\n}\n\n\njava 8 @repeatable\n\n 1: \n\n@hints({@hint("hint1"), @hint("hint2")})\nclass person {}\n\n\n 2\n\n@hint("hint1")\n@hint("hint2")\nclass person {}\n\n\n java @hints \n\nhint hint = person.class.getannotation(hint.class);\nsystem.out.println(hint);                   // null\nhints hints1 = person.class.getannotation(hints.class);\nsystem.out.println(hints1.value().length);  // 2\n\nhint[] hints2 = person.class.getannotationsbytype(hint.class);\nsystem.out.println(hints2.length);          // 2\n\n\n person @hints getannotation(hints.class) @hints getannotationsbytype @hint  java 8  target \n\n@target({elementtype.type_parameter, elementtype.type_use})\n@interface myannotation {}\n\n\n\n# where to go from here?\n\n java 8 jdk 1.8 arrays.parallelsort, stampedlockcompletablefuture',charsets:{cjk:!0}},{title:"Java 9 ",frontmatter:{title:"Java 9 ",category:"Java",tag:["Java"],date:"2024-08-21T23:05:56.000Z",permalink:"/pages/1091ad/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/03.java9.html",relativePath:"01.Java/05./03.java9.md",key:"v-2dd572b2",path:"/pages/1091ad/",headers:[{level:2,title:"JShell",slug:"jshell",normalizedTitle:"jshell",charIndex:360},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:288},{level:2,title:"G1 ",slug:"g1-",normalizedTitle:"g1 ",charIndex:305},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:1863},{level:2,title:"String ",slug:"string-",normalizedTitle:"string ",charIndex:2125},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:2406},{level:2,title:"try-with-resources ",slug:"try-with-resources-",normalizedTitle:"try-with-resources ",charIndex:2545},{level:2,title:"Stream & Optional ",slug:"stream-optional-",normalizedTitle:"stream &amp; optional ",charIndex:null},{level:2,title:" API",slug:"-api",normalizedTitle:" api",charIndex:5104},{level:2,title:"  Reactive Streams ",slug:"-reactive-streams",normalizedTitle:"  reactive streams ",charIndex:5393},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:330},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:6024},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:1544}],headersStr:"JShell  G1   String   try-with-resources  Stream & Optional   API   Reactive Streams    ",content:'Java 9  2017  9  21   Java 8  3 Java 9  Java Stream \n\n Archived OpenJDK General-Availability Releases  JDK https://openjdk.java.net/projects/jdk/ \n\n\n\n * JEP 222: Java \n * JEP 261: \n * JEP 248G1 \n * JEP 193: \n * JEP 254\n\n\n# JShell\n\nJShell  Java 9  Java  Python \n\n JShell \n\n\n\nJShell \n\n 1.  Java "Hello World"\n 2.  IDE  IDEIDE \n 3. \n\nJShell \n\n 1. JShell \n 2. JShell \n 3. JShell  1 + 1\n 4. \n\n\n# \n\nJigsaw Project Java \n\n \n\n> A uniquely named, reusable group of related packages, as well as resources (such as images and XML files) and a module descriptor\n\nmodule-info.java\n\n jar module-info.java\n\n\n\nJDK  94 Java  jlink  (Jlink  Java 9  Java  JRE) JDK  Java \n\n exports \n\nmodule my.module {\n    //exports \n    exports com.my.package.name;\n}\n\nmodule my.module {\n     //exportsto \n    export com.my.package.name to com.specific.package;\n}\n\n\n Java 9 \n\n * Project Jigsaw: Module System Quick-Start Guide\n * Java 9 Modules: part 1\n * Java 9 2. \n\n\n# G1 \n\n Java 8  Parallel Scavenge+Parallel Old Java 9, CMS G1Garbage-First Garbage Collector \n\nG1  Java 7 \n\n\n# \n\nList.of()Set.of()Map.of()  Map.ofEntries() Guava \n\nList.of("Java", "C++");\nSet.of("Java", "C++");\nMap.of("Java", 1, "C++", 2);\n\n\n of()   java.lang.UnsupportedOperationException \n\n\n# String \n\nJava 8 String  char[]  Java 9 String  byte[] \n\npublic final class String implements java.io.Serializable,Comparable<String>, CharSequence {\n    // @Stable \n    @Stable\n    private final byte[] value;\n}\n\n\n\n# \n\nJava 9 \n\npublic interface MyInterface {\n    private void methodPrivate(){\n    }\n}\n\n\n\n# try-with-resources \n\n Java 9  try-with-resources \n\ntry (Scanner scanner = new Scanner(new File("testRead.txt"));\n    PrintWriter writer = new PrintWriter(new File("testWrite.txt"))) {\n    // omitted\n}\n\n\n Java 9  try-with-resources  effectively-final \n\nfinal Scanner scanner = new Scanner(new File("testRead.txt"));\nPrintWriter writer = new PrintWriter(new File("testWrite.txt"))\ntry (scanner;writer) {\n    // omitted\n}\n\n\n effectively-final   final \n\n writer  final effectively-final \n\n\n# Stream & Optional \n\nStream  ofNullable()dropWhile()takeWhile()  iterate() \n\nJava 9  ofNullable()   Stream Stream  Java 8  Stream \n\nStream<String> stringStream = Stream.ofNullable("Java");\nSystem.out.println(stringStream.count());// 1\nStream<String> nullStream = Stream.ofNullable(null);\nSystem.out.println(nullStream.count());//0\n\n\ntakeWhile()  Stream \n\nList<Integer> integerList = List.of(11, 33, 66, 8, 9, 13);\nintegerList.stream().takeWhile(x -> x < 50).forEach(System.out::println);// 11 33\n\n\ndropWhile()  takeWhile() \n\nList<Integer> integerList2 = List.of(11, 33, 66, 8, 9, 13);\nintegerList2.stream().dropWhile(x -> x < 50).forEach(System.out::println);// 66 8 9 13\n\n\niterate()  Predicate  ()\n\npublic static<T> Stream<T> iterate(final T seed, final UnaryOperator<T> f) {\n}\n// \npublic static<T> Stream<T> iterate(T seed, Predicate<? super T> hasNext, UnaryOperator<T> next) {\n\n}\n\n\n iterate() \n\n//  iterate()  1~10\nStream.iterate(1, i -> i + 1).limit(10).forEach(System.out::println);\n//  iterate()  1~10\nStream.iterate(1, i -> i <= 10, i -> i + 1).forEach(System.out::println);\n\n\nOptional  ifPresentOrElse()or()  stream() \n\nifPresentOrElse()  Consumer  Runnable  Optional  Consumer  Runnable \n\npublic void ifPresentOrElse(Consumer<? super T> action, Runnable emptyAction)\n\nOptional<Object> objectOptional = Optional.empty();\nobjectOptional.ifPresentOrElse(System.out::println, () -> System.out.println("Empty!!!"));// Empty!!!\n\n\nor()  Supplier   Optional  Supplier  Optional \n\npublic Optional<T> or(Supplier<? extends Optional<? extends T>> supplier)\n\nOptional<Object> objectOptional = Optional.empty();\nobjectOptional.or(() -> Optional.of("java")).ifPresent(System.out::println);//java\n\n\n\n#  API\n\nJava 9  java.lang.ProcessHandle \n\n//  JVM \nProcessHandle currentProcess = ProcessHandle.current();\n//  id\nSystem.out.println(currentProcess.pid());\n// \nSystem.out.println(currentProcess.info());\n\n\nProcessHandle \n\n\n\n\n#   Reactive Streams \n\n Java 9  java.util.concurrent.Flow  \n\nFlow  Flow.PublisherFlow.SubscriberFlow.Subscription  Flow.Processor  4 Java 9 SubmissionPublisher Flow.Publisher \n\n Java 9  Java 9 17. Reactive Streams -  \n\n\n# \n\n\n\n MethodHandle  Java  java.lang.invoke.VarHandle  java.lang.invoke.MethodHandles.Lookup  VarHandle \n\nVarHandle  java.util.concurrent.atomic  sun.misc.Unsafe  API\n\n\n# \n\n *  API Java 9  JDK  System.LoggerFinder  JDK  JVM  LoggerFinder  System.LoggerFinder  JDK  SLF4J \n * CompletableFuturecompleteAsync orTimeout \n * Nashorn Nashorn  Java8  JavaScript Java9  Nashorn  ES6 Java 11 \n * I/O  InputStream \n * Java 9  4  SHA- 3 SHA3-224SHA3-256SHA3-384  SHA3-512\n * Method Handle Java7 Java9 java.lang.invoke.MethodHandles \n * \n\n\n# \n\n * Java version historyhttps://en.wikipedia.org/wiki/Java_version_history\n * Release Notes for JDK 9 and JDK 9 Update Releases : https://www.oracle.com/java/technologies/javase/9-all-relnotes.html\n *  Java - - JShell\n * New Features in Java 9: https://www.baeldung.com/new-java-9\n * Java  Try with Resourceshttps://www.baeldung.com/java-try-with-resources',normalizedContent:'java 9  2017  9  21   java 8  3 java 9  java stream \n\n archived openjdk general-availability releases  jdk https://openjdk.java.net/projects/jdk/ \n\n\n\n * jep 222: java \n * jep 261: \n * jep 248g1 \n * jep 193: \n * jep 254\n\n\n# jshell\n\njshell  java 9  java  python \n\n jshell \n\n\n\njshell \n\n 1.  java "hello world"\n 2.  ide  ideide \n 3. \n\njshell \n\n 1. jshell \n 2. jshell \n 3. jshell  1 + 1\n 4. \n\n\n# \n\njigsaw project java \n\n \n\n> a uniquely named, reusable group of related packages, as well as resources (such as images and xml files) and a module descriptor\n\nmodule-info.java\n\n jar module-info.java\n\n\n\njdk  94 java  jlink  (jlink  java 9  java  jre) jdk  java \n\n exports \n\nmodule my.module {\n    //exports \n    exports com.my.package.name;\n}\n\nmodule my.module {\n     //exportsto \n    export com.my.package.name to com.specific.package;\n}\n\n\n java 9 \n\n * project jigsaw: module system quick-start guide\n * java 9 modules: part 1\n * java 9 2. \n\n\n# g1 \n\n java 8  parallel scavenge+parallel old java 9, cms g1garbage-first garbage collector \n\ng1  java 7 \n\n\n# \n\nlist.of()set.of()map.of()  map.ofentries() guava \n\nlist.of("java", "c++");\nset.of("java", "c++");\nmap.of("java", 1, "c++", 2);\n\n\n of()   java.lang.unsupportedoperationexception \n\n\n# string \n\njava 8 string  char[]  java 9 string  byte[] \n\npublic final class string implements java.io.serializable,comparable<string>, charsequence {\n    // @stable \n    @stable\n    private final byte[] value;\n}\n\n\n\n# \n\njava 9 \n\npublic interface myinterface {\n    private void methodprivate(){\n    }\n}\n\n\n\n# try-with-resources \n\n java 9  try-with-resources \n\ntry (scanner scanner = new scanner(new file("testread.txt"));\n    printwriter writer = new printwriter(new file("testwrite.txt"))) {\n    // omitted\n}\n\n\n java 9  try-with-resources  effectively-final \n\nfinal scanner scanner = new scanner(new file("testread.txt"));\nprintwriter writer = new printwriter(new file("testwrite.txt"))\ntry (scanner;writer) {\n    // omitted\n}\n\n\n effectively-final   final \n\n writer  final effectively-final \n\n\n# stream & optional \n\nstream  ofnullable()dropwhile()takewhile()  iterate() \n\njava 9  ofnullable()   stream stream  java 8  stream \n\nstream<string> stringstream = stream.ofnullable("java");\nsystem.out.println(stringstream.count());// 1\nstream<string> nullstream = stream.ofnullable(null);\nsystem.out.println(nullstream.count());//0\n\n\ntakewhile()  stream \n\nlist<integer> integerlist = list.of(11, 33, 66, 8, 9, 13);\nintegerlist.stream().takewhile(x -> x < 50).foreach(system.out::println);// 11 33\n\n\ndropwhile()  takewhile() \n\nlist<integer> integerlist2 = list.of(11, 33, 66, 8, 9, 13);\nintegerlist2.stream().dropwhile(x -> x < 50).foreach(system.out::println);// 66 8 9 13\n\n\niterate()  predicate  ()\n\npublic static<t> stream<t> iterate(final t seed, final unaryoperator<t> f) {\n}\n// \npublic static<t> stream<t> iterate(t seed, predicate<? super t> hasnext, unaryoperator<t> next) {\n\n}\n\n\n iterate() \n\n//  iterate()  1~10\nstream.iterate(1, i -> i + 1).limit(10).foreach(system.out::println);\n//  iterate()  1~10\nstream.iterate(1, i -> i <= 10, i -> i + 1).foreach(system.out::println);\n\n\noptional  ifpresentorelse()or()  stream() \n\nifpresentorelse()  consumer  runnable  optional  consumer  runnable \n\npublic void ifpresentorelse(consumer<? super t> action, runnable emptyaction)\n\noptional<object> objectoptional = optional.empty();\nobjectoptional.ifpresentorelse(system.out::println, () -> system.out.println("empty!!!"));// empty!!!\n\n\nor()  supplier   optional  supplier  optional \n\npublic optional<t> or(supplier<? extends optional<? extends t>> supplier)\n\noptional<object> objectoptional = optional.empty();\nobjectoptional.or(() -> optional.of("java")).ifpresent(system.out::println);//java\n\n\n\n#  api\n\njava 9  java.lang.processhandle \n\n//  jvm \nprocesshandle currentprocess = processhandle.current();\n//  id\nsystem.out.println(currentprocess.pid());\n// \nsystem.out.println(currentprocess.info());\n\n\nprocesshandle \n\n\n\n\n#   reactive streams \n\n java 9  java.util.concurrent.flow  \n\nflow  flow.publisherflow.subscriberflow.subscription  flow.processor  4 java 9 submissionpublisher flow.publisher \n\n java 9  java 9 17. reactive streams -  \n\n\n# \n\n\n\n methodhandle  java  java.lang.invoke.varhandle  java.lang.invoke.methodhandles.lookup  varhandle \n\nvarhandle  java.util.concurrent.atomic  sun.misc.unsafe  api\n\n\n# \n\n *  api java 9  jdk  system.loggerfinder  jdk  jvm  loggerfinder  system.loggerfinder  jdk  slf4j \n * completablefuturecompleteasync ortimeout \n * nashorn nashorn  java8  javascript java9  nashorn  es6 java 11 \n * i/o  inputstream \n * java 9  4  sha- 3 sha3-224sha3-256sha3-384  sha3-512\n * method handle java7 java9 java.lang.invoke.methodhandles \n * \n\n\n# \n\n * java version historyhttps://en.wikipedia.org/wiki/java_version_history\n * release notes for jdk 9 and jdk 9 update releases : https://www.oracle.com/java/technologies/javase/9-all-relnotes.html\n *  java - - jshell\n * new features in java 9: https://www.baeldung.com/new-java-9\n * java  try with resourceshttps://www.baeldung.com/java-try-with-resources',charsets:{cjk:!0}},{title:"Java 10 ",frontmatter:{title:"Java 10 ",category:"Java",tag:["Java"],date:"2024-08-21T23:04:46.000Z",permalink:"/pages/e43406/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/04.java10.html",relativePath:"01.Java/05./04.java10.md",key:"v-31d26f3c",path:"/pages/e43406/",headers:[{level:2,title:"(var)",slug:"-var",normalizedTitle:"(var)",charIndex:242},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:140},{level:2,title:"G1  Full GC",slug:"g1--full-gc",normalizedTitle:"g1  full gc",charIndex:159},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:1326},{level:2,title:"Optional ",slug:"optional-",normalizedTitle:"optional ",charIndex:1804},{level:2,title:"( CDS )",slug:"--cds-",normalizedTitle:"( cds )",charIndex:184},{level:2,title:" Java  JIT ",slug:"-java--jit-",normalizedTitle:" java  jit ",charIndex:216},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:60},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:3012}],headersStr:"(var)  G1  Full GC  Optional  ( CDS )  Java  JIT   ",content:'Java 10  2018  3  20  var GC \n\n\n\n * JEP 286\n * JEP 304\n * JEP 307G1  Full GC\n * JEP 310( CDS )\n * JEP 317 Java  JIT \n\n\n# (var)\n\n Java  Java  Java 10 \n\nJava 10  var \n\nvar id = 0;\nvar codefx = new URL("https://mp.weixin.qq.com/");\nvar list = new ArrayList<>();\nvar list = List.of(1, 2, 3);\nvar map = new HashMap<String, String>();\nvar p = Paths.of("src/test/java/Java9FeaturesTest.java");\nvar numbers = List.of("a", "b", "c");\nfor (var n : list)\n    System.out.print(n+ " ");\n\n\nvar  for \n\nvar count=null; // null\nvar r = () -> Math.random();//, Lambda\nvar array = {1,2,3};//,\n\n\nvar  Java \n\nScala  Kotlin  val  ( final var )\n\nJava 10 \n\n\n# \n\n JDK  (GC)  Java 10 \n\n\n# G1  Full GC\n\n Java9  G1 G1  Full GC, Java9  G1  FullGC , Full GC\n\n Full GC  Java10 G1  FullGC  Full GC \n\n\n# \n\nListSetMap copyOf()\n\nstatic <E> List<E> copyOf(Collection<? extends E> coll) {\n    return ImmutableCollections.listCopy(coll);\n}\n\n\n copyOf()   java.lang.UnsupportedOperationException  IDEA \n\n\n\njava.util.stream.Collectors \n\nvar list = new ArrayList<>();\nlist.stream().collect(Collectors.toUnmodifiableList());\nlist.stream().collect(Collectors.toUnmodifiableSet());\n\n\n\n# Optional \n\nOptional orElseThrow()\n\nOptional.ofNullable(cache.getIfPresent(key))\n        .orElseThrow(() -> new PrestoException(NOT_FOUND, "Missing entry found for key: " + key));\n\n\n\n# ( CDS )\n\n Java 5  (Class Data Sharing CDS) Java  Java JVMCDS  Oracle JDK \n\nJava 10  CDS CDS  bootstrap  CDS  (Application Class-Data SharingAppCDS)  CDS \n\n\n#  Java  JIT \n\nGraal  Java  JIT  JDK 9  Ahead-of-Time (AOT) \n\nOracle  HotSpot VM  C++  JIT compilerC1  C2 Java 10 (Linux/x64, macOS/x64)  HotSpot  C2 java  -XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler  C2  Graal\n\n Java 10  JIT  Graal - \n\n\n# \n\n * -Java 10  JVM  JVM  JVM \n * Java 10  JVM \n * \n\n\n# \n\n * Java 10 Features and Enhancements : https://howtodoinjava.com/java10/java10-features/\n\n * Guide to Java10 : https://www.baeldung.com/java-10-overview\n\n * 4 Class Data Sharing : https://docs.oracle.com/javase/10/vm/class-data-sharing.htm#JSJVM-GUID-7EAA3411-8CF0-4D19-BD05-DF5E1780AA91',normalizedContent:'java 10  2018  3  20  var gc \n\n\n\n * jep 286\n * jep 304\n * jep 307g1  full gc\n * jep 310( cds )\n * jep 317 java  jit \n\n\n# (var)\n\n java  java  java 10 \n\njava 10  var \n\nvar id = 0;\nvar codefx = new url("https://mp.weixin.qq.com/");\nvar list = new arraylist<>();\nvar list = list.of(1, 2, 3);\nvar map = new hashmap<string, string>();\nvar p = paths.of("src/test/java/java9featurestest.java");\nvar numbers = list.of("a", "b", "c");\nfor (var n : list)\n    system.out.print(n+ " ");\n\n\nvar  for \n\nvar count=null; // null\nvar r = () -> math.random();//, lambda\nvar array = {1,2,3};//,\n\n\nvar  java \n\nscala  kotlin  val  ( final var )\n\njava 10 \n\n\n# \n\n jdk  (gc)  java 10 \n\n\n# g1  full gc\n\n java9  g1 g1  full gc, java9  g1  fullgc , full gc\n\n full gc  java10 g1  fullgc  full gc \n\n\n# \n\nlistsetmap copyof()\n\nstatic <e> list<e> copyof(collection<? extends e> coll) {\n    return immutablecollections.listcopy(coll);\n}\n\n\n copyof()   java.lang.unsupportedoperationexception  idea \n\n\n\njava.util.stream.collectors \n\nvar list = new arraylist<>();\nlist.stream().collect(collectors.tounmodifiablelist());\nlist.stream().collect(collectors.tounmodifiableset());\n\n\n\n# optional \n\noptional orelsethrow()\n\noptional.ofnullable(cache.getifpresent(key))\n        .orelsethrow(() -> new prestoexception(not_found, "missing entry found for key: " + key));\n\n\n\n# ( cds )\n\n java 5  (class data sharing cds) java  java jvmcds  oracle jdk \n\njava 10  cds cds  bootstrap  cds  (application class-data sharingappcds)  cds \n\n\n#  java  jit \n\ngraal  java  jit  jdk 9  ahead-of-time (aot) \n\noracle  hotspot vm  c++  jit compilerc1  c2 java 10 (linux/x64, macos/x64)  hotspot  c2 java  -xx:+unlockexperimentalvmoptions -xx:+usejvmcicompiler  c2  graal\n\n java 10  jit  graal - \n\n\n# \n\n * -java 10  jvm  jvm  jvm \n * java 10  jvm \n * \n\n\n# \n\n * java 10 features and enhancements : https://howtodoinjava.com/java10/java10-features/\n\n * guide to java10 : https://www.baeldung.com/java-10-overview\n\n * 4 class data sharing : https://docs.oracle.com/javase/10/vm/class-data-sharing.htm#jsjvm-guid-7eaa3411-8cf0-4d19-bd05-df5e1780aa91',charsets:{cjk:!0}},{title:"Java 11 ",frontmatter:{title:"Java 11 ",category:"Java",tag:["Java"],date:"2024-08-21T23:04:53.000Z",permalink:"/pages/f37c60/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/05.java11.html",relativePath:"01.Java/05./05.java11.md",key:"v-4ad5cd7c",path:"/pages/f37c60/",headers:[{level:2,title:"HTTP Client ",slug:"http-client-",normalizedTitle:"http client ",charIndex:277},{level:2,title:"String ",slug:"string-",normalizedTitle:"string ",charIndex:1060},{level:2,title:"Optional ",slug:"optional-",normalizedTitle:"optional ",charIndex:1434},{level:2,title:"ZGC()",slug:"zgc-",normalizedTitle:"zgc()",charIndex:304},{level:2,title:"Lambda ",slug:"lambda-",normalizedTitle:"lambda ",charIndex:332},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:360},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:2573},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:3016}],headersStr:"HTTP Client  String  Optional  ZGC() Lambda    ",content:'Java 11  2018  9  25 Java 11  2017  9  Java 9  2018  3  Java 10 (Long-Term-Support)Oracle  Java 11  2026  9  Java 8 \n\n Oracle  Oracle JDK \n\n\n\n\n\n * JEP 321HTTP Client \n * JEP 333ZGC()\n * JEP 323Lambda \n * JEP 330\n\n\n# HTTP Client \n\nJava 11  Java 9  Java 10  Http Client API Http Client \n\nJava 11 Http Client  jdk.incubator.http java.net.http API  CompleteableFuture \n\nvar request = HttpRequest.newBuilder()\n    .uri(URI.create("https://javastack.cn"))\n    .GET()\n    .build();\nvar client = HttpClient.newHttpClient();\n\n// \nHttpResponse<String> response = client.send(request, HttpResponse.BodyHandlers.ofString());\nSystem.out.println(response.body());\n\n// \nclient.sendAsync(request, HttpResponse.BodyHandlers.ofString())\n    .thenApply(HttpResponse::body)\n    .thenAccept(System.out::println);\n\n\n\n# String \n\nJava 11 \n\n//\n" ".isBlank();//true\n//\n" Java ".strip();// "Java"\n//\n" Java ".stripLeading();   // "Java "\n//\n" Java ".stripTrailing();  // " Java"\n//\n"Java".repeat(3);             // "JavaJavaJava"\n//\n"A\\nB\\nC".lines().count();    // 3\n"A\\nB\\nC".lines().collect(Collectors.toList());\n\n\n\n# Optional \n\nisEmpty() Optional \n\nvar op = Optional.empty();\nSystem.out.println(op.isEmpty());// Optional \n\n\n\n# ZGC()\n\nZGC  Z Garbage Collector\n\nZGC \n\n * GC  10ms\n *  MB  TB \n *  15% G1 \n *  GC  colored  Load barriers \n *  Linux/x64 \n\nZGC   Linux/x64 \n\n CMS  ParNew  G1 ZGC - ZGC \n\n ZGC  Stop The World \n\n ZGC \n\n\n# Lambda \n\n Java 10  var \n\nJava 10  var \n\n * \n * \n * \n *  Lambda \n\nJava11  Lambda  var \n\n// \nConsumer<String> consumer = (var i) -> System.out.println(i);\nConsumer<String> consumer = (String i) -> System.out.println(i);\n\n\n\n# \n\n Java  Java  Java  .class  Java \n\n Java  jshell  Java \n\n\n# \n\n *  Epsilon GC \n *  Heap ProfilingJava 11  Java  Java  JVMTI \n * TLS1.3 Java 11 TLS1.3 RFC 8446 TLS TLS 1.2 TLS  OCSP RFC 6066RFC 6961RFC 7627\n * (Java Flight Recorder) JDK  Java 11 \n * \n\n\n# \n\n * JDK 11 Release Noteshttps://www.oracle.com/java/technologies/javase/11-relnote-issues.html\n * Java 11  Features and Comparisonhttps://www.geeksforgeeks.org/java-11-features-and-comparison/',normalizedContent:'java 11  2018  9  25 java 11  2017  9  java 9  2018  3  java 10 (long-term-support)oracle  java 11  2026  9  java 8 \n\n oracle  oracle jdk \n\n\n\n\n\n * jep 321http client \n * jep 333zgc()\n * jep 323lambda \n * jep 330\n\n\n# http client \n\njava 11  java 9  java 10  http client api http client \n\njava 11 http client  jdk.incubator.http java.net.http api  completeablefuture \n\nvar request = httprequest.newbuilder()\n    .uri(uri.create("https://javastack.cn"))\n    .get()\n    .build();\nvar client = httpclient.newhttpclient();\n\n// \nhttpresponse<string> response = client.send(request, httpresponse.bodyhandlers.ofstring());\nsystem.out.println(response.body());\n\n// \nclient.sendasync(request, httpresponse.bodyhandlers.ofstring())\n    .thenapply(httpresponse::body)\n    .thenaccept(system.out::println);\n\n\n\n# string \n\njava 11 \n\n//\n" ".isblank();//true\n//\n" java ".strip();// "java"\n//\n" java ".stripleading();   // "java "\n//\n" java ".striptrailing();  // " java"\n//\n"java".repeat(3);             // "javajavajava"\n//\n"a\\nb\\nc".lines().count();    // 3\n"a\\nb\\nc".lines().collect(collectors.tolist());\n\n\n\n# optional \n\nisempty() optional \n\nvar op = optional.empty();\nsystem.out.println(op.isempty());// optional \n\n\n\n# zgc()\n\nzgc  z garbage collector\n\nzgc \n\n * gc  10ms\n *  mb  tb \n *  15% g1 \n *  gc  colored  load barriers \n *  linux/x64 \n\nzgc   linux/x64 \n\n cms  parnew  g1 zgc - zgc \n\n zgc  stop the world \n\n zgc \n\n\n# lambda \n\n java 10  var \n\njava 10  var \n\n * \n * \n * \n *  lambda \n\njava11  lambda  var \n\n// \nconsumer<string> consumer = (var i) -> system.out.println(i);\nconsumer<string> consumer = (string i) -> system.out.println(i);\n\n\n\n# \n\n java  java  java  .class  java \n\n java  jshell  java \n\n\n# \n\n *  epsilon gc \n *  heap profilingjava 11  java  java  jvmti \n * tls1.3 java 11 tls1.3 rfc 8446 tls tls 1.2 tls  ocsp rfc 6066rfc 6961rfc 7627\n * (java flight recorder) jdk  java 11 \n * \n\n\n# \n\n * jdk 11 release noteshttps://www.oracle.com/java/technologies/javase/11-relnote-issues.html\n * java 11  features and comparisonhttps://www.geeksforgeeks.org/java-11-features-and-comparison/',charsets:{cjk:!0}},{title:"Java 12  & 13 ",frontmatter:{title:"Java 12  & 13 ",category:"Java",tag:["Java"],date:"2024-08-21T23:04:59.000Z",permalink:"/pages/79a5f6/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/06.java12-13.html",relativePath:"01.Java/05./06.java12-13.md",key:"v-676002b2",path:"/pages/79a5f6/",headers:[{level:2,title:"Java12",slug:"java12",normalizedTitle:"java12",charIndex:2},{level:3,title:"String ",slug:"string-",normalizedTitle:"string ",charIndex:13},{level:3,title:"Files ",slug:"files--",normalizedTitle:"files ",charIndex:363},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:1163},{level:3,title:"Shenandoah GC",slug:"shenandoah-gc",normalizedTitle:"shenandoah gc",charIndex:1377},{level:3,title:"G1 ",slug:"g1-",normalizedTitle:"g1 ",charIndex:1554},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:1785},{level:4,title:" Switch",slug:"-switch",normalizedTitle:" switch",charIndex:1845},{level:4,title:"instanceof ",slug:"instanceof-",normalizedTitle:"instanceof ",charIndex:2235},{level:2,title:"Java13",slug:"java13",normalizedTitle:"java13",charIndex:2544},{level:3,title:" ZGC()",slug:"-zgc-",normalizedTitle:" zgc()",charIndex:2555},{level:3,title:"SocketAPI ",slug:"socketapi-",normalizedTitle:"socketapi ",charIndex:2801},{level:3,title:"FileSystems",slug:"filesystems",normalizedTitle:"filesystems",charIndex:3124},{level:3,title:" CDS ",slug:"-cds-",normalizedTitle:" cds ",charIndex:3311},{level:3,title:"",slug:"-2",normalizedTitle:"",charIndex:1785},{level:4,title:"",slug:"",normalizedTitle:"",charIndex:3636},{level:4,title:" Switch( yield  Switch )",slug:"-switch--yield--switch-",normalizedTitle:" switch( yield  switch )",charIndex:4924},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:5410},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:5417},{level:3,title:"JVM ",slug:"jvm-",normalizedTitle:"jvm ",charIndex:6063},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:6247}],headersStr:"Java12 String  Files   Shenandoah GC G1    Switch instanceof  Java13  ZGC() SocketAPI  FileSystems  CDS     Switch( yield  Switch )   JVM  ",content:'# Java12\n\n\n# String \n\nJava 12 \n\nindent() \n\nString text = "Java";\n//  4 \ntext = text.indent(4);\nSystem.out.println(text);\ntext = text.indent(-10);\nSystem.out.println(text);\n\n\n\n\n     Java\nJava\n\n\ntransform() \n\nString result = "foo".transform(input -> input + " bar");\nSystem.out.println(result); // foo bar\n\n\n\n# Files \n\nJava 12 \n\npublic static long mismatch(Path path, Path path2) throws IOException\n\n\nmismatch()  -1L\n\n\n\nPath filePath1 = Files.createTempFile("file1", ".txt");\nPath filePath2 = Files.createTempFile("file2", ".txt");\nFiles.writeString(filePath1, "Java 12 Article");\nFiles.writeString(filePath2, "Java 12 Article");\n\nlong mismatch = Files.mismatch(filePath1, filePath2);\nassertEquals(-1, mismatch);\n\n\n\n\nPath filePath3 = Files.createTempFile("file3", ".txt");\nPath filePath4 = Files.createTempFile("file4", ".txt");\nFiles.writeString(filePath3, "Java 12 Article");\nFiles.writeString(filePath4, "Java 12 Tutorial");\n\nlong mismatch = Files.mismatch(filePath3, filePath4);\nassertEquals(8, mismatch);\n\n\n\n# \n\nNumberFormat \n\nNumberFormat fmt = NumberFormat.getCompactNumberInstance(Locale.US, NumberFormat.Style.SHORT);\nString result = fmt.format(1000);\nSystem.out.println(result);\n\n\n:\n\n1K\n\n\n\n# Shenandoah GC\n\nRedhat  Pauseless GC  99.9%  10ms\n\n Java11  ZGC  JDK11 Shenandoah GC  JDK8u  Java8 \n\n\n# G1 \n\nJava12  G1 :\n\n * JEP344 JEP 344  G1  G1 \n * JEP346  G1 GC Java \n\n\n# \n\njavacjava--enable-preview \n\n#  Switch\n\n switch  break  break \n\nJava12  switch  lambda  break \n\nswitch (day) {\n    case MONDAY, FRIDAY, SUNDAY -> System.out.println(6);\n    case TUESDAY                -> System.out.println(7);\n    case THURSDAY, SATURDAY     -> System.out.println(8);\n    case WEDNESDAY              -> System.out.println(9);\n}\n\n\n# instanceof \n\ninstanceof \n\n\n\nObject obj = "";\nif(obj instanceof String){\n   String str = (String) obj;\n  System.out.println(str);\n}\n\n\n instanceof \n\nObject obj = "";\nif(obj instanceof String str){\n  System.out.println(str);\n}\n\n\n\n# Java13\n\n\n#  ZGC()\n\n Java 11  ZGC \n\nZGC  ZPages  GC  ZPages  ZPageCache  ZPages LRU\n\n Java 13 ZGC \n\n\n# SocketAPI \n\nJava Socket API \n\nJava 13  Socket API  NioSocketImpl  PlainSocketImpl  java.util.concurrent  -Djdk.net.usePlainSocketImpl=true\n\n Java 13  Socket \n\npublic final class NioSocketImpl extends SocketImpl implements PlatformSocketImpl {\n}\n\n\n\n# FileSystems\n\nFileSystems \n\n * newFileSystem(Path)\n * newFileSystem(Path, Map<String, ?>)\n * newFileSystem(Path, Map<String, ?>, ClassLoader)\n\n\n#  CDS \n\nJava 13  Java 10 (AppCDS) Java  CDS \n\nAppCDS\n\njava -XX:ArchiveClassesAtExit=my_app_cds.jsa -cp my_app.jar\njava -XX:SharedArchiveFile=my_app_cds.jsa -cp my_app.jar\n\n\n\n# \n\n# \n\n Java \n\nJava 13  """ \n\n HTML \n\nString json ="{\\n" +\n              "   \\"name\\":\\"mkyong\\",\\n" +\n              "   \\"age\\":38\\n" +\n              "}\\n";\n\n\n HTML \n\n String json = """\n                {\n                    "name":"mkyong",\n                    "age":38\n                }\n                """;\n\n\n SQL \n\nString query = "SELECT `EMP_ID`, `LAST_NAME` FROM `EMPLOYEE_TB`\\n" +\n               "WHERE `CITY` = \'INDIANAPOLIS\'\\n" +\n               "ORDER BY `EMP_ID`, `LAST_NAME`;\\n";\n\n\n SQL \n\nString query = """\n               SELECT `EMP_ID`, `LAST_NAME` FROM `EMPLOYEE_TB`\n               WHERE `CITY` = \'INDIANAPOLIS\'\n               ORDER BY `EMP_ID`, `LAST_NAME`;\n               """;\n\n\nString  3 \n\n * formatted(Object... args) String format()\n * stripIndent()\n * translateEscapes() \\\\t  \\t\n\n\n\n@Deprecated(forRemoval=true, since="13")\npublic String stripIndent() {\n}\n@Deprecated(forRemoval=true, since="13")\npublic String formatted(Object... args) {\n\n}\n@Deprecated(forRemoval=true, since="13")\npublic String translateEscapes() {\n}\n\n\n#  Switch( yield  Switch )\n\nSwitch  Switch  yield\n\nyield return return  yield  Switch  yield  default \n\n private static String descLanguage(String name) {\n        return switch (name) {\n            case "Java": yield "object-oriented, platform independent and secured";\n            case "Ruby": yield "a programmer\'s best friend";\n            default: yield name +" is a good language";\n        };\n }\n\n\n\n# \n\n\n# \n\n oracle This is a preview feature, which is a feature whose design, specification, and implementation are complete, but is not permanent, which means that the feature may exist in a different form or not at all in future JDK releases. To compile and run code that contains preview features, you must specify additional command-line options.\n\n JDK  \n\nswitch Java12  Java13  Java14  JDK  JDK \n\n JDK \n\n\n# JVM \n\n Java  JVM \n\n\n\n Java JVM \n\n\n# \n\n * JDK Project Overviewhttps://openjdk.java.net/projects/jdk/\n * Oracle Java12 ReleaseNotehttps://www.oracle.com/java/technologies/javase/12all-relnotes.htm\n * What is new in Java 12https://mkyong.com/java/what-is-new-in-java-12/\n * Oracle Java13 ReleaseNote https://www.oracle.com/technetwork/java/javase/13all-relnotes-5461743.html#NewFeature\n * New Java13 Features https://www.baeldung.com/java-13-new-features\n * Java13  https://www.ibm.com/developerworks/cn/java/the-new-features-of-Java-13/index.html',normalizedContent:'# java12\n\n\n# string \n\njava 12 \n\nindent() \n\nstring text = "java";\n//  4 \ntext = text.indent(4);\nsystem.out.println(text);\ntext = text.indent(-10);\nsystem.out.println(text);\n\n\n\n\n     java\njava\n\n\ntransform() \n\nstring result = "foo".transform(input -> input + " bar");\nsystem.out.println(result); // foo bar\n\n\n\n# files \n\njava 12 \n\npublic static long mismatch(path path, path path2) throws ioexception\n\n\nmismatch()  -1l\n\n\n\npath filepath1 = files.createtempfile("file1", ".txt");\npath filepath2 = files.createtempfile("file2", ".txt");\nfiles.writestring(filepath1, "java 12 article");\nfiles.writestring(filepath2, "java 12 article");\n\nlong mismatch = files.mismatch(filepath1, filepath2);\nassertequals(-1, mismatch);\n\n\n\n\npath filepath3 = files.createtempfile("file3", ".txt");\npath filepath4 = files.createtempfile("file4", ".txt");\nfiles.writestring(filepath3, "java 12 article");\nfiles.writestring(filepath4, "java 12 tutorial");\n\nlong mismatch = files.mismatch(filepath3, filepath4);\nassertequals(8, mismatch);\n\n\n\n# \n\nnumberformat \n\nnumberformat fmt = numberformat.getcompactnumberinstance(locale.us, numberformat.style.short);\nstring result = fmt.format(1000);\nsystem.out.println(result);\n\n\n:\n\n1k\n\n\n\n# shenandoah gc\n\nredhat  pauseless gc  99.9%  10ms\n\n java11  zgc  jdk11 shenandoah gc  jdk8u  java8 \n\n\n# g1 \n\njava12  g1 :\n\n * jep344 jep 344  g1  g1 \n * jep346  g1 gc java \n\n\n# \n\njavacjava--enable-preview \n\n#  switch\n\n switch  break  break \n\njava12  switch  lambda  break \n\nswitch (day) {\n    case monday, friday, sunday -> system.out.println(6);\n    case tuesday                -> system.out.println(7);\n    case thursday, saturday     -> system.out.println(8);\n    case wednesday              -> system.out.println(9);\n}\n\n\n# instanceof \n\ninstanceof \n\n\n\nobject obj = "";\nif(obj instanceof string){\n   string str = (string) obj;\n  system.out.println(str);\n}\n\n\n instanceof \n\nobject obj = "";\nif(obj instanceof string str){\n  system.out.println(str);\n}\n\n\n\n# java13\n\n\n#  zgc()\n\n java 11  zgc \n\nzgc  zpages  gc  zpages  zpagecache  zpages lru\n\n java 13 zgc \n\n\n# socketapi \n\njava socket api \n\njava 13  socket api  niosocketimpl  plainsocketimpl  java.util.concurrent  -djdk.net.useplainsocketimpl=true\n\n java 13  socket \n\npublic final class niosocketimpl extends socketimpl implements platformsocketimpl {\n}\n\n\n\n# filesystems\n\nfilesystems \n\n * newfilesystem(path)\n * newfilesystem(path, map<string, ?>)\n * newfilesystem(path, map<string, ?>, classloader)\n\n\n#  cds \n\njava 13  java 10 (appcds) java  cds \n\nappcds\n\njava -xx:archiveclassesatexit=my_app_cds.jsa -cp my_app.jar\njava -xx:sharedarchivefile=my_app_cds.jsa -cp my_app.jar\n\n\n\n# \n\n# \n\n java \n\njava 13  """ \n\n html \n\nstring json ="{\\n" +\n              "   \\"name\\":\\"mkyong\\",\\n" +\n              "   \\"age\\":38\\n" +\n              "}\\n";\n\n\n html \n\n string json = """\n                {\n                    "name":"mkyong",\n                    "age":38\n                }\n                """;\n\n\n sql \n\nstring query = "select `emp_id`, `last_name` from `employee_tb`\\n" +\n               "where `city` = \'indianapolis\'\\n" +\n               "order by `emp_id`, `last_name`;\\n";\n\n\n sql \n\nstring query = """\n               select `emp_id`, `last_name` from `employee_tb`\n               where `city` = \'indianapolis\'\n               order by `emp_id`, `last_name`;\n               """;\n\n\nstring  3 \n\n * formatted(object... args) string format()\n * stripindent()\n * translateescapes() \\\\t  \\t\n\n\n\n@deprecated(forremoval=true, since="13")\npublic string stripindent() {\n}\n@deprecated(forremoval=true, since="13")\npublic string formatted(object... args) {\n\n}\n@deprecated(forremoval=true, since="13")\npublic string translateescapes() {\n}\n\n\n#  switch( yield  switch )\n\nswitch  switch  yield\n\nyield return return  yield  switch  yield  default \n\n private static string desclanguage(string name) {\n        return switch (name) {\n            case "java": yield "object-oriented, platform independent and secured";\n            case "ruby": yield "a programmer\'s best friend";\n            default: yield name +" is a good language";\n        };\n }\n\n\n\n# \n\n\n# \n\n oracle this is a preview feature, which is a feature whose design, specification, and implementation are complete, but is not permanent, which means that the feature may exist in a different form or not at all in future jdk releases. to compile and run code that contains preview features, you must specify additional command-line options.\n\n jdk  \n\nswitch java12  java13  java14  jdk  jdk \n\n jdk \n\n\n# jvm \n\n java  jvm \n\n\n\n java jvm \n\n\n# \n\n * jdk project overviewhttps://openjdk.java.net/projects/jdk/\n * oracle java12 releasenotehttps://www.oracle.com/java/technologies/javase/12all-relnotes.htm\n * what is new in java 12https://mkyong.com/java/what-is-new-in-java-12/\n * oracle java13 releasenote https://www.oracle.com/technetwork/java/javase/13all-relnotes-5461743.html#newfeature\n * new java13 features https://www.baeldung.com/java-13-new-features\n * java13  https://www.ibm.com/developerworks/cn/java/the-new-features-of-java-13/index.html',charsets:{cjk:!0}},{title:"Java 14  & 15 ",frontmatter:{title:"Java 14  & 15 ",category:"Java",tag:["Java"],date:"2024-08-21T23:05:05.000Z",permalink:"/pages/683a03/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/07.java14-15.html",relativePath:"01.Java/05./07.java14-15.md",key:"v-f4d1815c",path:"/pages/683a03/",headers:[{level:2,title:"Java14",slug:"java14",normalizedTitle:"java14",charIndex:2},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:13},{level:3,title:"switch ()",slug:"switch--",normalizedTitle:"switch ()",charIndex:462},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:997},{level:4,title:"record ",slug:"record-",normalizedTitle:"record ",charIndex:1006},{level:4,title:"",slug:"",normalizedTitle:"",charIndex:1793},{level:4,title:"instanceof ",slug:"instanceof-",normalizedTitle:"instanceof ",charIndex:2129},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:2174},{level:2,title:"Java15",slug:"java15",normalizedTitle:"java15",charIndex:2438},{level:3,title:"CharSequence",slug:"charsequence",normalizedTitle:"charsequence",charIndex:2449},{level:3,title:"TreeMap",slug:"treemap",normalizedTitle:"treemap",charIndex:2628},{level:3,title:"ZGC()",slug:"zgc-",normalizedTitle:"zgc()",charIndex:2746},{level:3,title:"EdDSA()",slug:"eddsa-",normalizedTitle:"eddsa()",charIndex:2943},{level:3,title:"()",slug:"-",normalizedTitle:"()",charIndex:3582},{level:3,title:"(Hidden Classes)",slug:"-hidden-classes",normalizedTitle:"(hidden classes)",charIndex:3620},{level:3,title:"",slug:"-2",normalizedTitle:"",charIndex:997},{level:4,title:"",slug:"",normalizedTitle:"",charIndex:3718},{level:4,title:"instanceof ",slug:"instanceof-",normalizedTitle:"instanceof ",charIndex:4247},{level:3,title:"",slug:"-2",normalizedTitle:"",charIndex:2174}],headersStr:"Java14  switch ()  record   instanceof   Java15 CharSequence TreeMap ZGC() EdDSA() () (Hidden Classes)   instanceof  ",content:'# Java14\n\n\n# \n\n JVM -XX:+ShowCodeDetailsInExceptionMessages\n\na.b.c.i = 99; // \n\n\nJava 14 \n\nException in thread "main" java.lang.NullPointerException\n    at NullPointerExample.main(NullPointerExample.java:5)\n\n\nJava 14 \n\n // \nException in thread "main" java.lang.NullPointerException:\n        Cannot read field \'c\' because \'a.b\' is null.\n    at Prog.main(Prog.java:5)\n\n\n\n# switch ()\n\nJava12  switch Java14  JDK14 \n\nJava12  switch  lambda  break Java13  yield  block \n\nString result = switch (day) {\n            case "M", "W", "F" -> "MWF";\n            case "T", "TH", "S" -> "TTS";\n            default -> {\n                if(day.isEmpty())\n                    yield "Please insert a valid day.";\n                else\n                    yield "Looks like a Sunday.";\n            }\n\n        };\nSystem.out.println(result);\n\n\n\n# \n\n# record \n\nrecord   Java  record  class  toString()hashCode(), equals()\n\n class  lombok @Getter,@ToString,@EqualsAndHashCode\n\n/**\n * \n * 1. final\n * 2. \n * record\n */\nfinal class Rectangle implements Shape {\n    final double length;\n    final double width;\n\n    public Rectangle(double length, double width) {\n        this.length = length;\n        this.width = width;\n    }\n\n    double length() { return length; }\n    double width() { return width; }\n}\n/**\n * 1. record\n * 2. equals()hashCode()toString()\n * 3. toString\n */\nrecord Rectangle(float length, float width) { }\n\n\n# \n\nJava14 \n\n * \\ : \n * \\s\n\nString str = "";\n\nString str2 = """\n         \\\n        """;\nSystem.out.println(str2);//  \nString text = """\n        java\n        c++\\sphp\n        """;\nSystem.out.println(text);\n//\njava\nc++ php\n\n\n# instanceof \n\n Java 12 \n\n\n# \n\n *  Java11  ZGC  G1  GC  Linux  Java14  MacOS  Windows ZGC  G1 \n *  CMS(Concurrent Mark Sweep) \n *  jpackage  jar  linux debrpmwindow msiexe\n\n\n# Java15\n\n\n# CharSequence\n\nCharSequence  isEmpty()  true\n\npublic interface CharSequence {\n  default boolean isEmpty() {\n      return this.length() == 0;\n  }\n}\n\n\n\n# TreeMap\n\nTreeMap \n\n * putIfAbsent()\n * computeIfAbsent()\n * computeIfPresent()\n * compute()\n * merge()\n\n\n# ZGC()\n\nJava11  ZGC \n\nZGC  Java \n\nZGC  Java 15 \n\n G1 ZGC\n\njava -XX:+UseZGC className\n\n\n\n# EdDSA()\n\n Edwards-Curve Digital Signature Algorithm EdDSA\n\n ECDSA  JDK ( ECDSA)\n\nKeyPairGenerator kpg = KeyPairGenerator.getInstance("Ed25519");\nKeyPair kp = kpg.generateKeyPair();\n\nbyte[] msg = "test_string".getBytes(StandardCharsets.UTF_8);\n\nSignature sig = Signature.getInstance("Ed25519");\nsig.initSign(kp.getPrivate());\nsig.update(msg);\nbyte[] s = sig.sign();\n\nString encodedString = Base64.getEncoder().encodeToString(s);\nSystem.out.println(encodedString);\n\n\n\n\n0Hc0lxxASZNvS52WsvnncJOH/mlFhnA8Tc6D/k5DtAX5BSsNVjtPF4R4+yMWXVjrvB2mxVXmChIbki6goFBgAg==\n\n\n\n# ()\n\n Java 15 \n\n\n# (Hidden Classes)\n\nframeworks\n\n\n# \n\n# \n\nSealed Classes  Java 15 \n\n Java final \n\n\n\n//  Person  Employee  Manager \npublic abstract sealed class Person\n    permits Employee, Manager {\n\n    //...\n}\n\n\n sealednon-sealed  final\n\npublic final class Employee extends Person {\n}\n\npublic non-sealed class Manager extends Person {\n}\n\n\n\n\n permits Java \n\n# instanceof \n\nJava 15 \n\n Java Java  instanceof \n\n\n# \n\n * Nashorn JavaScript Nashorn  Java8  JavaScript Java9  Nashorn  ES6  Java 11  Java 15 \n * DatagramSocket API \n * Biased Locking JVM  -XX:+UseBiasedLocking  API\n * ',normalizedContent:'# java14\n\n\n# \n\n jvm -xx:+showcodedetailsinexceptionmessages\n\na.b.c.i = 99; // \n\n\njava 14 \n\nexception in thread "main" java.lang.nullpointerexception\n    at nullpointerexample.main(nullpointerexample.java:5)\n\n\njava 14 \n\n // \nexception in thread "main" java.lang.nullpointerexception:\n        cannot read field \'c\' because \'a.b\' is null.\n    at prog.main(prog.java:5)\n\n\n\n# switch ()\n\njava12  switch java14  jdk14 \n\njava12  switch  lambda  break java13  yield  block \n\nstring result = switch (day) {\n            case "m", "w", "f" -> "mwf";\n            case "t", "th", "s" -> "tts";\n            default -> {\n                if(day.isempty())\n                    yield "please insert a valid day.";\n                else\n                    yield "looks like a sunday.";\n            }\n\n        };\nsystem.out.println(result);\n\n\n\n# \n\n# record \n\nrecord   java  record  class  tostring()hashcode(), equals()\n\n class  lombok @getter,@tostring,@equalsandhashcode\n\n/**\n * \n * 1. final\n * 2. \n * record\n */\nfinal class rectangle implements shape {\n    final double length;\n    final double width;\n\n    public rectangle(double length, double width) {\n        this.length = length;\n        this.width = width;\n    }\n\n    double length() { return length; }\n    double width() { return width; }\n}\n/**\n * 1. record\n * 2. equals()hashcode()tostring()\n * 3. tostring\n */\nrecord rectangle(float length, float width) { }\n\n\n# \n\njava14 \n\n * \\ : \n * \\s\n\nstring str = "";\n\nstring str2 = """\n         \\\n        """;\nsystem.out.println(str2);//  \nstring text = """\n        java\n        c++\\sphp\n        """;\nsystem.out.println(text);\n//\njava\nc++ php\n\n\n# instanceof \n\n java 12 \n\n\n# \n\n *  java11  zgc  g1  gc  linux  java14  macos  windows zgc  g1 \n *  cms(concurrent mark sweep) \n *  jpackage  jar  linux debrpmwindow msiexe\n\n\n# java15\n\n\n# charsequence\n\ncharsequence  isempty()  true\n\npublic interface charsequence {\n  default boolean isempty() {\n      return this.length() == 0;\n  }\n}\n\n\n\n# treemap\n\ntreemap \n\n * putifabsent()\n * computeifabsent()\n * computeifpresent()\n * compute()\n * merge()\n\n\n# zgc()\n\njava11  zgc \n\nzgc  java \n\nzgc  java 15 \n\n g1 zgc\n\njava -xx:+usezgc classname\n\n\n\n# eddsa()\n\n edwards-curve digital signature algorithm eddsa\n\n ecdsa  jdk ( ecdsa)\n\nkeypairgenerator kpg = keypairgenerator.getinstance("ed25519");\nkeypair kp = kpg.generatekeypair();\n\nbyte[] msg = "test_string".getbytes(standardcharsets.utf_8);\n\nsignature sig = signature.getinstance("ed25519");\nsig.initsign(kp.getprivate());\nsig.update(msg);\nbyte[] s = sig.sign();\n\nstring encodedstring = base64.getencoder().encodetostring(s);\nsystem.out.println(encodedstring);\n\n\n\n\n0hc0lxxasznvs52wsvnncjoh/mlfhna8tc6d/k5dtax5bssnvjtpf4r4+ymwxvjrvb2mxvxmchibki6gofbgag==\n\n\n\n# ()\n\n java 15 \n\n\n# (hidden classes)\n\nframeworks\n\n\n# \n\n# \n\nsealed classes  java 15 \n\n java final \n\n\n\n//  person  employee  manager \npublic abstract sealed class person\n    permits employee, manager {\n\n    //...\n}\n\n\n sealednon-sealed  final\n\npublic final class employee extends person {\n}\n\npublic non-sealed class manager extends person {\n}\n\n\n\n\n permits java \n\n# instanceof \n\njava 15 \n\n java java  instanceof \n\n\n# \n\n * nashorn javascript nashorn  java8  javascript java9  nashorn  es6  java 11  java 15 \n * datagramsocket api \n * biased locking jvm  -xx:+usebiasedlocking  api\n * ',charsets:{cjk:!0}},{title:"Java 16 ",frontmatter:{title:"Java 16 ",category:"Java",tag:["Java"],date:"2024-08-21T23:05:13.000Z",permalink:"/pages/fa2c73/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/08.java16.html",relativePath:"01.Java/05./08.java16.md",key:"v-38ca00b8",path:"/pages/fa2c73/",headers:[{level:2,title:"JEP 338: API()",slug:"jep-338--api-",normalizedTitle:"jep 338: api()",charIndex:75},{level:2,title:"JEP 347: C++ 14 ",slug:"jep-347--c-14-",normalizedTitle:"jep 347: c++ 14 ",charIndex:508},{level:2,title:"JEP 376:ZGC ",slug:"jep-376-zgc-",normalizedTitle:"jep 376:zgc ",charIndex:679},{level:2,title:"JEP 387:",slug:"jep-387-",normalizedTitle:"jep 387:",charIndex:799},{level:2,title:"JEP 390:",slug:"jep-390-",normalizedTitle:"jep 390:",charIndex:972},{level:2,title:"JEP 392:",slug:"jep-392-",normalizedTitle:"jep 392:",charIndex:2253},{level:2,title:"JEP 393: API()",slug:"jep-393--api-",normalizedTitle:"jep 393: api()",charIndex:2689},{level:2,title:"JEP 394:instanceof ()",slug:"jep-394-instanceof--",normalizedTitle:"jep 394:instanceof ()",charIndex:3029},{level:2,title:"JEP 395:()",slug:"jep-395--",normalizedTitle:"jep 395:()",charIndex:3489},{level:2,title:"JEP 396: JDK ",slug:"jep-396--jdk-",normalizedTitle:"jep 396: jdk ",charIndex:4073},{level:2,title:"JEP 397:()",slug:"jep-397--",normalizedTitle:"jep 397:()",charIndex:4391},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:4554},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:5776}],headersStr:"JEP 338: API() JEP 347: C++ 14  JEP 376:ZGC  JEP 387: JEP 390: JEP 392: JEP 393: API() JEP 394:instanceof () JEP 395:() JEP 396: JDK  JEP 397:()  ",content:"Java 16  2021  3  16 LTS\n\nOpenJDK Java 16  \n\n\n# JEP 338: API()\n\nVector API  JEP 338  API Java 16  JEP 414  Java 17  JEP 417  Java 18  JEP 426  Java 19 \n\n API  API  CPU SIMD CPU  HotSpot  API  Java \n\n Java 18   API\n\n\n# JEP 347: C++ 14 \n\nJava 16  JDK  C++  C++14  HotSpot \n\n Java 15 JDK  C++  C++98/03 \n\n\n# JEP 376:ZGC \n\nJava16  ZGC  GC  ZGC \n\n\n# JEP 387:\n\n Metaspace Metaspace  HotSpot metaspace\n\n\n\n\n# JEP 390:\n\n>  |  Java16 \n\n Java9 Java  @Deprecated  since  forRemoval  2 since  @Deprecated  API  forRemoval  API  @Deprecated forRemoval=true API  API Java9  @Deprecated  API\n\njava.lang.Integerjava.lang.Double@Deprecated(since=\"9\", forRemoval = true)new Integer();Integer a = 10;Integer.valueOf()'Integer(int)' is deprecated and marked for removal  java.util.Optional  java.time.LocalDateTime \n\n synchronized  synchronized  1-5\n\npublic void inc(Integer count) {\n    for (int i = 0; i < 10; i++) {\n        new Thread(() -> {\n            synchronized (count) {\n                count++;\n            }\n        }).start();\n    }\n}\n\n\nInteger  synchronized count++ hashcode  AtomicInteger\n\n\n# JEP 392:\n\n Java 14 JEP 343  jpackage Java 15  Java 16 \n\n Java  Windows  msi  exemacOS  pkg  dmg Linux  deb  rpm ToolProvider API  jpackage  jdk.incubator.jpackage  jdk.jpackage\n\n Playing with Java 16 jpackage\n\n\n# JEP 393: API()\n\n API  Java  Java \n\nJava 14(JEP 370)  APIJava 15 JEP 383 Java 16 \n\n API \n\n *  API \n * API  JVM \n * \n * API  sun.misc.Unsafe.\n\n\n# JEP 394:instanceof ()\n\nJDK                        JEP       \nJava SE 14   preview             JEP 305    instanceof \nJava SE 15   Second Preview      JEP 375   \nJava SE 16   Permanent Release   JEP 394    final\n\n Java 16  instanceof \n\n// Old code\nif (o instanceof String) {\n    String s = (String)o;\n    ... use s ...\n}\n\n// New code\nif (o instanceof String s) {\n    ... use s ...\n}\n\n\n\n# JEP 395:()\n\n\n\nJDK                        JEP       \nJava SE 14   Preview             JEP 359    record record \nJava SE 15   Second Preview      JEP 384    record\nJava SE 16   Permanent Release   JEP 395   \n\n Java SE 16 \n\npublic class Outer {\n  class Inner {\n    static int age;\n  }\n}\n\n\n>  JDK 16 IDE  age The field age cannot be declared static in a non-static inner type, unless initialized with a constant expression\n\n\n# JEP 396: JDK \n\n JDK  API sun.misc.Unsafe JDK  API  API  Java  JDK 9 illegal-access  JDK 15  warning JDK 16  denyadd-opens \n\n\n# JEP 397:()\n\n JEP 360  Java 15  JDK 16   JEP 397 \n\n Java 14 & 15  \n\n\n# \n\n * JEP 380:Unix-Domain Unix-domain  Unix  Windows 10  Windows Server 2019  java.nio.channels  API  Unix-domainAF_UNIX Unix-domain Unix-domain IPC TCP/IP Internet IPUnix-domain  TCP/IP \n * JEP 389: API()  API  Java  API Java 1.1  Java JNIJava  JNI \n * JEP 357: Mercurial  GitOpenJDK  Mercurial  Git\n * JEP 369: GitHub JEP 357  Mercurial  Git  Git  GitHub  OpenJDK  Git  JDK 11  JDK \n * JEP 386: Alpine LinuxAlpine Linux  Linux  8MB  130MB  JDK  Apline Linux Apline Linux  musl lib  Linux  x64  AArch64  musl lib  Linux \n * JEP 388:Windows/AArch64  JEP  JDK JEP 386  JDK  Alpine Linux  musl  x64  C JEP 388  JDK  Windows AArch64ARM64\n\n\n# \n\n * Java Language Changes\n * Consolidated JDK 16 Release Notes\n * Java 16 \n *  |  Java16 ",normalizedContent:"java 16  2021  3  16 lts\n\nopenjdk java 16  \n\n\n# jep 338: api()\n\nvector api  jep 338  api java 16  jep 414  java 17  jep 417  java 18  jep 426  java 19 \n\n api  api  cpu simd cpu  hotspot  api  java \n\n java 18   api\n\n\n# jep 347: c++ 14 \n\njava 16  jdk  c++  c++14  hotspot \n\n java 15 jdk  c++  c++98/03 \n\n\n# jep 376:zgc \n\njava16  zgc  gc  zgc \n\n\n# jep 387:\n\n metaspace metaspace  hotspot metaspace\n\n\n\n\n# jep 390:\n\n>  |  java16 \n\n java9 java  @deprecated  since  forremoval  2 since  @deprecated  api  forremoval  api  @deprecated forremoval=true api  api java9  @deprecated  api\n\njava.lang.integerjava.lang.double@deprecated(since=\"9\", forremoval = true)new integer();integer a = 10;integer.valueof()'integer(int)' is deprecated and marked for removal  java.util.optional  java.time.localdatetime \n\n synchronized  synchronized  1-5\n\npublic void inc(integer count) {\n    for (int i = 0; i < 10; i++) {\n        new thread(() -> {\n            synchronized (count) {\n                count++;\n            }\n        }).start();\n    }\n}\n\n\ninteger  synchronized count++ hashcode  atomicinteger\n\n\n# jep 392:\n\n java 14 jep 343  jpackage java 15  java 16 \n\n java  windows  msi  exemacos  pkg  dmg linux  deb  rpm toolprovider api  jpackage  jdk.incubator.jpackage  jdk.jpackage\n\n playing with java 16 jpackage\n\n\n# jep 393: api()\n\n api  java  java \n\njava 14(jep 370)  apijava 15 jep 383 java 16 \n\n api \n\n *  api \n * api  jvm \n * \n * api  sun.misc.unsafe.\n\n\n# jep 394:instanceof ()\n\njdk                        jep       \njava se 14   preview             jep 305    instanceof \njava se 15   second preview      jep 375   \njava se 16   permanent release   jep 394    final\n\n java 16  instanceof \n\n// old code\nif (o instanceof string) {\n    string s = (string)o;\n    ... use s ...\n}\n\n// new code\nif (o instanceof string s) {\n    ... use s ...\n}\n\n\n\n# jep 395:()\n\n\n\njdk                        jep       \njava se 14   preview             jep 359    record record \njava se 15   second preview      jep 384    record\njava se 16   permanent release   jep 395   \n\n java se 16 \n\npublic class outer {\n  class inner {\n    static int age;\n  }\n}\n\n\n>  jdk 16 ide  age the field age cannot be declared static in a non-static inner type, unless initialized with a constant expression\n\n\n# jep 396: jdk \n\n jdk  api sun.misc.unsafe jdk  api  api  java  jdk 9 illegal-access  jdk 15  warning jdk 16  denyadd-opens \n\n\n# jep 397:()\n\n jep 360  java 15  jdk 16   jep 397 \n\n java 14 & 15  \n\n\n# \n\n * jep 380:unix-domain unix-domain  unix  windows 10  windows server 2019  java.nio.channels  api  unix-domainaf_unix unix-domain unix-domain ipc tcp/ip internet ipunix-domain  tcp/ip \n * jep 389: api()  api  java  api java 1.1  java jnijava  jni \n * jep 357: mercurial  gitopenjdk  mercurial  git\n * jep 369: github jep 357  mercurial  git  git  github  openjdk  git  jdk 11  jdk \n * jep 386: alpine linuxalpine linux  linux  8mb  130mb  jdk  apline linux apline linux  musl lib  linux  x64  aarch64  musl lib  linux \n * jep 388:windows/aarch64  jep  jdk jep 386  jdk  alpine linux  musl  x64  c jep 388  jdk  windows aarch64arm64\n\n\n# \n\n * java language changes\n * consolidated jdk 16 release notes\n * java 16 \n *  |  java16 ",charsets:{cjk:!0}},{title:"Java 17 ",frontmatter:{title:"Java 17 ",category:"Java",tag:["Java"],date:"2024-08-21T23:05:19.000Z",permalink:"/pages/245aa2/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/09.java17.html",relativePath:"01.Java/05./09.java17.md",key:"v-51cd5ef8",path:"/pages/245aa2/",headers:[{level:2,title:"JEP 356:",slug:"jep-356-",normalizedTitle:"jep 356:",charIndex:1140},{level:2,title:"JEP 398: Applet API ",slug:"jep-398--applet-api-",normalizedTitle:"jep 398: applet api ",charIndex:1744},{level:2,title:"JEP 406:switch ",slug:"jep-406-switch--",normalizedTitle:"jep 406:switch ",charIndex:1884},{level:2,title:"JEP 407:",slug:"jep-407-",normalizedTitle:"jep 407:",charIndex:3494},{level:2,title:"JEP 409:",slug:"jep-409--",normalizedTitle:"jep 409:",charIndex:3573},{level:2,title:"JEP 410: AOT  JIT ",slug:"jep-410--aot--jit-",normalizedTitle:"jep 410: aot  jit ",charIndex:3736},{level:2,title:"JEP 411:",slug:"jep-411-",normalizedTitle:"jep 411:",charIndex:3966},{level:2,title:"JEP 412: API",slug:"jep-412--api-",normalizedTitle:"jep 412: api",charIndex:4140},{level:2,title:"JEP 414: API",slug:"jep-414--api-",normalizedTitle:"jep 414: api",charIndex:4469}],headersStr:"JEP 356: JEP 398: Applet API  JEP 406:switch  JEP 407: JEP 409: JEP 410: AOT  JIT  JEP 411: JEP 412: API JEP 414: API",content:'Java 17  2021  9  14 LTS\n\n Oracle  Oracle JDK Java\n\n17  2029  9 \n\n\n\nJava 17  Java 8 LTS Java Spring 6.x  Spring Boot 3.x  Java 17\n\n 14 \n\n * JEP 306:Restore Always-Strict Floating-Point Semantics\n * JEP 356:Enhanced Pseudo-Random Number Generators\n * JEP 382:New macOS Rendering Pipeline macOS \n * JEP 391:macOS/AArch64 Port macOS AArch64\n * JEP 398:Deprecate the Applet API for Removal Applet API\n * JEP 403:Strongly Encapsulate JDK Internals JDK \n * JEP 406:Pattern Matching for switch (switch )\n * JEP 407:Remove RMI Activation\n * JEP 409:Sealed Classes\n * JEP 410:Remove the Experimental AOT and JIT Compiler AOT  JIT \n * JEP 411:Deprecate the Security Manager for Removal\n * JEP 412:Foreign Function & Memory API ( API)\n * JEP 414:Vector API\n * JEP 415:Context-Specific Deserialization Filters\n\n 356398413406407409410411412414 \n\nOpenJDK Java 17  \n\n\n# JEP 356:\n\nJDK 17  RandomThreadLocalRandomSplittableRandom 3 \n\nJava 17  pseudorandom number generatorPRNG PRNG \n\n> PRNG PRNG PRNG \n\n\n\nRandomGeneratorFactory<RandomGenerator> l128X256MixRandom = RandomGeneratorFactory.of("L128X256MixRandom");\n// \nRandomGenerator randomGenerator = l128X256MixRandom.create(System.currentTimeMillis());\n// \nrandomGenerator.nextInt(10);\n\n\n\n# JEP 398: Applet API \n\nApplet API  Web  Java \n\nApplet API  Java 9 JEP 289\n\n\n# JEP 406:switch \n\n instanceof  switch \n\ninstanceof \n\n// Old code\nif (o instanceof String) {\n    String s = (String)o;\n    ... use s ...\n}\n\n// New code\nif (o instanceof String s) {\n    ... use s ...\n}\n\n\nswitch \n\n// Old code\nstatic String formatter(Object o) {\n    String formatted = "unknown";\n    if (o instanceof Integer i) {\n        formatted = String.format("int %d", i);\n    } else if (o instanceof Long l) {\n        formatted = String.format("long %d", l);\n    } else if (o instanceof Double d) {\n        formatted = String.format("double %f", d);\n    } else if (o instanceof String s) {\n        formatted = String.format("String %s", s);\n    }\n    return formatted;\n}\n\n// New code\nstatic String formatterPatternSwitch(Object o) {\n    return switch (o) {\n        case Integer i -> String.format("int %d", i);\n        case Long l    -> String.format("long %d", l);\n        case Double d  -> String.format("double %f", d);\n        case String s  -> String.format("String %s", s);\n        default        -> o.toString();\n    };\n}\n\n\n\n null \n\n// Old code\nstatic void testFooBar(String s) {\n    if (s == null) {\n        System.out.println("oops!");\n        return;\n    }\n    switch (s) {\n        case "Foo", "Bar" -> System.out.println("Great");\n        default           -> System.out.println("Ok");\n    }\n}\n\n// New code\nstatic void testFooBar(String s) {\n    switch (s) {\n        case null         -> System.out.println("Oops");\n        case "Foo", "Bar" -> System.out.println("Great");\n        default           -> System.out.println("Ok");\n    }\n}\n\n\n\n# JEP 407:\n\n (RMI)  RMI RMI \n\n\n# JEP 409:\n\n JEP 360  Java 15  JDK 16   JEP 397 \n\n Java 14 & 15  \n\n\n# JEP 410: AOT  JIT \n\n Java 9  JEP 295 , (AOT)  Java \n\nJava 17 (AOT)  (JIT)  Java  JVM  (JVMCI) JIT \n\n\n# JEP 411:\n\n\n\n Java 1.0 Java  Java Java 17  Applet API ( JEP 398 ) \n\n\n# JEP 412: API\n\nJava  API  Java  JVM  JVM  API  Java  JNI \n\n API  Java 17  JEP 412 JEP 419  Java 18  JEP 424  Java 19 \n\n Java 19   API\n\n\n# JEP 414: API\n\nVector API  JEP 338  API Java 16  JEP 414  Java 17  JEP 417  Java 18  JEP 426  Java 19 \n\n API  API  CPU SIMD CPU  HotSpot  API  Java \n\n Java 18   API',normalizedContent:'java 17  2021  9  14 lts\n\n oracle  oracle jdk java\n\n17  2029  9 \n\n\n\njava 17  java 8 lts java spring 6.x  spring boot 3.x  java 17\n\n 14 \n\n * jep 306:restore always-strict floating-point semantics\n * jep 356:enhanced pseudo-random number generators\n * jep 382:new macos rendering pipeline macos \n * jep 391:macos/aarch64 port macos aarch64\n * jep 398:deprecate the applet api for removal applet api\n * jep 403:strongly encapsulate jdk internals jdk \n * jep 406:pattern matching for switch (switch )\n * jep 407:remove rmi activation\n * jep 409:sealed classes\n * jep 410:remove the experimental aot and jit compiler aot  jit \n * jep 411:deprecate the security manager for removal\n * jep 412:foreign function & memory api ( api)\n * jep 414:vector api\n * jep 415:context-specific deserialization filters\n\n 356398413406407409410411412414 \n\nopenjdk java 17  \n\n\n# jep 356:\n\njdk 17  randomthreadlocalrandomsplittablerandom 3 \n\njava 17  pseudorandom number generatorprng prng \n\n> prng prng prng \n\n\n\nrandomgeneratorfactory<randomgenerator> l128x256mixrandom = randomgeneratorfactory.of("l128x256mixrandom");\n// \nrandomgenerator randomgenerator = l128x256mixrandom.create(system.currenttimemillis());\n// \nrandomgenerator.nextint(10);\n\n\n\n# jep 398: applet api \n\napplet api  web  java \n\napplet api  java 9 jep 289\n\n\n# jep 406:switch \n\n instanceof  switch \n\ninstanceof \n\n// old code\nif (o instanceof string) {\n    string s = (string)o;\n    ... use s ...\n}\n\n// new code\nif (o instanceof string s) {\n    ... use s ...\n}\n\n\nswitch \n\n// old code\nstatic string formatter(object o) {\n    string formatted = "unknown";\n    if (o instanceof integer i) {\n        formatted = string.format("int %d", i);\n    } else if (o instanceof long l) {\n        formatted = string.format("long %d", l);\n    } else if (o instanceof double d) {\n        formatted = string.format("double %f", d);\n    } else if (o instanceof string s) {\n        formatted = string.format("string %s", s);\n    }\n    return formatted;\n}\n\n// new code\nstatic string formatterpatternswitch(object o) {\n    return switch (o) {\n        case integer i -> string.format("int %d", i);\n        case long l    -> string.format("long %d", l);\n        case double d  -> string.format("double %f", d);\n        case string s  -> string.format("string %s", s);\n        default        -> o.tostring();\n    };\n}\n\n\n\n null \n\n// old code\nstatic void testfoobar(string s) {\n    if (s == null) {\n        system.out.println("oops!");\n        return;\n    }\n    switch (s) {\n        case "foo", "bar" -> system.out.println("great");\n        default           -> system.out.println("ok");\n    }\n}\n\n// new code\nstatic void testfoobar(string s) {\n    switch (s) {\n        case null         -> system.out.println("oops");\n        case "foo", "bar" -> system.out.println("great");\n        default           -> system.out.println("ok");\n    }\n}\n\n\n\n# jep 407:\n\n (rmi)  rmi rmi \n\n\n# jep 409:\n\n jep 360  java 15  jdk 16   jep 397 \n\n java 14 & 15  \n\n\n# jep 410: aot  jit \n\n java 9  jep 295 , (aot)  java \n\njava 17 (aot)  (jit)  java  jvm  (jvmci) jit \n\n\n# jep 411:\n\n\n\n java 1.0 java  java java 17  applet api ( jep 398 ) \n\n\n# jep 412: api\n\njava  api  java  jvm  jvm  api  java  jni \n\n api  java 17  jep 412 jep 419  java 18  jep 424  java 19 \n\n java 19   api\n\n\n# jep 414: api\n\nvector api  jep 338  api java 16  jep 414  java 17  jep 417  java 18  jep 426  java 19 \n\n api  api  cpu simd cpu  hotspot  api  java \n\n java 18   api',charsets:{cjk:!0}},{title:"Java 18 ",frontmatter:{title:"Java 18 ",category:"Java",tag:["Java"],date:"2024-08-21T23:05:23.000Z",permalink:"/pages/ce76de/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/10.java18.html",relativePath:"01.Java/05./10.java18.md",key:"v-497d7762",path:"/pages/ce76de/",headers:[{level:2,title:"JEP 400: UTF-8",slug:"jep-400--utf-8",normalizedTitle:"jep 400: utf-8",charIndex:770},{level:2,title:"JEP 408: Web ",slug:"jep-408--web-",normalizedTitle:"jep 408: web ",charIndex:961},{level:2,title:"JEP 413: Java API ",slug:"jep-413--java-api-",normalizedTitle:"jep 413: java api ",charIndex:1246},{level:2,title:"JEP 416:",slug:"jep-416-",normalizedTitle:"jep 416:",charIndex:1673},{level:2,title:"JEP 417:  API",slug:"jep-417--api-",normalizedTitle:"jep 417:  api",charIndex:1850},{level:2,title:"JEP 418: SPI",slug:"jep-418--spi",normalizedTitle:"jep 418: spi",charIndex:3006},{level:2,title:"JEP 419:Foreign Function & Memory API",slug:"jep-419-foreign-function-memory-api-",normalizedTitle:"jep 419:foreign function &amp; memory api",charIndex:null}],headersStr:"JEP 400: UTF-8 JEP 408: Web  JEP 413: Java API  JEP 416: JEP 417:  API JEP 418: SPI JEP 419:Foreign Function & Memory API",content:'Java 18  2022  3  22 \n\nJava 18  9 \n\n * JEP 400:UTF-8 by Default UTF-8\n * JEP 408:Simple Web Server Web \n * JEP 413:Code Snippets in Java API DocumentationJava API \n * JEP 416:Reimplement Core Reflection with Method Handles\n * JEP 417:Vector API\n * JEP 418:Internet-Address ResolutionSPI\n * JEP 419:Foreign Function & Memory API API\n * JEP 420:Pattern Matching for switchswitch \n * JEP 421:Deprecate Finalization for Removal\n\nJava 17  14 Java 16  17 Java 15  14 Java 14  16 Java 18 \n\n 400408413416417418419 \n\n\n\n * OpenJDK Java 18 \n * IntelliJ IDEA | Java 18 \n\n\n# JEP 400: UTF-8\n\nJDK  UTF-8 \n\n Java 17  Java  Mac  Java  Windows \n\n\n# JEP 408: Web \n\nJava 18  jwebserver  Web \n\n$ jwebserver\nBinding to loopback by default. For all interfaces use "-b 0.0.0.0" or "-b ::".\nServing /cwd and subdirectories on 127.0.0.1 port 8000\nURL: http://127.0.0.1:8000/\n\n\n CGI  Servlet\n\n\n# JEP 413: Java API \n\n Java 18  Javadoc  <pre>{@code ...}</pre> \n\n<pre>{@code\n    lines of source code\n}</pre>\n\n\n<pre>{@code ...}</pre> \n\n Java 18  @snippet \n\n/**\n * The following code shows how to use {@code Optional.isPresent}:\n * {@snippet :\n * if (v.isPresent()) {\n *     System.out.println("v: " + v.get());\n * }\n * }\n */\n\n\n@snippet \n\n\n# JEP 416:\n\nJava 18  java.lang.reflect.MethodConstructor  API \n\nOpenJDK \n\n\n\n\n# JEP 417:  API\n\nVector API  JEP 338  API Java 16  JEP 414  Java 17  JEP 417  Java 18  JEP 426  Java 19 \n\n API  CPU \n\n API \n\n\n\nvoid scalarComputation(float[] a, float[] b, float[] c) {\n   for (int i = 0; i < a.length; i++) {\n        c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f;\n   }\n}\n\n\n Vector API \n\nstatic final VectorSpecies<Float> SPECIES = FloatVector.SPECIES_PREFERRED;\n\nvoid vectorComputation(float[] a, float[] b, float[] c) {\n    int i = 0;\n    int upperBound = SPECIES.loopBound(a.length);\n    for (; i < upperBound; i += SPECIES.length()) {\n        // FloatVector va, vb, vc;\n        var va = FloatVector.fromArray(SPECIES, a, i);\n        var vb = FloatVector.fromArray(SPECIES, b, i);\n        var vc = va.mul(va)\n                   .add(vb.mul(vb))\n                   .neg();\n        vc.intoArray(c, i);\n    }\n    for (; i < a.length; i++) {\n        c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f;\n    }\n}\n\n\n\n JDK 18  API \n\n\n# JEP 418: SPI\n\nJava 18  SPIservice-provider interface java.net.InetAddress \n\n\n# JEP 419:Foreign Function & Memory API\n\nJava  API  Java  JVM  JVM  API  Java  JNI \n\n API  Java 17  JEP 412 JEP 419  Java 18  JEP 424  Java 19 \n\n Java 19   API',normalizedContent:'java 18  2022  3  22 \n\njava 18  9 \n\n * jep 400:utf-8 by default utf-8\n * jep 408:simple web server web \n * jep 413:code snippets in java api documentationjava api \n * jep 416:reimplement core reflection with method handles\n * jep 417:vector api\n * jep 418:internet-address resolutionspi\n * jep 419:foreign function & memory api api\n * jep 420:pattern matching for switchswitch \n * jep 421:deprecate finalization for removal\n\njava 17  14 java 16  17 java 15  14 java 14  16 java 18 \n\n 400408413416417418419 \n\n\n\n * openjdk java 18 \n * intellij idea | java 18 \n\n\n# jep 400: utf-8\n\njdk  utf-8 \n\n java 17  java  mac  java  windows \n\n\n# jep 408: web \n\njava 18  jwebserver  web \n\n$ jwebserver\nbinding to loopback by default. for all interfaces use "-b 0.0.0.0" or "-b ::".\nserving /cwd and subdirectories on 127.0.0.1 port 8000\nurl: http://127.0.0.1:8000/\n\n\n cgi  servlet\n\n\n# jep 413: java api \n\n java 18  javadoc  <pre>{@code ...}</pre> \n\n<pre>{@code\n    lines of source code\n}</pre>\n\n\n<pre>{@code ...}</pre> \n\n java 18  @snippet \n\n/**\n * the following code shows how to use {@code optional.ispresent}:\n * {@snippet :\n * if (v.ispresent()) {\n *     system.out.println("v: " + v.get());\n * }\n * }\n */\n\n\n@snippet \n\n\n# jep 416:\n\njava 18  java.lang.reflect.methodconstructor  api \n\nopenjdk \n\n\n\n\n# jep 417:  api\n\nvector api  jep 338  api java 16  jep 414  java 17  jep 417  java 18  jep 426  java 19 \n\n api  cpu \n\n api \n\n\n\nvoid scalarcomputation(float[] a, float[] b, float[] c) {\n   for (int i = 0; i < a.length; i++) {\n        c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f;\n   }\n}\n\n\n vector api \n\nstatic final vectorspecies<float> species = floatvector.species_preferred;\n\nvoid vectorcomputation(float[] a, float[] b, float[] c) {\n    int i = 0;\n    int upperbound = species.loopbound(a.length);\n    for (; i < upperbound; i += species.length()) {\n        // floatvector va, vb, vc;\n        var va = floatvector.fromarray(species, a, i);\n        var vb = floatvector.fromarray(species, b, i);\n        var vc = va.mul(va)\n                   .add(vb.mul(vb))\n                   .neg();\n        vc.intoarray(c, i);\n    }\n    for (; i < a.length; i++) {\n        c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f;\n    }\n}\n\n\n\n jdk 18  api \n\n\n# jep 418: spi\n\njava 18  spiservice-provider interface java.net.inetaddress \n\n\n# jep 419:foreign function & memory api\n\njava  api  java  jvm  jvm  api  java  jni \n\n api  java 17  jep 412 jep 419  java 18  jep 424  java 19 \n\n java 19   api',charsets:{cjk:!0}},{title:"Java 19 ",frontmatter:{title:"Java 19 ",category:"Java",tag:["Java"],date:"2024-08-21T23:05:28.000Z",permalink:"/pages/42d550/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/11.java19.html",relativePath:"01.Java/05./11.java19.md",key:"v-6280d5a2",path:"/pages/42d550/",headers:[{level:2,title:"JEP 424:  API",slug:"jep-424--api-",normalizedTitle:"jep 424:  api",charIndex:464},{level:2,title:"JEP 425: ",slug:"jep-425--",normalizedTitle:"jep 425: ",charIndex:2592},{level:2,title:"JEP 426:  API",slug:"jep-426--api-",normalizedTitle:"jep 426:  api",charIndex:3044},{level:2,title:"JEP 428: ()",slug:"jep-428--",normalizedTitle:"jep 428: ()",charIndex:3268}],headersStr:"JEP 424:  API JEP 425:  JEP 426:  API JEP 428: ()",content:'JDK 19  2022  9  20 JDK 19 \n\nJDK 19  7 \n\n * JEP 405: Record Patterns\n * JEP 422: Linux/RISC-V Port\n * JEP 424: Foreign Function & Memory API API\n * JEP 425: Virtual Threads\n * JEP 426: VectorAPI\n * JEP 427: Pattern Matching for switchswitch \n * JEP 428: Structured Concurrency\n\n 424425426428  4 \n\nOpenJDK Java 19 \n\n\n# JEP 424:  API\n\nJava  API  Java  JVM  JVM  API  Java  JNI \n\n API  Java 17  JEP 412 JEP 419  Java 18  JEP 424  Java 19 \n\n API \n\n * Java  sun.misc.Unsafe Unsafe  Java  C  Java  Unsafe \n * Java 1.1  Java JNIJNI Guide to JNI (Java Native Interface)  JVM  Java JNI  JNI  JIT ()JNAJNRJavaCPP JNI \n\n API  Java \n\nForeign Function & Memory API (FFM API) \n\n * MemorySegmentMemoryAddressSegmentAllocator\n * MemoryLayout, VarHandle\n * MemorySession\n * LinkerFunctionDescriptorSymbolLookup\n\n FFM API  C  radixsort  Java \n\n// 1. C\nLinker linker = Linker.nativeLinker();\nSymbolLookup stdlib = linker.defaultLookup();\nMethodHandle radixSort = linker.downcallHandle(\n                             stdlib.lookup("radixsort"), ...);\n// 2. \nString[] javaStrings   = { "mouse", "cat", "dog", "car" };\n// 3. \nSegmentAllocator allocator = implicitAllocator();\nMemorySegment offHeap  = allocator.allocateArray(ValueLayout.ADDRESS, javaStrings.length);\n// 4. \nfor (int i = 0; i < javaStrings.length; i++) {\n    // \n    MemorySegment cString = allocator.allocateUtf8String(javaStrings[i]);\n    offHeap.setAtIndex(ValueLayout.ADDRESS, i, cString);\n}\n// 5. \nradixSort.invoke(offHeap, javaStrings.length, MemoryAddress.NULL, \'\\0\');\n// 6. ()\nfor (int i = 0; i < javaStrings.length; i++) {\n    MemoryAddress cStringPtr = offHeap.getAtIndex(ValueLayout.ADDRESS, i);\n    javaStrings[i] = cStringPtr.getUtf8String(0);\n}\nassert Arrays.equals(javaStrings, new String[] {"car", "cat", "dog", "mouse"});  // true\n\n\n\n# JEP 425: \n\nVirtual Thread- JDK  OS (Lightweight ProcessLWP\n\n Go  GoroutineErlang \n\n\n\n Java 19 https://www.zhihu.com/question/536743167 \n\nJava \n\n * \n * Java19  GA\n *  - VirtualThread \n\n\n# JEP 426:  API\n\nVector API  JEP 338  API Java 16  JEP 414  Java 17  JEP 417  Java 18  JEP 426  Java 19 \n\n Java 18   API\n\n\n# JEP 428: ()\n\nJDK 19  API java.util.concurrent\n\n\n\n API StructuredTaskScopeStructuredTaskScope \n\nStructuredTaskScope \n\n    try (var scope = new StructuredTaskScope<Object>()) {\n        // fork\n        Future<Integer> future1 = scope.fork(task1);\n        Future<String> future2 = scope.fork(task2);\n        // \n        scope.join();\n        // \n        ... process results/exceptions ...\n    } // close\n\n\n JDK ',normalizedContent:'jdk 19  2022  9  20 jdk 19 \n\njdk 19  7 \n\n * jep 405: record patterns\n * jep 422: linux/risc-v port\n * jep 424: foreign function & memory api api\n * jep 425: virtual threads\n * jep 426: vectorapi\n * jep 427: pattern matching for switchswitch \n * jep 428: structured concurrency\n\n 424425426428  4 \n\nopenjdk java 19 \n\n\n# jep 424:  api\n\njava  api  java  jvm  jvm  api  java  jni \n\n api  java 17  jep 412 jep 419  java 18  jep 424  java 19 \n\n api \n\n * java  sun.misc.unsafe unsafe  java  c  java  unsafe \n * java 1.1  java jnijni guide to jni (java native interface)  jvm  java jni  jni  jit ()jnajnrjavacpp jni \n\n api  java \n\nforeign function & memory api (ffm api) \n\n * memorysegmentmemoryaddresssegmentallocator\n * memorylayout, varhandle\n * memorysession\n * linkerfunctiondescriptorsymbollookup\n\n ffm api  c  radixsort  java \n\n// 1. c\nlinker linker = linker.nativelinker();\nsymbollookup stdlib = linker.defaultlookup();\nmethodhandle radixsort = linker.downcallhandle(\n                             stdlib.lookup("radixsort"), ...);\n// 2. \nstring[] javastrings   = { "mouse", "cat", "dog", "car" };\n// 3. \nsegmentallocator allocator = implicitallocator();\nmemorysegment offheap  = allocator.allocatearray(valuelayout.address, javastrings.length);\n// 4. \nfor (int i = 0; i < javastrings.length; i++) {\n    // \n    memorysegment cstring = allocator.allocateutf8string(javastrings[i]);\n    offheap.setatindex(valuelayout.address, i, cstring);\n}\n// 5. \nradixsort.invoke(offheap, javastrings.length, memoryaddress.null, \'\\0\');\n// 6. ()\nfor (int i = 0; i < javastrings.length; i++) {\n    memoryaddress cstringptr = offheap.getatindex(valuelayout.address, i);\n    javastrings[i] = cstringptr.getutf8string(0);\n}\nassert arrays.equals(javastrings, new string[] {"car", "cat", "dog", "mouse"});  // true\n\n\n\n# jep 425: \n\nvirtual thread- jdk  os (lightweight processlwp\n\n go  goroutineerlang \n\n\n\n java 19 https://www.zhihu.com/question/536743167 \n\njava \n\n * \n * java19  ga\n *  - virtualthread \n\n\n# jep 426:  api\n\nvector api  jep 338  api java 16  jep 414  java 17  jep 417  java 18  jep 426  java 19 \n\n java 18   api\n\n\n# jep 428: ()\n\njdk 19  api java.util.concurrent\n\n\n\n api structuredtaskscopestructuredtaskscope \n\nstructuredtaskscope \n\n    try (var scope = new structuredtaskscope<object>()) {\n        // fork\n        future<integer> future1 = scope.fork(task1);\n        future<string> future2 = scope.fork(task2);\n        // \n        scope.join();\n        // \n        ... process results/exceptions ...\n    } // close\n\n\n jdk ',charsets:{cjk:!0}},{title:"Java 20 ",frontmatter:{title:"Java 20 ",category:"Java",tag:["Java"],date:"2024-08-21T23:05:34.000Z",permalink:"/pages/d5208b/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/12.java20.html",relativePath:"01.Java/05./12.java20.md",key:"v-abc39610",path:"/pages/d5208b/",headers:[{level:2,title:"JEP 429",slug:"jep-429--",normalizedTitle:"jep 429",charIndex:391},{level:2,title:"JEP 432",slug:"jep-432--",normalizedTitle:"jep 432",charIndex:808},{level:2,title:"JEP 433switch ",slug:"jep-433-switch--",normalizedTitle:"jep 433switch ",charIndex:184},{level:2,title:"JEP 434:  API",slug:"jep-434--api-",normalizedTitle:"jep 434:  api",charIndex:4128},{level:2,title:"JEP 436: ",slug:"jep-436--",normalizedTitle:"jep 436: ",charIndex:4613},{level:2,title:"JEP 437: ()",slug:"jep-437--",normalizedTitle:"jep 437: ()",charIndex:6517},{level:2,title:"JEP 432 API",slug:"jep-432--api-",normalizedTitle:"jep 432 api",charIndex:7328}],headersStr:"JEP 429 JEP 432 JEP 433switch  JEP 434:  API JEP 436:  JEP 437: () JEP 432 API",content:'JDK 20  2023  3  21 \n\n LTS  2023  9  JDK 21\n\n\n\nJDK 20  7 \n\n * JEP 429Scoped Values\n * JEP 432Record Patterns\n * JEP 433switch \n * JEP 434: Foreign Function & Memory API API\n * JEP 436: Virtual Threads\n * JEP 437:Structured Concurrency()\n * JEP 432: API\n\n\n# JEP 429\n\nScoped Values\n\nfinal static ScopedValue<...> V = new ScopedValue<>();\n\n// In some method\nScopedValue.where(V, <value>)\n           .run(() -> { ... V.get() ... call methods ... });\n\n// In a method called directly or indirectly from the lambda expression\n... V.get() ...\n\n\n\n\n\n\n\n# JEP 432\n\nRecord Patterns  record Record Class\n\n instanceof  switch \n\n instanceof \n\n\n\nrecord Shape(String type, long unit){}\n\n\n\n\nShape circle = new Shape("Circle", 10);\nif (circle instanceof Shape shape) {\n\n  System.out.println("Area of " + shape.type() + " is : " + Math.PI * Math.pow(shape.unit(), 2));\n}\n\n\n\n\nShape circle = new Shape("Circle", 10);\nif (circle instanceof Shape(String type, long unit)) {\n  System.out.println("Area of " + type + " is : " + Math.PI * Math.pow(unit, 2));\n}\n\n\n switch \n\n\n\ninterface Shape {}\nrecord Circle(double radius) implements Shape { }\nrecord Square(double side) implements Shape { }\nrecord Rectangle(double length, double width) implements Shape { }\n\n\n\n\nShape shape = new Circle(10);\nswitch (shape) {\n    case Circle c:\n        System.out.println("The shape is Circle with area: " + Math.PI * c.radius() * c.radius());\n        break;\n\n    case Square s:\n        System.out.println("The shape is Square with area: " + s.side() * s.side());\n        break;\n\n    case Rectangle r:\n        System.out.println("The shape is Rectangle with area: + " + r.length() * r.width());\n        break;\n\n    default:\n        System.out.println("Unknown Shape");\n        break;\n}\n\n\n\n\nShape shape = new Circle(10);\nswitch(shape) {\n\n  case Circle(double radius):\n    System.out.println("The shape is Circle with area: " + Math.PI * radius * radius);\n    break;\n\n  case Square(double side):\n    System.out.println("The shape is Square with area: " + side * side);\n    break;\n\n  case Rectangle(double length, double width):\n    System.out.println("The shape is Rectangle with area: + " + length * width);\n    break;\n\n  default:\n    System.out.println("Unknown Shape");\n    break;\n}\n\n\n null  NullPointerException\n\n Java 19   JEP 405 JDK 20  JEP 432 \n\n * \n * for\n * \n\n JDK16 \n\n\n# JEP 433switch \n\n instanceof  switch \n\ninstanceof \n\n// Old code\nif (o instanceof String) {\n    String s = (String)o;\n    ... use s ...\n}\n\n// New code\nif (o instanceof String s) {\n    ... use s ...\n}\n\n\nswitch \n\n// Old code\nstatic String formatter(Object o) {\n    String formatted = "unknown";\n    if (o instanceof Integer i) {\n        formatted = String.format("int %d", i);\n    } else if (o instanceof Long l) {\n        formatted = String.format("long %d", l);\n    } else if (o instanceof Double d) {\n        formatted = String.format("double %f", d);\n    } else if (o instanceof String s) {\n        formatted = String.format("String %s", s);\n    }\n    return formatted;\n}\n\n// New code\nstatic String formatterPatternSwitch(Object o) {\n    return switch (o) {\n        case Integer i -> String.format("int %d", i);\n        case Long l    -> String.format("long %d", l);\n        case Double d  -> String.format("double %f", d);\n        case String s  -> String.format("String %s", s);\n        default        -> o.toString();\n    };\n}\n\n\nswitch  Java17Java18Java19 Java20 \n\n\n# JEP 434:  API\n\nJava  API  Java  JVM  JVM  API  Java  JNI \n\n API  Java 17  JEP 412 Java 18 JEP 419 Java 19  JEP 424 \n\nJDK 20  JEP 434 \n\n * MemorySegment  MemoryAddress \n *  MemoryLayout \n * MemorySessionArenaSegmentScope\n\n Java 19   API\n\n\n# JEP 436: \n\nVirtual Thread JDK  OS (Lightweight ProcessLWP JVM \n\njava.lang.Thread JVM \n\nHow to Use Java 19 Virtual Threads\n\n\n\n Windows  Linux Java Solaris HotSpot VM  Solaris  R : JVM \n\n\n\n Go  GoroutineErlang \n\n Java 19 https://www.zhihu.com/question/536743167 \n\nJava \n\n * \n * Java19  GA\n *  - VirtualThread \n\n Java 19 JEP 425JDK 20 \n\n\n\n// 1 Thread.ofVirtual() \nRunnable fn = () -> {\n  // your code here\n};\n\nThread thread = Thread.ofVirtual(fn)\n                      .start();\n\n// 2 Thread.startVirtualThread() \nThread thread = Thread.startVirtualThread(() -> {\n  // your code here\n});\n\n// 3 Executors.newVirtualThreadPerTaskExecutor() \nvar executorService = Executors.newVirtualThreadPerTaskExecutor();\n\nexecutorService.submit(() -> {\n  // your code here\n});\n\nclass CustomThread implements Runnable {\n  @Override\n  public void run() {\n    System.out.println("CustomThread run");\n  }\n}\n\n//4 ThreadFactory \nCustomThread customThread = new CustomThread();\n// \nThreadFactory factory = Thread.ofVirtual().factory();\n// \nThread thread = factory.newThread(customThread);\n// \nthread.start();\n\n\n 4  Thread \n\n\n# JEP 437: ()\n\nJava 19  API java.util.concurrent\n\n\n\n API StructuredTaskScopeStructuredTaskScope \n\nStructuredTaskScope \n\n    try (var scope = new StructuredTaskScope<Object>()) {\n        // fork\n        Future<Integer> future1 = scope.fork(task1);\n        Future<String> future2 = scope.fork(task2);\n        // \n        scope.join();\n        // \n        ... process results/exceptions ...\n    } // close\n\n\n JDK \n\nJDK 20 StructuredTaskScope JEP 429\n\n\n# JEP 432 API\n\n API  CPU \n\n API \n\nVector API  JEP 338  API Java 16  JEP 414  Java 17  JEP 417  Java 18  JEP 426  Java 19 \n\nJava20  API  JEP 438',normalizedContent:'jdk 20  2023  3  21 \n\n lts  2023  9  jdk 21\n\n\n\njdk 20  7 \n\n * jep 429scoped values\n * jep 432record patterns\n * jep 433switch \n * jep 434: foreign function & memory api api\n * jep 436: virtual threads\n * jep 437:structured concurrency()\n * jep 432: api\n\n\n# jep 429\n\nscoped values\n\nfinal static scopedvalue<...> v = new scopedvalue<>();\n\n// in some method\nscopedvalue.where(v, <value>)\n           .run(() -> { ... v.get() ... call methods ... });\n\n// in a method called directly or indirectly from the lambda expression\n... v.get() ...\n\n\n\n\n\n\n\n# jep 432\n\nrecord patterns  record record class\n\n instanceof  switch \n\n instanceof \n\n\n\nrecord shape(string type, long unit){}\n\n\n\n\nshape circle = new shape("circle", 10);\nif (circle instanceof shape shape) {\n\n  system.out.println("area of " + shape.type() + " is : " + math.pi * math.pow(shape.unit(), 2));\n}\n\n\n\n\nshape circle = new shape("circle", 10);\nif (circle instanceof shape(string type, long unit)) {\n  system.out.println("area of " + type + " is : " + math.pi * math.pow(unit, 2));\n}\n\n\n switch \n\n\n\ninterface shape {}\nrecord circle(double radius) implements shape { }\nrecord square(double side) implements shape { }\nrecord rectangle(double length, double width) implements shape { }\n\n\n\n\nshape shape = new circle(10);\nswitch (shape) {\n    case circle c:\n        system.out.println("the shape is circle with area: " + math.pi * c.radius() * c.radius());\n        break;\n\n    case square s:\n        system.out.println("the shape is square with area: " + s.side() * s.side());\n        break;\n\n    case rectangle r:\n        system.out.println("the shape is rectangle with area: + " + r.length() * r.width());\n        break;\n\n    default:\n        system.out.println("unknown shape");\n        break;\n}\n\n\n\n\nshape shape = new circle(10);\nswitch(shape) {\n\n  case circle(double radius):\n    system.out.println("the shape is circle with area: " + math.pi * radius * radius);\n    break;\n\n  case square(double side):\n    system.out.println("the shape is square with area: " + side * side);\n    break;\n\n  case rectangle(double length, double width):\n    system.out.println("the shape is rectangle with area: + " + length * width);\n    break;\n\n  default:\n    system.out.println("unknown shape");\n    break;\n}\n\n\n null  nullpointerexception\n\n java 19   jep 405 jdk 20  jep 432 \n\n * \n * for\n * \n\n jdk16 \n\n\n# jep 433switch \n\n instanceof  switch \n\ninstanceof \n\n// old code\nif (o instanceof string) {\n    string s = (string)o;\n    ... use s ...\n}\n\n// new code\nif (o instanceof string s) {\n    ... use s ...\n}\n\n\nswitch \n\n// old code\nstatic string formatter(object o) {\n    string formatted = "unknown";\n    if (o instanceof integer i) {\n        formatted = string.format("int %d", i);\n    } else if (o instanceof long l) {\n        formatted = string.format("long %d", l);\n    } else if (o instanceof double d) {\n        formatted = string.format("double %f", d);\n    } else if (o instanceof string s) {\n        formatted = string.format("string %s", s);\n    }\n    return formatted;\n}\n\n// new code\nstatic string formatterpatternswitch(object o) {\n    return switch (o) {\n        case integer i -> string.format("int %d", i);\n        case long l    -> string.format("long %d", l);\n        case double d  -> string.format("double %f", d);\n        case string s  -> string.format("string %s", s);\n        default        -> o.tostring();\n    };\n}\n\n\nswitch  java17java18java19 java20 \n\n\n# jep 434:  api\n\njava  api  java  jvm  jvm  api  java  jni \n\n api  java 17  jep 412 java 18 jep 419 java 19  jep 424 \n\njdk 20  jep 434 \n\n * memorysegment  memoryaddress \n *  memorylayout \n * memorysessionarenasegmentscope\n\n java 19   api\n\n\n# jep 436: \n\nvirtual thread jdk  os (lightweight processlwp jvm \n\njava.lang.thread jvm \n\nhow to use java 19 virtual threads\n\n\n\n windows  linux java solaris hotspot vm  solaris  r : jvm \n\n\n\n go  goroutineerlang \n\n java 19 https://www.zhihu.com/question/536743167 \n\njava \n\n * \n * java19  ga\n *  - virtualthread \n\n java 19 jep 425jdk 20 \n\n\n\n// 1 thread.ofvirtual() \nrunnable fn = () -> {\n  // your code here\n};\n\nthread thread = thread.ofvirtual(fn)\n                      .start();\n\n// 2 thread.startvirtualthread() \nthread thread = thread.startvirtualthread(() -> {\n  // your code here\n});\n\n// 3 executors.newvirtualthreadpertaskexecutor() \nvar executorservice = executors.newvirtualthreadpertaskexecutor();\n\nexecutorservice.submit(() -> {\n  // your code here\n});\n\nclass customthread implements runnable {\n  @override\n  public void run() {\n    system.out.println("customthread run");\n  }\n}\n\n//4 threadfactory \ncustomthread customthread = new customthread();\n// \nthreadfactory factory = thread.ofvirtual().factory();\n// \nthread thread = factory.newthread(customthread);\n// \nthread.start();\n\n\n 4  thread \n\n\n# jep 437: ()\n\njava 19  api java.util.concurrent\n\n\n\n api structuredtaskscopestructuredtaskscope \n\nstructuredtaskscope \n\n    try (var scope = new structuredtaskscope<object>()) {\n        // fork\n        future<integer> future1 = scope.fork(task1);\n        future<string> future2 = scope.fork(task2);\n        // \n        scope.join();\n        // \n        ... process results/exceptions ...\n    } // close\n\n\n jdk \n\njdk 20 structuredtaskscope jep 429\n\n\n# jep 432 api\n\n api  cpu \n\n api \n\nvector api  jep 338  api java 16  jep 414  java 17  jep 417  java 18  jep 426  java 19 \n\njava20  api  jep 438',charsets:{cjk:!0}},{title:"Java 21 ()",frontmatter:{title:"Java 21 ()",category:"Java",tag:["Java"],date:"2024-08-21T23:05:40.000Z",permalink:"/pages/54087b/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/13.java21.html",relativePath:"01.Java/05./13.java21.md",key:"v-79bcd990",path:"/pages/54087b/",headers:[{level:2,title:"JEP 430",slug:"jep-430--",normalizedTitle:"jep 430",charIndex:595},{level:2,title:"JEP431",slug:"jep431-",normalizedTitle:"jep431",charIndex:2624},{level:2,title:"JEP 439 ZGC",slug:"jep-439--zgc",normalizedTitle:"jep 439 zgc",charIndex:5627},{level:2,title:"JEP 440",slug:"jep-440-",normalizedTitle:"jep 440",charIndex:6291},{level:2,title:"JEP 441switch ",slug:"jep-441-switch-",normalizedTitle:"jep 441switch ",charIndex:6430},{level:2,title:"JEP 442:  API",slug:"jep-442--api-",normalizedTitle:"jep 442:  api",charIndex:6908},{level:2,title:"JEP 443",slug:"jep-443--",normalizedTitle:"jep 443",charIndex:7294},{level:2,title:"JEP 444",slug:"jep-444-",normalizedTitle:"jep 444",charIndex:7984},{level:2,title:"JEP 445 main  ",slug:"jep-445--main--",normalizedTitle:"jep 445 main  ",charIndex:8132},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:8591}],headersStr:"JEP 430 JEP431 JEP 439 ZGC JEP 440 JEP 441switch  JEP 442:  API JEP 443 JEP 444 JEP 445 main   ",content:'JDK 21  2023  9  19  \n\nJDK21  LTS JDK8JDK11JDK17  JDK21 \n\nJDK 21  15 \n\n * JEP 430String Templates\n\n * JEP 431Sequenced Collections\n\n * JEP 439Generational ZGC ZGC\n\n * JEP 440Record Patterns\n\n * JEP 441Pattern Matching for switchswitch \n\n * JEP 442Foreign Function & Memory API API\n\n * JEP 443Unnamed Patterns and Variables\n\n * JEP 444Virtual Threads\n\n * JEP 445Unnamed Classes and Instance Main Methods main  \n\n\n# JEP 430\n\nString Templates()  JDK 21 \n\nString Templates ${}Java /\n\nString Templates:\n\n"Greetings {{ name }}!";  //Angular\n`Greetings ${ name }!`;    //Typescript\n$"Greetings { name }!"    //Visual basic\nf"Greetings { name }!"    //Python\n\n\nJava  String Templates \n\n//concatenation\nmessage = "Greetings " + name + "!";\n\n//String.format()\nmessage = String.format("Greetings %s!", name);  //concatenation\n\n//MessageFormat\nmessage = new MessageFormat("Greetings {0}!").format(name);\n\n//StringBuilder\nmessage = new StringBuilder().append("Greetings ").append(name).append("!").toString();\n\n\n\n\nJava  String Templates \n\nString message = STR."Greetings \\{name}!";\n\n\n\n\n * STR \n * \\{name}\n\nJava \n\n * STR\n * FMT STR \n * RAW STR  FMT  StringTemplate \n\nString name = "Lokesh";\n\n//STR\nString message = STR."Greetings \\{name}.";\n\n//FMT\nString message = STR."Greetings %-12s\\{name}.";\n\n//RAW\nStringTemplate st = RAW."Greetings \\{name}.";\nString message = STR.process(st);\n\n\n JDK  StringTemplate.Processor  StringTemplate.Processor process \n\n/\n\n//variable\nmessage = STR."Greetings \\{name}!";\n\n//method\nmessage = STR."Greetings \\{getName()}!";\n\n//field\nmessage = STR."Greetings \\{this.name}!";\n\n\n\n\nint x = 10, y = 20;\nString s = STR."\\{x} + \\{y} = \\{x + y}";  //"10 + 20 = 30"\n\n\n:\n\nString time = STR."The current time is \\{\n    //sample comment - current time in HH:mm:ss\n    DateTimeFormatter\n      .ofPattern("HH:mm:ss")\n      .format(LocalTime.now())\n  }.";\n\n\n\n# JEP431\n\nJDK 21 Sequenced Collectionsencounter order\n\nSequenced Collections \n\n * SequencedCollection\n * SequencedSet\n * SequencedMap\n\nSequencedCollection  Collection \n\ninterface SequencedCollection<E> extends Collection<E> {\n\n  // New Method\n\n  SequencedCollection<E> reversed();\n\n  // Promoted methods from Deque<E>\n\n  void addFirst(E);\n  void addLast(E);\n\n  E getFirst();\n  E getLast();\n\n  E removeFirst();\n  E removeLast();\n}\n\n\nList  Deque SequencedCollection \n\n ArrayList \n\nArrayList<Integer> arrayList = new ArrayList<>();\n\narrayList.add(1);   // List contains: [1]\n\narrayList.addFirst(0);  // List contains: [0, 1]\narrayList.addLast(2);   // List contains: [0, 1, 2]\n\nInteger firstElement = arrayList.getFirst();  // 0\nInteger lastElement = arrayList.getLast();  // 2\n\nList<Integer> reversed = arrayList.reversed();\nSystem.out.println(reversed); // Prints [2, 1, 0]\n\n\nSequencedSet SequencedCollection  reversed() \n\ninterface SequencedSet<E> extends SequencedCollection<E>, Set<E> {\n\n    SequencedSet<E> reversed();\n}\n\n\nSortedSet  LinkedHashSet SequencedSet\n\n LinkedHashSet \n\nLinkedHashSet<Integer> linkedHashSet = new LinkedHashSet<>(List.of(1, 2, 3));\n\nInteger firstElement = linkedHashSet.getFirst();   // 1\nInteger lastElement = linkedHashSet.getLast();    // 3\n\nlinkedHashSet.addFirst(0);  //List contains: [0, 1, 2, 3]\nlinkedHashSet.addLast(4);   //List contains: [0, 1, 2, 3, 4]\n\nSystem.out.println(linkedHashSet.reversed());   //Prints [5, 3, 2, 1, 0]\n\n\nSequencedMap  Map  key  SequencedSet value  SequencedCollection entry  SequencedSet\n\ninterface SequencedMap<K,V> extends Map<K,V> {\n\n  // New Methods\n\n  SequencedMap<K,V> reversed();\n\n  SequencedSet<K> sequencedKeySet();\n  SequencedCollection<V> sequencedValues();\n  SequencedSet<Entry<K,V>> sequencedEntrySet();\n\n  V putFirst(K, V);\n  V putLast(K, V);\n\n\n  // Promoted Methods from NavigableMap<K, V>\n\n  Entry<K, V> firstEntry();\n  Entry<K, V> lastEntry();\n\n  Entry<K, V> pollFirstEntry();\n  Entry<K, V> pollLastEntry();\n}\n\n\nSortedMap LinkedHashMap SequencedMap \n\n LinkedHashMap \n\nLinkedHashMap<Integer, String> map = new LinkedHashMap<>();\n\nmap.put(1, "One");\nmap.put(2, "Two");\nmap.put(3, "Three");\n\nmap.firstEntry();   //1=One\nmap.lastEntry();    //3=Three\n\nSystem.out.println(map);  //{1=One, 2=Two, 3=Three}\n\nMap.Entry<Integer, String> first = map.pollFirstEntry();   //1=One\nMap.Entry<Integer, String> last = map.pollLastEntry();    //3=Three\n\nSystem.out.println(map);  //{2=Two}\n\nmap.putFirst(1, "One");     //{1=One, 2=Two}\nmap.putLast(3, "Three");    //{1=One, 2=Two, 3=Three}\n\nSystem.out.println(map);  //{1=One, 2=Two, 3=Three}\nSystem.out.println(map.reversed());   //{3=Three, 2=Two, 1=One}\n\n\n\n# JEP 439 ZGC\n\nJDK21  ZGC  GC \n\n// ZGC\njava -XX:+UseZGC -XX:+ZGenerational ...\n\n\n ZGenerational  ZGC  GC ZGC \n\n> In a future release we intend to make Generational ZGC the default, at which point -XX:-ZGenerational will select non-generational ZGC. In an even later release we intend to remove non-generational ZGC, at which point the ZGenerational option will become obsolete.\n> \n>  Generational ZGC -XX:-ZGenerational  ZGC ZGC ZGenerational \n\n ZGC  Java \n\n\n# JEP 440\n\n Java 19   JEP 405 JDK 20  JEP 432  JDK21 \n\nJava 20 \n\n\n# JEP 441switch \n\n Java  switch  case  case \n\nswitch \n\nstatic String formatterPatternSwitch(Object obj) {\n    return switch (obj) {\n        case Integer i -> String.format("int %d", i);\n        case Long l    -> String.format("long %d", l);\n        case Double d  -> String.format("double %f", d);\n        case String s  -> String.format("String %s", s);\n        default        -> obj.toString();\n    };\n}\n\n\n\n# JEP 442:  API\n\nJava  API  Java  JVM  JVM  API  Java  JNI \n\n API  Java 17  JEP 412 Java 18 JEP 419 Java 19  JEP 424 JDK 20  JEP 434 JDK 21  JEP 442 \n\n Java 19   API\n\n\n# JEP 443\n\n _ \n\n try-with-resources  catch for _\n\ntry (var _ = ScopedContext.acquire()) {\n  // No use of acquired resource\n}\ntry { ... }\ncatch (Exception _) { ... }\ncatch (Throwable _) { ... }\n\nfor (int i = 0, _ = runOnce(); i < arr.length; i++) {\n  ...\n}\n\n\n\n\nif (r instanceof ColoredPoint(_, Color c)) { ... c ... }\n\nswitch (b) {\n    case Box(RedBall _), Box(BlueBall _) -> processBox(b);\n    case Box(GreenBall _)                -> stopProcessing();\n    case Box(_)                          -> pickAnotherBox();\n}\n\n\n\n# JEP 444\n\n\n\n Java 19 JEP 425JDK 20  JDK21 \n\nJava 20 \n\n\n# JEP 445 main  \n\n main  Java  main  Java \n\n main \n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        System.out.println("Hello, World!");\n    }\n}\n\n\n main \n\nclass HelloWorld {\n    void main() {\n        System.out.println("Hello, World!");\n    }\n}\n\n\n()\n\nvoid main() {\n   System.out.println("Hello, World!");\n}\n\n\n\n# \n\n * Java 21 String Templateshttps://howtodoinjava.com/java/java-string-templates/\n * Java 21 Sequenced Collectionshttps://howtodoinjava.com/java/sequenced-collections/',normalizedContent:'jdk 21  2023  9  19  \n\njdk21  lts jdk8jdk11jdk17  jdk21 \n\njdk 21  15 \n\n * jep 430string templates\n\n * jep 431sequenced collections\n\n * jep 439generational zgc zgc\n\n * jep 440record patterns\n\n * jep 441pattern matching for switchswitch \n\n * jep 442foreign function & memory api api\n\n * jep 443unnamed patterns and variables\n\n * jep 444virtual threads\n\n * jep 445unnamed classes and instance main methods main  \n\n\n# jep 430\n\nstring templates()  jdk 21 \n\nstring templates ${}java /\n\nstring templates:\n\n"greetings {{ name }}!";  //angular\n`greetings ${ name }!`;    //typescript\n$"greetings { name }!"    //visual basic\nf"greetings { name }!"    //python\n\n\njava  string templates \n\n//concatenation\nmessage = "greetings " + name + "!";\n\n//string.format()\nmessage = string.format("greetings %s!", name);  //concatenation\n\n//messageformat\nmessage = new messageformat("greetings {0}!").format(name);\n\n//stringbuilder\nmessage = new stringbuilder().append("greetings ").append(name).append("!").tostring();\n\n\n\n\njava  string templates \n\nstring message = str."greetings \\{name}!";\n\n\n\n\n * str \n * \\{name}\n\njava \n\n * str\n * fmt str \n * raw str  fmt  stringtemplate \n\nstring name = "lokesh";\n\n//str\nstring message = str."greetings \\{name}.";\n\n//fmt\nstring message = str."greetings %-12s\\{name}.";\n\n//raw\nstringtemplate st = raw."greetings \\{name}.";\nstring message = str.process(st);\n\n\n jdk  stringtemplate.processor  stringtemplate.processor process \n\n/\n\n//variable\nmessage = str."greetings \\{name}!";\n\n//method\nmessage = str."greetings \\{getname()}!";\n\n//field\nmessage = str."greetings \\{this.name}!";\n\n\n\n\nint x = 10, y = 20;\nstring s = str."\\{x} + \\{y} = \\{x + y}";  //"10 + 20 = 30"\n\n\n:\n\nstring time = str."the current time is \\{\n    //sample comment - current time in hh:mm:ss\n    datetimeformatter\n      .ofpattern("hh:mm:ss")\n      .format(localtime.now())\n  }.";\n\n\n\n# jep431\n\njdk 21 sequenced collectionsencounter order\n\nsequenced collections \n\n * sequencedcollection\n * sequencedset\n * sequencedmap\n\nsequencedcollection  collection \n\ninterface sequencedcollection<e> extends collection<e> {\n\n  // new method\n\n  sequencedcollection<e> reversed();\n\n  // promoted methods from deque<e>\n\n  void addfirst(e);\n  void addlast(e);\n\n  e getfirst();\n  e getlast();\n\n  e removefirst();\n  e removelast();\n}\n\n\nlist  deque sequencedcollection \n\n arraylist \n\narraylist<integer> arraylist = new arraylist<>();\n\narraylist.add(1);   // list contains: [1]\n\narraylist.addfirst(0);  // list contains: [0, 1]\narraylist.addlast(2);   // list contains: [0, 1, 2]\n\ninteger firstelement = arraylist.getfirst();  // 0\ninteger lastelement = arraylist.getlast();  // 2\n\nlist<integer> reversed = arraylist.reversed();\nsystem.out.println(reversed); // prints [2, 1, 0]\n\n\nsequencedset sequencedcollection  reversed() \n\ninterface sequencedset<e> extends sequencedcollection<e>, set<e> {\n\n    sequencedset<e> reversed();\n}\n\n\nsortedset  linkedhashset sequencedset\n\n linkedhashset \n\nlinkedhashset<integer> linkedhashset = new linkedhashset<>(list.of(1, 2, 3));\n\ninteger firstelement = linkedhashset.getfirst();   // 1\ninteger lastelement = linkedhashset.getlast();    // 3\n\nlinkedhashset.addfirst(0);  //list contains: [0, 1, 2, 3]\nlinkedhashset.addlast(4);   //list contains: [0, 1, 2, 3, 4]\n\nsystem.out.println(linkedhashset.reversed());   //prints [5, 3, 2, 1, 0]\n\n\nsequencedmap  map  key  sequencedset value  sequencedcollection entry  sequencedset\n\ninterface sequencedmap<k,v> extends map<k,v> {\n\n  // new methods\n\n  sequencedmap<k,v> reversed();\n\n  sequencedset<k> sequencedkeyset();\n  sequencedcollection<v> sequencedvalues();\n  sequencedset<entry<k,v>> sequencedentryset();\n\n  v putfirst(k, v);\n  v putlast(k, v);\n\n\n  // promoted methods from navigablemap<k, v>\n\n  entry<k, v> firstentry();\n  entry<k, v> lastentry();\n\n  entry<k, v> pollfirstentry();\n  entry<k, v> polllastentry();\n}\n\n\nsortedmap linkedhashmap sequencedmap \n\n linkedhashmap \n\nlinkedhashmap<integer, string> map = new linkedhashmap<>();\n\nmap.put(1, "one");\nmap.put(2, "two");\nmap.put(3, "three");\n\nmap.firstentry();   //1=one\nmap.lastentry();    //3=three\n\nsystem.out.println(map);  //{1=one, 2=two, 3=three}\n\nmap.entry<integer, string> first = map.pollfirstentry();   //1=one\nmap.entry<integer, string> last = map.polllastentry();    //3=three\n\nsystem.out.println(map);  //{2=two}\n\nmap.putfirst(1, "one");     //{1=one, 2=two}\nmap.putlast(3, "three");    //{1=one, 2=two, 3=three}\n\nsystem.out.println(map);  //{1=one, 2=two, 3=three}\nsystem.out.println(map.reversed());   //{3=three, 2=two, 1=one}\n\n\n\n# jep 439 zgc\n\njdk21  zgc  gc \n\n// zgc\njava -xx:+usezgc -xx:+zgenerational ...\n\n\n zgenerational  zgc  gc zgc \n\n> in a future release we intend to make generational zgc the default, at which point -xx:-zgenerational will select non-generational zgc. in an even later release we intend to remove non-generational zgc, at which point the zgenerational option will become obsolete.\n> \n>  generational zgc -xx:-zgenerational  zgc zgc zgenerational \n\n zgc  java \n\n\n# jep 440\n\n java 19   jep 405 jdk 20  jep 432  jdk21 \n\njava 20 \n\n\n# jep 441switch \n\n java  switch  case  case \n\nswitch \n\nstatic string formatterpatternswitch(object obj) {\n    return switch (obj) {\n        case integer i -> string.format("int %d", i);\n        case long l    -> string.format("long %d", l);\n        case double d  -> string.format("double %f", d);\n        case string s  -> string.format("string %s", s);\n        default        -> obj.tostring();\n    };\n}\n\n\n\n# jep 442:  api\n\njava  api  java  jvm  jvm  api  java  jni \n\n api  java 17  jep 412 java 18 jep 419 java 19  jep 424 jdk 20  jep 434 jdk 21  jep 442 \n\n java 19   api\n\n\n# jep 443\n\n _ \n\n try-with-resources  catch for _\n\ntry (var _ = scopedcontext.acquire()) {\n  // no use of acquired resource\n}\ntry { ... }\ncatch (exception _) { ... }\ncatch (throwable _) { ... }\n\nfor (int i = 0, _ = runonce(); i < arr.length; i++) {\n  ...\n}\n\n\n\n\nif (r instanceof coloredpoint(_, color c)) { ... c ... }\n\nswitch (b) {\n    case box(redball _), box(blueball _) -> processbox(b);\n    case box(greenball _)                -> stopprocessing();\n    case box(_)                          -> pickanotherbox();\n}\n\n\n\n# jep 444\n\n\n\n java 19 jep 425jdk 20  jdk21 \n\njava 20 \n\n\n# jep 445 main  \n\n main  java  main  java \n\n main \n\npublic class helloworld {\n    public static void main(string[] args) {\n        system.out.println("hello, world!");\n    }\n}\n\n\n main \n\nclass helloworld {\n    void main() {\n        system.out.println("hello, world!");\n    }\n}\n\n\n()\n\nvoid main() {\n   system.out.println("hello, world!");\n}\n\n\n\n# \n\n * java 21 string templateshttps://howtodoinjava.com/java/java-string-templates/\n * java 21 sequenced collectionshttps://howtodoinjava.com/java/sequenced-collections/',charsets:{cjk:!0}},{title:"Spring",frontmatter:{title:"Spring",date:"2024-08-23T07:01:06.000Z",permalink:"/pages/be9ac8/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/06.SpringBoot/01.Spring%E6%BA%90%E7%A0%81.html",relativePath:"01.Java/06.SpringBoot/01.Spring.md",key:"v-1ccb3574",path:"/pages/be9ac8/",headersStr:null,content:" * \n\n * md\n\n * \n\n * \n\n * \n\n * 1\n\n * 2\n\n * maven",normalizedContent:" * \n\n * md\n\n * \n\n * \n\n * \n\n * 1\n\n * 2\n\n * maven",charsets:{cjk:!0}},{title:"",frontmatter:{title:"",date:"2024-08-26T17:38:32.000Z",permalink:"/pages/5b4265/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/06.SpringBoot/02.%E6%9D%83%E9%99%90%E6%A8%A1%E5%9E%8B.html",relativePath:"01.Java/06.SpringBoot/02..md",key:"v-4bad8eff",path:"/pages/5b4265/",headers:[{level:3,title:"RBAC: Role-Based Access Control",slug:"rbac-role-based-access-control",normalizedTitle:"rbac: role-based access control",charIndex:100},{level:3,title:"ABAC: Role-Based Access Control",slug:"abac-role-based-access-control",normalizedTitle:"abac: role-based access control",charIndex:166}],headersStr:"RBAC: Role-Based Access Control ABAC: Role-Based Access Control",content:"\n\n 1. : ,!\n 2. :\n\n * \n * :URL\n\n 3. ,RBACABAC\n\n\n# RBAC: Role-Based Access Control\n\n,  : \n\n\n# ABAC: Role-Based Access Control\n\n,,\n\n:",normalizedContent:"\n\n 1. : ,!\n 2. :\n\n * \n * :url\n\n 3. ,rbacabac\n\n\n# rbac: role-based access control\n\n,  : \n\n\n# abac: role-based access control\n\n,,\n\n:",charsets:{cjk:!0}},{title:"Cookie-Session-Token-JWT",frontmatter:{title:"Cookie-Session-Token-JWT",date:"2024-09-13T23:07:28.000Z",permalink:"/pages/c6bced/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/06.SpringBoot/03.Cookie-Session-Token-JWT.html",relativePath:"01.Java/06.SpringBoot/03.Cookie-Session-Token-JWT.md",key:"v-6ef6bf36",path:"/pages/c6bced/",headers:[{level:2,title:"Acesss Token",slug:"acesss-token",normalizedTitle:"acesss token",charIndex:3268},{level:2,title:"Refresh Token",slug:"refresh-token",normalizedTitle:"refresh token",charIndex:3896},{level:2,title:" JWT",slug:"-jwt",normalizedTitle:" jwt",charIndex:5316},{level:2,title:"JWT ",slug:"jwt-",normalizedTitle:"jwt ",charIndex:5357},{level:2,title:"JWT ",slug:"jwt-",normalizedTitle:"jwt ",charIndex:5793},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:5864},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:6331},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:6374},{level:2,title:" JWT",slug:"-jwt",normalizedTitle:" jwt",charIndex:6435},{level:2,title:" cookie ",slug:"-cookie-",normalizedTitle:" cookie ",charIndex:7627},{level:2,title:" session ",slug:"-session-",normalizedTitle:" session ",charIndex:7930},{level:2,title:" token ",slug:"-token-",normalizedTitle:" token ",charIndex:8448},{level:2,title:" JWT ",slug:"-jwt-",normalizedTitle:" jwt ",charIndex:8673},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:9274},{level:2,title:" session ",slug:"-session-",normalizedTitle:" session ",charIndex:9609},{level:3,title:"1\\. session ",slug:"_1-session-",normalizedTitle:"1. session ",charIndex:9633},{level:3,title:"2\\.  session /IP ",slug:"_2--session-ip-",normalizedTitle:"2.  session /ip ",charIndex:9841},{level:3,title:"3\\. session ",slug:"_3-session--",normalizedTitle:"3. session ",charIndex:10230},{level:3,title:"4\\. session ",slug:"_4-session-",normalizedTitle:"4. session ",charIndex:10552},{level:2,title:" session ",slug:"-session-",normalizedTitle:" session ",charIndex:10697}],headersStr:"Acesss Token Refresh Token  JWT JWT  JWT      JWT  cookie   session   token   JWT    session  1\\. session  2\\.  session /IP  3\\. session  4\\. session   session ",content:"#  CookieSessionTokenJWT\n\n:  juejin.im/post/5e055d9ef265da33997a42cc \n\n * Authentication\n * Authorization\n * Credentials\n *  Cookie\n *  Session\n * Cookie  Session \n *  Token\n * Token  Session \n *  JWT\n * Token  JWT \n * \n * \n * \n\n----------------------------------------\n\n\n# Authentication\n\n * \n * \n   * \n   * \n   * \n   * /\n\n\n# Authorization\n\n * \n   * APP \n   * \n * cookiesessiontokenOAuth\n\n\n# Credentials\n\n * \n   \n   \n   \n   \n   \n   \n   \n   * \n   * ///\n   * //token\n\n\n#  Cookie\n\n * HTTP  cookie  session \n * cookie  cookie \n * cookie   cookie  domain\n\ncookie \n\n\n\n\n\nname=value\n\n Cookie  -  Unicode  -  BASE64 \n\ndomain\n\n cookie \n\npath\n\n cookie  '/'  /abc /abc  cookie/abc/read\n\nmaxAge\n\ncookie  cookie  maxAge  cookie  cookie  cookie  0 cookie  -1 -  expires \n\nexpires\n\n cookie   cookie  cookie \n\nsecure\n\n cookie  HTTPSSSLfalse  secure  true cookie  HTTP  HTTPS \n\nhttpOnly\n\n cookie  httpOnly  JS   cookie  Application  cookie XSS \n\n\n#  Session\n\n * session \n * session  cookie session sessionId cookie \n\n\n\n * session \n   *  Session\n   *  Session  SessionID \n   *  SessionID  Cookie  Cookie  SessionID \n   *  Cookie  Cookie  Cookie  SessionID SessionID  Session  Session \n\nSessionID  Cookie  Session \n\n\n# Cookie  Session \n\n *  Session  Cookie Session Cookie \n * Cookie Session \n *  Cookie Session  Session \n *   Cookie  4KSession  Cookie\n\n\n#  Token\n\n\n# Acesss Token\n\n * API\n *  token  uid()time()signtoken \n * \n   * \n   * \n   * \n   * \n * token \n\n\n\n 1. \n 2. \n 3.  token  token \n 4.  token  cookie  localStorage \n 5.  token\n 6.  token \n\n *  token token  HTTP  Header \n *  token  token  token  session \n * token \n\n\n# Refresh Token\n\n *  tokenrefresh token\n * refresh token  access token  token refresh token access token refresh token refresh token  access token\n\n\n\n * Access Token  Acesss Token  Refresh Token  Token Refresh Token \n * Refresh Token  Acesss Token  Session \n\n\n# Token  Session \n\n * Session  Token APIToken \n * Session  Token  Token  Session  Session  Session \n *  Session  User  Session  SessionID  Token  OAuth Token      App  App  Token  AppSession  SessionID  User  App API  Token  App\n\n\n#  JWT\n\n * JSON Web Token JWT\n * \n * JWT  JSON RFC 7519JWT \n *  HMAC  RSA / JWT \n *  JSON Web Token  \n\n\n#  JWT\n\njwt.io/ www.jsonwebtoken.io/\n\n\n# JWT \n\n\n\n * JWT \n   * / JWT\n   *  token  localstorage cookie\n   *  Authorization Bearer  JWT\n\nAuthorization: Bearer\n\n *  Authorization  JWT \n *  JWT \n *  JWT  Cookie  API CORS\n * \n\n\n# JWT \n\n *  JWT Cookie  localStorage\n\n\n# \n\n *  Cookie  HTTP  Authorization  Bearer  JWT\n   \n   GET /calendar/v1/events\n   Host: api.example.com\n   Authorization: Bearer\n   \n   *  \n   *  Authorization  JWT \n   *  JWT \n   * JWT  API \n   *  JWT  Cookie  API CORS\n\n\n# \n\n *  JWT  POST \n\n\n# \n\n *  URL \n\nhttp://www.example.com/user?token=xxx\n\n\n#  JWT\n\n\n\n\n# Token  JWT \n\n\n\n * \n * \n * \n * \n\n\n\n * Token Token  Token \n * JWT  Token  Payload  JWT  JWT \n\n\n# \n\n 1. Session-Cookie\n 2. Token  JWTSSO\n 3. OAuth2.0\n\n\n# \n\n\n\n * (Hash Algorithm)\n * ()\n * \n   * \n   * \n   * \n   *  10  60  80  2  256 \n     * 2  128  340282366920938463463374607431768211456 10  39 \n     * 2  160  1.4615016373309029182036848327163e+48 10  48 \n     * 2  256  1.1579208923731619542357098500869  10  77  10  77 \n\n\n\n 1. RSA \n 2.  7  8 12.5%  128bit  256bit \n\n\n# \n\n\n#  cookie \n\n * \n * \n *  httpOnly \n *  cookie  4kb\n *  domain  path\n * cookie \n *  20 Cookie 300 Cookie\n *  cookie  session  cookie  token\n\n\n#  session \n\n *  session  session  session\n *  web  session  session  session  session \n *  session  cookie \n * sessionId  cookie  cookie  cookie   sessionId  url  url session  cookie \n *  cookie  session  cookie  token\n\n\n#  token \n\n *  token  redis  token \n * token \n * token  CSRF ( cookie )\n *  cookie  session  cookie  token\n\n\n#  JWT \n\n *  JWT  Cookie  API CORS\n * JWT  Token \n * JWT  JWT\n * JWT  JWT\n * JWT  Session JWT  Session  Token  Token  JWT \n * JWT JWT\n * JWT  JWT JWT JWT\n * JWT  HTTP  HTTPS \n\n\n# \n\n * \n *    Base64   \n *  MD5  SHA1 \n *    \n\n\n#  session \n\n\n# 1. session \n\n *  session  session  session  session \n\n  session    session \n\n\n# 2.  session /IP \n\n *  Ngnix  ip_hash  ip  A  session  A  A  session \n\n  session    session       Nginx  upstream  ip_hash  session\n\n\n# 3. session \n\n *  Memcached Redis  session Memcached  Redis \n *  session  Redis  Redis \n   *  session \n   *  Redis \n   *  session  session  Redis /\n   *  session  APP \n\n\n\n\n# 4. session \n\n *  session  session \n\n session    session \n\n\n#  session \n\n session  session log off  session  session  cookie  session id session id  session cookie  HTTP  session id  session  session  session  session  session \n\n\n# \n\n JWT\n\n\n# \n\n * /\n * ~~",normalizedContent:"#  cookiesessiontokenjwt\n\n:  juejin.im/post/5e055d9ef265da33997a42cc \n\n * authentication\n * authorization\n * credentials\n *  cookie\n *  session\n * cookie  session \n *  token\n * token  session \n *  jwt\n * token  jwt \n * \n * \n * \n\n----------------------------------------\n\n\n# authentication\n\n * \n * \n   * \n   * \n   * \n   * /\n\n\n# authorization\n\n * \n   * app \n   * \n * cookiesessiontokenoauth\n\n\n# credentials\n\n * \n   \n   \n   \n   \n   \n   \n   \n   * \n   * ///\n   * //token\n\n\n#  cookie\n\n * http  cookie  session \n * cookie  cookie \n * cookie   cookie  domain\n\ncookie \n\n\n\n\n\nname=value\n\n cookie  -  unicode  -  base64 \n\ndomain\n\n cookie \n\npath\n\n cookie  '/'  /abc /abc  cookie/abc/read\n\nmaxage\n\ncookie  cookie  maxage  cookie  cookie  cookie  0 cookie  -1 -  expires \n\nexpires\n\n cookie   cookie  cookie \n\nsecure\n\n cookie  httpssslfalse  secure  true cookie  http  https \n\nhttponly\n\n cookie  httponly  js   cookie  application  cookie xss \n\n\n#  session\n\n * session \n * session  cookie session sessionid cookie \n\n\n\n * session \n   *  session\n   *  session  sessionid \n   *  sessionid  cookie  cookie  sessionid \n   *  cookie  cookie  cookie  sessionid sessionid  session  session \n\nsessionid  cookie  session \n\n\n# cookie  session \n\n *  session  cookie session cookie \n * cookie session \n *  cookie session  session \n *   cookie  4ksession  cookie\n\n\n#  token\n\n\n# acesss token\n\n * api\n *  token  uid()time()signtoken \n * \n   * \n   * \n   * \n   * \n * token \n\n\n\n 1. \n 2. \n 3.  token  token \n 4.  token  cookie  localstorage \n 5.  token\n 6.  token \n\n *  token token  http  header \n *  token  token  token  session \n * token \n\n\n# refresh token\n\n *  tokenrefresh token\n * refresh token  access token  token refresh token access token refresh token refresh token  access token\n\n\n\n * access token  acesss token  refresh token  token refresh token \n * refresh token  acesss token  session \n\n\n# token  session \n\n * session  token apitoken \n * session  token  token  session  session  session \n *  session  user  session  sessionid  token  oauth token      app  app  token  appsession  sessionid  user  app api  token  app\n\n\n#  jwt\n\n * json web token jwt\n * \n * jwt  json rfc 7519jwt \n *  hmac  rsa / jwt \n *  json web token  \n\n\n#  jwt\n\njwt.io/ www.jsonwebtoken.io/\n\n\n# jwt \n\n\n\n * jwt \n   * / jwt\n   *  token  localstorage cookie\n   *  authorization bearer  jwt\n\nauthorization: bearer\n\n *  authorization  jwt \n *  jwt \n *  jwt  cookie  api cors\n * \n\n\n# jwt \n\n *  jwt cookie  localstorage\n\n\n# \n\n *  cookie  http  authorization  bearer  jwt\n   \n   get /calendar/v1/events\n   host: api.example.com\n   authorization: bearer\n   \n   *  \n   *  authorization  jwt \n   *  jwt \n   * jwt  api \n   *  jwt  cookie  api cors\n\n\n# \n\n *  jwt  post \n\n\n# \n\n *  url \n\nhttp://www.example.com/user?token=xxx\n\n\n#  jwt\n\n\n\n\n# token  jwt \n\n\n\n * \n * \n * \n * \n\n\n\n * token token  token \n * jwt  token  payload  jwt  jwt \n\n\n# \n\n 1. session-cookie\n 2. token  jwtsso\n 3. oauth2.0\n\n\n# \n\n\n\n * (hash algorithm)\n * ()\n * \n   * \n   * \n   * \n   *  10  60  80  2  256 \n     * 2  128  340282366920938463463374607431768211456 10  39 \n     * 2  160  1.4615016373309029182036848327163e+48 10  48 \n     * 2  256  1.1579208923731619542357098500869  10  77  10  77 \n\n\n\n 1. rsa \n 2.  7  8 12.5%  128bit  256bit \n\n\n# \n\n\n#  cookie \n\n * \n * \n *  httponly \n *  cookie  4kb\n *  domain  path\n * cookie \n *  20 cookie 300 cookie\n *  cookie  session  cookie  token\n\n\n#  session \n\n *  session  session  session\n *  web  session  session  session  session \n *  session  cookie \n * sessionid  cookie  cookie  cookie   sessionid  url  url session  cookie \n *  cookie  session  cookie  token\n\n\n#  token \n\n *  token  redis  token \n * token \n * token  csrf ( cookie )\n *  cookie  session  cookie  token\n\n\n#  jwt \n\n *  jwt  cookie  api cors\n * jwt  token \n * jwt  jwt\n * jwt  jwt\n * jwt  session jwt  session  token  token  jwt \n * jwt jwt\n * jwt  jwt jwt jwt\n * jwt  http  https \n\n\n# \n\n * \n *    base64   \n *  md5  sha1 \n *    \n\n\n#  session \n\n\n# 1. session \n\n *  session  session  session  session \n\n  session    session \n\n\n# 2.  session /ip \n\n *  ngnix  ip_hash  ip  a  session  a  a  session \n\n  session    session       nginx  upstream  ip_hash  session\n\n\n# 3. session \n\n *  memcached redis  session memcached  redis \n *  session  redis  redis \n   *  session \n   *  redis \n   *  session  session  redis /\n   *  session  app \n\n\n\n\n# 4. session \n\n *  session  session \n\n session    session \n\n\n#  session \n\n session  session log off  session  session  cookie  session id session id  session cookie  http  session id  session  session  session  session  session \n\n\n# \n\n jwt\n\n\n# \n\n * /\n * ~~",charsets:{cjk:!0}},{title:"-coursera",frontmatter:{title:"-coursera",date:"2024-08-21T17:12:36.000Z",permalink:"/pages/3c4623/"},regularPath:"/03.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/01.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BEcoursera.html",relativePath:"03./01.-coursera.md",key:"v-c290b01e",path:"/pages/3c4623/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"",frontmatter:{title:"",date:"2024-08-13T16:19:12.000Z",permalink:"/pages/cb2190/"},regularPath:"/03.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/02.%E5%90%B4%E6%81%A9%E8%BE%BE%EF%BC%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%85%AD%E4%B8%AA%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95.html",relativePath:"03./02..md",key:"v-e70761c4",path:"/pages/cb2190/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"",frontmatter:{title:"",date:"2023-09-06T15:03:26.000Z",permalink:"/pages/8448ab/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/01.%E6%80%BB%E8%A7%88.html",relativePath:"04./02./01..md",key:"v-660b1f27",path:"/pages/8448ab/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/09/06, 16:05:49",lastUpdatedTimestamp:1693987549e3},{title:"Program",frontmatter:{title:"Program",date:"2023-09-06T15:29:54.000Z",permalink:"/pages/372b2d/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/02.Program%E5%85%A5%E5%8F%A3.html",relativePath:"04./02./02.Program.md",key:"v-80aef426",path:"/pages/372b2d/",headersStr:null,content:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/02-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%20%EF%BC%88Program%EF%BC%89.xmind\n\n",normalizedContent:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/02-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%20%ef%bc%88program%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"",frontmatter:{title:"",article:!1,date:"2023-04-15T17:04:40.000Z",permalink:"/pages/f8be69/"},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/01.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/01.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE.html",relativePath:"04./01./01..md",key:"v-639a0f7a",path:"/pages/f8be69/",headersStr:null,content:"\n\nhttps://roadmap.sh/aspnet-core\n\n",normalizedContent:"\n\nhttps://roadmap.sh/aspnet-core\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:05:49",lastUpdatedTimestamp:1693987549e3},{title:"WebApplication",frontmatter:{title:"WebApplication",date:"2023-09-06T15:29:54.000Z",permalink:"/pages/cb2fbc/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/03.WebApplication%E4%B8%BB%E6%9C%BA.html",relativePath:"04./02./03.WebApplication.md",key:"v-03a6f1e0",path:"/pages/cb2fbc/",headersStr:null,content:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/03-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%20%EF%BC%88WebApplication%EF%BC%89.xmind\n\n",normalizedContent:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/03-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%20%ef%bc%88webapplication%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"Host",frontmatter:{title:"Host",date:"2023-09-06T15:29:54.000Z",permalink:"/pages/78c443/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/04.Host%E4%B8%BB%E6%9C%BA.html",relativePath:"04./02./04.Host.md",key:"v-4e919d70",path:"/pages/78c443/",headersStr:null,content:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/04-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%20%EF%BC%88Host%EF%BC%89.xmind\n\n",normalizedContent:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/04-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%20%ef%bc%88host%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"WebHost",frontmatter:{title:"WebHost",date:"2023-09-06T15:29:54.000Z",permalink:"/pages/840f86/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/05.WebHost%E4%B8%BB%E6%9C%BA.html",relativePath:"04./02./05.WebHost.md",key:"v-4f7e5a56",path:"/pages/840f86/",headersStr:null,content:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/05-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%20%EF%BC%88WebHost%EF%BC%89.xmind\n\n",normalizedContent:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/05-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%20%ef%bc%88webhost%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"",frontmatter:{title:"",date:"2023-09-06T15:29:53.000Z",permalink:"/pages/0d115d/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/06.%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5.html",relativePath:"04./02./06..md",key:"v-f7980a44",path:"/pages/0d115d/",headersStr:null,content:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/06-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%EF%BC%89.xmind\n\n",normalizedContent:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/06-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88%e4%be%9d%e8%b5%96%e6%b3%a8%e5%85%a5%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"Autofac",frontmatter:{title:"Autofac",date:"2023-09-06T15:33:02.000Z",permalink:"/pages/e2d1de/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/07.Autofac.html",relativePath:"04./02./07.Autofac.md",key:"v-039b7178",path:"/pages/e2d1de/",headersStr:null,content:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/07-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88Autofac%EF%BC%89.xmind\n\n",normalizedContent:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/07-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88autofac%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"Middleware",frontmatter:{title:"Middleware",date:"2023-09-06T15:33:02.000Z",article:!1,permalink:"/pages/899977/"},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/08.Middleware%E4%B8%AD%E9%97%B4%E4%BB%B6.html",relativePath:"04./02./08.Middleware.md",key:"v-5459eecd",path:"/pages/899977/",headersStr:null,content:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/08-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88Middleware%EF%BC%89.xmind\n\n",normalizedContent:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/08-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88middleware%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"RateLimiter",frontmatter:{title:"RateLimiter",date:"2023-09-06T15:33:02.000Z",article:!1,permalink:"/pages/5991be/"},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/09.RateLimiter%E9%99%90%E5%88%B6%E9%80%9F%E7%8E%87.html",relativePath:"04./02./09.RateLimiter.md",key:"v-27c64bc0",path:"/pages/5991be/",headersStr:null,content:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/09-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88%E9%99%90%E5%88%B6%E9%80%9F%E7%8E%87%E4%B8%AD%E9%97%B4%E4%BB%B6%EF%BC%89.xmind\n\n",normalizedContent:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/09-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88%e9%99%90%e5%88%b6%e9%80%9f%e7%8e%87%e4%b8%ad%e9%97%b4%e4%bb%b6%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"",frontmatter:{title:"",date:"2023-09-06T15:33:02.000Z",article:!1,permalink:"/pages/bacc57/"},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/10.%E5%93%8D%E5%BA%94%E7%BC%93%E5%AD%98%E8%AF%B7%E6%B1%82%E8%A7%A3%E5%8E%8B%E7%BC%A9.html",relativePath:"04./02./10..md",key:"v-cd219960",path:"/pages/bacc57/",headersStr:null,content:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/10-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88%E5%93%8D%E5%BA%94%E7%BC%93%E5%AD%98%26%E8%AF%B7%E6%B1%82%E8%A7%A3%E5%8E%8B%E7%BC%A9%EF%BC%89.xmind\n\n",normalizedContent:"\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/10-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88%e5%93%8d%e5%ba%94%e7%bc%93%e5%ad%98%26%e8%af%b7%e6%b1%82%e8%a7%a3%e5%8e%8b%e7%bc%a9%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"",frontmatter:{title:"",article:!1,date:"2023-04-15T17:04:41.000Z",permalink:"/pages/e50dff/"},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/01.%E5%BC%80%E6%BA%90%E7%AE%80%E4%BB%8B.html",relativePath:"05.&/01.Docker/01..md",key:"v-0b12933a",path:"/pages/e50dff/",headers:[{level:2,title:"",slug:"",normalizedTitle:"",charIndex:2}],headersStr:"",content:"# \n\n * [x] AdminerMySQL \n * [x] ApacheAPISIX  API \n * [x] Apollo\n * [ ] Atlassian\n * [x] CassandraNoSQL\n * [x] CerebroElasticSearch\n * [x] ClickhouseOLAP\n * [x] Consul\n * [x] Easymock\n * [x] Elasticseasrch\n * [x] Emqx MQTT \n * [x] FastDFS\n * [x] Flink\n * [x] Gitlab\n * [x] Jenkins\n * [x] JrebelIDEA\n * [x] MariaDB(RDBS)\n * [x] MySQL(RDBS)\n * [x] Percona(RDBS)\n * [x] PhpMyAdminWebMySQL \n * [x] PostgreSQLORDBMS\n * [x] Rediskey-value",normalizedContent:"# \n\n * [x] adminermysql \n * [x] apacheapisix  api \n * [x] apollo\n * [ ] atlassian\n * [x] cassandranosql\n * [x] cerebroelasticsearch\n * [x] clickhouseolap\n * [x] consul\n * [x] easymock\n * [x] elasticseasrch\n * [x] emqx mqtt \n * [x] fastdfs\n * [x] flink\n * [x] gitlab\n * [x] jenkins\n * [x] jrebelidea\n * [x] mariadb(rdbs)\n * [x] mysql(rdbs)\n * [x] percona(rdbs)\n * [x] phpmyadminwebmysql \n * [x] postgresqlordbms\n * [x] rediskey-value",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"",frontmatter:{title:"",date:"2024-08-11T15:47:44.000Z",permalink:"/pages/f1d3fb/"},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/02.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BEcoursera.html",relativePath:"05.&/01.Docker/02.-coursera.md",key:"v-7b9db9b6",path:"/pages/f1d3fb/",headers:[{level:3,title:"(Introduction)",slug:"-introduction",normalizedTitle:"(introduction)",charIndex:10},{level:4,title:"1.1 ",slug:"_1-1-",normalizedTitle:"1.1 ",charIndex:63},{level:5,title:"1.2 ",slug:"_1-2-",normalizedTitle:"1.2 ",charIndex:73},{level:5,title:"1.3 ",slug:"_1-3-",normalizedTitle:"1.3 ",charIndex:772},{level:2,title:"Jupyter ",slug:"jupyter-",normalizedTitle:"jupyter ",charIndex:1605},{level:4,title:" usahousingprice.csv",slug:"-usa-housing-price-csv",normalizedTitle:" usahousingprice.csv",charIndex:null},{level:5,title:"1.4 ",slug:"_1-4-",normalizedTitle:"1.4 ",charIndex:1650},{level:4,title:"(Linear Regression with One Variable)",slug:"-linear-regression-with-one-variable",normalizedTitle:"(linear regression with one variable)",charIndex:2336},{level:5,title:"2.1 ",slug:"_2-1-",normalizedTitle:"2.1 ",charIndex:2386},{level:5,title:"2.2 ",slug:"_2-2-",normalizedTitle:"2.2 ",charIndex:2398},{level:5,title:"2.3 I",slug:"_2-3-i",normalizedTitle:"2.3 i",charIndex:2412},{level:5,title:"2.4 II",slug:"_2-4-ii",normalizedTitle:"2.4 ii",charIndex:2430},{level:5,title:"2.5 ",slug:"_2-5-",normalizedTitle:"2.5 ",charIndex:2449},{level:5,title:"2.6 ",slug:"_2-6-",normalizedTitle:"2.6 ",charIndex:2461},{level:5,title:"2.7 ",slug:"_2-7-",normalizedTitle:"2.7 ",charIndex:2478},{level:5,title:"2.8 ",slug:"_2-8-",normalizedTitle:"2.8 ",charIndex:2495},{level:5,title:"(Linear Algebra Review)",slug:"-linear-algebra-review",normalizedTitle:"(linear algebra review)",charIndex:2509},{level:5,title:"3.1 ",slug:"_3-1-",normalizedTitle:"3.1 ",charIndex:2544},{level:5,title:"3.2 ",slug:"_3-2-",normalizedTitle:"3.2 ",charIndex:2557},{level:5,title:"3.3 ",slug:"_3-3-",normalizedTitle:"3.3 ",charIndex:2572},{level:5,title:"3.4 ",slug:"_3-4-",normalizedTitle:"3.4 ",charIndex:2586},{level:5,title:"3.5 ",slug:"_3-5-",normalizedTitle:"3.5 ",charIndex:2598},{level:5,title:"3.6 ",slug:"_3-6-",normalizedTitle:"3.6 ",charIndex:2613}],headersStr:"(Introduction) 1.1  1.2  1.3  Jupyter   usahousingprice.csv 1.4  (Linear Regression with One Variable) 2.1  2.2  2.3 I 2.4 II 2.5  2.6  2.7  2.8  (Linear Algebra Review) 3.1  3.2  3.3  3.4  3.5  3.6 ",content:"# \n\n\n# (Introduction)\n\n> \n\n# 1.1 \n\n# 1.2 \n\n * Arthur SamuelSamuel50\n * Tom MitchellTomETPEPTE T P\n\n> \n\n# 1.3 \n\n, , , , , , .\n\n\n\n: x(y), xy, x, y\n\n\n\n 750\n\n\n\n$150000$200000\n\n \n\n\n\n\n# Jupyter \n\n\n\n#  usa_housing_price.csv\n\n# 1.4 \n\n\n\n\n\n 1. Clustering\n    * \n    * DNA \n    * \n    * \n    * \n 2. Non-clustering\n    * \n\n\n\nURLnews.google.com\n\n\n\n# (Linear Regression with One Variable)\n\n# 2.1 \n\n# 2.2 \n\n\n\n# 2.3 I\n\n# 2.4 II\n\n# 2.5 \n\n# 2.6 \n\n# 2.7 \n\n# 2.8 \n\n# (Linear Algebra Review)\n\n# 3.1 \n\n# 3.2 \n\n# 3.3 \n\n# 3.4 \n\n# 3.5 \n\n# 3.6 ",normalizedContent:"# \n\n\n# (introduction)\n\n> \n\n# 1.1 \n\n# 1.2 \n\n * arthur samuelsamuel50\n * tom mitchelltometpepte t p\n\n> \n\n# 1.3 \n\n, , , , , , .\n\n\n\n: x(y), xy, x, y\n\n\n\n 750\n\n\n\n$150000$200000\n\n \n\n\n\n\n# jupyter \n\n\n\n#  usa_housing_price.csv\n\n# 1.4 \n\n\n\n\n\n 1. clustering\n    * \n    * dna \n    * \n    * \n    * \n 2. non-clustering\n    * \n\n\n\nurlnews.google.com\n\n\n\n# (linear regression with one variable)\n\n# 2.1 \n\n# 2.2 \n\n\n\n# 2.3 i\n\n# 2.4 ii\n\n# 2.5 \n\n# 2.6 \n\n# 2.7 \n\n# 2.8 \n\n# (linear algebra review)\n\n# 3.1 \n\n# 3.2 \n\n# 3.3 \n\n# 3.4 \n\n# 3.5 \n\n# 3.6 ",charsets:{cjk:!0}},{title:"Apisix",frontmatter:{title:"Apisix",date:"2023-09-05T13:32:15.000Z",permalink:"/pages/fbe42b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/03.Apisix.html",relativePath:"05.&/01.Docker/03.Apisix.md",key:"v-098edc32",path:"/pages/fbe42b/",headers:[{level:2,title:"Apache APISIX  API ",slug:"apache-apisix--api-",normalizedTitle:"apache apisix  api ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:109},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:312},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:806},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1049},{level:2,title:"apisix_conf/config.yaml",slug:"apisix-conf-config-yaml",normalizedTitle:"apisix_conf/config.yaml",charIndex:1519},{level:2,title:"dashboard_conf/conf.yaml",slug:"dashboard-conf-conf-yaml",normalizedTitle:"dashboard_conf/conf.yaml",charIndex:1250},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:6483}],headersStr:"Apache APISIX  API     docker-compose.yml apisix_conf/config.yaml dashboard_conf/conf.yaml deploy.sh",content:'# Apache APISIX  API \n\n\n\nhttps://apisix.apache.org/\n\ngithubhttps://github.com/apache/apisix\n\n\n# \n\n> Apache APISIX  Apache  API  Apache APISIX  K8s Ingress Controller \n\n\n# \n\n * APISIX  Kubernetes  AWS LambdaAzure FunctionLua  Apache OpenWhisk \n * APISIX  APISIX  Apache APISIX  Nginx + Lua \n * APISIX  NGINX \n * APISIX HashiCorp VaultZipkinApache SkyWalkingConsulNacosEureka APISIX Dashboard UI  APISIX\n * APISIX  SDK \n\n\n# \n\n Apache APISIX \n\n\n\n APISIX \n\n/       \nRoute       \nUpstream    \nAdmin API    Admin API  APISIX \n\n\n# docker-compose.yml\n\nversion: \'3.7\'\nservices: \n  apisix-dashboard:\n    image: apache/apisix-dashboard:2.13-alpine\n    container_name: apisix-dashboard\n    restart: always\n    volumes:\n    - /etc/apisix/dashboard_conf/conf.yaml:/usr/local/apisix-dashboard/conf/conf.yaml\n    ports:\n    - "9000:9000"\n\n  apisix:\n    image: apache/apisix:2.15.0-alpine\n    container_name: apisix\n    restart: always\n    volumes:\n      - apisix_log:/usr/local/apisix/logs\n      - /etc/apisix/apisix_conf/config.yaml:/usr/local/apisix/conf/config.yaml:ro\n    depends_on:\n      - etcd\n    ##network_mode: host\n    ports:\n      - "9080:9080/tcp"\n      - "9091:9091/tcp"\n      - "9443:9443/tcp"\n      - "9092:9092/tcp"\n\n  etcd:\n    image: bitnami/etcd:3.4.14\n    container_name: etcd\n    restart: always\n    volumes:\n      - etcd:/bitnami/etcd\n    environment:\n      ETCD_ENABLE_V2: "true"\n      ALLOW_NONE_AUTHENTICATION: "yes"\n      ETCD_ADVERTISE_CLIENT_URLS: "http://0.0.0.0:2379"\n      ETCD_LISTEN_CLIENT_URLS: "http://0.0.0.0:2379"\n    ports:\n      - "2379:2379/tcp"\n\nvolumes: \n  apisix_log: \n  etcd: \n\n\n\n# apisix_conf/config.yaml\n\napisix:\n  node_listen: 9080              # APISIX listening port\n  enable_ipv6: false\n\n  allow_admin:                  # http://nginx.org/en/docs/http/ngx_http_access_module.html#allow\n    - 0.0.0.0/0              # We need to restrict ip access rules for security. 0.0.0.0/0 is for test.\n\n  admin_key:\n    - name: "admin"\n      key: edd1c9f034335f136f87ad84b625c8f1\n      role: admin                 # admin: manage all configuration data\n                                  # viewer: only can view configuration data\n    - name: "viewer"\n      key: 4054f7cf07e344346cd3f287985e76a2\n      role: viewer\n  \n  enable_control: true\n  control:\n    ip: "0.0.0.0"\n    port: 9092\n\netcd:\n  host:                           # it\'s possible to define multiple etcd hosts addresses of the same etcd cluster.\n    - "http://etcd:2379"     # multiple etcd address\n  prefix: "/apisix"               # apisix configurations prefix\n  timeout: 30                     # 30 seconds\n\nplugin_attr:\n  prometheus:\n    export_addr:\n      ip: "0.0.0.0"\n      port: 9091\n\n\n\n# dashboard_conf/conf.yaml\n\nconf:\n  listen:\n    host: 0.0.0.0     # `manager api` listening ip or host name\n    port: 9000          # `manager api` listening port\n  allow_list:           # If we don\'t set any IP list, then any IP access is allowed by default.\n    - 0.0.0.0/0\n  etcd:\n    endpoints:          # supports defining multiple etcd host addresses for an etcd cluster\n      - "http://etcd:2379"\n                          # yamllint disable rule:comments-indentation\n                          # etcd basic auth info\n    # username: "root"    # ignore etcd username if not enable etcd auth\n    # password: "123456"  # ignore etcd password if not enable etcd auth\n    mtls:\n      key_file: ""          # Path of your self-signed client side key\n      cert_file: ""         # Path of your self-signed client side cert\n      ca_file: ""           # Path of your self-signed ca cert, the CA is used to sign callers\' certificates\n    # prefix: /apisix     # apisix config\'s prefix in etcd, /apisix by default\n  log:\n    error_log:\n      level: warn       # supports levels, lower to higher: debug, info, warn, error, panic, fatal\n      file_path:\n        logs/error.log  # supports relative path, absolute path, standard output\n                        # such as: logs/error.log, /tmp/logs/error.log, /dev/stdout, /dev/stderr\n    access_log:\n      file_path:\n        logs/access.log  # supports relative path, absolute path, standard output\n                         # such as: logs/access.log, /tmp/logs/access.log, /dev/stdout, /dev/stderr\n                         # log example: 2020-12-09T16:38:09.039+0800\tINFO\tfilter/logging.go:46\t/apisix/admin/routes/r1\t{"status": 401, "host": "127.0.0.1:9000", "query": "asdfsafd=adf&a=a", "requestId": "3d50ecb8-758c-46d1-af5b-cd9d1c820156", "latency": 0, "remoteIP": "127.0.0.1", "method": "PUT", "errs": []}\nauthentication:\n  secret:\n    secret              # secret for jwt token generation.\n                        # NOTE: Highly recommended to modify this value to protect `manager api`.\n                        # if it\'s default value, when `manager api` start, it will generate a random string to replace it.\n  expire_time: 3600     # jwt token expire time, in second\n  users:                # yamllint enable rule:comments-indentation\n    - username: admin   # username and password for login `manager api`\n      password: admin\n    - username: user\n      password: user\n\nplugins:                          # plugin list (sorted in alphabetical order)\n  - api-breaker\n  - authz-keycloak\n  - basic-auth\n  - batch-requests\n  - consumer-restriction\n  - cors\n  # - dubbo-proxy\n  - echo\n  # - error-log-logger\n  # - example-plugin\n  - fault-injection\n  - grpc-transcode\n  - hmac-auth\n  - http-logger\n  - ip-restriction\n  - jwt-auth\n  - kafka-logger\n  - key-auth\n  - limit-conn\n  - limit-count\n  - limit-req\n  # - log-rotate\n  # - node-status\n  - openid-connect\n  - prometheus\n  - proxy-cache\n  - proxy-mirror\n  - proxy-rewrite\n  - redirect\n  - referer-restriction\n  - request-id\n  - request-validation\n  - response-rewrite\n  - serverless-post-function\n  - serverless-pre-function\n  # - skywalking\n  - sls-logger\n  - syslog\n  - tcp-logger\n  - udp-logger\n  - uri-blocker\n  - wolf-rbac\n  - zipkin\n  - server-info\n  - traffic-split\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/apisix/dashboard_conf\nmkdir -p /etc/apisix/apisix_conf\n\\cp ./dashboard_conf/conf.yaml /etc/apisix/dashboard_conf/conf.yaml -f\n\\cp ./apisix_conf/config.yaml /etc/apisix//apisix_conf/config.yaml -f\ndocker-compose up -d\n',normalizedContent:'# apache apisix  api \n\n\n\nhttps://apisix.apache.org/\n\ngithubhttps://github.com/apache/apisix\n\n\n# \n\n> apache apisix  apache  api  apache apisix  k8s ingress controller \n\n\n# \n\n * apisix  kubernetes  aws lambdaazure functionlua  apache openwhisk \n * apisix  apisix  apache apisix  nginx + lua \n * apisix  nginx \n * apisix hashicorp vaultzipkinapache skywalkingconsulnacoseureka apisix dashboard ui  apisix\n * apisix  sdk \n\n\n# \n\n apache apisix \n\n\n\n apisix \n\n/       \nroute       \nupstream    \nadmin api    admin api  apisix \n\n\n# docker-compose.yml\n\nversion: \'3.7\'\nservices: \n  apisix-dashboard:\n    image: apache/apisix-dashboard:2.13-alpine\n    container_name: apisix-dashboard\n    restart: always\n    volumes:\n    - /etc/apisix/dashboard_conf/conf.yaml:/usr/local/apisix-dashboard/conf/conf.yaml\n    ports:\n    - "9000:9000"\n\n  apisix:\n    image: apache/apisix:2.15.0-alpine\n    container_name: apisix\n    restart: always\n    volumes:\n      - apisix_log:/usr/local/apisix/logs\n      - /etc/apisix/apisix_conf/config.yaml:/usr/local/apisix/conf/config.yaml:ro\n    depends_on:\n      - etcd\n    ##network_mode: host\n    ports:\n      - "9080:9080/tcp"\n      - "9091:9091/tcp"\n      - "9443:9443/tcp"\n      - "9092:9092/tcp"\n\n  etcd:\n    image: bitnami/etcd:3.4.14\n    container_name: etcd\n    restart: always\n    volumes:\n      - etcd:/bitnami/etcd\n    environment:\n      etcd_enable_v2: "true"\n      allow_none_authentication: "yes"\n      etcd_advertise_client_urls: "http://0.0.0.0:2379"\n      etcd_listen_client_urls: "http://0.0.0.0:2379"\n    ports:\n      - "2379:2379/tcp"\n\nvolumes: \n  apisix_log: \n  etcd: \n\n\n\n# apisix_conf/config.yaml\n\napisix:\n  node_listen: 9080              # apisix listening port\n  enable_ipv6: false\n\n  allow_admin:                  # http://nginx.org/en/docs/http/ngx_http_access_module.html#allow\n    - 0.0.0.0/0              # we need to restrict ip access rules for security. 0.0.0.0/0 is for test.\n\n  admin_key:\n    - name: "admin"\n      key: edd1c9f034335f136f87ad84b625c8f1\n      role: admin                 # admin: manage all configuration data\n                                  # viewer: only can view configuration data\n    - name: "viewer"\n      key: 4054f7cf07e344346cd3f287985e76a2\n      role: viewer\n  \n  enable_control: true\n  control:\n    ip: "0.0.0.0"\n    port: 9092\n\netcd:\n  host:                           # it\'s possible to define multiple etcd hosts addresses of the same etcd cluster.\n    - "http://etcd:2379"     # multiple etcd address\n  prefix: "/apisix"               # apisix configurations prefix\n  timeout: 30                     # 30 seconds\n\nplugin_attr:\n  prometheus:\n    export_addr:\n      ip: "0.0.0.0"\n      port: 9091\n\n\n\n# dashboard_conf/conf.yaml\n\nconf:\n  listen:\n    host: 0.0.0.0     # `manager api` listening ip or host name\n    port: 9000          # `manager api` listening port\n  allow_list:           # if we don\'t set any ip list, then any ip access is allowed by default.\n    - 0.0.0.0/0\n  etcd:\n    endpoints:          # supports defining multiple etcd host addresses for an etcd cluster\n      - "http://etcd:2379"\n                          # yamllint disable rule:comments-indentation\n                          # etcd basic auth info\n    # username: "root"    # ignore etcd username if not enable etcd auth\n    # password: "123456"  # ignore etcd password if not enable etcd auth\n    mtls:\n      key_file: ""          # path of your self-signed client side key\n      cert_file: ""         # path of your self-signed client side cert\n      ca_file: ""           # path of your self-signed ca cert, the ca is used to sign callers\' certificates\n    # prefix: /apisix     # apisix config\'s prefix in etcd, /apisix by default\n  log:\n    error_log:\n      level: warn       # supports levels, lower to higher: debug, info, warn, error, panic, fatal\n      file_path:\n        logs/error.log  # supports relative path, absolute path, standard output\n                        # such as: logs/error.log, /tmp/logs/error.log, /dev/stdout, /dev/stderr\n    access_log:\n      file_path:\n        logs/access.log  # supports relative path, absolute path, standard output\n                         # such as: logs/access.log, /tmp/logs/access.log, /dev/stdout, /dev/stderr\n                         # log example: 2020-12-09t16:38:09.039+0800\tinfo\tfilter/logging.go:46\t/apisix/admin/routes/r1\t{"status": 401, "host": "127.0.0.1:9000", "query": "asdfsafd=adf&a=a", "requestid": "3d50ecb8-758c-46d1-af5b-cd9d1c820156", "latency": 0, "remoteip": "127.0.0.1", "method": "put", "errs": []}\nauthentication:\n  secret:\n    secret              # secret for jwt token generation.\n                        # note: highly recommended to modify this value to protect `manager api`.\n                        # if it\'s default value, when `manager api` start, it will generate a random string to replace it.\n  expire_time: 3600     # jwt token expire time, in second\n  users:                # yamllint enable rule:comments-indentation\n    - username: admin   # username and password for login `manager api`\n      password: admin\n    - username: user\n      password: user\n\nplugins:                          # plugin list (sorted in alphabetical order)\n  - api-breaker\n  - authz-keycloak\n  - basic-auth\n  - batch-requests\n  - consumer-restriction\n  - cors\n  # - dubbo-proxy\n  - echo\n  # - error-log-logger\n  # - example-plugin\n  - fault-injection\n  - grpc-transcode\n  - hmac-auth\n  - http-logger\n  - ip-restriction\n  - jwt-auth\n  - kafka-logger\n  - key-auth\n  - limit-conn\n  - limit-count\n  - limit-req\n  # - log-rotate\n  # - node-status\n  - openid-connect\n  - prometheus\n  - proxy-cache\n  - proxy-mirror\n  - proxy-rewrite\n  - redirect\n  - referer-restriction\n  - request-id\n  - request-validation\n  - response-rewrite\n  - serverless-post-function\n  - serverless-pre-function\n  # - skywalking\n  - sls-logger\n  - syslog\n  - tcp-logger\n  - udp-logger\n  - uri-blocker\n  - wolf-rbac\n  - zipkin\n  - server-info\n  - traffic-split\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/apisix/dashboard_conf\nmkdir -p /etc/apisix/apisix_conf\n\\cp ./dashboard_conf/conf.yaml /etc/apisix/dashboard_conf/conf.yaml -f\n\\cp ./apisix_conf/config.yaml /etc/apisix//apisix_conf/config.yaml -f\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Apollo",frontmatter:{title:"Apollo",date:"2023-09-05T13:49:16.000Z",permalink:"/pages/272684/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/04.Apollo.html",relativePath:"05.&/01.Docker/04.Apollo.md",key:"v-3fa091ca",path:"/pages/272684/",headers:[{level:2,title:"Apollo  ",slug:"apollo--",normalizedTitle:"apollo  ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:116},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:396},{level:2,title:"Sql",slug:"sql",normalizedTitle:"sql",charIndex:2458},{level:3,title:"apolloconfigdb.sql",slug:"apolloconfigdb-sql",normalizedTitle:"apolloconfigdb.sql",charIndex:2466},{level:3,title:"apolloportaldb.sql",slug:"apolloportaldb-sql",normalizedTitle:"apolloportaldb.sql",charIndex:22464},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:38657},{level:2,title:"sql",slug:"sql",normalizedTitle:"sql",charIndex:38866}],headersStr:"Apollo    docker-compose.yml Sql apolloconfigdb.sql apolloportaldb.sql deploy.sh sql",content:"# Apollo  \n\n\n\nhttps://www.apolloconfig.com/#/\n\ngithubhttps://github.com/apolloconfig/apollo\n\n\n# \n\n\n\nApollo\n\nSpring BootSpring CloudTomcat\n\nJavaJavaSpring/Spring Boot\n\n.Net.Net\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\n# http://ip:8070 apollo admin\n\nservices:\n  apollo-all-in-one:\n    container_name: apollo-all-in-one\n    image: idoop/docker-apollo:1.4.0\n    restart: always\n    #  portal504\"host\"\n    # network_mode: \"host\"\n    ports: \n      - 8070:8070\n      - 8080:8080\n      - 8081:8081\n      - 8082:8082\n      - 8083:8083\n      - 8090:8090\n      - 8091:8091\n      - 8092:8092\n      - 8093:8093\n    environment:\n      TZ: Asia/Shanghai\n\n      # Potal,:8070\n      # ServerConfigapollo.portal.envsdev,fat,uat\n      PORTAL_DB: jdbc:mysql://apollo-db:3306/ApolloPortalDB?characterEncoding=utf8\n      PORTAL_DB_USER: root\n      PORTAL_DB_PWD: apollo_123456\n\n      # DevAdmin:8090,Config:8080\n      # ServerConfigeureka.service.urlhttp://localhost:8080/eureka/\n      DEV_DB: jdbc:mysql://apollo-db:3306/ApolloConfigDB?characterEncoding=utf8\n      DEV_DB_USER: root\n      DEV_DB_PWD: apollo_123456\n\n      # FatAdmin:8091,Config:8081\n      # ServerConfigeureka.service.urlhttp://localhost:8081/eureka/\n      # FAT_DB: jdbc:mysql://10.0.0.8:3306/ApolloConfigDBFat?characterEncoding=utf8\n      # FAT_DB_USER: root\n      # FAT_DB_PWD: password\n     \n      # UathostUat\n      # config1000,ServerConfigeureka.service.urlhttp://localhost:1000/eureka/\n      # UAT_DB: jdbc:mysql://10.0.0.8:3306/ApolloConfigDBUat?characterEncoding=utf8\n      # UAT_DB_USER: root\n      # UAT_DB_PWD: password\n      # UAT_ADMIN_PORT: 2000\n      # UAT_CONFIG_PORT: 1000\n      # ,Pro\n    depends_on: ['apollo-db']\n\n  apollo-db:\n    image: mysql:5.7\n    container_name: apollo-db\n    restart: always\n    ports: \n      - 3306:3306\n    # network_mode: \"host\"\n    environment:\n      TZ: Asia/Shanghai\n      # MYSQL_ALLOW_EMPTY_PASSWORD: 'yes'\n      MYSQL_ROOT_PASSWORD: apollo_123456\n      MYSQL_ROOT_HOST: '%'\n    volumes:\n      - /etc/apollo/sql:/docker-entrypoint-initdb.d\n      - apollo_mysqldb:/var/lib/mysql\n\nvolumes:\n  apollo_mysqldb: \n\n\n\n\n# Sql\n\n\n# apolloconfigdb.sql\n\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n/*!40101 SET NAMES utf8 */;\n/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;\n/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\n/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\n\n# Create Database\n# ------------------------------------------------------------\nCREATE DATABASE IF NOT EXISTS ApolloConfigDB DEFAULT CHARACTER SET = utf8mb4;\n\nUse ApolloConfigDB;\n\n# Dump of table app\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `App`;\n\nCREATE TABLE `App` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `Name` varchar(500) NOT NULL DEFAULT 'default' COMMENT '',\n  `OrgId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Id',\n  `OrgName` varchar(64) NOT NULL DEFAULT 'default' COMMENT '',\n  `OwnerName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerName',\n  `OwnerEmail` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerEmail',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Name` (`Name`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table appnamespace\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `AppNamespace`;\n\nCREATE TABLE `AppNamespace` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `Name` varchar(32) NOT NULL DEFAULT '' COMMENT 'namespace',\n  `AppId` varchar(32) NOT NULL DEFAULT '' COMMENT 'app id',\n  `Format` varchar(32) NOT NULL DEFAULT 'properties' COMMENT 'namespaceformat',\n  `IsPublic` bit(1) NOT NULL DEFAULT b'0' COMMENT 'namespace',\n  `Comment` varchar(64) NOT NULL DEFAULT '' COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_AppId` (`AppId`),\n  KEY `Name_AppId` (`Name`,`AppId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='namespace';\n\n\n\n# Dump of table audit\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Audit`;\n\nCREATE TABLE `Audit` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `EntityName` varchar(50) NOT NULL DEFAULT 'default' COMMENT '',\n  `EntityId` int(10) unsigned DEFAULT NULL COMMENT 'ID',\n  `OpName` varchar(50) NOT NULL DEFAULT 'default' COMMENT '',\n  `Comment` varchar(500) DEFAULT NULL COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table cluster\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Cluster`;\n\nCREATE TABLE `Cluster` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `Name` varchar(32) NOT NULL DEFAULT '' COMMENT '',\n  `AppId` varchar(32) NOT NULL DEFAULT '' COMMENT 'App id',\n  `ParentClusterId` int(10) unsigned NOT NULL DEFAULT '0' COMMENT 'cluster',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_AppId_Name` (`AppId`,`Name`),\n  KEY `IX_ParentClusterId` (`ParentClusterId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table commit\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Commit`;\n\nCREATE TABLE `Commit` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `ChangeSets` longtext NOT NULL COMMENT '',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',\n  `NamespaceName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'namespaceName',\n  `Comment` varchar(500) DEFAULT NULL COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `ClusterName` (`ClusterName`(191)),\n  KEY `NamespaceName` (`NamespaceName`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='commit ';\n\n# Dump of table grayreleaserule\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `GrayReleaseRule`;\n\nCREATE TABLE `GrayReleaseRule` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `AppId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Cluster Name',\n  `NamespaceName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Namespace Name',\n  `BranchName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'branch name',\n  `Rules` varchar(16000) DEFAULT '[]' COMMENT '',\n  `ReleaseId` int(11) unsigned NOT NULL DEFAULT '0' COMMENT 'release',\n  `BranchStatus` tinyint(2) DEFAULT '1' COMMENT ': 0:,1: 2',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Namespace` (`AppId`,`ClusterName`,`NamespaceName`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n# Dump of table instance\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Instance`;\n\nCREATE TABLE `Instance` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `AppId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',\n  `DataCenter` varchar(64) NOT NULL DEFAULT 'default' COMMENT 'Data Center Name',\n  `Ip` varchar(32) NOT NULL DEFAULT '' COMMENT 'instance ip',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  UNIQUE KEY `IX_UNIQUE_KEY` (`AppId`,`ClusterName`,`Ip`,`DataCenter`),\n  KEY `IX_IP` (`Ip`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table instanceconfig\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `InstanceConfig`;\n\nCREATE TABLE `InstanceConfig` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `InstanceId` int(11) unsigned DEFAULT NULL COMMENT 'Instance Id',\n  `ConfigAppId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Config App Id',\n  `ConfigClusterName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Config Cluster Name',\n  `ConfigNamespaceName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Config Namespace Name',\n  `ReleaseKey` varchar(64) NOT NULL DEFAULT '' COMMENT 'Key',\n  `ReleaseDeliveryTime` timestamp NULL DEFAULT NULL COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  UNIQUE KEY `IX_UNIQUE_KEY` (`InstanceId`,`ConfigAppId`,`ConfigNamespaceName`),\n  KEY `IX_ReleaseKey` (`ReleaseKey`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Valid_Namespace` (`ConfigAppId`,`ConfigClusterName`,`ConfigNamespaceName`,`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table item\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Item`;\n\nCREATE TABLE `Item` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `NamespaceId` int(10) unsigned NOT NULL DEFAULT '0' COMMENT 'NamespaceId',\n  `Key` varchar(128) NOT NULL DEFAULT 'default' COMMENT 'Key',\n  `Value` longtext NOT NULL COMMENT '',\n  `Comment` varchar(1024) DEFAULT '' COMMENT '',\n  `LineNum` int(10) unsigned DEFAULT '0' COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_GroupId` (`NamespaceId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table namespace\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Namespace`;\n\nCREATE TABLE `Namespace` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'Cluster Name',\n  `NamespaceName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'Namespace Name',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `AppId_ClusterName_NamespaceName` (`AppId`(191),`ClusterName`(191),`NamespaceName`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_NamespaceName` (`NamespaceName`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table namespacelock\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `NamespaceLock`;\n\nCREATE TABLE `NamespaceLock` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',\n  `NamespaceId` int(10) unsigned NOT NULL DEFAULT '0' COMMENT 'NamespaceId',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT 'default' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  `IsDeleted` bit(1) DEFAULT b'0' COMMENT '',\n  PRIMARY KEY (`Id`),\n  UNIQUE KEY `IX_NamespaceId` (`NamespaceId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='namespace';\n\n\n\n# Dump of table release\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Release`;\n\nCREATE TABLE `Release` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `ReleaseKey` varchar(64) NOT NULL DEFAULT '' COMMENT 'Key',\n  `Name` varchar(64) NOT NULL DEFAULT 'default' COMMENT '',\n  `Comment` varchar(256) DEFAULT NULL COMMENT '',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',\n  `NamespaceName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'namespaceName',\n  `Configurations` longtext NOT NULL COMMENT '',\n  `IsAbandoned` bit(1) NOT NULL DEFAULT b'0' COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `AppId_ClusterName_GroupName` (`AppId`(191),`ClusterName`(191),`NamespaceName`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_ReleaseKey` (`ReleaseKey`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n# Dump of table releasehistory\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ReleaseHistory`;\n\nCREATE TABLE `ReleaseHistory` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `AppId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',\n  `NamespaceName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'namespaceName',\n  `BranchName` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `ReleaseId` int(11) unsigned NOT NULL DEFAULT '0' COMMENT 'Release Id',\n  `PreviousReleaseId` int(11) unsigned NOT NULL DEFAULT '0' COMMENT 'ReleaseId',\n  `Operation` tinyint(3) unsigned NOT NULL DEFAULT '0' COMMENT '0: 1: 2: 3: 4: 5: 6: 7: ',\n  `OperationContext` longtext NOT NULL COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_Namespace` (`AppId`,`ClusterName`,`NamespaceName`,`BranchName`),\n  KEY `IX_ReleaseId` (`ReleaseId`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n# Dump of table releasemessage\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ReleaseMessage`;\n\nCREATE TABLE `ReleaseMessage` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `Message` varchar(1024) NOT NULL DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Message` (`Message`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table serverconfig\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ServerConfig`;\n\nCREATE TABLE `ServerConfig` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `Key` varchar(64) NOT NULL DEFAULT 'default' COMMENT 'Key',\n  `Cluster` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'default',\n  `Value` varchar(2048) NOT NULL DEFAULT 'default' COMMENT '',\n  `Comment` varchar(1024) DEFAULT '' COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_Key` (`Key`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n# Config\n# ------------------------------------------------------------\nINSERT INTO `ServerConfig` (`Key`, `Cluster`, `Value`, `Comment`)\nVALUES\n    ('eureka.service.url', 'default', 'http://localhost:8080/eureka/', 'EurekaUrlservice'),\n    ('namespace.lock.switch', 'default', 'false', ''),\n    ('item.value.length.limit', 'default', '20000', 'item value'),\n    ('config-service.cache.enabled', 'default', 'false', 'ConfigService'),\n    ('item.key.length.limit', 'default', '128', 'item key ');\n\n# Sample Data\n# ------------------------------------------------------------\nINSERT INTO `App` (`AppId`, `Name`, `OrgId`, `OrgName`, `OwnerName`, `OwnerEmail`)\nVALUES\n\t('SampleApp', 'Sample App', 'TEST1', '1', 'apollo', 'apollo@acme.com');\n\nINSERT INTO `AppNamespace` (`Name`, `AppId`, `Format`, `IsPublic`, `Comment`)\nVALUES\n\t('application', 'SampleApp', 'properties', 0, 'default app namespace');\n\nINSERT INTO `Cluster` (`Name`, `AppId`)\nVALUES\n\t('default', 'SampleApp');\n\nINSERT INTO `Namespace` (`Id`, `AppId`, `ClusterName`, `NamespaceName`)\nVALUES\n\t(1, 'SampleApp', 'default', 'application');\n\n\nINSERT INTO `Item` (`NamespaceId`, `Key`, `Value`, `Comment`, `LineNum`)\nVALUES\n\t(1, 'timeout', '100', 'sample timeout', 1);\n\nINSERT INTO `Release` (`ReleaseKey`, `Name`, `Comment`, `AppId`, `ClusterName`, `NamespaceName`, `Configurations`)\nVALUES\n\t('20161009155425-d3a0749c6e20bc15', '20161009155424-release', 'Sample', 'SampleApp', 'default', 'application', '{\\\"timeout\\\":\\\"100\\\"}');\n\nINSERT INTO `ReleaseHistory` (`AppId`, `ClusterName`, `NamespaceName`, `BranchName`, `ReleaseId`, `PreviousReleaseId`, `Operation`, `OperationContext`, `DataChange_CreatedBy`, `DataChange_LastModifiedBy`)\nVALUES\n  ('SampleApp', 'default', 'application', 'default', 1, 0, 0, '{}', 'apollo', 'apollo');\n\n\n/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;\n/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;\n/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;\n/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;\n/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;\n/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;\n\n\n\n# apolloportaldb.sql\n\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n/*!40101 SET NAMES utf8 */;\n/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;\n/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\n/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\n\n# Create Database\n# ------------------------------------------------------------\nCREATE DATABASE IF NOT EXISTS ApolloPortalDB DEFAULT CHARACTER SET = utf8mb4;\n\nUse ApolloPortalDB;\n\n# Dump of table app\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `App`;\n\nCREATE TABLE `App` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `Name` varchar(500) NOT NULL DEFAULT 'default' COMMENT '',\n  `OrgId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Id',\n  `OrgName` varchar(64) NOT NULL DEFAULT 'default' COMMENT '',\n  `OwnerName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerName',\n  `OwnerEmail` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerEmail',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Name` (`Name`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table appnamespace\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `AppNamespace`;\n\nCREATE TABLE `AppNamespace` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `Name` varchar(32) NOT NULL DEFAULT '' COMMENT 'namespace',\n  `AppId` varchar(32) NOT NULL DEFAULT '' COMMENT 'app id',\n  `Format` varchar(32) NOT NULL DEFAULT 'properties' COMMENT 'namespaceformat',\n  `IsPublic` bit(1) NOT NULL DEFAULT b'0' COMMENT 'namespace',\n  `Comment` varchar(64) NOT NULL DEFAULT '' COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_AppId` (`AppId`),\n  KEY `Name_AppId` (`Name`,`AppId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='namespace';\n\n\n\n# Dump of table consumer\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Consumer`;\n\nCREATE TABLE `Consumer` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `Name` varchar(500) NOT NULL DEFAULT 'default' COMMENT '',\n  `OrgId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Id',\n  `OrgName` varchar(64) NOT NULL DEFAULT 'default' COMMENT '',\n  `OwnerName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerName',\n  `OwnerEmail` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerEmail',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='API';\n\n\n\n# Dump of table consumeraudit\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ConsumerAudit`;\n\nCREATE TABLE `ConsumerAudit` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `ConsumerId` int(11) unsigned DEFAULT NULL COMMENT 'Consumer Id',\n  `Uri` varchar(1024) NOT NULL DEFAULT '' COMMENT 'Uri',\n  `Method` varchar(16) NOT NULL DEFAULT '' COMMENT 'Method',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_ConsumerId` (`ConsumerId`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='consumer';\n\n\n\n# Dump of table consumerrole\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ConsumerRole`;\n\nCREATE TABLE `ConsumerRole` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `ConsumerId` int(11) unsigned DEFAULT NULL COMMENT 'Consumer Id',\n  `RoleId` int(10) unsigned DEFAULT NULL COMMENT 'Role Id',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_RoleId` (`RoleId`),\n  KEY `IX_ConsumerId_RoleId` (`ConsumerId`,`RoleId`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='consumerrole';\n\n\n\n# Dump of table consumertoken\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ConsumerToken`;\n\nCREATE TABLE `ConsumerToken` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `ConsumerId` int(11) unsigned DEFAULT NULL COMMENT 'ConsumerId',\n  `Token` varchar(128) NOT NULL DEFAULT '' COMMENT 'token',\n  `Expires` datetime NOT NULL DEFAULT '2099-01-01 00:00:00' COMMENT 'token',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  UNIQUE KEY `IX_Token` (`Token`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='consumer token';\n\n# Dump of table favorite\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Favorite`;\n\nCREATE TABLE `Favorite` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '',\n  `UserId` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `Position` int(32) NOT NULL DEFAULT '10000' COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `IX_UserId` (`UserId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB AUTO_INCREMENT=23 DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n# Dump of table permission\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Permission`;\n\nCREATE TABLE `Permission` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `PermissionType` varchar(32) NOT NULL DEFAULT '' COMMENT '',\n  `TargetId` varchar(256) NOT NULL DEFAULT '' COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_TargetId_PermissionType` (`TargetId`(191),`PermissionType`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='permission';\n\n\n\n# Dump of table role\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Role`;\n\nCREATE TABLE `Role` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `RoleName` varchar(256) NOT NULL DEFAULT '' COMMENT 'Role name',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_RoleName` (`RoleName`(191)),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table rolepermission\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `RolePermission`;\n\nCREATE TABLE `RolePermission` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `RoleId` int(10) unsigned DEFAULT NULL COMMENT 'Role Id',\n  `PermissionId` int(10) unsigned DEFAULT NULL COMMENT 'Permission Id',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_RoleId` (`RoleId`),\n  KEY `IX_PermissionId` (`PermissionId`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table serverconfig\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ServerConfig`;\n\nCREATE TABLE `ServerConfig` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `Key` varchar(64) NOT NULL DEFAULT 'default' COMMENT 'Key',\n  `Value` varchar(2048) NOT NULL DEFAULT 'default' COMMENT '',\n  `Comment` varchar(1024) DEFAULT '' COMMENT '',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_Key` (`Key`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n\n# Dump of table userrole\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `UserRole`;\n\nCREATE TABLE `UserRole` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `UserId` varchar(128) DEFAULT '' COMMENT '',\n  `RoleId` int(10) unsigned DEFAULT NULL COMMENT 'Role Id',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '',\n  PRIMARY KEY (`Id`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_RoleId` (`RoleId`),\n  KEY `IX_UserId_RoleId` (`UserId`,`RoleId`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='role';\n\n# Dump of table Users\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Users`;\n\nCREATE TABLE `Users` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `Username` varchar(64) NOT NULL DEFAULT 'default' COMMENT '',\n  `Password` varchar(64) NOT NULL DEFAULT 'default' COMMENT '',\n  `Email` varchar(64) NOT NULL DEFAULT 'default' COMMENT '',\n  `Enabled` tinyint(4) DEFAULT NULL COMMENT '',\n  PRIMARY KEY (`Id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='';\n\n\n# Dump of table Authorities\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Authorities`;\n\nCREATE TABLE `Authorities` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Id',\n  `Username` varchar(64) NOT NULL,\n  `Authority` varchar(50) NOT NULL,\n  PRIMARY KEY (`Id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n\n\n# Config\n# ------------------------------------------------------------\nINSERT INTO `ServerConfig` (`Key`, `Value`, `Comment`)\nVALUES\n    ('apollo.portal.envs', 'dev', ''),\n    ('organizations', '[{\\\"orgId\\\":\\\"TEST1\\\",\\\"orgName\\\":\\\"1\\\"},{\\\"orgId\\\":\\\"TEST2\\\",\\\"orgName\\\":\\\"2\\\"}]', ''),\n    ('superAdmin', 'apollo', 'Portal'),\n    ('api.readTimeout', '10000', 'httpread timeout'),\n    ('consumer.token.salt', 'someSalt', 'consumer token salt'),\n    ('admin.createPrivateNamespace.switch', 'true', 'namespace'),\n    ('configView.memberOnly.envs', 'dev', 'env');\n\nINSERT INTO `Users` (`Username`, `Password`, `Email`, `Enabled`)\nVALUES\n\t('apollo', '$2a$10$7r20uS.BQ9uBpf3Baj3uQOZvMVvB1RN3PYoKE94gtz2.WAOuiiwXS', 'apollo@acme.com', 1);\n\nINSERT INTO `Authorities` (`Username`, `Authority`) VALUES ('apollo', 'ROLE_user');\n\n# Sample Data\n# ------------------------------------------------------------\nINSERT INTO `App` (`AppId`, `Name`, `OrgId`, `OrgName`, `OwnerName`, `OwnerEmail`)\nVALUES\n\t('SampleApp', 'Sample App', 'TEST1', '1', 'apollo', 'apollo@acme.com');\n\nINSERT INTO `AppNamespace` (`Name`, `AppId`, `Format`, `IsPublic`, `Comment`)\nVALUES\n\t('application', 'SampleApp', 'properties', 0, 'default app namespace');\n\nINSERT INTO `Permission` (`Id`, `PermissionType`, `TargetId`)\nVALUES\n\t(1, 'CreateCluster', 'SampleApp'),\n\t(2, 'CreateNamespace', 'SampleApp'),\n\t(3, 'AssignRole', 'SampleApp'),\n\t(4, 'ModifyNamespace', 'SampleApp+application'),\n\t(5, 'ReleaseNamespace', 'SampleApp+application');\n\nINSERT INTO `Role` (`Id`, `RoleName`)\nVALUES\n\t(1, 'Master+SampleApp'),\n\t(2, 'ModifyNamespace+SampleApp+application'),\n\t(3, 'ReleaseNamespace+SampleApp+application');\n\nINSERT INTO `RolePermission` (`RoleId`, `PermissionId`)\nVALUES\n\t(1, 1),\n\t(1, 2),\n\t(1, 3),\n\t(2, 4),\n\t(3, 5);\n\nINSERT INTO `UserRole` (`UserId`, `RoleId`)\nVALUES\n\t('apollo', 1),\n\t('apollo', 2),\n\t('apollo', 3);\n\n/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;\n/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;\n/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;\n/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;\n/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;\n/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/apollo/sql\n\\cp ./sql/apolloconfigdb.sql /etc/apollo/sql/apolloconfigdb.sql -f\n\\cp ./sql/apolloportaldb.sql /etc/apollo/sql/apolloportaldb.sql -f\ndocker-compose up -d\n\n\n\n# sql\n\n# ApolloConfigDB\n\nset @appId = 'tjs_public';\n \nUse `ApolloConfigDB`;\n \nupdate `App` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `AppNamespace` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Cluster` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Commit` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `GrayReleaseRule` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Release` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `ReleaseHistory` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\ndelete from `Instance` where `AppId` = @appId;\ndelete from `InstanceConfig` where `ConfigAppId` = @appId;\ndelete from `ReleaseMessage` where `Message` like CONCAT(@appId, '+%');\n \n# handle namespaces and items\ncreate temporary table `NamespaceIds` as select `Id` from `Namespace` where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Namespace` set `IsDeleted` = 1 where `Id` in (select `Id` from `NamespaceIds`);\nupdate `Item` set `IsDeleted` = 1 where `NamespaceId` in (select `Id` from `NamespaceIds`);\ndelete from `NamespaceLock` where `NamespaceId` in (select `Id` from `NamespaceIds`);\ndrop temporary table `NamespaceIds`;\n\n\n# ApolloPortalDB\n\nset @appId = 'tjs_public';\n \nUse `ApolloPortalDB`;\n \nupdate `App` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `AppNamespace` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Favorite` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\n \n# handle roles and permissions\ncreate temporary table `PermissionIds` as select `Id` from `Permission` where (`TargetId` = @appId or `TargetId` like CONCAT(@appId, '+%'))  and `IsDeleted` = 0;\nupdate `Permission` set `IsDeleted` = 1 where `Id` in (select `Id` from `PermissionIds`);\nupdate `RolePermission` set `IsDeleted` = 1 where `PermissionId` in (select `Id` from `PermissionIds`);\ndrop temporary table `PermissionIds`;\n \ncreate temporary table `RoleIds` as select `Id` from `Role` where (`RoleName` = CONCAT('Master+', @appId) or `RoleName` like CONCAT('ModifyNamespace+', @appId, '+%') or `RoleName` like CONCAT('ReleaseNamespace+', @appId, '+%')) and `IsDeleted` = 0;\nupdate `Role` set `IsDeleted` = 1 where `Id` in (select `Id` from `RoleIds`);\nupdate `UserRole` set `IsDeleted` = 1 where `RoleId` in (select `Id` from `RoleIds`);\nupdate `ConsumerRole` set `IsDeleted` = 1 where `RoleId` in (select `Id` from `RoleIds`);\ndrop temporary table `RoleIds`;\n",normalizedContent:"# apollo  \n\n\n\nhttps://www.apolloconfig.com/#/\n\ngithubhttps://github.com/apolloconfig/apollo\n\n\n# \n\n\n\napollo\n\nspring bootspring cloudtomcat\n\njavajavaspring/spring boot\n\n.net.net\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\n# http://ip:8070 apollo admin\n\nservices:\n  apollo-all-in-one:\n    container_name: apollo-all-in-one\n    image: idoop/docker-apollo:1.4.0\n    restart: always\n    #  portal504\"host\"\n    # network_mode: \"host\"\n    ports: \n      - 8070:8070\n      - 8080:8080\n      - 8081:8081\n      - 8082:8082\n      - 8083:8083\n      - 8090:8090\n      - 8091:8091\n      - 8092:8092\n      - 8093:8093\n    environment:\n      tz: asia/shanghai\n\n      # potal,:8070\n      # serverconfigapollo.portal.envsdev,fat,uat\n      portal_db: jdbc:mysql://apollo-db:3306/apolloportaldb?characterencoding=utf8\n      portal_db_user: root\n      portal_db_pwd: apollo_123456\n\n      # devadmin:8090,config:8080\n      # serverconfigeureka.service.urlhttp://localhost:8080/eureka/\n      dev_db: jdbc:mysql://apollo-db:3306/apolloconfigdb?characterencoding=utf8\n      dev_db_user: root\n      dev_db_pwd: apollo_123456\n\n      # fatadmin:8091,config:8081\n      # serverconfigeureka.service.urlhttp://localhost:8081/eureka/\n      # fat_db: jdbc:mysql://10.0.0.8:3306/apolloconfigdbfat?characterencoding=utf8\n      # fat_db_user: root\n      # fat_db_pwd: password\n     \n      # uathostuat\n      # config1000,serverconfigeureka.service.urlhttp://localhost:1000/eureka/\n      # uat_db: jdbc:mysql://10.0.0.8:3306/apolloconfigdbuat?characterencoding=utf8\n      # uat_db_user: root\n      # uat_db_pwd: password\n      # uat_admin_port: 2000\n      # uat_config_port: 1000\n      # ,pro\n    depends_on: ['apollo-db']\n\n  apollo-db:\n    image: mysql:5.7\n    container_name: apollo-db\n    restart: always\n    ports: \n      - 3306:3306\n    # network_mode: \"host\"\n    environment:\n      tz: asia/shanghai\n      # mysql_allow_empty_password: 'yes'\n      mysql_root_password: apollo_123456\n      mysql_root_host: '%'\n    volumes:\n      - /etc/apollo/sql:/docker-entrypoint-initdb.d\n      - apollo_mysqldb:/var/lib/mysql\n\nvolumes:\n  apollo_mysqldb: \n\n\n\n\n# sql\n\n\n# apolloconfigdb.sql\n\n/*!40101 set @old_character_set_client=@@character_set_client */;\n/*!40101 set @old_character_set_results=@@character_set_results */;\n/*!40101 set @old_collation_connection=@@collation_connection */;\n/*!40101 set names utf8 */;\n/*!40014 set @old_foreign_key_checks=@@foreign_key_checks, foreign_key_checks=0 */;\n/*!40101 set @old_sql_mode=@@sql_mode, sql_mode='no_auto_value_on_zero' */;\n/*!40111 set @old_sql_notes=@@sql_notes, sql_notes=0 */;\n\n# create database\n# ------------------------------------------------------------\ncreate database if not exists apolloconfigdb default character set = utf8mb4;\n\nuse apolloconfigdb;\n\n# dump of table app\n# ------------------------------------------------------------\n\ndrop table if exists `app`;\n\ncreate table `app` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `name` varchar(500) not null default 'default' comment '',\n  `orgid` varchar(32) not null default 'default' comment 'id',\n  `orgname` varchar(64) not null default 'default' comment '',\n  `ownername` varchar(500) not null default 'default' comment 'ownername',\n  `owneremail` varchar(500) not null default 'default' comment 'owneremail',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `appid` (`appid`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_name` (`name`(191))\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table appnamespace\n# ------------------------------------------------------------\n\ndrop table if exists `appnamespace`;\n\ncreate table `appnamespace` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `name` varchar(32) not null default '' comment 'namespace',\n  `appid` varchar(32) not null default '' comment 'app id',\n  `format` varchar(32) not null default 'properties' comment 'namespaceformat',\n  `ispublic` bit(1) not null default b'0' comment 'namespace',\n  `comment` varchar(64) not null default '' comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default '' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_appid` (`appid`),\n  key `name_appid` (`name`,`appid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='namespace';\n\n\n\n# dump of table audit\n# ------------------------------------------------------------\n\ndrop table if exists `audit`;\n\ncreate table `audit` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `entityname` varchar(50) not null default 'default' comment '',\n  `entityid` int(10) unsigned default null comment 'id',\n  `opname` varchar(50) not null default 'default' comment '',\n  `comment` varchar(500) default null comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table cluster\n# ------------------------------------------------------------\n\ndrop table if exists `cluster`;\n\ncreate table `cluster` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `name` varchar(32) not null default '' comment '',\n  `appid` varchar(32) not null default '' comment 'app id',\n  `parentclusterid` int(10) unsigned not null default '0' comment 'cluster',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default '' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_appid_name` (`appid`,`name`),\n  key `ix_parentclusterid` (`parentclusterid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table commit\n# ------------------------------------------------------------\n\ndrop table if exists `commit`;\n\ncreate table `commit` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `changesets` longtext not null comment '',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `clustername` varchar(500) not null default 'default' comment 'clustername',\n  `namespacename` varchar(500) not null default 'default' comment 'namespacename',\n  `comment` varchar(500) default null comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `appid` (`appid`(191)),\n  key `clustername` (`clustername`(191)),\n  key `namespacename` (`namespacename`(191))\n) engine=innodb default charset=utf8mb4 comment='commit ';\n\n# dump of table grayreleaserule\n# ------------------------------------------------------------\n\ndrop table if exists `grayreleaserule`;\n\ncreate table `grayreleaserule` (\n  `id` int(11) unsigned not null auto_increment comment '',\n  `appid` varchar(32) not null default 'default' comment 'appid',\n  `clustername` varchar(32) not null default 'default' comment 'cluster name',\n  `namespacename` varchar(32) not null default 'default' comment 'namespace name',\n  `branchname` varchar(32) not null default 'default' comment 'branch name',\n  `rules` varchar(16000) default '[]' comment '',\n  `releaseid` int(11) unsigned not null default '0' comment 'release',\n  `branchstatus` tinyint(2) default '1' comment ': 0:,1: 2',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_namespace` (`appid`,`clustername`,`namespacename`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n# dump of table instance\n# ------------------------------------------------------------\n\ndrop table if exists `instance`;\n\ncreate table `instance` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `appid` varchar(32) not null default 'default' comment 'appid',\n  `clustername` varchar(32) not null default 'default' comment 'clustername',\n  `datacenter` varchar(64) not null default 'default' comment 'data center name',\n  `ip` varchar(32) not null default '' comment 'instance ip',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lasttime` timestamp not null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  unique key `ix_unique_key` (`appid`,`clustername`,`ip`,`datacenter`),\n  key `ix_ip` (`ip`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table instanceconfig\n# ------------------------------------------------------------\n\ndrop table if exists `instanceconfig`;\n\ncreate table `instanceconfig` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `instanceid` int(11) unsigned default null comment 'instance id',\n  `configappid` varchar(32) not null default 'default' comment 'config app id',\n  `configclustername` varchar(32) not null default 'default' comment 'config cluster name',\n  `confignamespacename` varchar(32) not null default 'default' comment 'config namespace name',\n  `releasekey` varchar(64) not null default '' comment 'key',\n  `releasedeliverytime` timestamp null default null comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lasttime` timestamp not null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  unique key `ix_unique_key` (`instanceid`,`configappid`,`confignamespacename`),\n  key `ix_releasekey` (`releasekey`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_valid_namespace` (`configappid`,`configclustername`,`confignamespacename`,`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table item\n# ------------------------------------------------------------\n\ndrop table if exists `item`;\n\ncreate table `item` (\n  `id` int(10) unsigned not null auto_increment comment 'id',\n  `namespaceid` int(10) unsigned not null default '0' comment 'namespaceid',\n  `key` varchar(128) not null default 'default' comment 'key',\n  `value` longtext not null comment '',\n  `comment` varchar(1024) default '' comment '',\n  `linenum` int(10) unsigned default '0' comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_groupid` (`namespaceid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table namespace\n# ------------------------------------------------------------\n\ndrop table if exists `namespace`;\n\ncreate table `namespace` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `clustername` varchar(500) not null default 'default' comment 'cluster name',\n  `namespacename` varchar(500) not null default 'default' comment 'namespace name',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `appid_clustername_namespacename` (`appid`(191),`clustername`(191),`namespacename`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_namespacename` (`namespacename`(191))\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table namespacelock\n# ------------------------------------------------------------\n\ndrop table if exists `namespacelock`;\n\ncreate table `namespacelock` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `namespaceid` int(10) unsigned not null default '0' comment 'namespaceid',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default 'default' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  `isdeleted` bit(1) default b'0' comment '',\n  primary key (`id`),\n  unique key `ix_namespaceid` (`namespaceid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='namespace';\n\n\n\n# dump of table release\n# ------------------------------------------------------------\n\ndrop table if exists `release`;\n\ncreate table `release` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `releasekey` varchar(64) not null default '' comment 'key',\n  `name` varchar(64) not null default 'default' comment '',\n  `comment` varchar(256) default null comment '',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `clustername` varchar(500) not null default 'default' comment 'clustername',\n  `namespacename` varchar(500) not null default 'default' comment 'namespacename',\n  `configurations` longtext not null comment '',\n  `isabandoned` bit(1) not null default b'0' comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `appid_clustername_groupname` (`appid`(191),`clustername`(191),`namespacename`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_releasekey` (`releasekey`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n# dump of table releasehistory\n# ------------------------------------------------------------\n\ndrop table if exists `releasehistory`;\n\ncreate table `releasehistory` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `appid` varchar(32) not null default 'default' comment 'appid',\n  `clustername` varchar(32) not null default 'default' comment 'clustername',\n  `namespacename` varchar(32) not null default 'default' comment 'namespacename',\n  `branchname` varchar(32) not null default 'default' comment '',\n  `releaseid` int(11) unsigned not null default '0' comment 'release id',\n  `previousreleaseid` int(11) unsigned not null default '0' comment 'releaseid',\n  `operation` tinyint(3) unsigned not null default '0' comment '0: 1: 2: 3: 4: 5: 6: 7: ',\n  `operationcontext` longtext not null comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_namespace` (`appid`,`clustername`,`namespacename`,`branchname`),\n  key `ix_releaseid` (`releaseid`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n# dump of table releasemessage\n# ------------------------------------------------------------\n\ndrop table if exists `releasemessage`;\n\ncreate table `releasemessage` (\n  `id` int(11) unsigned not null auto_increment comment '',\n  `message` varchar(1024) not null default '' comment '',\n  `datachange_lasttime` timestamp not null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_message` (`message`(191))\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table serverconfig\n# ------------------------------------------------------------\n\ndrop table if exists `serverconfig`;\n\ncreate table `serverconfig` (\n  `id` int(10) unsigned not null auto_increment comment 'id',\n  `key` varchar(64) not null default 'default' comment 'key',\n  `cluster` varchar(32) not null default 'default' comment 'default',\n  `value` varchar(2048) not null default 'default' comment '',\n  `comment` varchar(1024) default '' comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_key` (`key`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n# config\n# ------------------------------------------------------------\ninsert into `serverconfig` (`key`, `cluster`, `value`, `comment`)\nvalues\n    ('eureka.service.url', 'default', 'http://localhost:8080/eureka/', 'eurekaurlservice'),\n    ('namespace.lock.switch', 'default', 'false', ''),\n    ('item.value.length.limit', 'default', '20000', 'item value'),\n    ('config-service.cache.enabled', 'default', 'false', 'configservice'),\n    ('item.key.length.limit', 'default', '128', 'item key ');\n\n# sample data\n# ------------------------------------------------------------\ninsert into `app` (`appid`, `name`, `orgid`, `orgname`, `ownername`, `owneremail`)\nvalues\n\t('sampleapp', 'sample app', 'test1', '1', 'apollo', 'apollo@acme.com');\n\ninsert into `appnamespace` (`name`, `appid`, `format`, `ispublic`, `comment`)\nvalues\n\t('application', 'sampleapp', 'properties', 0, 'default app namespace');\n\ninsert into `cluster` (`name`, `appid`)\nvalues\n\t('default', 'sampleapp');\n\ninsert into `namespace` (`id`, `appid`, `clustername`, `namespacename`)\nvalues\n\t(1, 'sampleapp', 'default', 'application');\n\n\ninsert into `item` (`namespaceid`, `key`, `value`, `comment`, `linenum`)\nvalues\n\t(1, 'timeout', '100', 'sample timeout', 1);\n\ninsert into `release` (`releasekey`, `name`, `comment`, `appid`, `clustername`, `namespacename`, `configurations`)\nvalues\n\t('20161009155425-d3a0749c6e20bc15', '20161009155424-release', 'sample', 'sampleapp', 'default', 'application', '{\\\"timeout\\\":\\\"100\\\"}');\n\ninsert into `releasehistory` (`appid`, `clustername`, `namespacename`, `branchname`, `releaseid`, `previousreleaseid`, `operation`, `operationcontext`, `datachange_createdby`, `datachange_lastmodifiedby`)\nvalues\n  ('sampleapp', 'default', 'application', 'default', 1, 0, 0, '{}', 'apollo', 'apollo');\n\n\n/*!40111 set sql_notes=@old_sql_notes */;\n/*!40101 set sql_mode=@old_sql_mode */;\n/*!40014 set foreign_key_checks=@old_foreign_key_checks */;\n/*!40101 set character_set_client=@old_character_set_client */;\n/*!40101 set character_set_results=@old_character_set_results */;\n/*!40101 set collation_connection=@old_collation_connection */;\n\n\n\n# apolloportaldb.sql\n\n/*!40101 set @old_character_set_client=@@character_set_client */;\n/*!40101 set @old_character_set_results=@@character_set_results */;\n/*!40101 set @old_collation_connection=@@collation_connection */;\n/*!40101 set names utf8 */;\n/*!40014 set @old_foreign_key_checks=@@foreign_key_checks, foreign_key_checks=0 */;\n/*!40101 set @old_sql_mode=@@sql_mode, sql_mode='no_auto_value_on_zero' */;\n/*!40111 set @old_sql_notes=@@sql_notes, sql_notes=0 */;\n\n# create database\n# ------------------------------------------------------------\ncreate database if not exists apolloportaldb default character set = utf8mb4;\n\nuse apolloportaldb;\n\n# dump of table app\n# ------------------------------------------------------------\n\ndrop table if exists `app`;\n\ncreate table `app` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `name` varchar(500) not null default 'default' comment '',\n  `orgid` varchar(32) not null default 'default' comment 'id',\n  `orgname` varchar(64) not null default 'default' comment '',\n  `ownername` varchar(500) not null default 'default' comment 'ownername',\n  `owneremail` varchar(500) not null default 'default' comment 'owneremail',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `appid` (`appid`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_name` (`name`(191))\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table appnamespace\n# ------------------------------------------------------------\n\ndrop table if exists `appnamespace`;\n\ncreate table `appnamespace` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `name` varchar(32) not null default '' comment 'namespace',\n  `appid` varchar(32) not null default '' comment 'app id',\n  `format` varchar(32) not null default 'properties' comment 'namespaceformat',\n  `ispublic` bit(1) not null default b'0' comment 'namespace',\n  `comment` varchar(64) not null default '' comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default '' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_appid` (`appid`),\n  key `name_appid` (`name`,`appid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='namespace';\n\n\n\n# dump of table consumer\n# ------------------------------------------------------------\n\ndrop table if exists `consumer`;\n\ncreate table `consumer` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `name` varchar(500) not null default 'default' comment '',\n  `orgid` varchar(32) not null default 'default' comment 'id',\n  `orgname` varchar(64) not null default 'default' comment '',\n  `ownername` varchar(500) not null default 'default' comment 'ownername',\n  `owneremail` varchar(500) not null default 'default' comment 'owneremail',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `appid` (`appid`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='api';\n\n\n\n# dump of table consumeraudit\n# ------------------------------------------------------------\n\ndrop table if exists `consumeraudit`;\n\ncreate table `consumeraudit` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `consumerid` int(11) unsigned default null comment 'consumer id',\n  `uri` varchar(1024) not null default '' comment 'uri',\n  `method` varchar(16) not null default '' comment 'method',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_consumerid` (`consumerid`)\n) engine=innodb default charset=utf8mb4 comment='consumer';\n\n\n\n# dump of table consumerrole\n# ------------------------------------------------------------\n\ndrop table if exists `consumerrole`;\n\ncreate table `consumerrole` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `consumerid` int(11) unsigned default null comment 'consumer id',\n  `roleid` int(10) unsigned default null comment 'role id',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) default '' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_roleid` (`roleid`),\n  key `ix_consumerid_roleid` (`consumerid`,`roleid`)\n) engine=innodb default charset=utf8mb4 comment='consumerrole';\n\n\n\n# dump of table consumertoken\n# ------------------------------------------------------------\n\ndrop table if exists `consumertoken`;\n\ncreate table `consumertoken` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `consumerid` int(11) unsigned default null comment 'consumerid',\n  `token` varchar(128) not null default '' comment 'token',\n  `expires` datetime not null default '2099-01-01 00:00:00' comment 'token',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  unique key `ix_token` (`token`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='consumer token';\n\n# dump of table favorite\n# ------------------------------------------------------------\n\ndrop table if exists `favorite`;\n\ncreate table `favorite` (\n  `id` int(10) unsigned not null auto_increment comment '',\n  `userid` varchar(32) not null default 'default' comment '',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `position` int(32) not null default '10000' comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `appid` (`appid`(191)),\n  key `ix_userid` (`userid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb auto_increment=23 default charset=utf8mb4 comment='';\n\n# dump of table permission\n# ------------------------------------------------------------\n\ndrop table if exists `permission`;\n\ncreate table `permission` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `permissiontype` varchar(32) not null default '' comment '',\n  `targetid` varchar(256) not null default '' comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default '' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_targetid_permissiontype` (`targetid`(191),`permissiontype`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='permission';\n\n\n\n# dump of table role\n# ------------------------------------------------------------\n\ndrop table if exists `role`;\n\ncreate table `role` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `rolename` varchar(256) not null default '' comment 'role name',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_rolename` (`rolename`(191)),\n  key `ix_datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table rolepermission\n# ------------------------------------------------------------\n\ndrop table if exists `rolepermission`;\n\ncreate table `rolepermission` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `roleid` int(10) unsigned default null comment 'role id',\n  `permissionid` int(10) unsigned default null comment 'permission id',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) default '' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_roleid` (`roleid`),\n  key `ix_permissionid` (`permissionid`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table serverconfig\n# ------------------------------------------------------------\n\ndrop table if exists `serverconfig`;\n\ncreate table `serverconfig` (\n  `id` int(10) unsigned not null auto_increment comment 'id',\n  `key` varchar(64) not null default 'default' comment 'key',\n  `value` varchar(2048) not null default 'default' comment '',\n  `comment` varchar(1024) default '' comment '',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_key` (`key`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n\n# dump of table userrole\n# ------------------------------------------------------------\n\ndrop table if exists `userrole`;\n\ncreate table `userrole` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `userid` varchar(128) default '' comment '',\n  `roleid` int(10) unsigned default null comment 'role id',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) default '' comment '',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '',\n  primary key (`id`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_roleid` (`roleid`),\n  key `ix_userid_roleid` (`userid`,`roleid`)\n) engine=innodb default charset=utf8mb4 comment='role';\n\n# dump of table users\n# ------------------------------------------------------------\n\ndrop table if exists `users`;\n\ncreate table `users` (\n  `id` int(10) unsigned not null auto_increment comment 'id',\n  `username` varchar(64) not null default 'default' comment '',\n  `password` varchar(64) not null default 'default' comment '',\n  `email` varchar(64) not null default 'default' comment '',\n  `enabled` tinyint(4) default null comment '',\n  primary key (`id`)\n) engine=innodb default charset=utf8mb4 comment='';\n\n\n# dump of table authorities\n# ------------------------------------------------------------\n\ndrop table if exists `authorities`;\n\ncreate table `authorities` (\n  `id` int(11) unsigned not null auto_increment comment 'id',\n  `username` varchar(64) not null,\n  `authority` varchar(50) not null,\n  primary key (`id`)\n) engine=innodb default charset=utf8mb4;\n\n\n# config\n# ------------------------------------------------------------\ninsert into `serverconfig` (`key`, `value`, `comment`)\nvalues\n    ('apollo.portal.envs', 'dev', ''),\n    ('organizations', '[{\\\"orgid\\\":\\\"test1\\\",\\\"orgname\\\":\\\"1\\\"},{\\\"orgid\\\":\\\"test2\\\",\\\"orgname\\\":\\\"2\\\"}]', ''),\n    ('superadmin', 'apollo', 'portal'),\n    ('api.readtimeout', '10000', 'httpread timeout'),\n    ('consumer.token.salt', 'somesalt', 'consumer token salt'),\n    ('admin.createprivatenamespace.switch', 'true', 'namespace'),\n    ('configview.memberonly.envs', 'dev', 'env');\n\ninsert into `users` (`username`, `password`, `email`, `enabled`)\nvalues\n\t('apollo', '$2a$10$7r20us.bq9ubpf3baj3uqozvmvvb1rn3pyoke94gtz2.waouiiwxs', 'apollo@acme.com', 1);\n\ninsert into `authorities` (`username`, `authority`) values ('apollo', 'role_user');\n\n# sample data\n# ------------------------------------------------------------\ninsert into `app` (`appid`, `name`, `orgid`, `orgname`, `ownername`, `owneremail`)\nvalues\n\t('sampleapp', 'sample app', 'test1', '1', 'apollo', 'apollo@acme.com');\n\ninsert into `appnamespace` (`name`, `appid`, `format`, `ispublic`, `comment`)\nvalues\n\t('application', 'sampleapp', 'properties', 0, 'default app namespace');\n\ninsert into `permission` (`id`, `permissiontype`, `targetid`)\nvalues\n\t(1, 'createcluster', 'sampleapp'),\n\t(2, 'createnamespace', 'sampleapp'),\n\t(3, 'assignrole', 'sampleapp'),\n\t(4, 'modifynamespace', 'sampleapp+application'),\n\t(5, 'releasenamespace', 'sampleapp+application');\n\ninsert into `role` (`id`, `rolename`)\nvalues\n\t(1, 'master+sampleapp'),\n\t(2, 'modifynamespace+sampleapp+application'),\n\t(3, 'releasenamespace+sampleapp+application');\n\ninsert into `rolepermission` (`roleid`, `permissionid`)\nvalues\n\t(1, 1),\n\t(1, 2),\n\t(1, 3),\n\t(2, 4),\n\t(3, 5);\n\ninsert into `userrole` (`userid`, `roleid`)\nvalues\n\t('apollo', 1),\n\t('apollo', 2),\n\t('apollo', 3);\n\n/*!40111 set sql_notes=@old_sql_notes */;\n/*!40101 set sql_mode=@old_sql_mode */;\n/*!40014 set foreign_key_checks=@old_foreign_key_checks */;\n/*!40101 set character_set_client=@old_character_set_client */;\n/*!40101 set character_set_results=@old_character_set_results */;\n/*!40101 set collation_connection=@old_collation_connection */;\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/apollo/sql\n\\cp ./sql/apolloconfigdb.sql /etc/apollo/sql/apolloconfigdb.sql -f\n\\cp ./sql/apolloportaldb.sql /etc/apollo/sql/apolloportaldb.sql -f\ndocker-compose up -d\n\n\n\n# sql\n\n# apolloconfigdb\n\nset @appid = 'tjs_public';\n \nuse `apolloconfigdb`;\n \nupdate `app` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `appnamespace` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `cluster` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `commit` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `grayreleaserule` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `release` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `releasehistory` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\ndelete from `instance` where `appid` = @appid;\ndelete from `instanceconfig` where `configappid` = @appid;\ndelete from `releasemessage` where `message` like concat(@appid, '+%');\n \n# handle namespaces and items\ncreate temporary table `namespaceids` as select `id` from `namespace` where `appid` = @appid and `isdeleted` = 0;\nupdate `namespace` set `isdeleted` = 1 where `id` in (select `id` from `namespaceids`);\nupdate `item` set `isdeleted` = 1 where `namespaceid` in (select `id` from `namespaceids`);\ndelete from `namespacelock` where `namespaceid` in (select `id` from `namespaceids`);\ndrop temporary table `namespaceids`;\n\n\n# apolloportaldb\n\nset @appid = 'tjs_public';\n \nuse `apolloportaldb`;\n \nupdate `app` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `appnamespace` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `favorite` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\n \n# handle roles and permissions\ncreate temporary table `permissionids` as select `id` from `permission` where (`targetid` = @appid or `targetid` like concat(@appid, '+%'))  and `isdeleted` = 0;\nupdate `permission` set `isdeleted` = 1 where `id` in (select `id` from `permissionids`);\nupdate `rolepermission` set `isdeleted` = 1 where `permissionid` in (select `id` from `permissionids`);\ndrop temporary table `permissionids`;\n \ncreate temporary table `roleids` as select `id` from `role` where (`rolename` = concat('master+', @appid) or `rolename` like concat('modifynamespace+', @appid, '+%') or `rolename` like concat('releasenamespace+', @appid, '+%')) and `isdeleted` = 0;\nupdate `role` set `isdeleted` = 1 where `id` in (select `id` from `roleids`);\nupdate `userrole` set `isdeleted` = 1 where `roleid` in (select `id` from `roleids`);\nupdate `consumerrole` set `isdeleted` = 1 where `roleid` in (select `id` from `roleids`);\ndrop temporary table `roleids`;\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Cassandra",frontmatter:{title:"Cassandra",date:"2023-09-05T14:43:18.000Z",permalink:"/pages/01958e/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/05.Cassandra.html",relativePath:"05.&/01.Docker/05.Cassandra.md",key:"v-54077827",path:"/pages/01958e/",headers:[{level:2,title:"Apache Cassandra  K/V ",slug:"apache-cassandra--k-v-",normalizedTitle:"apache cassandra  k/v ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:123},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1193},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2396}],headersStr:"Apache Cassandra  K/V   docker-compose.yml deploy.sh",content:'# Apache Cassandra  K/V \n\n\n\nhttps://cassandra.apache.org/\n\ngithubhttps://github.com/apolloconfig/apollo\n\n\n# \n\n\n\n> Apache Cassandra  Key-Value  Facebook \n\n\n\n * \n *  column \n * \n\nCassandra  Cassandra  Cassandra  Cassandra  \n\nCassandra  Google  BigTable Dynomite Key-Value   MongoDB  json  bjson Cassandra  Facebook  Amazon  Dynamo  Google BigTable Column FamilyP2P  Dynamo 2.0\n\n\n\n *   Cassandra \n *  Cassandra \n *  \n\n Cassandra \n\n *  \n *   5 \n *  \n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\n# 3 node cluster\n# If you see exit code 137 (OOM killer) then ensure Docker has access to more resources\nservices:\n\n  cassandra1:\n    image: cassandra:3.11.4\n    container_name: cassandra1\n    restart: always\n    environment:\n      TZ: Asia/Shanghai\n    ports:\n      - 9042:9042   # Native transport\n      - 7199:7199   # JMX\n      - 9160:9160   # Thrift clients\n\n  cassandra2:\n    image: cassandra:3.11.4\n    container_name: cassandra2\n    restart: always\n    command: /bin/bash -c "echo \'Waiting for seed node\' && sleep 30 && /docker-entrypoint.sh cassandra -f"\n    environment:\n      TZ: Asia/Shanghai\n      CASSANDRA_SEEDS: cassandra1\n    depends_on:\n      - "cassandra1"\n\n  # you cannot have multiple nodes join the cluster at the same time when\n  # cassandra.consistent.rangemovement is true so we further delay it to give it time to stabilize\n  cassandra3:\n    image: cassandra:3.11.4\n    container_name: cassandra3\n    restart: always\n    command: /bin/bash -c "echo \'Waiting for seed node\' && sleep 80 && /docker-entrypoint.sh cassandra -f"\n    environment:\n      TZ: Asia/Shanghai\n      CASSANDRA_SEEDS: cassandra1\n    depends_on:\n      - "cassandra1"\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',normalizedContent:'# apache cassandra  k/v \n\n\n\nhttps://cassandra.apache.org/\n\ngithubhttps://github.com/apolloconfig/apollo\n\n\n# \n\n\n\n> apache cassandra  key-value  facebook \n\n\n\n * \n *  column \n * \n\ncassandra  cassandra  cassandra  cassandra  \n\ncassandra  google  bigtable dynomite key-value   mongodb  json  bjson cassandra  facebook  amazon  dynamo  google bigtable column familyp2p  dynamo 2.0\n\n\n\n *   cassandra \n *  cassandra \n *  \n\n cassandra \n\n *  \n *   5 \n *  \n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\n# 3 node cluster\n# if you see exit code 137 (oom killer) then ensure docker has access to more resources\nservices:\n\n  cassandra1:\n    image: cassandra:3.11.4\n    container_name: cassandra1\n    restart: always\n    environment:\n      tz: asia/shanghai\n    ports:\n      - 9042:9042   # native transport\n      - 7199:7199   # jmx\n      - 9160:9160   # thrift clients\n\n  cassandra2:\n    image: cassandra:3.11.4\n    container_name: cassandra2\n    restart: always\n    command: /bin/bash -c "echo \'waiting for seed node\' && sleep 30 && /docker-entrypoint.sh cassandra -f"\n    environment:\n      tz: asia/shanghai\n      cassandra_seeds: cassandra1\n    depends_on:\n      - "cassandra1"\n\n  # you cannot have multiple nodes join the cluster at the same time when\n  # cassandra.consistent.rangemovement is true so we further delay it to give it time to stabilize\n  cassandra3:\n    image: cassandra:3.11.4\n    container_name: cassandra3\n    restart: always\n    command: /bin/bash -c "echo \'waiting for seed node\' && sleep 80 && /docker-entrypoint.sh cassandra -f"\n    environment:\n      tz: asia/shanghai\n      cassandra_seeds: cassandra1\n    depends_on:\n      - "cassandra1"\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Cerebro",frontmatter:{title:"Cerebro",date:"2023-09-05T15:06:10.000Z",permalink:"/pages/7e58c5/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/06.Cerebro.html",relativePath:"05.&/01.Docker/06.Cerebro.md",key:"v-1c067b47",path:"/pages/7e58c5/",headers:[{level:2,title:"Cerebro  Elastic Search ",slug:"cerebro--elastic-search-",normalizedTitle:"cerebro  elastic search ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:91},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:147},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:576}],headersStr:"Cerebro  Elastic Search   docker-compose.yml deploy.sh",content:"# Cerebro  Elastic Search \n\n\n\ngithubhttps://github.com/lmenezes/cerebro\n\n\n# \n\n\n\n> ES\n\nES\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\n# docker run -p 9000:9000 lmenezes/cerebro:0.9.2\n\nservices: \n\n  cerebro: \n    image: lmenezes/cerebro:0.9.2\n    container_name: cerebro\n    restart: always\n    hostname: cerebro\n    ports:\n      - 9000:9000\n    environment:\n      TZ: Asia/Shanghai\n    command: \n#      - -Dhosts.0.host=http://elasticsearch_node1:9200\n# ES\n      - -Dhosts.0.host=http://192.168.0.110:9200  \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# cerebro  elastic search \n\n\n\ngithubhttps://github.com/lmenezes/cerebro\n\n\n# \n\n\n\n> es\n\nes\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\n# docker run -p 9000:9000 lmenezes/cerebro:0.9.2\n\nservices: \n\n  cerebro: \n    image: lmenezes/cerebro:0.9.2\n    container_name: cerebro\n    restart: always\n    hostname: cerebro\n    ports:\n      - 9000:9000\n    environment:\n      tz: asia/shanghai\n    command: \n#      - -dhosts.0.host=http://elasticsearch_node1:9200\n# es\n      - -dhosts.0.host=http://192.168.0.110:9200  \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Consul",frontmatter:{title:"Consul",date:"2023-09-05T15:16:32.000Z",permalink:"/pages/3d230b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/08.Consul.html",relativePath:"05.&/01.Docker/08.Consul.md",key:"v-54a5a8f1",path:"/pages/3d230b/",headers:[{level:2,title:"Consul ",slug:"consul-",normalizedTitle:"consul ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:100},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:494},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:808},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1083},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:380},{level:3,title:"docker-compose.yml",slug:"docker-compose-yml-2",normalizedTitle:"docker-compose.yml",charIndex:808},{level:3,title:"deploy.sh",slug:"deploy-sh-2",normalizedTitle:"deploy.sh",charIndex:1083}],headersStr:"Consul    docker-compose.yml deploy.sh  docker-compose.yml deploy.sh",content:"# Consul \n\n\n\nhttps://consulproject.org/\n\ngithubhttps://github.com/consul/consul\n\n\n# \n\n\n\n> Consul  HTTP  DNS  SaaS \n\nhttp://demo.consul.io/ui/\n\nConsulHashiCorp Consul :\n\n * consulDNSHTTPsaas\n * consul\n * /HTTP\n * \n\n\n# \n\n *  Raft ,  Paxos . , zookeeper  Paxos,  etcd  Raft.\n *  ,, . zookeeper  etcd .\n * . etcd .\n *  http  dns . zookeeper , etcd  http .\n * web, etcd .\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n  consul:\n    image: consul:1.5\n    container_name: consul\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data:/consul/data\n    ports:\n      - 8500:8500\n\nvolumes: \n  consul_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n  consul1:\n    image: consul:1.5\n    container_name: consul1\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data1:/consul/data\n      - /etc/consul/watchs.json:/consul/config/watchs.json\n    command: agent -server -bootstrap-expect=3 -node=consul1 -bind '{{ GetPrivateInterfaces  | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n\n  consul2:\n    image: consul:1.5\n    container_name: consul2\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data2:/consul/data\n    command: agent -server -retry-join=consul1 -node=consul2 -bind '{{ GetPrivateInterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n    depends_on:\n        - consul1\n\n  consul3:\n    image: consul:1.5\n    container_name: consul3\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data3:/consul/data\n    command: agent -server -retry-join=consul1 -node=consul3 -bind '{{ GetPrivateInterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n    depends_on:\n        - consul1\n\n  consul4:\n    image: consul:1.5\n    container_name: consul4\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data4:/consul/data\n    command: agent -retry-join=consul1 -node=consul4 -bind '{{ GetPrivateInterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1 -ui \n    ports:\n      - 8500:8500\n    depends_on:\n        - consul2\n        - consul3\n\nvolumes: \n  consul_data1: \n  consul_data2: \n  consul_data3: \n  consul_data4: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/consul\n\\cp ../config/watchs.json /etc/consul/watchs.json -f\ndocker-compose up -d\n",normalizedContent:"# consul \n\n\n\nhttps://consulproject.org/\n\ngithubhttps://github.com/consul/consul\n\n\n# \n\n\n\n> consul  http  dns  saas \n\nhttp://demo.consul.io/ui/\n\nconsulhashicorp consul :\n\n * consuldnshttpsaas\n * consul\n * /http\n * \n\n\n# \n\n *  raft ,  paxos . , zookeeper  paxos,  etcd  raft.\n *  ,, . zookeeper  etcd .\n * . etcd .\n *  http  dns . zookeeper , etcd  http .\n * web, etcd .\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n  consul:\n    image: consul:1.5\n    container_name: consul\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data:/consul/data\n    ports:\n      - 8500:8500\n\nvolumes: \n  consul_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n  consul1:\n    image: consul:1.5\n    container_name: consul1\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data1:/consul/data\n      - /etc/consul/watchs.json:/consul/config/watchs.json\n    command: agent -server -bootstrap-expect=3 -node=consul1 -bind '{{ getprivateinterfaces  | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n\n  consul2:\n    image: consul:1.5\n    container_name: consul2\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data2:/consul/data\n    command: agent -server -retry-join=consul1 -node=consul2 -bind '{{ getprivateinterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n    depends_on:\n        - consul1\n\n  consul3:\n    image: consul:1.5\n    container_name: consul3\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data3:/consul/data\n    command: agent -server -retry-join=consul1 -node=consul3 -bind '{{ getprivateinterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n    depends_on:\n        - consul1\n\n  consul4:\n    image: consul:1.5\n    container_name: consul4\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data4:/consul/data\n    command: agent -retry-join=consul1 -node=consul4 -bind '{{ getprivateinterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1 -ui \n    ports:\n      - 8500:8500\n    depends_on:\n        - consul2\n        - consul3\n\nvolumes: \n  consul_data1: \n  consul_data2: \n  consul_data3: \n  consul_data4: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/consul\n\\cp ../config/watchs.json /etc/consul/watchs.json -f\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"ClickHouse",frontmatter:{title:"ClickHouse",date:"2023-09-05T15:08:57.000Z",permalink:"/pages/3b4977/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/07.ClickHouse.html",relativePath:"05.&/01.Docker/07.ClickHouse.md",key:"v-4b206a0f",path:"/pages/3b4977/",headers:[{level:2,title:"ClickHouse ",slug:"clickhouse-",normalizedTitle:"clickhouse ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:108},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:495},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:1085},{level:2,title:"sql",slug:"sql",normalizedTitle:"sql",charIndex:1303},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:2804},{level:2,title:"config.xml",slug:"config-xml",normalizedTitle:"config.xml",charIndex:3065},{level:2,title:"users.xml",slug:"users-xml",normalizedTitle:"users.xml",charIndex:3134},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:61546}],headersStr:"ClickHouse     sql docker-compose.yml config.xml users.xml deploy.sh",content:"# ClickHouse \n\n\n\nhttps://clickhouse.com/\n\ngithubhttps://github.com/ClickHouse/ClickHouse\n\n\n# \n\n\n\n> ClickHouse  Yandex  MPP  Vertica,InfiniDB.\n\nClickHouse  100-1000X:\n\n100Million :\n\n * ClickHouse  Vertica  5  Hive  279  My SQL  801 \n\n1Billion :\n\n * ClickHouse  Vertica  5 MySQL  Hive \n\n:\n\n * pre-build  Ubuntu \n *  Github  C++ \n\n\n# \n\n * True column-oriented\n * Vectorized query execution\n * Data compression\n * Parallel and distributed query execution\n * Real-time data ingestion\n * On-disk locality of reference\n * Real-time query processing\n * Cross-datacenter replication\n * High availability\n * SQL support\n * Local and distributed joins\n * Pluggable external dimension tables\n * Arrays and nested data types\n * Approximate query processing\n * Probabilistic data structures\n * Full support of IPv6\n * Features for web analytics\n * State-of-the-art algorithms\n * Detailed documentation\n * Clean documented code\n\n\n# \n\n * Web and App analytics\n * Advertising networks and RTB\n * Telecommunications\n * E-commerce\n * Information security\n * Monitoring and telemetry\n * Business intelligence\n * Online games\n * Internet of Things\n\n\n# sql\n\n-- \nSELECT * FROM system.metrics WHERE metric LIKE '%Connection';\n\n\n-- \nSELECT query_id, user, address, query  FROM system.processes ORDER BY query_id;\n\n-- \nSELECT name,path,formatReadableSize(free_space) AS free,formatReadableSize(total_space) AS total,formatReadableSize(keep_free_space) AS reserved FROM system.disks;\n\n-- \nSELECT\n    user,\n    client_hostname AS host,\n    client_name AS client,\n    formatDateTime(query_start_time, '%T') AS started,\n    query_duration_ms / 1000 AS sec,\n    round(memory_usage / 1048576) AS MEM_MB,\n    result_rows AS RES_CNT,\n    result_bytes / 1048576 AS RES_MB,\n    read_rows AS R_CNT,\n    round(read_bytes / 1048576) AS R_MB,\n    written_rows AS W_CNT,\n    round(written_bytes / 1048576) AS W_MB,\n    query\nFROM system.query_log\nWHERE type = 2\nORDER BY query_duration_ms DESC\n    LIMIT 10;\n\n-- \nselect\n    sum(rows) as row,--\n    formatReadableSize(sum(data_uncompressed_bytes)) as ysq,--\n    formatReadableSize(sum(data_compressed_bytes)) as ysh,--\n    round(sum(data_compressed_bytes) / sum(data_uncompressed_bytes) * 100, 0) ys_rate--\nfrom system.parts\nwhere database='datacenter';\n\n-- \nselect database,table,sum(rows) as rows\nfrom system.parts\nwhere database='datacenter'\ngroup by database, table\norder by rows desc;\n\n\nselect distinct table from system.parts where database='datacenter';\n\n\n-- drop  database datacenter;\n\nselect * from datacenter.`3cdb162688e14cc6a1bc65befca5347c_YC150`;\n\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  clickhouseserver: \n    image: yandex/clickhouse-server:21\n    container_name: clickhouseserver\n    restart: always\n    hostname: clickhouse\n    volumes: \n      - data:/var/lib/clickhouse\n      - /etc/clickhouse/config.xml:/etc/clickhouse-server/config.xml\n      - /etc/clickhouse/users.xml:/etc/clickhouse-server/users.xml\n    ports:\n      - 8123:8123\n      - 9000:9000\n    environment:\n      TZ: Asia/Shanghai \n  \n  # clickhouseclient:\n  #   image: yandex/clickhouse-client:21\n  #   container_name: clickhouseclient\n  #   restart: always\n  #   environment:\n  #     TZ: Asia/Shanghai\n  #   depends_on: ['clickhouseserver']\n\n  #docker run -it --rm --link clickhouseserver --net swarm_net yandex/clickhouse-client:21 --host clickhouseserver\n\nvolumes: \n  data: \n    driver: local\n\n\n\n# config.xml\n\n<?xml version=\"1.0\"?>\n\x3c!--\n  NOTE: User and query level settings are set up in \"users.xml\" file.\n  If you have accidentally specified user-level settings here, server won't start.\n  You can either move the settings to the right place inside \"users.xml\" file\n   or add <skip_check_for_incorrect_settings>1</skip_check_for_incorrect_settings> here.\n--\x3e\n<yandex>\n    <logger>\n        \x3c!-- Possible levels [1]:\n\n          - none (turns off logging)\n          - fatal\n          - critical\n          - error\n          - warning\n          - notice\n          - information\n          - debug\n          - trace\n\n            [1]: https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/Logger.h#L105-L114\n        --\x3e\n        <level>trace</level>\n        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>\n        \x3c!-- Rotation policy\n             See https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/FileChannel.h#L54-L85\n          --\x3e\n        <size>1000M</size>\n        <count>10</count>\n        \x3c!-- <console>1</console> --\x3e \x3c!-- Default behavior is autodetection (log to console if not daemon mode and is tty) --\x3e\n\n        \x3c!-- Per level overrides (legacy):\n\n        For example to suppress logging of the ConfigReloader you can use:\n        NOTE: levels.logger is reserved, see below.\n        --\x3e\n        \x3c!--\n        <levels>\n          <ConfigReloader>none</ConfigReloader>\n        </levels>\n        --\x3e\n\n        \x3c!-- Per level overrides:\n\n        For example to suppress logging of the RBAC for default user you can use:\n        (But please note that the logger name maybe changed from version to version, even after minor upgrade)\n        --\x3e\n        \x3c!--\n        <levels>\n          <logger>\n            <name>ContextAccess (default)</name>\n            <level>none</level>\n          </logger>\n          <logger>\n            <name>DatabaseOrdinary (test)</name>\n            <level>none</level>\n          </logger>\n        </levels>\n        --\x3e\n    </logger>\n\n    \x3c!-- It is the name that will be shown in the clickhouse-client.\n         By default, anything with \"production\" will be highlighted in red in query prompt.\n    --\x3e\n    \x3c!--display_name>production</display_name--\x3e\n\n    \x3c!-- Port for HTTP API. See also 'https_port' for secure connections.\n         This interface is also used by ODBC and JDBC drivers (DataGrip, Dbeaver, ...)\n         and by most of web interfaces (embedded UI, Grafana, Redash, ...).\n      --\x3e\n    <http_port>8123</http_port>\n\n    \x3c!-- Port for interaction by native protocol with:\n         - clickhouse-client and other native ClickHouse tools (clickhouse-benchmark, clickhouse-copier);\n         - clickhouse-server with other clickhouse-servers for distributed query processing;\n         - ClickHouse drivers and applications supporting native protocol\n         (this protocol is also informally called as \"the TCP protocol\");\n         See also 'tcp_port_secure' for secure connections.\n    --\x3e\n    <tcp_port>9000</tcp_port>\n\n    \x3c!-- Compatibility with MySQL protocol.\n         ClickHouse will pretend to be MySQL for applications connecting to this port.\n    --\x3e\n    <mysql_port>9004</mysql_port>\n\n    \x3c!-- Compatibility with PostgreSQL protocol.\n         ClickHouse will pretend to be PostgreSQL for applications connecting to this port.\n    --\x3e\n    <postgresql_port>9005</postgresql_port>\n\n    \x3c!-- HTTP API with TLS (HTTPS).\n         You have to configure certificate to enable this interface.\n         See the openSSL section below.\n    --\x3e\n    \x3c!-- <https_port>8443</https_port> --\x3e\n\n    \x3c!-- Native interface with TLS.\n         You have to configure certificate to enable this interface.\n         See the openSSL section below.\n    --\x3e\n    \x3c!-- <tcp_port_secure>9440</tcp_port_secure> --\x3e\n\n    \x3c!-- Native interface wrapped with PROXYv1 protocol\n         PROXYv1 header sent for every connection.\n         ClickHouse will extract information about proxy-forwarded client address from the header.\n    --\x3e\n    \x3c!-- <tcp_with_proxy_port>9011</tcp_with_proxy_port> --\x3e\n\n    \x3c!-- Port for communication between replicas. Used for data exchange.\n         It provides low-level data access between servers.\n         This port should not be accessible from untrusted networks.\n         See also 'interserver_http_credentials'.\n         Data transferred over connections to this port should not go through untrusted networks.\n         See also 'interserver_https_port'.\n      --\x3e\n    <interserver_http_port>9009</interserver_http_port>\n\n    \x3c!-- Port for communication between replicas with TLS.\n         You have to configure certificate to enable this interface.\n         See the openSSL section below.\n         See also 'interserver_http_credentials'.\n      --\x3e\n    \x3c!-- <interserver_https_port>9010</interserver_https_port> --\x3e\n\n    \x3c!-- Hostname that is used by other replicas to request this server.\n         If not specified, than it is determined analogous to 'hostname -f' command.\n         This setting could be used to switch replication to another network interface\n         (the server may be connected to multiple networks via multiple addresses)\n      --\x3e\n    \x3c!--\n    <interserver_http_host>example.yandex.ru</interserver_http_host>\n    --\x3e\n\n    \x3c!-- You can specify credentials for authenthication between replicas.\n         This is required when interserver_https_port is accessible from untrusted networks,\n         and also recommended to avoid SSRF attacks from possibly compromised services in your network.\n      --\x3e\n    \x3c!--<interserver_http_credentials>\n        <user>interserver</user>\n        <password></password>\n    </interserver_http_credentials>--\x3e\n\n    \x3c!-- Listen specified address.\n         Use :: (wildcard IPv6 address), if you want to accept connections both with IPv4 and IPv6 from everywhere.\n         Notes:\n         If you open connections from wildcard address, make sure that at least one of the following measures applied:\n         - server is protected by firewall and not accessible from untrusted networks;\n         - all users are restricted to subset of network addresses (see users.xml);\n         - all users have strong passwords, only secure (TLS) interfaces are accessible, or connections are only made via TLS interfaces.\n         - users without password have readonly access.\n         See also: https://www.shodan.io/search?query=clickhouse\n      --\x3e\n    \x3c!-- <listen_host>::</listen_host> --\x3e\n\n    \x3c!-- Same for hosts without support for IPv6: --\x3e\n    \x3c!-- <listen_host>0.0.0.0</listen_host> --\x3e\n\n    \x3c!-- Default values - try listen localhost on IPv4 and IPv6. --\x3e\n    \x3c!--\n    <listen_host>::1</listen_host>\n    <listen_host>127.0.0.1</listen_host>\n    --\x3e\n\n    \x3c!-- Don't exit if IPv6 or IPv4 networks are unavailable while trying to listen. --\x3e\n    \x3c!-- <listen_try>0</listen_try> --\x3e\n\n    \x3c!-- Allow multiple servers to listen on the same address:port. This is not recommended.\n      --\x3e\n    \x3c!-- <listen_reuse_port>0</listen_reuse_port> --\x3e\n\n    \x3c!-- <listen_backlog>64</listen_backlog> --\x3e\n\n    <max_connections>4096</max_connections>\n\n    \x3c!-- For 'Connection: keep-alive' in HTTP 1.1 --\x3e\n    <keep_alive_timeout>3</keep_alive_timeout>\n\n    \x3c!-- gRPC protocol (see src/Server/grpc_protos/clickhouse_grpc.proto for the API) --\x3e\n    \x3c!-- <grpc_port>9100</grpc_port> --\x3e\n    <grpc>\n        <enable_ssl>false</enable_ssl>\n\n        \x3c!-- The following two files are used only if enable_ssl=1 --\x3e\n        <ssl_cert_file>/path/to/ssl_cert_file</ssl_cert_file>\n        <ssl_key_file>/path/to/ssl_key_file</ssl_key_file>\n\n        \x3c!-- Whether server will request client for a certificate --\x3e\n        <ssl_require_client_auth>false</ssl_require_client_auth>\n\n        \x3c!-- The following file is used only if ssl_require_client_auth=1 --\x3e\n        <ssl_ca_cert_file>/path/to/ssl_ca_cert_file</ssl_ca_cert_file>\n\n        \x3c!-- Default compression algorithm (applied if client doesn't specify another algorithm).\n             Supported algorithms: none, deflate, gzip, stream_gzip --\x3e\n        <compression>deflate</compression>\n\n        \x3c!-- Default compression level (applied if client doesn't specify another level).\n             Supported levels: none, low, medium, high --\x3e\n        <compression_level>medium</compression_level>\n\n        \x3c!-- Send/receive message size limits in bytes. -1 means unlimited --\x3e\n        <max_send_message_size>-1</max_send_message_size>\n        <max_receive_message_size>-1</max_receive_message_size>\n\n        \x3c!-- Enable if you want very detailed logs --\x3e\n        <verbose_logs>false</verbose_logs>\n    </grpc>\n\n    \x3c!-- Used with https_port and tcp_port_secure. Full ssl options list: https://github.com/ClickHouse-Extras/poco/blob/master/NetSSL_OpenSSL/include/Poco/Net/SSLManager.h#L71 --\x3e\n    <openSSL>\n        <server> \x3c!-- Used for https server AND secure tcp port --\x3e\n            \x3c!-- openssl req -subj \"/CN=localhost\" -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout /etc/clickhouse-server/server.key -out /etc/clickhouse-server/server.crt --\x3e\n            <certificateFile>/etc/clickhouse-server/server.crt</certificateFile>\n            <privateKeyFile>/etc/clickhouse-server/server.key</privateKeyFile>\n            \x3c!-- dhparams are optional. You can delete the <dhParamsFile> element.\n                 To generate dhparams, use the following command:\n                  openssl dhparam -out /etc/clickhouse-server/dhparam.pem 4096\n                 Only file format with BEGIN DH PARAMETERS is supported.\n              --\x3e\n            <dhParamsFile>/etc/clickhouse-server/dhparam.pem</dhParamsFile>\n            <verificationMode>none</verificationMode>\n            <loadDefaultCAFile>true</loadDefaultCAFile>\n            <cacheSessions>true</cacheSessions>\n            <disableProtocols>sslv2,sslv3</disableProtocols>\n            <preferServerCiphers>true</preferServerCiphers>\n        </server>\n\n        <client> \x3c!-- Used for connecting to https dictionary source and secured Zookeeper communication --\x3e\n            <loadDefaultCAFile>true</loadDefaultCAFile>\n            <cacheSessions>true</cacheSessions>\n            <disableProtocols>sslv2,sslv3</disableProtocols>\n            <preferServerCiphers>true</preferServerCiphers>\n            \x3c!-- Use for self-signed: <verificationMode>none</verificationMode> --\x3e\n            <invalidCertificateHandler>\n                \x3c!-- Use for self-signed: <name>AcceptCertificateHandler</name> --\x3e\n                <name>RejectCertificateHandler</name>\n            </invalidCertificateHandler>\n        </client>\n    </openSSL>\n\n    \x3c!-- Default root page on http[s] server. For example load UI from https://tabix.io/ when opening http://localhost:8123 --\x3e\n    \x3c!--\n    <http_server_default_response><![CDATA[<html ng-app=\"SMI2\"><head><base href=\"http://ui.tabix.io/\"></head><body><div ui-view=\"\" class=\"content-ui\"></div><script src=\"http://loader.tabix.io/master.js\"><\/script></body></html>]]></http_server_default_response>\n    --\x3e\n\n    \x3c!-- Maximum number of concurrent queries. --\x3e\n    <max_concurrent_queries>1000</max_concurrent_queries>\n\n    \x3c!-- Maximum memory usage (resident set size) for server process.\n         Zero value or unset means default. Default is \"max_server_memory_usage_to_ram_ratio\" of available physical RAM.\n         If the value is larger than \"max_server_memory_usage_to_ram_ratio\" of available physical RAM, it will be cut down.\n\n         The constraint is checked on query execution time.\n         If a query tries to allocate memory and the current memory usage plus allocation is greater\n          than specified threshold, exception will be thrown.\n\n         It is not practical to set this constraint to small values like just a few gigabytes,\n          because memory allocator will keep this amount of memory in caches and the server will deny service of queries.\n      --\x3e\n    <max_server_memory_usage>0</max_server_memory_usage>\n\n    \x3c!-- Maximum number of threads in the Global thread pool.\n    This will default to a maximum of 10000 threads if not specified.\n    This setting will be useful in scenarios where there are a large number\n    of distributed queries that are running concurrently but are idling most\n    of the time, in which case a higher number of threads might be required.\n    --\x3e\n\n    <max_thread_pool_size>10000</max_thread_pool_size>\n\n    \x3c!-- On memory constrained environments you may have to set this to value larger than 1.\n      --\x3e\n    <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>\n\n    \x3c!-- Simple server-wide memory profiler. Collect a stack trace at every peak allocation step (in bytes).\n         Data will be stored in system.trace_log table with query_id = empty string.\n         Zero means disabled.\n      --\x3e\n    <total_memory_profiler_step>4194304</total_memory_profiler_step>\n\n    \x3c!-- Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type.\n         The probability is for every alloc/free regardless to the size of the allocation.\n         Note that sampling happens only when the amount of untracked memory exceeds the untracked memory limit,\n          which is 4 MiB by default but can be lowered if 'total_memory_profiler_step' is lowered.\n         You may want to set 'total_memory_profiler_step' to 1 for extra fine grained sampling.\n      --\x3e\n    <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>\n\n    \x3c!-- Set limit on number of open files (default: maximum). This setting makes sense on Mac OS X because getrlimit() fails to retrieve\n         correct maximum value. --\x3e\n    \x3c!-- <max_open_files>262144</max_open_files> --\x3e\n\n    \x3c!-- Size of cache of uncompressed blocks of data, used in tables of MergeTree family.\n         In bytes. Cache is single for server. Memory is allocated only on demand.\n         Cache is used when 'use_uncompressed_cache' user setting turned on (off by default).\n         Uncompressed cache is advantageous only for very short queries and in rare cases.\n\n         Note: uncompressed cache can be pointless for lz4, because memory bandwidth\n         is slower than multi-core decompression on some server configurations.\n         Enabling it can sometimes paradoxically make queries slower.\n      --\x3e\n    <uncompressed_cache_size>8589934592</uncompressed_cache_size>\n\n    \x3c!-- Approximate size of mark cache, used in tables of MergeTree family.\n         In bytes. Cache is single for server. Memory is allocated only on demand.\n         You should not lower this value.\n      --\x3e\n    <mark_cache_size>5368709120</mark_cache_size>\n\n\n    \x3c!-- If you enable the `min_bytes_to_use_mmap_io` setting,\n         the data in MergeTree tables can be read with mmap to avoid copying from kernel to userspace.\n         It makes sense only for large files and helps only if data reside in page cache.\n         To avoid frequent open/mmap/munmap/close calls (which are very expensive due to consequent page faults)\n         and to reuse mappings from several threads and queries,\n         the cache of mapped files is maintained. Its size is the number of mapped regions (usually equal to the number of mapped files).\n         The amount of data in mapped files can be monitored\n         in system.metrics, system.metric_log by the MMappedFiles, MMappedFileBytes metrics\n         and in system.asynchronous_metrics, system.asynchronous_metrics_log by the MMapCacheCells metric,\n         and also in system.events, system.processes, system.query_log, system.query_thread_log by the\n         CreatedReadBufferMMap, CreatedReadBufferMMapFailed, MMappedFileCacheHits, MMappedFileCacheMisses events.\n         Note that the amount of data in mapped files does not consume memory directly and is not accounted\n         in query or server memory usage - because this memory can be discarded similar to OS page cache.\n         The cache is dropped (the files are closed) automatically on removal of old parts in MergeTree,\n         also it can be dropped manually by the SYSTEM DROP MMAP CACHE query.\n      --\x3e\n    <mmap_cache_size>1000</mmap_cache_size>\n\n\n    \x3c!-- Path to data directory, with trailing slash. --\x3e\n    <path>/var/lib/clickhouse/</path>\n\n    \x3c!-- Path to temporary data for processing hard queries. --\x3e\n    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>\n\n    \x3c!-- Policy from the <storage_configuration> for the temporary files.\n         If not set <tmp_path> is used, otherwise <tmp_path> is ignored.\n\n         Notes:\n         - move_factor              is ignored\n         - keep_free_space_bytes    is ignored\n         - max_data_part_size_bytes is ignored\n         - you must have exactly one volume in that policy\n    --\x3e\n    \x3c!-- <tmp_policy>tmp</tmp_policy> --\x3e\n\n    \x3c!-- Directory with user provided files that are accessible by 'file' table function. --\x3e\n    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>\n\n    \x3c!-- LDAP server definitions. --\x3e\n    <ldap_servers>\n        \x3c!-- List LDAP servers with their connection parameters here to later 1) use them as authenticators for dedicated local users,\n              who have 'ldap' authentication mechanism specified instead of 'password', or to 2) use them as remote user directories.\n             Parameters:\n                host - LDAP server hostname or IP, this parameter is mandatory and cannot be empty.\n                port - LDAP server port, default is 636 if enable_tls is set to true, 389 otherwise.\n                bind_dn - template used to construct the DN to bind to.\n                        The resulting DN will be constructed by replacing all '{user_name}' substrings of the template with the actual\n                         user name during each authentication attempt.\n                verification_cooldown - a period of time, in seconds, after a successful bind attempt, during which a user will be assumed\n                         to be successfully authenticated for all consecutive requests without contacting the LDAP server.\n                        Specify 0 (the default) to disable caching and force contacting the LDAP server for each authentication request.\n                enable_tls - flag to trigger use of secure connection to the LDAP server.\n                        Specify 'no' for plain text (ldap://) protocol (not recommended).\n                        Specify 'yes' for LDAP over SSL/TLS (ldaps://) protocol (recommended, the default).\n                        Specify 'starttls' for legacy StartTLS protocol (plain text (ldap://) protocol, upgraded to TLS).\n                tls_minimum_protocol_version - the minimum protocol version of SSL/TLS.\n                        Accepted values are: 'ssl2', 'ssl3', 'tls1.0', 'tls1.1', 'tls1.2' (the default).\n                tls_require_cert - SSL/TLS peer certificate verification behavior.\n                        Accepted values are: 'never', 'allow', 'try', 'demand' (the default).\n                tls_cert_file - path to certificate file.\n                tls_key_file - path to certificate key file.\n                tls_ca_cert_file - path to CA certificate file.\n                tls_ca_cert_dir - path to the directory containing CA certificates.\n                tls_cipher_suite - allowed cipher suite (in OpenSSL notation).\n             Example:\n                <my_ldap_server>\n                    <host>localhost</host>\n                    <port>636</port>\n                    <bind_dn>uid={user_name},ou=users,dc=example,dc=com</bind_dn>\n                    <verification_cooldown>300</verification_cooldown>\n                    <enable_tls>yes</enable_tls>\n                    <tls_minimum_protocol_version>tls1.2</tls_minimum_protocol_version>\n                    <tls_require_cert>demand</tls_require_cert>\n                    <tls_cert_file>/path/to/tls_cert_file</tls_cert_file>\n                    <tls_key_file>/path/to/tls_key_file</tls_key_file>\n                    <tls_ca_cert_file>/path/to/tls_ca_cert_file</tls_ca_cert_file>\n                    <tls_ca_cert_dir>/path/to/tls_ca_cert_dir</tls_ca_cert_dir>\n                    <tls_cipher_suite>ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:AES256-GCM-SHA384</tls_cipher_suite>\n                </my_ldap_server>\n        --\x3e\n    </ldap_servers>\n\n    \x3c!-- To enable Kerberos authentication support for HTTP requests (GSS-SPNEGO), for those users who are explicitly configured\n          to authenticate via Kerberos, define a single 'kerberos' section here.\n         Parameters:\n            principal - canonical service principal name, that will be acquired and used when accepting security contexts.\n                    This parameter is optional, if omitted, the default principal will be used.\n                    This parameter cannot be specified together with 'realm' parameter.\n            realm - a realm, that will be used to restrict authentication to only those requests whose initiator's realm matches it.\n                    This parameter is optional, if omitted, no additional filtering by realm will be applied.\n                    This parameter cannot be specified together with 'principal' parameter.\n         Example:\n            <kerberos />\n         Example:\n            <kerberos>\n                <principal>HTTP/clickhouse.example.com@EXAMPLE.COM</principal>\n            </kerberos>\n         Example:\n            <kerberos>\n                <realm>EXAMPLE.COM</realm>\n            </kerberos>\n    --\x3e\n\n    \x3c!-- Sources to read users, roles, access rights, profiles of settings, quotas. --\x3e\n    <user_directories>\n        <users_xml>\n            \x3c!-- Path to configuration file with predefined users. --\x3e\n            <path>users.xml</path>\n        </users_xml>\n        <local_directory>\n            \x3c!-- Path to folder where users created by SQL commands are stored. --\x3e\n            <path>/var/lib/clickhouse/access/</path>\n        </local_directory>\n\n        \x3c!-- To add an LDAP server as a remote user directory of users that are not defined locally, define a single 'ldap' section\n              with the following parameters:\n                server - one of LDAP server names defined in 'ldap_servers' config section above.\n                        This parameter is mandatory and cannot be empty.\n                roles - section with a list of locally defined roles that will be assigned to each user retrieved from the LDAP server.\n                        If no roles are specified here or assigned during role mapping (below), user will not be able to perform any\n                         actions after authentication.\n                role_mapping - section with LDAP search parameters and mapping rules.\n                        When a user authenticates, while still bound to LDAP, an LDAP search is performed using search_filter and the\n                         name of the logged in user. For each entry found during that search, the value of the specified attribute is\n                         extracted. For each attribute value that has the specified prefix, the prefix is removed, and the rest of the\n                         value becomes the name of a local role defined in ClickHouse, which is expected to be created beforehand by\n                         CREATE ROLE command.\n                        There can be multiple 'role_mapping' sections defined inside the same 'ldap' section. All of them will be\n                         applied.\n                    base_dn - template used to construct the base DN for the LDAP search.\n                            The resulting DN will be constructed by replacing all '{user_name}' and '{bind_dn}' substrings\n                             of the template with the actual user name and bind DN during each LDAP search.\n                    scope - scope of the LDAP search.\n                            Accepted values are: 'base', 'one_level', 'children', 'subtree' (the default).\n                    search_filter - template used to construct the search filter for the LDAP search.\n                            The resulting filter will be constructed by replacing all '{user_name}', '{bind_dn}', and '{base_dn}'\n                             substrings of the template with the actual user name, bind DN, and base DN during each LDAP search.\n                            Note, that the special characters must be escaped properly in XML.\n                    attribute - attribute name whose values will be returned by the LDAP search.\n                    prefix - prefix, that will be expected to be in front of each string in the original list of strings returned by\n                             the LDAP search. Prefix will be removed from the original strings and resulting strings will be treated\n                             as local role names. Empty, by default.\n             Example:\n                <ldap>\n                    <server>my_ldap_server</server>\n                    <roles>\n                        <my_local_role1 />\n                        <my_local_role2 />\n                    </roles>\n                    <role_mapping>\n                        <base_dn>ou=groups,dc=example,dc=com</base_dn>\n                        <scope>subtree</scope>\n                        <search_filter>(&amp;(objectClass=groupOfNames)(member={bind_dn}))</search_filter>\n                        <attribute>cn</attribute>\n                        <prefix>clickhouse_</prefix>\n                    </role_mapping>\n                </ldap>\n        --\x3e\n    </user_directories>\n\n    \x3c!-- Default profile of settings. --\x3e\n    <default_profile>default</default_profile>\n\n    \x3c!-- Comma-separated list of prefixes for user-defined settings. --\x3e\n    <custom_settings_prefixes></custom_settings_prefixes>\n\n    \x3c!-- System profile of settings. This settings are used by internal processes (Distributed DDL worker and so on). --\x3e\n    \x3c!-- <system_profile>default</system_profile> --\x3e\n\n    \x3c!-- Buffer profile of settings.\n         This settings are used by Buffer storage to flush data to the underlying table.\n         Default: used from system_profile directive.\n    --\x3e\n    \x3c!-- <buffer_profile>default</buffer_profile> --\x3e\n\n    \x3c!-- Default database. --\x3e\n    <default_database>default</default_database>\n\n    \x3c!-- Server time zone could be set here.\n\n         Time zone is used when converting between String and DateTime types,\n          when printing DateTime in text formats and parsing DateTime from text,\n          it is used in date and time related functions, if specific time zone was not passed as an argument.\n\n         Time zone is specified as identifier from IANA time zone database, like UTC or Africa/Abidjan.\n         If not specified, system time zone at server startup is used.\n\n         Please note, that server could display time zone alias instead of specified name.\n         Example: W-SU is an alias for Europe/Moscow and Zulu is an alias for UTC.\n    --\x3e\n    \x3c!-- <timezone>Europe/Moscow</timezone> --\x3e\n\n    \x3c!-- You can specify umask here (see \"man umask\"). Server will apply it on startup.\n         Number is always parsed as octal. Default umask is 027 (other users cannot read logs, data files, etc; group can only read).\n    --\x3e\n    \x3c!-- <umask>022</umask> --\x3e\n\n    \x3c!-- Perform mlockall after startup to lower first queries latency\n          and to prevent clickhouse executable from being paged out under high IO load.\n         Enabling this option is recommended but will lead to increased startup time for up to a few seconds.\n    --\x3e\n    <mlock_executable>true</mlock_executable>\n\n    \x3c!-- Reallocate memory for machine code (\"text\") using huge pages. Highly experimental. --\x3e\n    <remap_executable>false</remap_executable>\n\n    \x3c!-- Configuration of clusters that could be used in Distributed tables.\n         https://clickhouse.tech/docs/en/operations/table_engines/distributed/\n      --\x3e\n    <remote_servers>\n        \x3c!-- Test only shard config for testing distributed storage --\x3e\n        <test_shard_localhost>\n            \x3c!-- Inter-server per-cluster secret for Distributed queries\n                 default: no secret (no authentication will be performed)\n\n                 If set, then Distributed queries will be validated on shards, so at least:\n                 - such cluster should exist on the shard,\n                 - such cluster should have the same secret.\n\n                 And also (and which is more important), the initial_user will\n                 be used as current user for the query.\n\n                 Right now the protocol is pretty simple and it only takes into account:\n                 - cluster name\n                 - query\n\n                 Also it will be nice if the following will be implemented:\n                 - source hostname (see interserver_http_host), but then it will depends from DNS,\n                   it can use IP address instead, but then the you need to get correct on the initiator node.\n                 - target hostname / ip address (same notes as for source hostname)\n                 - time-based security tokens\n            --\x3e\n            \x3c!-- <secret></secret> --\x3e\n\n            <shard>\n                \x3c!-- Optional. Whether to write data to just one of the replicas. Default: false (write data to all replicas). --\x3e\n                \x3c!-- <internal_replication>false</internal_replication> --\x3e\n                \x3c!-- Optional. Shard weight when writing data. Default: 1. --\x3e\n                \x3c!-- <weight>1</weight> --\x3e\n                <replica>\n                    <host>localhost</host>\n                    <port>9000</port>\n                    \x3c!-- Optional. Priority of the replica for load_balancing. Default: 1 (less value has more priority). --\x3e\n                    \x3c!-- <priority>1</priority> --\x3e\n                </replica>\n            </shard>\n        </test_shard_localhost>\n        <test_cluster_two_shards_localhost>\n             <shard>\n                 <replica>\n                     <host>localhost</host>\n                     <port>9000</port>\n                 </replica>\n             </shard>\n             <shard>\n                 <replica>\n                     <host>localhost</host>\n                     <port>9000</port>\n                 </replica>\n             </shard>\n        </test_cluster_two_shards_localhost>\n        <test_cluster_two_shards>\n            <shard>\n                <replica>\n                    <host>127.0.0.1</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <replica>\n                    <host>127.0.0.2</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n        </test_cluster_two_shards>\n        <test_cluster_two_shards_internal_replication>\n            <shard>\n                <internal_replication>true</internal_replication>\n                <replica>\n                    <host>127.0.0.1</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <internal_replication>true</internal_replication>\n                <replica>\n                    <host>127.0.0.2</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n        </test_cluster_two_shards_internal_replication>\n        <test_shard_localhost_secure>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>9440</port>\n                    <secure>1</secure>\n                </replica>\n            </shard>\n        </test_shard_localhost_secure>\n        <test_unavailable_shard>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>1</port>\n                </replica>\n            </shard>\n        </test_unavailable_shard>\n    </remote_servers>\n\n    \x3c!-- The list of hosts allowed to use in URL-related storage engines and table functions.\n        If this section is not present in configuration, all hosts are allowed.\n    --\x3e\n    \x3c!--<remote_url_allow_hosts>--\x3e\n        \x3c!-- Host should be specified exactly as in URL. The name is checked before DNS resolution.\n            Example: \"yandex.ru\", \"yandex.ru.\" and \"www.yandex.ru\" are different hosts.\n                    If port is explicitly specified in URL, the host:port is checked as a whole.\n                    If host specified here without port, any port with this host allowed.\n                    \"yandex.ru\" -> \"yandex.ru:443\", \"yandex.ru:80\" etc. is allowed, but \"yandex.ru:80\" -> only \"yandex.ru:80\" is allowed.\n            If the host is specified as IP address, it is checked as specified in URL. Example: \"[2a02:6b8:a::a]\".\n            If there are redirects and support for redirects is enabled, every redirect (the Location field) is checked.\n        --\x3e\n\n        \x3c!-- Regular expression can be specified. RE2 engine is used for regexps.\n            Regexps are not aligned: don't forget to add ^ and $. Also don't forget to escape dot (.) metacharacter\n            (forgetting to do so is a common source of error).\n        --\x3e\n    \x3c!--</remote_url_allow_hosts>--\x3e\n\n    \x3c!-- If element has 'incl' attribute, then for it's value will be used corresponding substitution from another file.\n         By default, path to file with substitutions is /etc/metrika.xml. It could be changed in config in 'include_from' element.\n         Values for substitutions are specified in /yandex/name_of_substitution elements in that file.\n      --\x3e\n\n    \x3c!-- ZooKeeper is used to store metadata about replicas, when using Replicated tables.\n         Optional. If you don't use replicated tables, you could omit that.\n\n         See https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/\n      --\x3e\n\n    \x3c!--\n    <zookeeper>\n        <node>\n            <host>example1</host>\n            <port>2181</port>\n        </node>\n        <node>\n            <host>example2</host>\n            <port>2181</port>\n        </node>\n        <node>\n            <host>example3</host>\n            <port>2181</port>\n        </node>\n    </zookeeper>\n    --\x3e\n\n    \x3c!-- Substitutions for parameters of replicated tables.\n          Optional. If you don't use replicated tables, you could omit that.\n\n         See https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/#creating-replicated-tables\n      --\x3e\n    \x3c!--\n    <macros>\n        <shard>01</shard>\n        <replica>example01-01-1</replica>\n    </macros>\n    --\x3e\n\n\n    \x3c!-- Reloading interval for embedded dictionaries, in seconds. Default: 3600. --\x3e\n    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>\n\n\n    \x3c!-- Maximum session timeout, in seconds. Default: 3600. --\x3e\n    <max_session_timeout>3600</max_session_timeout>\n\n    \x3c!-- Default session timeout, in seconds. Default: 60. --\x3e\n    <default_session_timeout>60</default_session_timeout>\n\n    \x3c!-- Sending data to Graphite for monitoring. Several sections can be defined. --\x3e\n    \x3c!--\n        interval - send every X second\n        root_path - prefix for keys\n        hostname_in_path - append hostname to root_path (default = true)\n        metrics - send data from table system.metrics\n        events - send data from table system.events\n        asynchronous_metrics - send data from table system.asynchronous_metrics\n    --\x3e\n    \x3c!--\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>60</interval>\n        <root_path>one_min</root_path>\n        <hostname_in_path>true</hostname_in_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <events_cumulative>false</events_cumulative>\n        <asynchronous_metrics>true</asynchronous_metrics>\n    </graphite>\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>1</interval>\n        <root_path>one_sec</root_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <events_cumulative>false</events_cumulative>\n        <asynchronous_metrics>false</asynchronous_metrics>\n    </graphite>\n    --\x3e\n\n    \x3c!-- Serve endpoint for Prometheus monitoring. --\x3e\n    \x3c!--\n        endpoint - mertics path (relative to root, statring with \"/\")\n        port - port to setup server. If not defined or 0 than http_port used\n        metrics - send data from table system.metrics\n        events - send data from table system.events\n        asynchronous_metrics - send data from table system.asynchronous_metrics\n        status_info - send data from different component from CH, ex: Dictionaries status\n    --\x3e\n    \x3c!--\n    <prometheus>\n        <endpoint>/metrics</endpoint>\n        <port>9363</port>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <asynchronous_metrics>true</asynchronous_metrics>\n        <status_info>true</status_info>\n    </prometheus>\n    --\x3e\n\n    \x3c!-- Query log. Used only for queries with setting log_queries = 1. --\x3e\n    <query_log>\n        \x3c!-- What table to insert data. If table is not exist, it will be created.\n             When query log structure is changed after system update,\n              then old table will be renamed and new table will be created automatically.\n        --\x3e\n        <database>system</database>\n        <table>query_log</table>\n        \x3c!--\n            PARTITION BY expr: https://clickhouse.yandex/docs/en/table_engines/mergetree-family/custom_partitioning_key/\n            Example:\n                event_date\n                toMonday(event_date)\n                toYYYYMM(event_date)\n                toStartOfHour(event_time)\n        --\x3e\n        <partition_by>toYYYYMM(event_date)</partition_by>\n        \x3c!--\n            Table TTL specification: https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/#mergetree-table-ttl\n            Example:\n                event_date + INTERVAL 1 WEEK\n                event_date + INTERVAL 7 DAY DELETE\n                event_date + INTERVAL 2 WEEK TO DISK 'bbb'\n\n        <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>\n        --\x3e\n\n        \x3c!-- Instead of partition_by, you can provide full engine expression (starting with ENGINE = ) with parameters,\n             Example: <engine>ENGINE = MergeTree PARTITION BY toYYYYMM(event_date) ORDER BY (event_date, event_time) SETTINGS index_granularity = 1024</engine>\n          --\x3e\n\n        \x3c!-- Interval of flushing data. --\x3e\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_log>\n\n    \x3c!-- Trace log. Stores stack traces collected by query profilers.\n         See query_profiler_real_time_period_ns and query_profiler_cpu_time_period_ns settings. --\x3e\n    <trace_log>\n        <database>system</database>\n        <table>trace_log</table>\n\n        <partition_by>toYYYYMM(event_date)</partition_by>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </trace_log>\n\n    \x3c!-- Query thread log. Has information about all threads participated in query execution.\n         Used only for queries with setting log_query_threads = 1. --\x3e\n    <query_thread_log>\n        <database>system</database>\n        <table>query_thread_log</table>\n        <partition_by>toYYYYMM(event_date)</partition_by>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_thread_log>\n\n    \x3c!-- Uncomment if use part log.\n         Part log contains information about all actions with parts in MergeTree tables (creation, deletion, merges, downloads).\n    <part_log>\n        <database>system</database>\n        <table>part_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </part_log>\n    --\x3e\n\n    \x3c!-- Uncomment to write text log into table.\n         Text log contains all information from usual server log but stores it in structured and efficient way.\n         The level of the messages that goes to the table can be limited (<level>), if not specified all messages will go to the table.\n    <text_log>\n        <database>system</database>\n        <table>text_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n        <level></level>\n    </text_log>\n    --\x3e\n\n    \x3c!-- Metric log contains rows with current values of ProfileEvents, CurrentMetrics collected with \"collect_interval_milliseconds\" interval. --\x3e\n    <metric_log>\n        <database>system</database>\n        <table>metric_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n    </metric_log>\n\n    \x3c!--\n        Asynchronous metric log contains values of metrics from\n        system.asynchronous_metrics.\n    --\x3e\n    <asynchronous_metric_log>\n        <database>system</database>\n        <table>asynchronous_metric_log</table>\n        \x3c!--\n            Asynchronous metrics are updated once a minute, so there is\n            no need to flush more often.\n        --\x3e\n        <flush_interval_milliseconds>60000</flush_interval_milliseconds>\n    </asynchronous_metric_log>\n\n    \x3c!--\n        OpenTelemetry log contains OpenTelemetry trace spans.\n    --\x3e\n    <opentelemetry_span_log>\n        \x3c!--\n            The default table creation code is insufficient, this <engine> spec\n            is a workaround. There is no 'event_time' for this log, but two times,\n            start and finish. It is sorted by finish time, to avoid inserting\n            data too far away in the past (probably we can sometimes insert a span\n            that is seconds earlier than the last span in the table, due to a race\n            between several spans inserted in parallel). This gives the spans a\n            global order that we can use to e.g. retry insertion into some external\n            system.\n        --\x3e\n        <engine>\n            engine MergeTree\n            partition by toYYYYMM(finish_date)\n            order by (finish_date, finish_time_us, trace_id)\n        </engine>\n        <database>system</database>\n        <table>opentelemetry_span_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </opentelemetry_span_log>\n\n\n    \x3c!-- Crash log. Stores stack traces for fatal errors.\n         This table is normally empty. --\x3e\n    <crash_log>\n        <database>system</database>\n        <table>crash_log</table>\n\n        <partition_by />\n        <flush_interval_milliseconds>1000</flush_interval_milliseconds>\n    </crash_log>\n\n    \x3c!-- Parameters for embedded dictionaries, used in Yandex.Metrica.\n         See https://clickhouse.yandex/docs/en/dicts/internal_dicts/\n    --\x3e\n\n    \x3c!-- Path to file with region hierarchy. --\x3e\n    \x3c!-- <path_to_regions_hierarchy_file>/opt/geo/regions_hierarchy.txt</path_to_regions_hierarchy_file> --\x3e\n\n    \x3c!-- Path to directory with files containing names of regions --\x3e\n    \x3c!-- <path_to_regions_names_files>/opt/geo/</path_to_regions_names_files> --\x3e\n\n\n    \x3c!-- <top_level_domains_path>/var/lib/clickhouse/top_level_domains/</top_level_domains_path> --\x3e\n    \x3c!-- Custom TLD lists.\n         Format: <name>/path/to/file</name>\n\n         Changes will not be applied w/o server restart.\n         Path to the list is under top_level_domains_path (see above).\n    --\x3e\n    <top_level_domains_lists>\n        \x3c!--\n        <public_suffix_list>/path/to/public_suffix_list.dat</public_suffix_list>\n        --\x3e\n    </top_level_domains_lists>\n\n    \x3c!-- Configuration of external dictionaries. See:\n         https://clickhouse.tech/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts\n    --\x3e\n    <dictionaries_config>*_dictionary.xml</dictionaries_config>\n\n    \x3c!-- Uncomment if you want data to be compressed 30-100% better.\n         Don't do that if you just started using ClickHouse.\n      --\x3e\n    \x3c!--\n    <compression>\n        <!- - Set of variants. Checked in order. Last matching case wins. If nothing matches, lz4 will be used. - ->\n        <case>\n\n            <!- - Conditions. All must be satisfied. Some conditions may be omitted. - ->\n            <min_part_size>10000000000</min_part_size>        <!- - Min part size in bytes. - ->\n            <min_part_size_ratio>0.01</min_part_size_ratio>   <!- - Min size of part relative to whole table size. - ->\n\n            <!- - What compression method to use. - ->\n            <method>zstd</method>\n        </case>\n    </compression>\n    --\x3e\n\n    \x3c!-- Allow to execute distributed DDL queries (CREATE, DROP, ALTER, RENAME) on cluster.\n         Works only if ZooKeeper is enabled. Comment it if such functionality isn't required. --\x3e\n    <distributed_ddl>\n        \x3c!-- Path in ZooKeeper to queue with DDL queries --\x3e\n        <path>/clickhouse/task_queue/ddl</path>\n\n        \x3c!-- Settings from this profile will be used to execute DDL queries --\x3e\n        \x3c!-- <profile>default</profile> --\x3e\n\n        \x3c!-- Controls how much ON CLUSTER queries can be run simultaneously. --\x3e\n        \x3c!-- <pool_size>1</pool_size> --\x3e\n\n        \x3c!--\n             Cleanup settings (active tasks will not be removed)\n        --\x3e\n\n        \x3c!-- Controls task TTL (default 1 week) --\x3e\n        \x3c!-- <task_max_lifetime>604800</task_max_lifetime> --\x3e\n\n        \x3c!-- Controls how often cleanup should be performed (in seconds) --\x3e\n        \x3c!-- <cleanup_delay_period>60</cleanup_delay_period> --\x3e\n\n        \x3c!-- Controls how many tasks could be in the queue --\x3e\n        \x3c!-- <max_tasks_in_queue>1000</max_tasks_in_queue> --\x3e\n    </distributed_ddl>\n\n    \x3c!-- Settings to fine tune MergeTree tables. See documentation in source code, in MergeTreeSettings.h --\x3e\n    \x3c!--\n    <merge_tree>\n        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>\n    </merge_tree>\n    --\x3e\n\n    \x3c!-- Protection from accidental DROP.\n         If size of a MergeTree table is greater than max_table_size_to_drop (in bytes) than table could not be dropped with any DROP query.\n         If you want do delete one table and don't want to change clickhouse-server config, you could create special file <clickhouse-path>/flags/force_drop_table and make DROP once.\n         By default max_table_size_to_drop is 50GB; max_table_size_to_drop=0 allows to DROP any tables.\n         The same for max_partition_size_to_drop.\n         Uncomment to disable protection.\n    --\x3e\n    \x3c!-- <max_table_size_to_drop>0</max_table_size_to_drop> --\x3e\n    \x3c!-- <max_partition_size_to_drop>0</max_partition_size_to_drop> --\x3e\n\n    \x3c!-- Example of parameters for GraphiteMergeTree table engine --\x3e\n    <graphite_rollup_example>\n        <pattern>\n            <regexp>click_cost</regexp>\n            <function>any</function>\n            <retention>\n                <age>0</age>\n                <precision>3600</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>60</precision>\n            </retention>\n        </pattern>\n        <default>\n            <function>max</function>\n            <retention>\n                <age>0</age>\n                <precision>60</precision>\n            </retention>\n            <retention>\n                <age>3600</age>\n                <precision>300</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>3600</precision>\n            </retention>\n        </default>\n    </graphite_rollup_example>\n\n    \x3c!-- Directory in <clickhouse-path> containing schema files for various input formats.\n         The directory will be created if it doesn't exist.\n      --\x3e\n    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>\n\n    \x3c!-- Default query masking rules, matching lines would be replaced with something else in the logs\n        (both text logs and system.query_log).\n        name - name for the rule (optional)\n        regexp - RE2 compatible regular expression (mandatory)\n        replace - substitution string for sensitive data (optional, by default - six asterisks)\n    --\x3e\n    <query_masking_rules>\n        <rule>\n            <name>hide encrypt/decrypt arguments</name>\n            <regexp>((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\\s*\\(\\s*(?:'(?:\\\\'|.)+'|.*?)\\s*\\)</regexp>\n            \x3c!-- or more secure, but also more invasive:\n                (aes_\\w+)\\s*\\(.*\\)\n            --\x3e\n            <replace>\\1(???)</replace>\n        </rule>\n    </query_masking_rules>\n\n    \x3c!-- Uncomment to use custom http handlers.\n        rules are checked from top to bottom, first match runs the handler\n            url - to match request URL, you can use 'regex:' prefix to use regex match(optional)\n            methods - to match request method, you can use commas to separate multiple method matches(optional)\n            headers - to match request headers, match each child element(child element name is header name), you can use 'regex:' prefix to use regex match(optional)\n        handler is request handler\n            type - supported types: static, dynamic_query_handler, predefined_query_handler\n            query - use with predefined_query_handler type, executes query when the handler is called\n            query_param_name - use with dynamic_query_handler type, extracts and executes the value corresponding to the <query_param_name> value in HTTP request params\n            status - use with static type, response status code\n            content_type - use with static type, response content-type\n            response_content - use with static type, Response content sent to client, when using the prefix 'file://' or 'config://', find the content from the file or configuration send to client.\n\n    <http_handlers>\n        <rule>\n            <url>/</url>\n            <methods>POST,GET</methods>\n            <headers><pragma>no-cache</pragma></headers>\n            <handler>\n                <type>dynamic_query_handler</type>\n                <query_param_name>query</query_param_name>\n            </handler>\n        </rule>\n\n        <rule>\n            <url>/predefined_query</url>\n            <methods>POST,GET</methods>\n            <handler>\n                <type>predefined_query_handler</type>\n                <query>SELECT * FROM system.settings</query>\n            </handler>\n        </rule>\n\n        <rule>\n            <handler>\n                <type>static</type>\n                <status>200</status>\n                <content_type>text/plain; charset=UTF-8</content_type>\n                <response_content>config://http_server_default_response</response_content>\n            </handler>\n        </rule>\n    </http_handlers>\n    --\x3e\n\n    <send_crash_reports>\n        \x3c!-- Changing <enabled> to true allows sending crash reports to --\x3e\n        \x3c!-- the ClickHouse core developers team via Sentry https://sentry.io --\x3e\n        \x3c!-- Doing so at least in pre-production environments is highly appreciated --\x3e\n        <enabled>false</enabled>\n        \x3c!-- Change <anonymize> to true if you don't feel comfortable attaching the server hostname to the crash report --\x3e\n        <anonymize>false</anonymize>\n        \x3c!-- Default endpoint should be changed to different Sentry DSN only if you have --\x3e\n        \x3c!-- some in-house engineers or hired consultants who're going to debug ClickHouse issues for you --\x3e\n        <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>\n    </send_crash_reports>\n\n    \x3c!-- Uncomment to disable ClickHouse internal DNS caching. --\x3e\n    \x3c!-- <disable_internal_dns_cache>1</disable_internal_dns_cache> --\x3e\n</yandex>\n\n\n\n# users.xml\n\n<?xml version=\"1.0\"?>\n<yandex>\n    \x3c!-- Profiles of settings. --\x3e\n    <profiles>\n        \x3c!-- Default settings. --\x3e\n        <default>\n            \x3c!-- Maximum memory usage for processing single query, in bytes. --\x3e\n            <max_memory_usage>10000000000</max_memory_usage>\n\n            \x3c!-- How to choose between replicas during distributed query processing.\n                 random - choose random replica from set of replicas with minimum number of errors\n                 nearest_hostname - from set of replicas with minimum number of errors, choose replica\n                  with minimum number of different symbols between replica's hostname and local hostname\n                  (Hamming distance).\n                 in_order - first live replica is chosen in specified order.\n                 first_or_random - if first replica one has higher number of errors, pick a random one from replicas with minimum number of errors.\n            --\x3e\n            <load_balancing>random</load_balancing>\n            <max_query_size>1073741824</max_query_size>\n            <max_ast_elements>10000000</max_ast_elements>\n            <max_expanded_ast_elements>10000000</max_expanded_ast_elements>\n        </default>\n\n        \x3c!-- Profile that allows only read queries. --\x3e\n        <readonly>\n            <readonly>1</readonly>\n        </readonly>\n    </profiles>\n\n    \x3c!-- Users and ACL. --\x3e\n    <users>\n        \x3c!-- If user name was not specified, 'default' user is used. --\x3e\n        <default>\n            \x3c!-- Password could be specified in plaintext or in SHA256 (in hex format).\n\n                 If you want to specify password in plaintext (not recommended), place it in 'password' element.\n                 Example: <password>qwerty</password>.\n                 Password could be empty.\n\n                 If you want to specify SHA256, place it in 'password_sha256_hex' element.\n                 Example: <password_sha256_hex>65e84be33532fb784c48129675f9eff3a682b27168c0ea744b2cf58ee02337c5</password_sha256_hex>\n                 Restrictions of SHA256: impossibility to connect to ClickHouse using MySQL JS client (as of July 2019).\n\n                 If you want to specify double SHA1, place it in 'password_double_sha1_hex' element.\n                 Example: <password_double_sha1_hex>e395796d6546b1b65db9d665cd43f0e858dd4303</password_double_sha1_hex>\n\n                 If you want to specify a previously defined LDAP server (see 'ldap_servers' in the main config) for authentication,\n                  place its name in 'server' element inside 'ldap' element.\n                 Example: <ldap><server>my_ldap_server</server></ldap>\n\n                 If you want to authenticate the user via Kerberos (assuming Kerberos is enabled, see 'kerberos' in the main config),\n                  place 'kerberos' element instead of 'password' (and similar) elements.\n                 The name part of the canonical principal name of the initiator must match the user name for authentication to succeed.\n                 You can also place 'realm' element inside 'kerberos' element to further restrict authentication to only those requests\n                  whose initiator's realm matches it. \n                 Example: <kerberos />\n                 Example: <kerberos><realm>EXAMPLE.COM</realm></kerberos>\n\n                 How to generate decent password:\n                 Execute: PASSWORD=$(base64 < /dev/urandom | head -c8); echo \"$PASSWORD\"; echo -n \"$PASSWORD\" | sha256sum | tr -d '-'\n                 In first line will be password and in second - corresponding SHA256.\n\n                 How to generate double SHA1:\n                 Execute: PASSWORD=$(base64 < /dev/urandom | head -c8); echo \"$PASSWORD\"; echo -n \"$PASSWORD\" | sha1sum | tr -d '-' | xxd -r -p | sha1sum | tr -d '-'\n                 In first line will be password and in second - corresponding double SHA1.\n            --\x3e\n            <password>Clickhouse123$</password>\n\n            \x3c!-- List of networks with open access.\n\n                 To open access from everywhere, specify:\n                    <ip>::/0</ip>\n\n                 To open access only from localhost, specify:\n                    <ip>::1</ip>\n                    <ip>127.0.0.1</ip>\n\n                 Each element of list has one of the following forms:\n                 <ip> IP-address or network mask. Examples: 213.180.204.3 or 10.0.0.1/8 or 10.0.0.1/255.255.255.0\n                     2a02:6b8::3 or 2a02:6b8::3/64 or 2a02:6b8::3/ffff:ffff:ffff:ffff::.\n                 <host> Hostname. Example: server01.yandex.ru.\n                     To check access, DNS query is performed, and all received addresses compared to peer address.\n                 <host_regexp> Regular expression for host names. Example, ^server\\d\\d-\\d\\d-\\d\\.yandex\\.ru$\n                     To check access, DNS PTR query is performed for peer address and then regexp is applied.\n                     Then, for result of PTR query, another DNS query is performed and all received addresses compared to peer address.\n                     Strongly recommended that regexp is ends with $\n                 All results of DNS requests are cached till server restart.\n            --\x3e\n            <networks>\n                <ip>::/0</ip>\n            </networks>\n\n            \x3c!-- Settings profile for user. --\x3e\n            <profile>default</profile>\n\n            \x3c!-- Quota for user. --\x3e\n            <quota>default</quota>\n\n            \x3c!-- User can create other users and grant rights to them. --\x3e\n            \x3c!-- <access_management>1</access_management> --\x3e\n        </default>\n    </users>\n\n    \x3c!-- Quotas. --\x3e\n    <quotas>\n        \x3c!-- Name of quota. --\x3e\n        <default>\n            \x3c!-- Limits for time interval. You could specify many intervals with different limits. --\x3e\n            <interval>\n                \x3c!-- Length of interval. --\x3e\n                <duration>3600</duration>\n\n                \x3c!-- No limits. Just calculate resource usage for time interval. --\x3e\n                <queries>0</queries>\n                <errors>0</errors>\n                <result_rows>0</result_rows>\n                <read_rows>0</read_rows>\n                <execution_time>0</execution_time>\n            </interval>\n        </default>\n    </quotas>\n</yandex>\n\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/clickhouse\n\\cp ./config.xml /etc/clickhouse/config.xml -f\n\\cp ./users.xml /etc/clickhouse/users.xml -f\ndocker-compose up -d\n",normalizedContent:"# clickhouse \n\n\n\nhttps://clickhouse.com/\n\ngithubhttps://github.com/clickhouse/clickhouse\n\n\n# \n\n\n\n> clickhouse  yandex  mpp  vertica,infinidb.\n\nclickhouse  100-1000x:\n\n100million :\n\n * clickhouse  vertica  5  hive  279  my sql  801 \n\n1billion :\n\n * clickhouse  vertica  5 mysql  hive \n\n:\n\n * pre-build  ubuntu \n *  github  c++ \n\n\n# \n\n * true column-oriented\n * vectorized query execution\n * data compression\n * parallel and distributed query execution\n * real-time data ingestion\n * on-disk locality of reference\n * real-time query processing\n * cross-datacenter replication\n * high availability\n * sql support\n * local and distributed joins\n * pluggable external dimension tables\n * arrays and nested data types\n * approximate query processing\n * probabilistic data structures\n * full support of ipv6\n * features for web analytics\n * state-of-the-art algorithms\n * detailed documentation\n * clean documented code\n\n\n# \n\n * web and app analytics\n * advertising networks and rtb\n * telecommunications\n * e-commerce\n * information security\n * monitoring and telemetry\n * business intelligence\n * online games\n * internet of things\n\n\n# sql\n\n-- \nselect * from system.metrics where metric like '%connection';\n\n\n-- \nselect query_id, user, address, query  from system.processes order by query_id;\n\n-- \nselect name,path,formatreadablesize(free_space) as free,formatreadablesize(total_space) as total,formatreadablesize(keep_free_space) as reserved from system.disks;\n\n-- \nselect\n    user,\n    client_hostname as host,\n    client_name as client,\n    formatdatetime(query_start_time, '%t') as started,\n    query_duration_ms / 1000 as sec,\n    round(memory_usage / 1048576) as mem_mb,\n    result_rows as res_cnt,\n    result_bytes / 1048576 as res_mb,\n    read_rows as r_cnt,\n    round(read_bytes / 1048576) as r_mb,\n    written_rows as w_cnt,\n    round(written_bytes / 1048576) as w_mb,\n    query\nfrom system.query_log\nwhere type = 2\norder by query_duration_ms desc\n    limit 10;\n\n-- \nselect\n    sum(rows) as row,--\n    formatreadablesize(sum(data_uncompressed_bytes)) as ysq,--\n    formatreadablesize(sum(data_compressed_bytes)) as ysh,--\n    round(sum(data_compressed_bytes) / sum(data_uncompressed_bytes) * 100, 0) ys_rate--\nfrom system.parts\nwhere database='datacenter';\n\n-- \nselect database,table,sum(rows) as rows\nfrom system.parts\nwhere database='datacenter'\ngroup by database, table\norder by rows desc;\n\n\nselect distinct table from system.parts where database='datacenter';\n\n\n-- drop  database datacenter;\n\nselect * from datacenter.`3cdb162688e14cc6a1bc65befca5347c_yc150`;\n\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  clickhouseserver: \n    image: yandex/clickhouse-server:21\n    container_name: clickhouseserver\n    restart: always\n    hostname: clickhouse\n    volumes: \n      - data:/var/lib/clickhouse\n      - /etc/clickhouse/config.xml:/etc/clickhouse-server/config.xml\n      - /etc/clickhouse/users.xml:/etc/clickhouse-server/users.xml\n    ports:\n      - 8123:8123\n      - 9000:9000\n    environment:\n      tz: asia/shanghai \n  \n  # clickhouseclient:\n  #   image: yandex/clickhouse-client:21\n  #   container_name: clickhouseclient\n  #   restart: always\n  #   environment:\n  #     tz: asia/shanghai\n  #   depends_on: ['clickhouseserver']\n\n  #docker run -it --rm --link clickhouseserver --net swarm_net yandex/clickhouse-client:21 --host clickhouseserver\n\nvolumes: \n  data: \n    driver: local\n\n\n\n# config.xml\n\n<?xml version=\"1.0\"?>\n\x3c!--\n  note: user and query level settings are set up in \"users.xml\" file.\n  if you have accidentally specified user-level settings here, server won't start.\n  you can either move the settings to the right place inside \"users.xml\" file\n   or add <skip_check_for_incorrect_settings>1</skip_check_for_incorrect_settings> here.\n--\x3e\n<yandex>\n    <logger>\n        \x3c!-- possible levels [1]:\n\n          - none (turns off logging)\n          - fatal\n          - critical\n          - error\n          - warning\n          - notice\n          - information\n          - debug\n          - trace\n\n            [1]: https://github.com/pocoproject/poco/blob/poco-1.9.4-release/foundation/include/poco/logger.h#l105-l114\n        --\x3e\n        <level>trace</level>\n        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>\n        \x3c!-- rotation policy\n             see https://github.com/pocoproject/poco/blob/poco-1.9.4-release/foundation/include/poco/filechannel.h#l54-l85\n          --\x3e\n        <size>1000m</size>\n        <count>10</count>\n        \x3c!-- <console>1</console> --\x3e \x3c!-- default behavior is autodetection (log to console if not daemon mode and is tty) --\x3e\n\n        \x3c!-- per level overrides (legacy):\n\n        for example to suppress logging of the configreloader you can use:\n        note: levels.logger is reserved, see below.\n        --\x3e\n        \x3c!--\n        <levels>\n          <configreloader>none</configreloader>\n        </levels>\n        --\x3e\n\n        \x3c!-- per level overrides:\n\n        for example to suppress logging of the rbac for default user you can use:\n        (but please note that the logger name maybe changed from version to version, even after minor upgrade)\n        --\x3e\n        \x3c!--\n        <levels>\n          <logger>\n            <name>contextaccess (default)</name>\n            <level>none</level>\n          </logger>\n          <logger>\n            <name>databaseordinary (test)</name>\n            <level>none</level>\n          </logger>\n        </levels>\n        --\x3e\n    </logger>\n\n    \x3c!-- it is the name that will be shown in the clickhouse-client.\n         by default, anything with \"production\" will be highlighted in red in query prompt.\n    --\x3e\n    \x3c!--display_name>production</display_name--\x3e\n\n    \x3c!-- port for http api. see also 'https_port' for secure connections.\n         this interface is also used by odbc and jdbc drivers (datagrip, dbeaver, ...)\n         and by most of web interfaces (embedded ui, grafana, redash, ...).\n      --\x3e\n    <http_port>8123</http_port>\n\n    \x3c!-- port for interaction by native protocol with:\n         - clickhouse-client and other native clickhouse tools (clickhouse-benchmark, clickhouse-copier);\n         - clickhouse-server with other clickhouse-servers for distributed query processing;\n         - clickhouse drivers and applications supporting native protocol\n         (this protocol is also informally called as \"the tcp protocol\");\n         see also 'tcp_port_secure' for secure connections.\n    --\x3e\n    <tcp_port>9000</tcp_port>\n\n    \x3c!-- compatibility with mysql protocol.\n         clickhouse will pretend to be mysql for applications connecting to this port.\n    --\x3e\n    <mysql_port>9004</mysql_port>\n\n    \x3c!-- compatibility with postgresql protocol.\n         clickhouse will pretend to be postgresql for applications connecting to this port.\n    --\x3e\n    <postgresql_port>9005</postgresql_port>\n\n    \x3c!-- http api with tls (https).\n         you have to configure certificate to enable this interface.\n         see the openssl section below.\n    --\x3e\n    \x3c!-- <https_port>8443</https_port> --\x3e\n\n    \x3c!-- native interface with tls.\n         you have to configure certificate to enable this interface.\n         see the openssl section below.\n    --\x3e\n    \x3c!-- <tcp_port_secure>9440</tcp_port_secure> --\x3e\n\n    \x3c!-- native interface wrapped with proxyv1 protocol\n         proxyv1 header sent for every connection.\n         clickhouse will extract information about proxy-forwarded client address from the header.\n    --\x3e\n    \x3c!-- <tcp_with_proxy_port>9011</tcp_with_proxy_port> --\x3e\n\n    \x3c!-- port for communication between replicas. used for data exchange.\n         it provides low-level data access between servers.\n         this port should not be accessible from untrusted networks.\n         see also 'interserver_http_credentials'.\n         data transferred over connections to this port should not go through untrusted networks.\n         see also 'interserver_https_port'.\n      --\x3e\n    <interserver_http_port>9009</interserver_http_port>\n\n    \x3c!-- port for communication between replicas with tls.\n         you have to configure certificate to enable this interface.\n         see the openssl section below.\n         see also 'interserver_http_credentials'.\n      --\x3e\n    \x3c!-- <interserver_https_port>9010</interserver_https_port> --\x3e\n\n    \x3c!-- hostname that is used by other replicas to request this server.\n         if not specified, than it is determined analogous to 'hostname -f' command.\n         this setting could be used to switch replication to another network interface\n         (the server may be connected to multiple networks via multiple addresses)\n      --\x3e\n    \x3c!--\n    <interserver_http_host>example.yandex.ru</interserver_http_host>\n    --\x3e\n\n    \x3c!-- you can specify credentials for authenthication between replicas.\n         this is required when interserver_https_port is accessible from untrusted networks,\n         and also recommended to avoid ssrf attacks from possibly compromised services in your network.\n      --\x3e\n    \x3c!--<interserver_http_credentials>\n        <user>interserver</user>\n        <password></password>\n    </interserver_http_credentials>--\x3e\n\n    \x3c!-- listen specified address.\n         use :: (wildcard ipv6 address), if you want to accept connections both with ipv4 and ipv6 from everywhere.\n         notes:\n         if you open connections from wildcard address, make sure that at least one of the following measures applied:\n         - server is protected by firewall and not accessible from untrusted networks;\n         - all users are restricted to subset of network addresses (see users.xml);\n         - all users have strong passwords, only secure (tls) interfaces are accessible, or connections are only made via tls interfaces.\n         - users without password have readonly access.\n         see also: https://www.shodan.io/search?query=clickhouse\n      --\x3e\n    \x3c!-- <listen_host>::</listen_host> --\x3e\n\n    \x3c!-- same for hosts without support for ipv6: --\x3e\n    \x3c!-- <listen_host>0.0.0.0</listen_host> --\x3e\n\n    \x3c!-- default values - try listen localhost on ipv4 and ipv6. --\x3e\n    \x3c!--\n    <listen_host>::1</listen_host>\n    <listen_host>127.0.0.1</listen_host>\n    --\x3e\n\n    \x3c!-- don't exit if ipv6 or ipv4 networks are unavailable while trying to listen. --\x3e\n    \x3c!-- <listen_try>0</listen_try> --\x3e\n\n    \x3c!-- allow multiple servers to listen on the same address:port. this is not recommended.\n      --\x3e\n    \x3c!-- <listen_reuse_port>0</listen_reuse_port> --\x3e\n\n    \x3c!-- <listen_backlog>64</listen_backlog> --\x3e\n\n    <max_connections>4096</max_connections>\n\n    \x3c!-- for 'connection: keep-alive' in http 1.1 --\x3e\n    <keep_alive_timeout>3</keep_alive_timeout>\n\n    \x3c!-- grpc protocol (see src/server/grpc_protos/clickhouse_grpc.proto for the api) --\x3e\n    \x3c!-- <grpc_port>9100</grpc_port> --\x3e\n    <grpc>\n        <enable_ssl>false</enable_ssl>\n\n        \x3c!-- the following two files are used only if enable_ssl=1 --\x3e\n        <ssl_cert_file>/path/to/ssl_cert_file</ssl_cert_file>\n        <ssl_key_file>/path/to/ssl_key_file</ssl_key_file>\n\n        \x3c!-- whether server will request client for a certificate --\x3e\n        <ssl_require_client_auth>false</ssl_require_client_auth>\n\n        \x3c!-- the following file is used only if ssl_require_client_auth=1 --\x3e\n        <ssl_ca_cert_file>/path/to/ssl_ca_cert_file</ssl_ca_cert_file>\n\n        \x3c!-- default compression algorithm (applied if client doesn't specify another algorithm).\n             supported algorithms: none, deflate, gzip, stream_gzip --\x3e\n        <compression>deflate</compression>\n\n        \x3c!-- default compression level (applied if client doesn't specify another level).\n             supported levels: none, low, medium, high --\x3e\n        <compression_level>medium</compression_level>\n\n        \x3c!-- send/receive message size limits in bytes. -1 means unlimited --\x3e\n        <max_send_message_size>-1</max_send_message_size>\n        <max_receive_message_size>-1</max_receive_message_size>\n\n        \x3c!-- enable if you want very detailed logs --\x3e\n        <verbose_logs>false</verbose_logs>\n    </grpc>\n\n    \x3c!-- used with https_port and tcp_port_secure. full ssl options list: https://github.com/clickhouse-extras/poco/blob/master/netssl_openssl/include/poco/net/sslmanager.h#l71 --\x3e\n    <openssl>\n        <server> \x3c!-- used for https server and secure tcp port --\x3e\n            \x3c!-- openssl req -subj \"/cn=localhost\" -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout /etc/clickhouse-server/server.key -out /etc/clickhouse-server/server.crt --\x3e\n            <certificatefile>/etc/clickhouse-server/server.crt</certificatefile>\n            <privatekeyfile>/etc/clickhouse-server/server.key</privatekeyfile>\n            \x3c!-- dhparams are optional. you can delete the <dhparamsfile> element.\n                 to generate dhparams, use the following command:\n                  openssl dhparam -out /etc/clickhouse-server/dhparam.pem 4096\n                 only file format with begin dh parameters is supported.\n              --\x3e\n            <dhparamsfile>/etc/clickhouse-server/dhparam.pem</dhparamsfile>\n            <verificationmode>none</verificationmode>\n            <loaddefaultcafile>true</loaddefaultcafile>\n            <cachesessions>true</cachesessions>\n            <disableprotocols>sslv2,sslv3</disableprotocols>\n            <preferserverciphers>true</preferserverciphers>\n        </server>\n\n        <client> \x3c!-- used for connecting to https dictionary source and secured zookeeper communication --\x3e\n            <loaddefaultcafile>true</loaddefaultcafile>\n            <cachesessions>true</cachesessions>\n            <disableprotocols>sslv2,sslv3</disableprotocols>\n            <preferserverciphers>true</preferserverciphers>\n            \x3c!-- use for self-signed: <verificationmode>none</verificationmode> --\x3e\n            <invalidcertificatehandler>\n                \x3c!-- use for self-signed: <name>acceptcertificatehandler</name> --\x3e\n                <name>rejectcertificatehandler</name>\n            </invalidcertificatehandler>\n        </client>\n    </openssl>\n\n    \x3c!-- default root page on http[s] server. for example load ui from https://tabix.io/ when opening http://localhost:8123 --\x3e\n    \x3c!--\n    <http_server_default_response><![cdata[<html ng-app=\"smi2\"><head><base href=\"http://ui.tabix.io/\"></head><body><div ui-view=\"\" class=\"content-ui\"></div><script src=\"http://loader.tabix.io/master.js\"><\/script></body></html>]]></http_server_default_response>\n    --\x3e\n\n    \x3c!-- maximum number of concurrent queries. --\x3e\n    <max_concurrent_queries>1000</max_concurrent_queries>\n\n    \x3c!-- maximum memory usage (resident set size) for server process.\n         zero value or unset means default. default is \"max_server_memory_usage_to_ram_ratio\" of available physical ram.\n         if the value is larger than \"max_server_memory_usage_to_ram_ratio\" of available physical ram, it will be cut down.\n\n         the constraint is checked on query execution time.\n         if a query tries to allocate memory and the current memory usage plus allocation is greater\n          than specified threshold, exception will be thrown.\n\n         it is not practical to set this constraint to small values like just a few gigabytes,\n          because memory allocator will keep this amount of memory in caches and the server will deny service of queries.\n      --\x3e\n    <max_server_memory_usage>0</max_server_memory_usage>\n\n    \x3c!-- maximum number of threads in the global thread pool.\n    this will default to a maximum of 10000 threads if not specified.\n    this setting will be useful in scenarios where there are a large number\n    of distributed queries that are running concurrently but are idling most\n    of the time, in which case a higher number of threads might be required.\n    --\x3e\n\n    <max_thread_pool_size>10000</max_thread_pool_size>\n\n    \x3c!-- on memory constrained environments you may have to set this to value larger than 1.\n      --\x3e\n    <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>\n\n    \x3c!-- simple server-wide memory profiler. collect a stack trace at every peak allocation step (in bytes).\n         data will be stored in system.trace_log table with query_id = empty string.\n         zero means disabled.\n      --\x3e\n    <total_memory_profiler_step>4194304</total_memory_profiler_step>\n\n    \x3c!-- collect random allocations and deallocations and write them into system.trace_log with 'memorysample' trace_type.\n         the probability is for every alloc/free regardless to the size of the allocation.\n         note that sampling happens only when the amount of untracked memory exceeds the untracked memory limit,\n          which is 4 mib by default but can be lowered if 'total_memory_profiler_step' is lowered.\n         you may want to set 'total_memory_profiler_step' to 1 for extra fine grained sampling.\n      --\x3e\n    <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>\n\n    \x3c!-- set limit on number of open files (default: maximum). this setting makes sense on mac os x because getrlimit() fails to retrieve\n         correct maximum value. --\x3e\n    \x3c!-- <max_open_files>262144</max_open_files> --\x3e\n\n    \x3c!-- size of cache of uncompressed blocks of data, used in tables of mergetree family.\n         in bytes. cache is single for server. memory is allocated only on demand.\n         cache is used when 'use_uncompressed_cache' user setting turned on (off by default).\n         uncompressed cache is advantageous only for very short queries and in rare cases.\n\n         note: uncompressed cache can be pointless for lz4, because memory bandwidth\n         is slower than multi-core decompression on some server configurations.\n         enabling it can sometimes paradoxically make queries slower.\n      --\x3e\n    <uncompressed_cache_size>8589934592</uncompressed_cache_size>\n\n    \x3c!-- approximate size of mark cache, used in tables of mergetree family.\n         in bytes. cache is single for server. memory is allocated only on demand.\n         you should not lower this value.\n      --\x3e\n    <mark_cache_size>5368709120</mark_cache_size>\n\n\n    \x3c!-- if you enable the `min_bytes_to_use_mmap_io` setting,\n         the data in mergetree tables can be read with mmap to avoid copying from kernel to userspace.\n         it makes sense only for large files and helps only if data reside in page cache.\n         to avoid frequent open/mmap/munmap/close calls (which are very expensive due to consequent page faults)\n         and to reuse mappings from several threads and queries,\n         the cache of mapped files is maintained. its size is the number of mapped regions (usually equal to the number of mapped files).\n         the amount of data in mapped files can be monitored\n         in system.metrics, system.metric_log by the mmappedfiles, mmappedfilebytes metrics\n         and in system.asynchronous_metrics, system.asynchronous_metrics_log by the mmapcachecells metric,\n         and also in system.events, system.processes, system.query_log, system.query_thread_log by the\n         createdreadbuffermmap, createdreadbuffermmapfailed, mmappedfilecachehits, mmappedfilecachemisses events.\n         note that the amount of data in mapped files does not consume memory directly and is not accounted\n         in query or server memory usage - because this memory can be discarded similar to os page cache.\n         the cache is dropped (the files are closed) automatically on removal of old parts in mergetree,\n         also it can be dropped manually by the system drop mmap cache query.\n      --\x3e\n    <mmap_cache_size>1000</mmap_cache_size>\n\n\n    \x3c!-- path to data directory, with trailing slash. --\x3e\n    <path>/var/lib/clickhouse/</path>\n\n    \x3c!-- path to temporary data for processing hard queries. --\x3e\n    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>\n\n    \x3c!-- policy from the <storage_configuration> for the temporary files.\n         if not set <tmp_path> is used, otherwise <tmp_path> is ignored.\n\n         notes:\n         - move_factor              is ignored\n         - keep_free_space_bytes    is ignored\n         - max_data_part_size_bytes is ignored\n         - you must have exactly one volume in that policy\n    --\x3e\n    \x3c!-- <tmp_policy>tmp</tmp_policy> --\x3e\n\n    \x3c!-- directory with user provided files that are accessible by 'file' table function. --\x3e\n    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>\n\n    \x3c!-- ldap server definitions. --\x3e\n    <ldap_servers>\n        \x3c!-- list ldap servers with their connection parameters here to later 1) use them as authenticators for dedicated local users,\n              who have 'ldap' authentication mechanism specified instead of 'password', or to 2) use them as remote user directories.\n             parameters:\n                host - ldap server hostname or ip, this parameter is mandatory and cannot be empty.\n                port - ldap server port, default is 636 if enable_tls is set to true, 389 otherwise.\n                bind_dn - template used to construct the dn to bind to.\n                        the resulting dn will be constructed by replacing all '{user_name}' substrings of the template with the actual\n                         user name during each authentication attempt.\n                verification_cooldown - a period of time, in seconds, after a successful bind attempt, during which a user will be assumed\n                         to be successfully authenticated for all consecutive requests without contacting the ldap server.\n                        specify 0 (the default) to disable caching and force contacting the ldap server for each authentication request.\n                enable_tls - flag to trigger use of secure connection to the ldap server.\n                        specify 'no' for plain text (ldap://) protocol (not recommended).\n                        specify 'yes' for ldap over ssl/tls (ldaps://) protocol (recommended, the default).\n                        specify 'starttls' for legacy starttls protocol (plain text (ldap://) protocol, upgraded to tls).\n                tls_minimum_protocol_version - the minimum protocol version of ssl/tls.\n                        accepted values are: 'ssl2', 'ssl3', 'tls1.0', 'tls1.1', 'tls1.2' (the default).\n                tls_require_cert - ssl/tls peer certificate verification behavior.\n                        accepted values are: 'never', 'allow', 'try', 'demand' (the default).\n                tls_cert_file - path to certificate file.\n                tls_key_file - path to certificate key file.\n                tls_ca_cert_file - path to ca certificate file.\n                tls_ca_cert_dir - path to the directory containing ca certificates.\n                tls_cipher_suite - allowed cipher suite (in openssl notation).\n             example:\n                <my_ldap_server>\n                    <host>localhost</host>\n                    <port>636</port>\n                    <bind_dn>uid={user_name},ou=users,dc=example,dc=com</bind_dn>\n                    <verification_cooldown>300</verification_cooldown>\n                    <enable_tls>yes</enable_tls>\n                    <tls_minimum_protocol_version>tls1.2</tls_minimum_protocol_version>\n                    <tls_require_cert>demand</tls_require_cert>\n                    <tls_cert_file>/path/to/tls_cert_file</tls_cert_file>\n                    <tls_key_file>/path/to/tls_key_file</tls_key_file>\n                    <tls_ca_cert_file>/path/to/tls_ca_cert_file</tls_ca_cert_file>\n                    <tls_ca_cert_dir>/path/to/tls_ca_cert_dir</tls_ca_cert_dir>\n                    <tls_cipher_suite>ecdhe-ecdsa-aes256-gcm-sha384:ecdhe-rsa-aes256-gcm-sha384:aes256-gcm-sha384</tls_cipher_suite>\n                </my_ldap_server>\n        --\x3e\n    </ldap_servers>\n\n    \x3c!-- to enable kerberos authentication support for http requests (gss-spnego), for those users who are explicitly configured\n          to authenticate via kerberos, define a single 'kerberos' section here.\n         parameters:\n            principal - canonical service principal name, that will be acquired and used when accepting security contexts.\n                    this parameter is optional, if omitted, the default principal will be used.\n                    this parameter cannot be specified together with 'realm' parameter.\n            realm - a realm, that will be used to restrict authentication to only those requests whose initiator's realm matches it.\n                    this parameter is optional, if omitted, no additional filtering by realm will be applied.\n                    this parameter cannot be specified together with 'principal' parameter.\n         example:\n            <kerberos />\n         example:\n            <kerberos>\n                <principal>http/clickhouse.example.com@example.com</principal>\n            </kerberos>\n         example:\n            <kerberos>\n                <realm>example.com</realm>\n            </kerberos>\n    --\x3e\n\n    \x3c!-- sources to read users, roles, access rights, profiles of settings, quotas. --\x3e\n    <user_directories>\n        <users_xml>\n            \x3c!-- path to configuration file with predefined users. --\x3e\n            <path>users.xml</path>\n        </users_xml>\n        <local_directory>\n            \x3c!-- path to folder where users created by sql commands are stored. --\x3e\n            <path>/var/lib/clickhouse/access/</path>\n        </local_directory>\n\n        \x3c!-- to add an ldap server as a remote user directory of users that are not defined locally, define a single 'ldap' section\n              with the following parameters:\n                server - one of ldap server names defined in 'ldap_servers' config section above.\n                        this parameter is mandatory and cannot be empty.\n                roles - section with a list of locally defined roles that will be assigned to each user retrieved from the ldap server.\n                        if no roles are specified here or assigned during role mapping (below), user will not be able to perform any\n                         actions after authentication.\n                role_mapping - section with ldap search parameters and mapping rules.\n                        when a user authenticates, while still bound to ldap, an ldap search is performed using search_filter and the\n                         name of the logged in user. for each entry found during that search, the value of the specified attribute is\n                         extracted. for each attribute value that has the specified prefix, the prefix is removed, and the rest of the\n                         value becomes the name of a local role defined in clickhouse, which is expected to be created beforehand by\n                         create role command.\n                        there can be multiple 'role_mapping' sections defined inside the same 'ldap' section. all of them will be\n                         applied.\n                    base_dn - template used to construct the base dn for the ldap search.\n                            the resulting dn will be constructed by replacing all '{user_name}' and '{bind_dn}' substrings\n                             of the template with the actual user name and bind dn during each ldap search.\n                    scope - scope of the ldap search.\n                            accepted values are: 'base', 'one_level', 'children', 'subtree' (the default).\n                    search_filter - template used to construct the search filter for the ldap search.\n                            the resulting filter will be constructed by replacing all '{user_name}', '{bind_dn}', and '{base_dn}'\n                             substrings of the template with the actual user name, bind dn, and base dn during each ldap search.\n                            note, that the special characters must be escaped properly in xml.\n                    attribute - attribute name whose values will be returned by the ldap search.\n                    prefix - prefix, that will be expected to be in front of each string in the original list of strings returned by\n                             the ldap search. prefix will be removed from the original strings and resulting strings will be treated\n                             as local role names. empty, by default.\n             example:\n                <ldap>\n                    <server>my_ldap_server</server>\n                    <roles>\n                        <my_local_role1 />\n                        <my_local_role2 />\n                    </roles>\n                    <role_mapping>\n                        <base_dn>ou=groups,dc=example,dc=com</base_dn>\n                        <scope>subtree</scope>\n                        <search_filter>(&amp;(objectclass=groupofnames)(member={bind_dn}))</search_filter>\n                        <attribute>cn</attribute>\n                        <prefix>clickhouse_</prefix>\n                    </role_mapping>\n                </ldap>\n        --\x3e\n    </user_directories>\n\n    \x3c!-- default profile of settings. --\x3e\n    <default_profile>default</default_profile>\n\n    \x3c!-- comma-separated list of prefixes for user-defined settings. --\x3e\n    <custom_settings_prefixes></custom_settings_prefixes>\n\n    \x3c!-- system profile of settings. this settings are used by internal processes (distributed ddl worker and so on). --\x3e\n    \x3c!-- <system_profile>default</system_profile> --\x3e\n\n    \x3c!-- buffer profile of settings.\n         this settings are used by buffer storage to flush data to the underlying table.\n         default: used from system_profile directive.\n    --\x3e\n    \x3c!-- <buffer_profile>default</buffer_profile> --\x3e\n\n    \x3c!-- default database. --\x3e\n    <default_database>default</default_database>\n\n    \x3c!-- server time zone could be set here.\n\n         time zone is used when converting between string and datetime types,\n          when printing datetime in text formats and parsing datetime from text,\n          it is used in date and time related functions, if specific time zone was not passed as an argument.\n\n         time zone is specified as identifier from iana time zone database, like utc or africa/abidjan.\n         if not specified, system time zone at server startup is used.\n\n         please note, that server could display time zone alias instead of specified name.\n         example: w-su is an alias for europe/moscow and zulu is an alias for utc.\n    --\x3e\n    \x3c!-- <timezone>europe/moscow</timezone> --\x3e\n\n    \x3c!-- you can specify umask here (see \"man umask\"). server will apply it on startup.\n         number is always parsed as octal. default umask is 027 (other users cannot read logs, data files, etc; group can only read).\n    --\x3e\n    \x3c!-- <umask>022</umask> --\x3e\n\n    \x3c!-- perform mlockall after startup to lower first queries latency\n          and to prevent clickhouse executable from being paged out under high io load.\n         enabling this option is recommended but will lead to increased startup time for up to a few seconds.\n    --\x3e\n    <mlock_executable>true</mlock_executable>\n\n    \x3c!-- reallocate memory for machine code (\"text\") using huge pages. highly experimental. --\x3e\n    <remap_executable>false</remap_executable>\n\n    \x3c!-- configuration of clusters that could be used in distributed tables.\n         https://clickhouse.tech/docs/en/operations/table_engines/distributed/\n      --\x3e\n    <remote_servers>\n        \x3c!-- test only shard config for testing distributed storage --\x3e\n        <test_shard_localhost>\n            \x3c!-- inter-server per-cluster secret for distributed queries\n                 default: no secret (no authentication will be performed)\n\n                 if set, then distributed queries will be validated on shards, so at least:\n                 - such cluster should exist on the shard,\n                 - such cluster should have the same secret.\n\n                 and also (and which is more important), the initial_user will\n                 be used as current user for the query.\n\n                 right now the protocol is pretty simple and it only takes into account:\n                 - cluster name\n                 - query\n\n                 also it will be nice if the following will be implemented:\n                 - source hostname (see interserver_http_host), but then it will depends from dns,\n                   it can use ip address instead, but then the you need to get correct on the initiator node.\n                 - target hostname / ip address (same notes as for source hostname)\n                 - time-based security tokens\n            --\x3e\n            \x3c!-- <secret></secret> --\x3e\n\n            <shard>\n                \x3c!-- optional. whether to write data to just one of the replicas. default: false (write data to all replicas). --\x3e\n                \x3c!-- <internal_replication>false</internal_replication> --\x3e\n                \x3c!-- optional. shard weight when writing data. default: 1. --\x3e\n                \x3c!-- <weight>1</weight> --\x3e\n                <replica>\n                    <host>localhost</host>\n                    <port>9000</port>\n                    \x3c!-- optional. priority of the replica for load_balancing. default: 1 (less value has more priority). --\x3e\n                    \x3c!-- <priority>1</priority> --\x3e\n                </replica>\n            </shard>\n        </test_shard_localhost>\n        <test_cluster_two_shards_localhost>\n             <shard>\n                 <replica>\n                     <host>localhost</host>\n                     <port>9000</port>\n                 </replica>\n             </shard>\n             <shard>\n                 <replica>\n                     <host>localhost</host>\n                     <port>9000</port>\n                 </replica>\n             </shard>\n        </test_cluster_two_shards_localhost>\n        <test_cluster_two_shards>\n            <shard>\n                <replica>\n                    <host>127.0.0.1</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <replica>\n                    <host>127.0.0.2</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n        </test_cluster_two_shards>\n        <test_cluster_two_shards_internal_replication>\n            <shard>\n                <internal_replication>true</internal_replication>\n                <replica>\n                    <host>127.0.0.1</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <internal_replication>true</internal_replication>\n                <replica>\n                    <host>127.0.0.2</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n        </test_cluster_two_shards_internal_replication>\n        <test_shard_localhost_secure>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>9440</port>\n                    <secure>1</secure>\n                </replica>\n            </shard>\n        </test_shard_localhost_secure>\n        <test_unavailable_shard>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>1</port>\n                </replica>\n            </shard>\n        </test_unavailable_shard>\n    </remote_servers>\n\n    \x3c!-- the list of hosts allowed to use in url-related storage engines and table functions.\n        if this section is not present in configuration, all hosts are allowed.\n    --\x3e\n    \x3c!--<remote_url_allow_hosts>--\x3e\n        \x3c!-- host should be specified exactly as in url. the name is checked before dns resolution.\n            example: \"yandex.ru\", \"yandex.ru.\" and \"www.yandex.ru\" are different hosts.\n                    if port is explicitly specified in url, the host:port is checked as a whole.\n                    if host specified here without port, any port with this host allowed.\n                    \"yandex.ru\" -> \"yandex.ru:443\", \"yandex.ru:80\" etc. is allowed, but \"yandex.ru:80\" -> only \"yandex.ru:80\" is allowed.\n            if the host is specified as ip address, it is checked as specified in url. example: \"[2a02:6b8:a::a]\".\n            if there are redirects and support for redirects is enabled, every redirect (the location field) is checked.\n        --\x3e\n\n        \x3c!-- regular expression can be specified. re2 engine is used for regexps.\n            regexps are not aligned: don't forget to add ^ and $. also don't forget to escape dot (.) metacharacter\n            (forgetting to do so is a common source of error).\n        --\x3e\n    \x3c!--</remote_url_allow_hosts>--\x3e\n\n    \x3c!-- if element has 'incl' attribute, then for it's value will be used corresponding substitution from another file.\n         by default, path to file with substitutions is /etc/metrika.xml. it could be changed in config in 'include_from' element.\n         values for substitutions are specified in /yandex/name_of_substitution elements in that file.\n      --\x3e\n\n    \x3c!-- zookeeper is used to store metadata about replicas, when using replicated tables.\n         optional. if you don't use replicated tables, you could omit that.\n\n         see https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/\n      --\x3e\n\n    \x3c!--\n    <zookeeper>\n        <node>\n            <host>example1</host>\n            <port>2181</port>\n        </node>\n        <node>\n            <host>example2</host>\n            <port>2181</port>\n        </node>\n        <node>\n            <host>example3</host>\n            <port>2181</port>\n        </node>\n    </zookeeper>\n    --\x3e\n\n    \x3c!-- substitutions for parameters of replicated tables.\n          optional. if you don't use replicated tables, you could omit that.\n\n         see https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/#creating-replicated-tables\n      --\x3e\n    \x3c!--\n    <macros>\n        <shard>01</shard>\n        <replica>example01-01-1</replica>\n    </macros>\n    --\x3e\n\n\n    \x3c!-- reloading interval for embedded dictionaries, in seconds. default: 3600. --\x3e\n    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>\n\n\n    \x3c!-- maximum session timeout, in seconds. default: 3600. --\x3e\n    <max_session_timeout>3600</max_session_timeout>\n\n    \x3c!-- default session timeout, in seconds. default: 60. --\x3e\n    <default_session_timeout>60</default_session_timeout>\n\n    \x3c!-- sending data to graphite for monitoring. several sections can be defined. --\x3e\n    \x3c!--\n        interval - send every x second\n        root_path - prefix for keys\n        hostname_in_path - append hostname to root_path (default = true)\n        metrics - send data from table system.metrics\n        events - send data from table system.events\n        asynchronous_metrics - send data from table system.asynchronous_metrics\n    --\x3e\n    \x3c!--\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>60</interval>\n        <root_path>one_min</root_path>\n        <hostname_in_path>true</hostname_in_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <events_cumulative>false</events_cumulative>\n        <asynchronous_metrics>true</asynchronous_metrics>\n    </graphite>\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>1</interval>\n        <root_path>one_sec</root_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <events_cumulative>false</events_cumulative>\n        <asynchronous_metrics>false</asynchronous_metrics>\n    </graphite>\n    --\x3e\n\n    \x3c!-- serve endpoint for prometheus monitoring. --\x3e\n    \x3c!--\n        endpoint - mertics path (relative to root, statring with \"/\")\n        port - port to setup server. if not defined or 0 than http_port used\n        metrics - send data from table system.metrics\n        events - send data from table system.events\n        asynchronous_metrics - send data from table system.asynchronous_metrics\n        status_info - send data from different component from ch, ex: dictionaries status\n    --\x3e\n    \x3c!--\n    <prometheus>\n        <endpoint>/metrics</endpoint>\n        <port>9363</port>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <asynchronous_metrics>true</asynchronous_metrics>\n        <status_info>true</status_info>\n    </prometheus>\n    --\x3e\n\n    \x3c!-- query log. used only for queries with setting log_queries = 1. --\x3e\n    <query_log>\n        \x3c!-- what table to insert data. if table is not exist, it will be created.\n             when query log structure is changed after system update,\n              then old table will be renamed and new table will be created automatically.\n        --\x3e\n        <database>system</database>\n        <table>query_log</table>\n        \x3c!--\n            partition by expr: https://clickhouse.yandex/docs/en/table_engines/mergetree-family/custom_partitioning_key/\n            example:\n                event_date\n                tomonday(event_date)\n                toyyyymm(event_date)\n                tostartofhour(event_time)\n        --\x3e\n        <partition_by>toyyyymm(event_date)</partition_by>\n        \x3c!--\n            table ttl specification: https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/#mergetree-table-ttl\n            example:\n                event_date + interval 1 week\n                event_date + interval 7 day delete\n                event_date + interval 2 week to disk 'bbb'\n\n        <ttl>event_date + interval 30 day delete</ttl>\n        --\x3e\n\n        \x3c!-- instead of partition_by, you can provide full engine expression (starting with engine = ) with parameters,\n             example: <engine>engine = mergetree partition by toyyyymm(event_date) order by (event_date, event_time) settings index_granularity = 1024</engine>\n          --\x3e\n\n        \x3c!-- interval of flushing data. --\x3e\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_log>\n\n    \x3c!-- trace log. stores stack traces collected by query profilers.\n         see query_profiler_real_time_period_ns and query_profiler_cpu_time_period_ns settings. --\x3e\n    <trace_log>\n        <database>system</database>\n        <table>trace_log</table>\n\n        <partition_by>toyyyymm(event_date)</partition_by>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </trace_log>\n\n    \x3c!-- query thread log. has information about all threads participated in query execution.\n         used only for queries with setting log_query_threads = 1. --\x3e\n    <query_thread_log>\n        <database>system</database>\n        <table>query_thread_log</table>\n        <partition_by>toyyyymm(event_date)</partition_by>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_thread_log>\n\n    \x3c!-- uncomment if use part log.\n         part log contains information about all actions with parts in mergetree tables (creation, deletion, merges, downloads).\n    <part_log>\n        <database>system</database>\n        <table>part_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </part_log>\n    --\x3e\n\n    \x3c!-- uncomment to write text log into table.\n         text log contains all information from usual server log but stores it in structured and efficient way.\n         the level of the messages that goes to the table can be limited (<level>), if not specified all messages will go to the table.\n    <text_log>\n        <database>system</database>\n        <table>text_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n        <level></level>\n    </text_log>\n    --\x3e\n\n    \x3c!-- metric log contains rows with current values of profileevents, currentmetrics collected with \"collect_interval_milliseconds\" interval. --\x3e\n    <metric_log>\n        <database>system</database>\n        <table>metric_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n    </metric_log>\n\n    \x3c!--\n        asynchronous metric log contains values of metrics from\n        system.asynchronous_metrics.\n    --\x3e\n    <asynchronous_metric_log>\n        <database>system</database>\n        <table>asynchronous_metric_log</table>\n        \x3c!--\n            asynchronous metrics are updated once a minute, so there is\n            no need to flush more often.\n        --\x3e\n        <flush_interval_milliseconds>60000</flush_interval_milliseconds>\n    </asynchronous_metric_log>\n\n    \x3c!--\n        opentelemetry log contains opentelemetry trace spans.\n    --\x3e\n    <opentelemetry_span_log>\n        \x3c!--\n            the default table creation code is insufficient, this <engine> spec\n            is a workaround. there is no 'event_time' for this log, but two times,\n            start and finish. it is sorted by finish time, to avoid inserting\n            data too far away in the past (probably we can sometimes insert a span\n            that is seconds earlier than the last span in the table, due to a race\n            between several spans inserted in parallel). this gives the spans a\n            global order that we can use to e.g. retry insertion into some external\n            system.\n        --\x3e\n        <engine>\n            engine mergetree\n            partition by toyyyymm(finish_date)\n            order by (finish_date, finish_time_us, trace_id)\n        </engine>\n        <database>system</database>\n        <table>opentelemetry_span_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </opentelemetry_span_log>\n\n\n    \x3c!-- crash log. stores stack traces for fatal errors.\n         this table is normally empty. --\x3e\n    <crash_log>\n        <database>system</database>\n        <table>crash_log</table>\n\n        <partition_by />\n        <flush_interval_milliseconds>1000</flush_interval_milliseconds>\n    </crash_log>\n\n    \x3c!-- parameters for embedded dictionaries, used in yandex.metrica.\n         see https://clickhouse.yandex/docs/en/dicts/internal_dicts/\n    --\x3e\n\n    \x3c!-- path to file with region hierarchy. --\x3e\n    \x3c!-- <path_to_regions_hierarchy_file>/opt/geo/regions_hierarchy.txt</path_to_regions_hierarchy_file> --\x3e\n\n    \x3c!-- path to directory with files containing names of regions --\x3e\n    \x3c!-- <path_to_regions_names_files>/opt/geo/</path_to_regions_names_files> --\x3e\n\n\n    \x3c!-- <top_level_domains_path>/var/lib/clickhouse/top_level_domains/</top_level_domains_path> --\x3e\n    \x3c!-- custom tld lists.\n         format: <name>/path/to/file</name>\n\n         changes will not be applied w/o server restart.\n         path to the list is under top_level_domains_path (see above).\n    --\x3e\n    <top_level_domains_lists>\n        \x3c!--\n        <public_suffix_list>/path/to/public_suffix_list.dat</public_suffix_list>\n        --\x3e\n    </top_level_domains_lists>\n\n    \x3c!-- configuration of external dictionaries. see:\n         https://clickhouse.tech/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts\n    --\x3e\n    <dictionaries_config>*_dictionary.xml</dictionaries_config>\n\n    \x3c!-- uncomment if you want data to be compressed 30-100% better.\n         don't do that if you just started using clickhouse.\n      --\x3e\n    \x3c!--\n    <compression>\n        <!- - set of variants. checked in order. last matching case wins. if nothing matches, lz4 will be used. - ->\n        <case>\n\n            <!- - conditions. all must be satisfied. some conditions may be omitted. - ->\n            <min_part_size>10000000000</min_part_size>        <!- - min part size in bytes. - ->\n            <min_part_size_ratio>0.01</min_part_size_ratio>   <!- - min size of part relative to whole table size. - ->\n\n            <!- - what compression method to use. - ->\n            <method>zstd</method>\n        </case>\n    </compression>\n    --\x3e\n\n    \x3c!-- allow to execute distributed ddl queries (create, drop, alter, rename) on cluster.\n         works only if zookeeper is enabled. comment it if such functionality isn't required. --\x3e\n    <distributed_ddl>\n        \x3c!-- path in zookeeper to queue with ddl queries --\x3e\n        <path>/clickhouse/task_queue/ddl</path>\n\n        \x3c!-- settings from this profile will be used to execute ddl queries --\x3e\n        \x3c!-- <profile>default</profile> --\x3e\n\n        \x3c!-- controls how much on cluster queries can be run simultaneously. --\x3e\n        \x3c!-- <pool_size>1</pool_size> --\x3e\n\n        \x3c!--\n             cleanup settings (active tasks will not be removed)\n        --\x3e\n\n        \x3c!-- controls task ttl (default 1 week) --\x3e\n        \x3c!-- <task_max_lifetime>604800</task_max_lifetime> --\x3e\n\n        \x3c!-- controls how often cleanup should be performed (in seconds) --\x3e\n        \x3c!-- <cleanup_delay_period>60</cleanup_delay_period> --\x3e\n\n        \x3c!-- controls how many tasks could be in the queue --\x3e\n        \x3c!-- <max_tasks_in_queue>1000</max_tasks_in_queue> --\x3e\n    </distributed_ddl>\n\n    \x3c!-- settings to fine tune mergetree tables. see documentation in source code, in mergetreesettings.h --\x3e\n    \x3c!--\n    <merge_tree>\n        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>\n    </merge_tree>\n    --\x3e\n\n    \x3c!-- protection from accidental drop.\n         if size of a mergetree table is greater than max_table_size_to_drop (in bytes) than table could not be dropped with any drop query.\n         if you want do delete one table and don't want to change clickhouse-server config, you could create special file <clickhouse-path>/flags/force_drop_table and make drop once.\n         by default max_table_size_to_drop is 50gb; max_table_size_to_drop=0 allows to drop any tables.\n         the same for max_partition_size_to_drop.\n         uncomment to disable protection.\n    --\x3e\n    \x3c!-- <max_table_size_to_drop>0</max_table_size_to_drop> --\x3e\n    \x3c!-- <max_partition_size_to_drop>0</max_partition_size_to_drop> --\x3e\n\n    \x3c!-- example of parameters for graphitemergetree table engine --\x3e\n    <graphite_rollup_example>\n        <pattern>\n            <regexp>click_cost</regexp>\n            <function>any</function>\n            <retention>\n                <age>0</age>\n                <precision>3600</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>60</precision>\n            </retention>\n        </pattern>\n        <default>\n            <function>max</function>\n            <retention>\n                <age>0</age>\n                <precision>60</precision>\n            </retention>\n            <retention>\n                <age>3600</age>\n                <precision>300</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>3600</precision>\n            </retention>\n        </default>\n    </graphite_rollup_example>\n\n    \x3c!-- directory in <clickhouse-path> containing schema files for various input formats.\n         the directory will be created if it doesn't exist.\n      --\x3e\n    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>\n\n    \x3c!-- default query masking rules, matching lines would be replaced with something else in the logs\n        (both text logs and system.query_log).\n        name - name for the rule (optional)\n        regexp - re2 compatible regular expression (mandatory)\n        replace - substitution string for sensitive data (optional, by default - six asterisks)\n    --\x3e\n    <query_masking_rules>\n        <rule>\n            <name>hide encrypt/decrypt arguments</name>\n            <regexp>((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\\s*\\(\\s*(?:'(?:\\\\'|.)+'|.*?)\\s*\\)</regexp>\n            \x3c!-- or more secure, but also more invasive:\n                (aes_\\w+)\\s*\\(.*\\)\n            --\x3e\n            <replace>\\1(???)</replace>\n        </rule>\n    </query_masking_rules>\n\n    \x3c!-- uncomment to use custom http handlers.\n        rules are checked from top to bottom, first match runs the handler\n            url - to match request url, you can use 'regex:' prefix to use regex match(optional)\n            methods - to match request method, you can use commas to separate multiple method matches(optional)\n            headers - to match request headers, match each child element(child element name is header name), you can use 'regex:' prefix to use regex match(optional)\n        handler is request handler\n            type - supported types: static, dynamic_query_handler, predefined_query_handler\n            query - use with predefined_query_handler type, executes query when the handler is called\n            query_param_name - use with dynamic_query_handler type, extracts and executes the value corresponding to the <query_param_name> value in http request params\n            status - use with static type, response status code\n            content_type - use with static type, response content-type\n            response_content - use with static type, response content sent to client, when using the prefix 'file://' or 'config://', find the content from the file or configuration send to client.\n\n    <http_handlers>\n        <rule>\n            <url>/</url>\n            <methods>post,get</methods>\n            <headers><pragma>no-cache</pragma></headers>\n            <handler>\n                <type>dynamic_query_handler</type>\n                <query_param_name>query</query_param_name>\n            </handler>\n        </rule>\n\n        <rule>\n            <url>/predefined_query</url>\n            <methods>post,get</methods>\n            <handler>\n                <type>predefined_query_handler</type>\n                <query>select * from system.settings</query>\n            </handler>\n        </rule>\n\n        <rule>\n            <handler>\n                <type>static</type>\n                <status>200</status>\n                <content_type>text/plain; charset=utf-8</content_type>\n                <response_content>config://http_server_default_response</response_content>\n            </handler>\n        </rule>\n    </http_handlers>\n    --\x3e\n\n    <send_crash_reports>\n        \x3c!-- changing <enabled> to true allows sending crash reports to --\x3e\n        \x3c!-- the clickhouse core developers team via sentry https://sentry.io --\x3e\n        \x3c!-- doing so at least in pre-production environments is highly appreciated --\x3e\n        <enabled>false</enabled>\n        \x3c!-- change <anonymize> to true if you don't feel comfortable attaching the server hostname to the crash report --\x3e\n        <anonymize>false</anonymize>\n        \x3c!-- default endpoint should be changed to different sentry dsn only if you have --\x3e\n        \x3c!-- some in-house engineers or hired consultants who're going to debug clickhouse issues for you --\x3e\n        <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>\n    </send_crash_reports>\n\n    \x3c!-- uncomment to disable clickhouse internal dns caching. --\x3e\n    \x3c!-- <disable_internal_dns_cache>1</disable_internal_dns_cache> --\x3e\n</yandex>\n\n\n\n# users.xml\n\n<?xml version=\"1.0\"?>\n<yandex>\n    \x3c!-- profiles of settings. --\x3e\n    <profiles>\n        \x3c!-- default settings. --\x3e\n        <default>\n            \x3c!-- maximum memory usage for processing single query, in bytes. --\x3e\n            <max_memory_usage>10000000000</max_memory_usage>\n\n            \x3c!-- how to choose between replicas during distributed query processing.\n                 random - choose random replica from set of replicas with minimum number of errors\n                 nearest_hostname - from set of replicas with minimum number of errors, choose replica\n                  with minimum number of different symbols between replica's hostname and local hostname\n                  (hamming distance).\n                 in_order - first live replica is chosen in specified order.\n                 first_or_random - if first replica one has higher number of errors, pick a random one from replicas with minimum number of errors.\n            --\x3e\n            <load_balancing>random</load_balancing>\n            <max_query_size>1073741824</max_query_size>\n            <max_ast_elements>10000000</max_ast_elements>\n            <max_expanded_ast_elements>10000000</max_expanded_ast_elements>\n        </default>\n\n        \x3c!-- profile that allows only read queries. --\x3e\n        <readonly>\n            <readonly>1</readonly>\n        </readonly>\n    </profiles>\n\n    \x3c!-- users and acl. --\x3e\n    <users>\n        \x3c!-- if user name was not specified, 'default' user is used. --\x3e\n        <default>\n            \x3c!-- password could be specified in plaintext or in sha256 (in hex format).\n\n                 if you want to specify password in plaintext (not recommended), place it in 'password' element.\n                 example: <password>qwerty</password>.\n                 password could be empty.\n\n                 if you want to specify sha256, place it in 'password_sha256_hex' element.\n                 example: <password_sha256_hex>65e84be33532fb784c48129675f9eff3a682b27168c0ea744b2cf58ee02337c5</password_sha256_hex>\n                 restrictions of sha256: impossibility to connect to clickhouse using mysql js client (as of july 2019).\n\n                 if you want to specify double sha1, place it in 'password_double_sha1_hex' element.\n                 example: <password_double_sha1_hex>e395796d6546b1b65db9d665cd43f0e858dd4303</password_double_sha1_hex>\n\n                 if you want to specify a previously defined ldap server (see 'ldap_servers' in the main config) for authentication,\n                  place its name in 'server' element inside 'ldap' element.\n                 example: <ldap><server>my_ldap_server</server></ldap>\n\n                 if you want to authenticate the user via kerberos (assuming kerberos is enabled, see 'kerberos' in the main config),\n                  place 'kerberos' element instead of 'password' (and similar) elements.\n                 the name part of the canonical principal name of the initiator must match the user name for authentication to succeed.\n                 you can also place 'realm' element inside 'kerberos' element to further restrict authentication to only those requests\n                  whose initiator's realm matches it. \n                 example: <kerberos />\n                 example: <kerberos><realm>example.com</realm></kerberos>\n\n                 how to generate decent password:\n                 execute: password=$(base64 < /dev/urandom | head -c8); echo \"$password\"; echo -n \"$password\" | sha256sum | tr -d '-'\n                 in first line will be password and in second - corresponding sha256.\n\n                 how to generate double sha1:\n                 execute: password=$(base64 < /dev/urandom | head -c8); echo \"$password\"; echo -n \"$password\" | sha1sum | tr -d '-' | xxd -r -p | sha1sum | tr -d '-'\n                 in first line will be password and in second - corresponding double sha1.\n            --\x3e\n            <password>clickhouse123$</password>\n\n            \x3c!-- list of networks with open access.\n\n                 to open access from everywhere, specify:\n                    <ip>::/0</ip>\n\n                 to open access only from localhost, specify:\n                    <ip>::1</ip>\n                    <ip>127.0.0.1</ip>\n\n                 each element of list has one of the following forms:\n                 <ip> ip-address or network mask. examples: 213.180.204.3 or 10.0.0.1/8 or 10.0.0.1/255.255.255.0\n                     2a02:6b8::3 or 2a02:6b8::3/64 or 2a02:6b8::3/ffff:ffff:ffff:ffff::.\n                 <host> hostname. example: server01.yandex.ru.\n                     to check access, dns query is performed, and all received addresses compared to peer address.\n                 <host_regexp> regular expression for host names. example, ^server\\d\\d-\\d\\d-\\d\\.yandex\\.ru$\n                     to check access, dns ptr query is performed for peer address and then regexp is applied.\n                     then, for result of ptr query, another dns query is performed and all received addresses compared to peer address.\n                     strongly recommended that regexp is ends with $\n                 all results of dns requests are cached till server restart.\n            --\x3e\n            <networks>\n                <ip>::/0</ip>\n            </networks>\n\n            \x3c!-- settings profile for user. --\x3e\n            <profile>default</profile>\n\n            \x3c!-- quota for user. --\x3e\n            <quota>default</quota>\n\n            \x3c!-- user can create other users and grant rights to them. --\x3e\n            \x3c!-- <access_management>1</access_management> --\x3e\n        </default>\n    </users>\n\n    \x3c!-- quotas. --\x3e\n    <quotas>\n        \x3c!-- name of quota. --\x3e\n        <default>\n            \x3c!-- limits for time interval. you could specify many intervals with different limits. --\x3e\n            <interval>\n                \x3c!-- length of interval. --\x3e\n                <duration>3600</duration>\n\n                \x3c!-- no limits. just calculate resource usage for time interval. --\x3e\n                <queries>0</queries>\n                <errors>0</errors>\n                <result_rows>0</result_rows>\n                <read_rows>0</read_rows>\n                <execution_time>0</execution_time>\n            </interval>\n        </default>\n    </quotas>\n</yandex>\n\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/clickhouse\n\\cp ./config.xml /etc/clickhouse/config.xml -f\n\\cp ./users.xml /etc/clickhouse/users.xml -f\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"EasyMock",frontmatter:{title:"EasyMock",date:"2023-09-05T15:22:11.000Z",permalink:"/pages/ca4b88/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/09.EasyMock.html",relativePath:"05.&/01.Docker/09.EasyMock.md",key:"v-10f613aa",path:"/pages/ca4b88/",headers:[{level:2,title:"EasyMock ",slug:"easymock-",normalizedTitle:"easymock ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:113},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:161},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:433},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:738}],headersStr:"EasyMock    docker-compose.yml deploy.sh",content:"# EasyMock \n\n\n\nhttps://easy-mock.com/ ()\n\ngithubhttps://github.com/easy-mock/easy-mock\n\n\n# \n\n\n\n> Easy Mock \n\n\n# \n\n * \n * \n * \n * \n *  RESTful\n *  Swagger | OpenAPI Specification (1.2 & 2.0 & 3.0)\n   *  Swagger \n   * \n   * \n * \n * status/headers/cookies\n *  Mock.js \n *  restc \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  easymock: \n    image: jptx1234/easy-mock-all-in-one\n    container_name: easymock\n    restart: always\n    ports:\n      - 7300:7300\n    environment:\n      TZ: Asia/Shanghai\n    networks: \n      - swarm_net \n\nnetworks: \n  swarm_net: \n    external: true\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# easymock \n\n\n\nhttps://easy-mock.com/ ()\n\ngithubhttps://github.com/easy-mock/easy-mock\n\n\n# \n\n\n\n> easy mock \n\n\n# \n\n * \n * \n * \n * \n *  restful\n *  swagger | openapi specification (1.2 & 2.0 & 3.0)\n   *  swagger \n   * \n   * \n * \n * status/headers/cookies\n *  mock.js \n *  restc \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  easymock: \n    image: jptx1234/easy-mock-all-in-one\n    container_name: easymock\n    restart: always\n    ports:\n      - 7300:7300\n    environment:\n      tz: asia/shanghai\n    networks: \n      - swarm_net \n\nnetworks: \n  swarm_net: \n    external: true\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Emqx",frontmatter:{title:"Emqx",date:"2023-09-05T16:32:35.000Z",permalink:"/pages/d93c0b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/11.Emqx.html",relativePath:"05.&/01.Docker/11.Emqx.md",key:"v-0c164253",path:"/pages/d93c0b/",headers:[{level:2,title:"EMQX  MQTT ",slug:"emqx--mqtt-",normalizedTitle:"emqx  mqtt ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:94},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:233},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:370},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:681},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:183},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:476},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:1368},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:1454},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:480},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:1662},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:1773},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1821},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2425}],headersStr:"EMQX  MQTT             docker-compose.yml deploy.sh",content:"# EMQX  MQTT \n\n\n\nhttps://www.emqx.io/\n\ngithubhttps://github.com/emqx/emqx\n\n\n# \n\n\n\n> EMQX  MQTT \n\n MQTT EMQX \n\n\n# \n\nEMQX  MQTT \n\n MQTT EMQX \n\n\n# \n\n *  Apache 2.0  2013  200+ \n * MQTT 5.0100%  MQTT 5.0  3.x \n *  500  MQTT  1  MQTT \n *  MQTT \n *  Erlang/OTP  1 \n *  Masterless \n\n\n# \n\n EMQX \n\n\n# \n\n *  MQTT v3.1v3.1.1  v5.0 \n   * QoS 0QoS 1QoS 2 \n   * \n   * Retained Message\n   * Will Message\n   * \n   * $SYS/ \n * MQTT  4 \n   * TCP\n   * TLS\n   * WebSocket\n   * QUIC\n * HTTP \n * \n   * CoAP\n   * LwM2M\n   * MQTT-SN\n   * Stomp\n   * GB/T 32960\n   * JT/T 808\n\n MQTT \n\n * \n * \n * \n\n\n# \n\n * /RedisMySQLPostgreSQLMongoDB  HTTP Server \n *  JWT  JWKs\n * MQTT 5.0 \n * PSK \n *  Client IDIP RedisMySQLPostgreSQLMongoDB  HTTP Server \n * \n\n\n# \n\n *  (Cluster)\n * mcastdnsetcdk8s \n *  (Bridge)\n\n\n# \n\n * SQL  MQTT \n *  MQTT  Broker  EMQX CloudAWS IoT CoreAzure IoT Hub\n *  Webhook \n\n\n# \n\n * \n * \n * \n\n\n# \n\n * \n * \n * Prometheus/StatsD \n * \n * (Log Trace)\n * Erlang \n\n\n# \n\n * \n * \n * gRPC \n * gRPC \n\n\n# docker-compose.yml\n\n\nversion: '3.7'\nservices: \n  emqx: \n    #image: emqx/emqx:v3.2.0\n    image: emqx/emqx:4.4.4\n    container_name: emqx\n    restart: always\n    environment:\n      TZ: Asia/Shanghai\n    ports: \n      - 1883:1883 \n      - 8083:8083\n      - 8883:8883\n      - 8084:8084\n      - 18083:18083\n      - 11883:11883\n      - 4369:4369\n      - 5369:5369\n      - 6369:6369\n      - 8080:8080\n    volumes: \n      - emqx_data:/opt/emqx/data\n      - emqx_etc:/opt/emqx/etc\n      - emqx_lib:/opt/emqx/lib\n      - emqx_log:/opt/emqx/log\n\nvolumes: \n  emqx_data: \n  emqx_etc: \n  emqx_lib: \n  emqx_log: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# emqx  mqtt \n\n\n\nhttps://www.emqx.io/\n\ngithubhttps://github.com/emqx/emqx\n\n\n# \n\n\n\n> emqx  mqtt \n\n mqtt emqx \n\n\n# \n\nemqx  mqtt \n\n mqtt emqx \n\n\n# \n\n *  apache 2.0  2013  200+ \n * mqtt 5.0100%  mqtt 5.0  3.x \n *  500  mqtt  1  mqtt \n *  mqtt \n *  erlang/otp  1 \n *  masterless \n\n\n# \n\n emqx \n\n\n# \n\n *  mqtt v3.1v3.1.1  v5.0 \n   * qos 0qos 1qos 2 \n   * \n   * retained message\n   * will message\n   * \n   * $sys/ \n * mqtt  4 \n   * tcp\n   * tls\n   * websocket\n   * quic\n * http \n * \n   * coap\n   * lwm2m\n   * mqtt-sn\n   * stomp\n   * gb/t 32960\n   * jt/t 808\n\n mqtt \n\n * \n * \n * \n\n\n# \n\n * /redismysqlpostgresqlmongodb  http server \n *  jwt  jwks\n * mqtt 5.0 \n * psk \n *  client idip redismysqlpostgresqlmongodb  http server \n * \n\n\n# \n\n *  (cluster)\n * mcastdnsetcdk8s \n *  (bridge)\n\n\n# \n\n * sql  mqtt \n *  mqtt  broker  emqx cloudaws iot coreazure iot hub\n *  webhook \n\n\n# \n\n * \n * \n * \n\n\n# \n\n * \n * \n * prometheus/statsd \n * \n * (log trace)\n * erlang \n\n\n# \n\n * \n * \n * grpc \n * grpc \n\n\n# docker-compose.yml\n\n\nversion: '3.7'\nservices: \n  emqx: \n    #image: emqx/emqx:v3.2.0\n    image: emqx/emqx:4.4.4\n    container_name: emqx\n    restart: always\n    environment:\n      tz: asia/shanghai\n    ports: \n      - 1883:1883 \n      - 8083:8083\n      - 8883:8883\n      - 8084:8084\n      - 18083:18083\n      - 11883:11883\n      - 4369:4369\n      - 5369:5369\n      - 6369:6369\n      - 8080:8080\n    volumes: \n      - emqx_data:/opt/emqx/data\n      - emqx_etc:/opt/emqx/etc\n      - emqx_lib:/opt/emqx/lib\n      - emqx_log:/opt/emqx/log\n\nvolumes: \n  emqx_data: \n  emqx_etc: \n  emqx_lib: \n  emqx_log: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"FastDFS",frontmatter:{title:"FastDFS",date:"2023-09-05T16:34:51.000Z",permalink:"/pages/7bfded/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/12.FastDFS.html",relativePath:"05.&/01.Docker/12.FastDFS.md",key:"v-65b952f2",path:"/pages/7bfded/",headers:[{level:2,title:"FastDFS ",slug:"fastdfs-",normalizedTitle:"fastdfs ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:76},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1218},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1744}],headersStr:"FastDFS   docker-compose.yml deploy.sh",content:'# FastDFS \n\n\n\ngithubhttps://github.com/happyfish100/fastdfs\n\n\n# \n\n> FastDFS \n\nFastDFS trackerstorage\n\nFastDFS  meta data  meta data key value pairwidth=1024 key  widthvalue  1024 meta data \n\nFastDFS \n\n\n\n\n\n  \n\n\n\n FastDFS \n\n\n\n\n\n 1. client  tracker  storage\n 2. tracker  storage\n 3. client  storage \n\n\n\n\n\n 1. client  tracker  storage\n 2. tracker  storage\n 3. client  storage \n\nclient  FastDFS client  tracker  storage \n\n\n# docker-compose.yml\n\nversion: \'3.7\'\nservices: \n  tracker:\n    image: delron/fastdfs\n    container_name: tracker\n    network_mode: "host"\n    volumes:\n      - tracker_data:/var/fdfs\n    command: tracker\n  storage:\n    image: delron/fastdfs\n    container_name: storage\n    network_mode: "host"\n    volumes:\n      - storage_data:/var/fdfs\n    environment:\n      - TRACKER_SERVER=192.168.23.134:22122\n      - GROUP_NAME=group1 \n    command: storage\n    depends_on:\n      - tracker\n\nvolumes: \n  tracker_data: \n  storage_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',normalizedContent:'# fastdfs \n\n\n\ngithubhttps://github.com/happyfish100/fastdfs\n\n\n# \n\n> fastdfs \n\nfastdfs trackerstorage\n\nfastdfs  meta data  meta data key value pairwidth=1024 key  widthvalue  1024 meta data \n\nfastdfs \n\n\n\n\n\n  \n\n\n\n fastdfs \n\n\n\n\n\n 1. client  tracker  storage\n 2. tracker  storage\n 3. client  storage \n\n\n\n\n\n 1. client  tracker  storage\n 2. tracker  storage\n 3. client  storage \n\nclient  fastdfs client  tracker  storage \n\n\n# docker-compose.yml\n\nversion: \'3.7\'\nservices: \n  tracker:\n    image: delron/fastdfs\n    container_name: tracker\n    network_mode: "host"\n    volumes:\n      - tracker_data:/var/fdfs\n    command: tracker\n  storage:\n    image: delron/fastdfs\n    container_name: storage\n    network_mode: "host"\n    volumes:\n      - storage_data:/var/fdfs\n    environment:\n      - tracker_server=192.168.23.134:22122\n      - group_name=group1 \n    command: storage\n    depends_on:\n      - tracker\n\nvolumes: \n  tracker_data: \n  storage_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Elasticsearch",frontmatter:{title:"Elasticsearch",date:"2023-09-05T15:23:58.000Z",permalink:"/pages/18fff0/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/10.Elasticsearch.html",relativePath:"05.&/01.Docker/10.Elasticsearch.md",key:"v-672547f2",path:"/pages/18fff0/",headers:[{level:2,title:"Elasticsearch - ",slug:"elasticsearch-",normalizedTitle:"elasticsearch - ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:130},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:898},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1722}],headersStr:"Elasticsearch -   docker-compose.yml deploy.sh",content:"# Elasticsearch - \n\n\n\nhttps://www.elastic.co/cn/elasticsearch/\n\ngithubhttps://github.com/elastic/elasticsearch\n\n\n# \n\n\n\n> Elasticsearch  RESTful  Elastic Stack \n\nElasticsearch   \n\n * Wikipedia  Elasticsearch  search-as-you-type  did-you-mean \n *   Elasticsearch \n * Stack Overflow  more-like-this \n * GitHub  Elasticsearch  1300 \n\n Elasticsearch  Datadog  Klout Elasticsearch  PB \n\nElasticsearch   \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  elasticsearch: \n    image: elasticsearch:6.8.1\n    container_name: elasticsearch\n    restart: always\n    hostname: elasticsearch\n    volumes: \n      - es_data:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n      - 9300:9300\n    environment:\n      - discovery.type=single-node\n      - \"TZ=Asia/Shanghai\"\n      # \n      - \"ES_JAVA_OPTS=-Xms6g -Xmx6g\"\n    deploy:\n      resources:\n        limits:\n          #cpus: '2'\n          memory: 6G      \n  \n  kibana:\n    image: kibana:6.8.1\n    container_name: kibana\n    restart: always\n    ports:\n      - 5601:5601\n    environment:\n      SERVER_NAME: kibana\n      ELASTICSEARCH_URL: http://elasticsearch:9200\n      TZ: Asia/Shanghai\n    depends_on: ['elasticsearch']\n\nvolumes: \n  es_data: \n    driver: local\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# elasticsearch - \n\n\n\nhttps://www.elastic.co/cn/elasticsearch/\n\ngithubhttps://github.com/elastic/elasticsearch\n\n\n# \n\n\n\n> elasticsearch  restful  elastic stack \n\nelasticsearch   \n\n * wikipedia  elasticsearch  search-as-you-type  did-you-mean \n *   elasticsearch \n * stack overflow  more-like-this \n * github  elasticsearch  1300 \n\n elasticsearch  datadog  klout elasticsearch  pb \n\nelasticsearch   \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  elasticsearch: \n    image: elasticsearch:6.8.1\n    container_name: elasticsearch\n    restart: always\n    hostname: elasticsearch\n    volumes: \n      - es_data:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n      - 9300:9300\n    environment:\n      - discovery.type=single-node\n      - \"tz=asia/shanghai\"\n      # \n      - \"es_java_opts=-xms6g -xmx6g\"\n    deploy:\n      resources:\n        limits:\n          #cpus: '2'\n          memory: 6g      \n  \n  kibana:\n    image: kibana:6.8.1\n    container_name: kibana\n    restart: always\n    ports:\n      - 5601:5601\n    environment:\n      server_name: kibana\n      elasticsearch_url: http://elasticsearch:9200\n      tz: asia/shanghai\n    depends_on: ['elasticsearch']\n\nvolumes: \n  es_data: \n    driver: local\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Flink",frontmatter:{title:"Flink",date:"2023-09-05T16:38:01.000Z",permalink:"/pages/53b154/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/13.Flink.html",relativePath:"05.&/01.Docker/13.Flink.md",key:"v-21a1b472",path:"/pages/53b154/",headers:[{level:2,title:"Apache Flink - ",slug:"apache-flink-",normalizedTitle:"apache flink - ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:109},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:238},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:725},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:1110},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:1366},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1539},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2190}],headersStr:"Apache Flink -       docker-compose.yml deploy.sh",content:'# Apache Flink - \n\n\n\nhttps://flink.apache.org/\n\ngithubhttps://github.com/apache/flink\n\n\n# \n\n\n\n> Apache Flink Flink \n\n Flink \n\n\n# \n\n\n\n    \n\n 1.  \n 2.  \n\n\n\nApache Flink   Flink (runtime)\n\n Flink   \n\n\n# \n\nApache Flink Flink  Hadoop YARN Apache Mesos  Kubernetes\n\nFlink (resource-manager-specific)Flink \n\n Flink Flink Flink  REST  Flink \n\n\n# \n\nFlink  CPU IO Flink \n\nFlink \n\n * ,\n * TB, \n * \n\n\n# \n\n Flink Flink \n\n\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\n# docker run --name flink_jobmanager -d -t flink jobmanager\n# docker run --name flink_taskmanager -d -t flink taskmanager\n\nservices: \n\n  jobmanager:\n    image: flink:1.15.2\n    expose:\n      - "6123"\n    ports:\n      - "8081:8081"\n    command: jobmanager\n    environment:\n      - JOB_MANAGER_RPC_ADDRESS=jobmanager\n      - TZ=Asia/Shanghai\n\n  taskmanager:\n    image: flink:1.15.2\n    expose:\n      - "6121"\n      - "6122"\n    depends_on:\n      - jobmanager\n    command: taskmanager\n    links:\n      - "jobmanager:jobmanager"\n    environment:\n      - JOB_MANAGER_RPC_ADDRESS=jobmanager\n      - TZ=Asia/Shanghai\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',normalizedContent:'# apache flink - \n\n\n\nhttps://flink.apache.org/\n\ngithubhttps://github.com/apache/flink\n\n\n# \n\n\n\n> apache flink flink \n\n flink \n\n\n# \n\n\n\n    \n\n 1.  \n 2.  \n\n\n\napache flink   flink (runtime)\n\n flink   \n\n\n# \n\napache flink flink  hadoop yarn apache mesos  kubernetes\n\nflink (resource-manager-specific)flink \n\n flink flink flink  rest  flink \n\n\n# \n\nflink  cpu io flink \n\nflink \n\n * ,\n * tb, \n * \n\n\n# \n\n flink flink \n\n\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\n# docker run --name flink_jobmanager -d -t flink jobmanager\n# docker run --name flink_taskmanager -d -t flink taskmanager\n\nservices: \n\n  jobmanager:\n    image: flink:1.15.2\n    expose:\n      - "6123"\n    ports:\n      - "8081:8081"\n    command: jobmanager\n    environment:\n      - job_manager_rpc_address=jobmanager\n      - tz=asia/shanghai\n\n  taskmanager:\n    image: flink:1.15.2\n    expose:\n      - "6121"\n      - "6122"\n    depends_on:\n      - jobmanager\n    command: taskmanager\n    links:\n      - "jobmanager:jobmanager"\n    environment:\n      - job_manager_rpc_address=jobmanager\n      - tz=asia/shanghai\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Gitlab",frontmatter:{title:"Gitlab",date:"2023-09-05T16:40:38.000Z",permalink:"/pages/83a3e2/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/14.Gitlab.html",relativePath:"05.&/01.Docker/14.Gitlab.md",key:"v-24c0bbfe",path:"/pages/83a3e2/",headers:[{level:2,title:"GitLab ",slug:"gitlab-",normalizedTitle:"gitlab ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:61},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:214},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:708},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:866},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1012},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2254},{level:2,title:"GitlabRunner",slug:"gitlabrunner",normalizedTitle:"gitlabrunner",charIndex:2304},{level:3,title:"docker-compose.yml",slug:"docker-compose-yml-2",normalizedTitle:"docker-compose.yml",charIndex:1012},{level:3,title:"deploy.sh",slug:"deploy-sh-2",normalizedTitle:"deploy.sh",charIndex:2254},{level:3,title:"",slug:"",normalizedTitle:"",charIndex:2752}],headersStr:"GitLab      docker-compose.yml deploy.sh GitlabRunner docker-compose.yml deploy.sh ",content:"# GitLab \n\n\n\nhttps://about.gitlab.com/\n\n\n# \n\n\n\n> GitLab /Wiki \n\n\n# \n\nGitLab \n\n *   Git  GitLab \n *   GitLab \n * / GitLab  CI/CD/\n *  Merge Requests\n * Wiki   Wiki\n *  GitLab \n *  GitLab \n\n\n# \n\nGitLab \n\n * GitLab.com GitLab  SaaS \n *   GitLab\n * \n\n\n# \n\nGitLab /GitLab GitLab \n\n\n# docker-compose.yml\n\nversion: '3.7'\nservices: \n  gitlab:\n    container_name: gitlab\n    image: 'gitlab/gitlab-ce:15.2.2-ce.0'\n    restart: always\n    hostname: '10.142.51.100'\n    environment:\n      GITLAB_OMNIBUS_CONFIG: |\n        external_url 'http://10.142.51.100:1230'\n        gitlab_rails['gitlab_shell_ssh_port'] = 1232\n        gitlab_rails['time_zone'] = 'Asia/Shanghai'\n        gitlab_rails['gitlab_email_enabled'] = true\n        gitlab_rails['smtp_enable'] = true\n        gitlab_rails['smtp_address'] = \"smtp.163.com\"\n        gitlab_rails['smtp_port'] = 465\n        gitlab_rails['smtp_user_name'] = \"\"\n        gitlab_rails['smtp_password'] = \"\"\n        gitlab_rails['smtp_domain'] = \"163.com\"\n        gitlab_rails['smtp_authentication'] = \"login\"\n        gitlab_rails['smtp_enable_starttls_auto'] = true\n        gitlab_rails['smtp_tls'] = true\n        gitlab_rails['gitlab_email_from'] = 'ego_it@163.com'\n        gitlab_rails['initial_root_password'] = 'Gitlab123$'\n    ports:\n      - '1230:1230'\n      - '1231:443'\n      - '1232:22'\n    volumes:\n      - 'gitlab_data:/etc/gitlab'\n      - 'gitlab_log_data:/var/log/gitlab'\n      - 'gitlab_opt_data:/var/opt/gitlab'\nvolumes: \n  gitlab_data: \n  gitlab_log_data:\n  gitlab_opt_data:\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# GitlabRunner\n\n\n# docker-compose.yml\n\nversion: '3.7'\nservices: \n  gitlab-runner:\n    container_name: gitlab-runner\n    image: 'gitlab/gitlab-runner:v15.2.1'\n    restart: always\n    privileged: true\n    volumes:\n      - 'data:/etc/gitlab-runner'\n      - '/var/run/docker.sock:/var/run/docker.sock'\n    networks: \n      - swarm_net\nvolumes: \n  data: \nnetworks: \n  swarm_net: \n    external: true \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# \n\n * docker in docker \n\n// \ndocker exec -it gitlab-runner bash\ngitlab-runner register\n//  Git Lab  URL  token\n[root@localhost-0002 GitLabRunner]# docker exec -it 8afd63e9abbb bash\nroot@8afd63e9abbb:/# gitlab-runner register\nRuntime platform                                    arch=amd64 os=linux pid=33 revision=58272c27 version=12.7.0\nRunning in system-mode.                            \n                                                   \nPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):\nhttp://192.168.0.123:1230/\nPlease enter the gitlab-ci token for this runner:\ni6aQMeza7Hxa1t_bAjzT\nPlease enter the gitlab-ci description for this runner:\n[8afd63e9abbb]: \nPlease enter the gitlab-ci tags for this runner (comma separated):\n\nRegistering runner... succeeded                     runner=i6aQMeza\nPlease enter the executor: custom, docker, docker-ssh, shell, docker+machine, docker-ssh+machine, kubernetes, parallels, ssh, virtualbox:\ndocker\nRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! \ndocker:19.03.8\n//  description  tags tagsdeploy docker\n//  GitLab \n/usr/local/bin/docker-compose -f /data/composefile/GitLabRunner/docker-compose.yml down\ndocker system prune -f --volumes\n/usr/local/bin/docker-compose -f /data/composefile/GitLabRunner/docker-compose.yml up -d\n\ndocker exec -it gitlab-runner sh\ngitlab-runner --help\ngitlab-runner restart\ncat /etc/gitlab-runner/config.toml\nvi /etc/gitlab-runner/config.toml\nprivileged = true\nvolumes = [\"/var/run/docker.sock:/var/run/docker.sock\", \"/cache\"]\nvi config.toml\n",normalizedContent:"# gitlab \n\n\n\nhttps://about.gitlab.com/\n\n\n# \n\n\n\n> gitlab /wiki \n\n\n# \n\ngitlab \n\n *   git  gitlab \n *   gitlab \n * / gitlab  ci/cd/\n *  merge requests\n * wiki   wiki\n *  gitlab \n *  gitlab \n\n\n# \n\ngitlab \n\n * gitlab.com gitlab  saas \n *   gitlab\n * \n\n\n# \n\ngitlab /gitlab gitlab \n\n\n# docker-compose.yml\n\nversion: '3.7'\nservices: \n  gitlab:\n    container_name: gitlab\n    image: 'gitlab/gitlab-ce:15.2.2-ce.0'\n    restart: always\n    hostname: '10.142.51.100'\n    environment:\n      gitlab_omnibus_config: |\n        external_url 'http://10.142.51.100:1230'\n        gitlab_rails['gitlab_shell_ssh_port'] = 1232\n        gitlab_rails['time_zone'] = 'asia/shanghai'\n        gitlab_rails['gitlab_email_enabled'] = true\n        gitlab_rails['smtp_enable'] = true\n        gitlab_rails['smtp_address'] = \"smtp.163.com\"\n        gitlab_rails['smtp_port'] = 465\n        gitlab_rails['smtp_user_name'] = \"\"\n        gitlab_rails['smtp_password'] = \"\"\n        gitlab_rails['smtp_domain'] = \"163.com\"\n        gitlab_rails['smtp_authentication'] = \"login\"\n        gitlab_rails['smtp_enable_starttls_auto'] = true\n        gitlab_rails['smtp_tls'] = true\n        gitlab_rails['gitlab_email_from'] = 'ego_it@163.com'\n        gitlab_rails['initial_root_password'] = 'gitlab123$'\n    ports:\n      - '1230:1230'\n      - '1231:443'\n      - '1232:22'\n    volumes:\n      - 'gitlab_data:/etc/gitlab'\n      - 'gitlab_log_data:/var/log/gitlab'\n      - 'gitlab_opt_data:/var/opt/gitlab'\nvolumes: \n  gitlab_data: \n  gitlab_log_data:\n  gitlab_opt_data:\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# gitlabrunner\n\n\n# docker-compose.yml\n\nversion: '3.7'\nservices: \n  gitlab-runner:\n    container_name: gitlab-runner\n    image: 'gitlab/gitlab-runner:v15.2.1'\n    restart: always\n    privileged: true\n    volumes:\n      - 'data:/etc/gitlab-runner'\n      - '/var/run/docker.sock:/var/run/docker.sock'\n    networks: \n      - swarm_net\nvolumes: \n  data: \nnetworks: \n  swarm_net: \n    external: true \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# \n\n * docker in docker \n\n// \ndocker exec -it gitlab-runner bash\ngitlab-runner register\n//  git lab  url  token\n[root@localhost-0002 gitlabrunner]# docker exec -it 8afd63e9abbb bash\nroot@8afd63e9abbb:/# gitlab-runner register\nruntime platform                                    arch=amd64 os=linux pid=33 revision=58272c27 version=12.7.0\nrunning in system-mode.                            \n                                                   \nplease enter the gitlab-ci coordinator url (e.g. https://gitlab.com/):\nhttp://192.168.0.123:1230/\nplease enter the gitlab-ci token for this runner:\ni6aqmeza7hxa1t_bajzt\nplease enter the gitlab-ci description for this runner:\n[8afd63e9abbb]: \nplease enter the gitlab-ci tags for this runner (comma separated):\n\nregistering runner... succeeded                     runner=i6aqmeza\nplease enter the executor: custom, docker, docker-ssh, shell, docker+machine, docker-ssh+machine, kubernetes, parallels, ssh, virtualbox:\ndocker\nrunner registered successfully. feel free to start it, but if it's running already the config should be automatically reloaded! \ndocker:19.03.8\n//  description  tags tagsdeploy docker\n//  gitlab \n/usr/local/bin/docker-compose -f /data/composefile/gitlabrunner/docker-compose.yml down\ndocker system prune -f --volumes\n/usr/local/bin/docker-compose -f /data/composefile/gitlabrunner/docker-compose.yml up -d\n\ndocker exec -it gitlab-runner sh\ngitlab-runner --help\ngitlab-runner restart\ncat /etc/gitlab-runner/config.toml\nvi /etc/gitlab-runner/config.toml\nprivileged = true\nvolumes = [\"/var/run/docker.sock:/var/run/docker.sock\", \"/cache\"]\nvi config.toml\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Jrebel",frontmatter:{title:"Jrebel",date:"2023-09-05T16:50:31.000Z",permalink:"/pages/8e9d93/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/16.Jrebel.html",relativePath:"05.&/01.Docker/16.Jrebel.md",key:"v-558dc8ba",path:"/pages/8e9d93/",headers:[{level:2,title:"JRebel - J2EE",slug:"jrebel-j2ee",normalizedTitle:"jrebel - j2ee",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:58},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:433},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:676}],headersStr:"JRebel - J2EE  docker-compose.yml deploy.sh",content:'# JRebel - J2EE\n\n\n\nhttps://www.jrebel.com/\n\n\n# \n\n\n\nJRebelJavaEEJRebel\n\nJRebel\n\nJRebelJAVAJAVAJRebel5.25\n\n,,Jreble,,,,,\n\n\n# docker-compose.yml\n\nversion: "3.7"\n\nservices:\n  jrebel:\n    image: nn200433/jrebel\n    container_name: jrebel\n    privileged: true\n    restart: always\n    environment:\n      TZ: Asia/Shanghai\n      PORT: 9001\n    ports:\n      - 9001:9001\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',normalizedContent:'# jrebel - j2ee\n\n\n\nhttps://www.jrebel.com/\n\n\n# \n\n\n\njrebeljavaeejrebel\n\njrebel\n\njrebeljavajavajrebel5.25\n\n,,jreble,,,,,\n\n\n# docker-compose.yml\n\nversion: "3.7"\n\nservices:\n  jrebel:\n    image: nn200433/jrebel\n    container_name: jrebel\n    privileged: true\n    restart: always\n    environment:\n      tz: asia/shanghai\n      port: 9001\n    ports:\n      - 9001:9001\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"MariaDB",frontmatter:{title:"MariaDB",date:"2023-09-05T17:06:09.000Z",permalink:"/pages/ee069d/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/17.MariaDB.html",relativePath:"05.&/01.Docker/17.MariaDB.md",key:"v-c8daa3f2",path:"/pages/ee069d/",headers:[{level:2,title:"MariaDB MySQL ",slug:"mariadb-mysql-",normalizedTitle:"mariadb mysql ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:94},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:390},{level:2,title:"my.cnf",slug:"my-cnf",normalizedTitle:"my.cnf",charIndex:826},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1196}],headersStr:"MariaDB MySQL   docker-compose.yml my.cnf deploy.sh",content:'# MariaDB MySQL \n\n\n\nhttps://mariadb.org/\n\ngithubhttps://github.com/MariaDB/server\n\n\n# \n\n\n\n> MariaDB Server  MySQL  Linux MariaDB  MySQL \n\nMariaDB  Galera Cluster 4  Oracle  Temporal Data Tables \n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\nservices: \n  mariadb: \n    image: mariadb:10.6.4\n    container_name: mariadb\n    # command: --default-authentication-plugin=mysql_native_password --lower_case_table_names=1\n    restart: always\n    ports: \n      - 3306:3306\n    environment: \n      - MYSQL_ROOT_PASSWORD=Mysql123$\n      # - MYSQL_ROOT_HOST=%\n      - TZ=Asia/Shanghai\n    volumes: \n      - mysql_data:/var/lib/mysql\n      - "/etc/mysql/my.cnf:/etc/mysql/my.cnf"\n\nvolumes: \n  mysql_data: \n\n\n\n# my.cnf\n\n[client-server]\n# Port or socket location where to connect\n# port = 3306\nsocket = /run/mysqld/mysqld.sock\nlower_case_table_name=1\n\n# Import all .cnf files from configuration directory\n[mariadbd]\nskip-host-cache\nskip-name-resolve\n\n!includedir /etc/mysql/mariadb.conf.d/\n!includedir /etc/mysql/conf.d/\n\n\n\n# deploy.sh\n\nmkdir -p /etc/mysql/\n\n\\cp ./my.cnf /etc/mysql/my.cnf -rf\n"/usr/local/bin/docker-compose" -f docker-compose.yml up -d\n',normalizedContent:'# mariadb mysql \n\n\n\nhttps://mariadb.org/\n\ngithubhttps://github.com/mariadb/server\n\n\n# \n\n\n\n> mariadb server  mysql  linux mariadb  mysql \n\nmariadb  galera cluster 4  oracle  temporal data tables \n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\nservices: \n  mariadb: \n    image: mariadb:10.6.4\n    container_name: mariadb\n    # command: --default-authentication-plugin=mysql_native_password --lower_case_table_names=1\n    restart: always\n    ports: \n      - 3306:3306\n    environment: \n      - mysql_root_password=mysql123$\n      # - mysql_root_host=%\n      - tz=asia/shanghai\n    volumes: \n      - mysql_data:/var/lib/mysql\n      - "/etc/mysql/my.cnf:/etc/mysql/my.cnf"\n\nvolumes: \n  mysql_data: \n\n\n\n# my.cnf\n\n[client-server]\n# port or socket location where to connect\n# port = 3306\nsocket = /run/mysqld/mysqld.sock\nlower_case_table_name=1\n\n# import all .cnf files from configuration directory\n[mariadbd]\nskip-host-cache\nskip-name-resolve\n\n!includedir /etc/mysql/mariadb.conf.d/\n!includedir /etc/mysql/conf.d/\n\n\n\n# deploy.sh\n\nmkdir -p /etc/mysql/\n\n\\cp ./my.cnf /etc/mysql/my.cnf -rf\n"/usr/local/bin/docker-compose" -f docker-compose.yml up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"MySQL",frontmatter:{title:"MySQL",date:"2023-09-05T19:38:05.000Z",permalink:"/pages/cff07b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/18.MySQL.html",relativePath:"05.&/01.Docker/18.MySQL.md",key:"v-0c46eaa7",path:"/pages/cff07b/",headers:[{level:2,title:"MySQL ",slug:"mysql-",normalizedTitle:"mysql ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:96},{level:2,title:"MySQL ",slug:"mysql-",normalizedTitle:"mysql ",charIndex:259},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:774},{level:2,title:"my.cnf",slug:"my-cnf",normalizedTitle:"my.cnf",charIndex:1237},{level:2,title:"init.sql",slug:"init-sql",normalizedTitle:"init.sql",charIndex:1172},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2123}],headersStr:"MySQL   MySQL  docker-compose.yml my.cnf init.sql deploy.sh",content:"# MySQL \n\n\n\nhttps://www.mysql.com/\n\ngithubhttps://github.com/mysql/mysql-server\n\n\n# \n\n\n\nMySQL  MySQL AB  MySQL  Internet  MySQL \n\n\n# MySQL \n\n *  C  C++ \n *  AIXBSDiFreeBSDHP-UXLinuxMac OSNovell NetwareNetBSDOpenBSDOS/2 WrapSolarisSunOSWindows \n *  API CC++C#DelphiEiffelJavaPerlPHPPythonRuby  Tcl \n *  CPU \n *  SQL \n * \n *  GB 2312BIG5 Shift_JIS \n *  TCP/IPODBC  JDBC \n * \n * \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  mysql8: \n    image: mysql:8.0.16\n    container_name: mysql8\n    command: --default-authentication-plugin=mysql_native_password --lower_case_table_names=1\n    restart: always\n    ports: \n      - 3306:3306\n    environment: \n      - MYSQL_ROOT_PASSWORD=Mysql123$\n      - MYSQL_ROOT_HOST=%\n      - TZ=Asia/Shanghai\n    volumes: \n      - /etc/mysql/sql/init.sql:/docker-entrypoint-initdb.d/init.sql\n      - /etc/mysql/my.cnf:/etc/mysql/my.cnf\n      - mysql_data:/var/lib/mysql\n\n  phpmyadmin: \n    image: phpmyadmin:5\n    container_name: phpmyadmin\n    restart: always\n    ports: \n      - 80:80\n    environment: \n      - PMA_ARBITRARY=1\n\nvolumes: \n  mysql_data: \n\n\n\n# my.cnf\n\n[mysqld]\ncharacter-set-server=utf8mb4\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\ndatadir         = /var/lib/mysql\nsecure-file-priv= NULL\n# Disabling symbolic-links is recommended to prevent assorted security risks\nsymbolic-links=0\n\n# Custom config should go here\n!includedir /etc/mysql/conf.d/\n\n[client]\ndefault-character-set=utf8mb4 \n[mysql]\ndefault-character-set=utf8mb4\n\n\n\n# init.sql\n\nuse mysql;\n# navicatmysql1251\nCREATE USER 'root'@'%' IDENTIFIED BY 'Mysql123$';\nALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY 'Mysql123$';\n\n# \nFLUSH PRIVILEGES;\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/mysql/sql\n\\cp ./sql/init.sql /etc/mysql/sql/init.sql -rf\n\\cp ./my.cnf /etc/mysql/my.cnf -rf\ndocker-compose up -d\n",normalizedContent:"# mysql \n\n\n\nhttps://www.mysql.com/\n\ngithubhttps://github.com/mysql/mysql-server\n\n\n# \n\n\n\nmysql  mysql ab  mysql  internet  mysql \n\n\n# mysql \n\n *  c  c++ \n *  aixbsdifreebsdhp-uxlinuxmac osnovell netwarenetbsdopenbsdos/2 wrapsolarissunoswindows \n *  api cc++c#delphieiffeljavaperlphppythonruby  tcl \n *  cpu \n *  sql \n * \n *  gb 2312big5 shift_jis \n *  tcp/ipodbc  jdbc \n * \n * \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  mysql8: \n    image: mysql:8.0.16\n    container_name: mysql8\n    command: --default-authentication-plugin=mysql_native_password --lower_case_table_names=1\n    restart: always\n    ports: \n      - 3306:3306\n    environment: \n      - mysql_root_password=mysql123$\n      - mysql_root_host=%\n      - tz=asia/shanghai\n    volumes: \n      - /etc/mysql/sql/init.sql:/docker-entrypoint-initdb.d/init.sql\n      - /etc/mysql/my.cnf:/etc/mysql/my.cnf\n      - mysql_data:/var/lib/mysql\n\n  phpmyadmin: \n    image: phpmyadmin:5\n    container_name: phpmyadmin\n    restart: always\n    ports: \n      - 80:80\n    environment: \n      - pma_arbitrary=1\n\nvolumes: \n  mysql_data: \n\n\n\n# my.cnf\n\n[mysqld]\ncharacter-set-server=utf8mb4\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\ndatadir         = /var/lib/mysql\nsecure-file-priv= null\n# disabling symbolic-links is recommended to prevent assorted security risks\nsymbolic-links=0\n\n# custom config should go here\n!includedir /etc/mysql/conf.d/\n\n[client]\ndefault-character-set=utf8mb4 \n[mysql]\ndefault-character-set=utf8mb4\n\n\n\n# init.sql\n\nuse mysql;\n# navicatmysql1251\ncreate user 'root'@'%' identified by 'mysql123$';\nalter user 'root'@'%' identified with mysql_native_password by 'mysql123$';\n\n# \nflush privileges;\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/mysql/sql\n\\cp ./sql/init.sql /etc/mysql/sql/init.sql -rf\n\\cp ./my.cnf /etc/mysql/my.cnf -rf\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"Percona",frontmatter:{title:"Percona",date:"2023-09-05T19:47:04.000Z",permalink:"/pages/862a97/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/19.Percona.html",relativePath:"05.&/01.Docker/19.Percona.md",key:"v-20feecc7",path:"/pages/862a97/",headers:[{level:2,title:"Percona MySQL ",slug:"percona-mysql-",normalizedTitle:"percona mysql ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:105},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:457},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:969}],headersStr:"Percona MySQL   docker-compose.yml deploy.sh",content:"# Percona MySQL \n\n\n\nhttps://www.percona.com\n\ngithubhttps://github.com/percona/percona-server\n\n\n# \n\n\n\n> Percona ServerMySQLPercona Percona ServerMySQLXtraDB\n\nPerconaPercona ServerOracleMySQL EnterpriseMySQL Percona Server PerconaXtraDBPXCperconatoolkitDBA\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n\n  percona: \n    image: percona/percona-xtradb-cluster:5.7.26\n    container_name: percona\n    restart: always\n    environment: \n      - TZ=Asia/Shanghai\n      - MYSQL_ROOT_PASSWORD=Percona123$\n      - CLUSTER_NAME=pxc\n      - XTRABACKUP_PASSWORD=Percona123 \n    ports:\n      - 3306:3306\n    volumes:\n      - percona_mysql:/var/lib/mysql\n      - percona_log:/var/log/mysql\n      - percona_data:/data\n\nvolumes: \n  percona_mysql: \n  percona_log: \n  percona_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# percona mysql \n\n\n\nhttps://www.percona.com\n\ngithubhttps://github.com/percona/percona-server\n\n\n# \n\n\n\n> percona servermysqlpercona percona servermysqlxtradb\n\nperconapercona serveroraclemysql enterprisemysql percona server perconaxtradbpxcperconatoolkitdba\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n\n  percona: \n    image: percona/percona-xtradb-cluster:5.7.26\n    container_name: percona\n    restart: always\n    environment: \n      - tz=asia/shanghai\n      - mysql_root_password=percona123$\n      - cluster_name=pxc\n      - xtrabackup_password=percona123 \n    ports:\n      - 3306:3306\n    volumes:\n      - percona_mysql:/var/lib/mysql\n      - percona_log:/var/log/mysql\n      - percona_data:/data\n\nvolumes: \n  percona_mysql: \n  percona_log: \n  percona_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"Jenkins",frontmatter:{title:"Jenkins",article:!1,date:"2023-09-11T15:36:13.000Z",permalink:"/pages/f90f99/"},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/15.Jenkins.html",relativePath:"05.&/01.Docker/15.Jenkins.md",key:"v-1deb9607",path:"/pages/f90f99/",headers:[{level:2,title:"Jenkins ",slug:"jenkins-",normalizedTitle:"jenkins ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:98},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:567},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:808},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1391}],headersStr:"Jenkins    docker-compose.yml deploy.sh",content:"# Jenkins \n\n\n\nhttps://www.jenkins.io/\n\ngithubhttps://github.com/jenkinsci/jenkins\n\n\n# \n\n\n\n> Jenkins CICD\n\nJenkins \n\n *  Jenkins \n *  Jenkins \n *  Jenkins \n *   Jenkins \n *  Jenkins SlackJIRA \n *  Jenkins \n\n\n# \n\nJenkins \n\n *  \n *  \n *  \n *  \n *  \n\n> jenkinsdocker\n\n\n# docker-compose.yml\n\nversion: \"3.7\"\n\nservices:\n  jenkins:\n    image: jenkins/jenkins:lts-jdk11\n    container_name: jenkins\n    privileged: true\n    restart: always\n    environment:\n      TZ: Asia/Shanghai\n      JAVA_OPTS: '-Djava.util.logging.config.file=/var/jenkins_home/log.properties'\n    volumes:\n      - jenkins_home:/var/jenkins_home\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /usr/bin/docker:/usr/bin/docker\n      - /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7\n    ports:\n      - 18080:8080\n      - 50000:50000\nvolumes: \n  jenkins_home: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /var/jenkins_data/\ncat > /var/jenkins_data/log.properties <<EOF\nhandlers=java.util.logging.ConsoleHandler\njenkins.level=FINEST\njava.util.logging.ConsoleHandler.level=FINEST\nEOF\ndocker-compose up -d\n",normalizedContent:"# jenkins \n\n\n\nhttps://www.jenkins.io/\n\ngithubhttps://github.com/jenkinsci/jenkins\n\n\n# \n\n\n\n> jenkins cicd\n\njenkins \n\n *  jenkins \n *  jenkins \n *  jenkins \n *   jenkins \n *  jenkins slackjira \n *  jenkins \n\n\n# \n\njenkins \n\n *  \n *  \n *  \n *  \n *  \n\n> jenkinsdocker\n\n\n# docker-compose.yml\n\nversion: \"3.7\"\n\nservices:\n  jenkins:\n    image: jenkins/jenkins:lts-jdk11\n    container_name: jenkins\n    privileged: true\n    restart: always\n    environment:\n      tz: asia/shanghai\n      java_opts: '-djava.util.logging.config.file=/var/jenkins_home/log.properties'\n    volumes:\n      - jenkins_home:/var/jenkins_home\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /usr/bin/docker:/usr/bin/docker\n      - /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7\n    ports:\n      - 18080:8080\n      - 50000:50000\nvolumes: \n  jenkins_home: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /var/jenkins_data/\ncat > /var/jenkins_data/log.properties <<eof\nhandlers=java.util.logging.consolehandler\njenkins.level=finest\njava.util.logging.consolehandler.level=finest\neof\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"Phpmyadmin",frontmatter:{title:"Phpmyadmin",date:"2023-09-05T19:49:09.000Z",permalink:"/pages/a560de/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/20.Phpmyadmin.html",relativePath:"05.&/01.Docker/20.Phpmyadmin.md",key:"v-ce147052",path:"/pages/a560de/",headers:[{level:2,title:"phpMyAdmin MySQL ",slug:"phpmyadmin-mysql-",normalizedTitle:"phpmyadmin mysql ",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:113},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:224},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:435}],headersStr:"phpMyAdmin MySQL   docker-compose.yml deploy.sh",content:"# phpMyAdmin MySQL \n\n\n\nhttps://www.phpmyadmin.net/\n\ngithubhttps://github.com/phpmyadmin/phpmyadmin\n\n\n# \n\n\n\n> phpMyAdmin  web  MySQL  /  /  /  /  SQL \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  phpmyadmin: \n    image: phpmyadmin:5\n    container_name: phpmyadmin\n    restart: always\n    ports: \n      - 80:80\n    environment: \n      - PMA_ARBITRARY=1\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# phpmyadmin mysql \n\n\n\nhttps://www.phpmyadmin.net/\n\ngithubhttps://github.com/phpmyadmin/phpmyadmin\n\n\n# \n\n\n\n> phpmyadmin  web  mysql  /  /  /  /  sql \n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  phpmyadmin: \n    image: phpmyadmin:5\n    container_name: phpmyadmin\n    restart: always\n    ports: \n      - 80:80\n    environment: \n      - pma_arbitrary=1\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/12, 03:21:58",lastUpdatedTimestamp:1694460118e3},{title:"PostgreSQL",frontmatter:{title:"PostgreSQL",date:"2023-09-05T19:51:18.000Z",permalink:"/pages/230ca1/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/21.PostgreSQL.html",relativePath:"05.&/01.Docker/21.PostgreSQL.md",key:"v-79dbae07",path:"/pages/230ca1/",headers:[{level:2,title:"PostgreSQL -",slug:"postgresql--",normalizedTitle:"postgresql -",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:107},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:783},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1122}],headersStr:"PostgreSQL -  docker-compose.yml deploy.sh",content:"# PostgreSQL -\n\n\n\nhttps://www.postgresql.org/\n\ngithubhttps://github.com/postgres/postgres\n\n\n# \n\n> PostgreSQL SQL\n\n\n\n1 2 B  GiST  3SQLINSERTINSERTUPDATE PostgreSQLMVCCMultiversion concurrency control\"\" 4RULEVIEWINSERTUPDATEDELETE 5JSON XML   6 Tsearch2  OpenFTS8.3 Tsearch2 7NoSQLJSONJSONBXMLHStore  NoSQL  8 PostgreSQL  GreenPlumDeepGreenHAWK  FDW  ETL\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n\n  postgres:\n    image: postgres:11.4\n    container_name: postgres\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n      POSTGRES_PASSWORD: postgres_123456\n    ports:\n      - 5432:5432\n    volumes: \n      - postgres_data:/var/lib/postgresql/data\n\nvolumes: \n  postgres_data:\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# postgresql -\n\n\n\nhttps://www.postgresql.org/\n\ngithubhttps://github.com/postgres/postgres\n\n\n# \n\n> postgresql sql\n\n\n\n1 2 b  gist  3sqlinsertinsertupdate postgresqlmvccmultiversion concurrency control\"\" 4ruleviewinsertupdatedelete 5json xml   6 tsearch2  openfts8.3 tsearch2 7nosqljsonjsonbxmlhstore  nosql  8 postgresql  greenplumdeepgreenhawk  fdw  etl\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n\n  postgres:\n    image: postgres:11.4\n    container_name: postgres\n    restart: always\n    environment: \n      tz: asia/shanghai\n      postgres_password: postgres_123456\n    ports:\n      - 5432:5432\n    volumes: \n      - postgres_data:/var/lib/postgresql/data\n\nvolumes: \n  postgres_data:\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"Linux",frontmatter:{title:"Linux",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/aa794b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/01.%E6%9F%A5%E7%9C%8BLinux%E7%B3%BB%E7%BB%9F%E4%BF%A1%E6%81%AF.html",relativePath:"05.&/02.Linux/01.Linux.md",key:"v-686ae17b",path:"/pages/aa794b/",headersStr:null,content:"# Bench.sh\n\n Linux \n\ncurl -Lso- bench.sh | bash\n\n\n\n\nwget -qO- bench.sh | bash\n\n\n\n\n-------------------- A Bench.sh Script By Teddysun -------------------\n Version            : v2022-06-01\n Usage              : wget -qO- bench.sh | bash\n----------------------------------------------------------------------\n CPU Model          : Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz\n CPU Cores          : 8 @ 800.024 MHz\n CPU Cache          : 6144 KB\n AES-NI             : Enabled\n VM-x/AMD-V         : Enabled\n Total Disk         : 449.8 GB (2.5 GB Used)\n Total Mem          : 31.3 GB (370.9 MB Used)\n Total Swap         : 15.7 GB (0 Used)\n System uptime      : 1 days, 2 hour 31 min\n Load average       : 0.00, 0.01, 0.05\n OS                 : CentOS Linux release 7.6.1810 (Core)\n Arch               : x86_64 (64 Bit)\n Kernel             : 3.10.0-957.el7.x86_64\n TCP CC             : cubic\n Virtualization     : Dedicated\n Organization       : AS4134 CHINANET-BACKBONE\n Location           : Nanjing / CN\n Region             : Jiangsu\n----------------------------------------------------------------------\n I/O Speed(1st run) : 428 MB/s\n I/O Speed(2nd run) : 424 MB/s\n I/O Speed(3rd run) : 425 MB/s\n I/O Speed(average) : 425.7 MB/s\n----------------------------------------------------------------------\n",normalizedContent:"# bench.sh\n\n linux \n\ncurl -lso- bench.sh | bash\n\n\n\n\nwget -qo- bench.sh | bash\n\n\n\n\n-------------------- a bench.sh script by teddysun -------------------\n version            : v2022-06-01\n usage              : wget -qo- bench.sh | bash\n----------------------------------------------------------------------\n cpu model          : intel(r) core(tm) i5-8250u cpu @ 1.60ghz\n cpu cores          : 8 @ 800.024 mhz\n cpu cache          : 6144 kb\n aes-ni             : enabled\n vm-x/amd-v         : enabled\n total disk         : 449.8 gb (2.5 gb used)\n total mem          : 31.3 gb (370.9 mb used)\n total swap         : 15.7 gb (0 used)\n system uptime      : 1 days, 2 hour 31 min\n load average       : 0.00, 0.01, 0.05\n os                 : centos linux release 7.6.1810 (core)\n arch               : x86_64 (64 bit)\n kernel             : 3.10.0-957.el7.x86_64\n tcp cc             : cubic\n virtualization     : dedicated\n organization       : as4134 chinanet-backbone\n location           : nanjing / cn\n region             : jiangsu\n----------------------------------------------------------------------\n i/o speed(1st run) : 428 mb/s\n i/o speed(2nd run) : 424 mb/s\n i/o speed(3rd run) : 425 mb/s\n i/o speed(average) : 425.7 mb/s\n----------------------------------------------------------------------\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Redis",frontmatter:{title:"Redis",date:"2023-09-05T19:53:07.000Z",permalink:"/pages/be7f5d/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/22.Redis.html",relativePath:"05.&/01.Docker/22.Redis.md",key:"v-0a9184e7",path:"/pages/be7f5d/",headers:[{level:2,title:"Redis key-value",slug:"redis-key-value",normalizedTitle:"redis key-value",charIndex:2},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:94},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:253},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:696},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:983},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1084},{level:2,title:"redis.conf",slug:"redis-conf",normalizedTitle:"redis.conf",charIndex:1360},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:64548}],headersStr:"Redis key-value     docker-compose.yml redis.conf deploy.sh",content:'# Redis key-value\n\n\n\nhttps://redis.io/\n\ngithubhttps://github.com/redis/redis\n\n\n# \n\n> RedisRemote Dictionary ServerRedisSalvatore Sanfilippo2009\n\n\n# \n\n 1.  RedisRedis\n 2.  Redis\n 3.  Redis\n 4.  Redis\n 5.  Redis\n 6.  Redis\n\n\n# \n\n 1.  Redis\n 2.  Redis\n 3.  Redis\n 4.  Redis\n 5.  Redis\n 6.  Redis\n\n\n# \n\nRedis\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\nservices: \n  redis:\n    image: redis:7.0.3\n    container_name: redis\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    ports:\n      - 6379:6379\n    volumes: \n      - data:/data\n    command: redis-server /usr/local/etc/redis/redis.conf\n    sysctls:\n      net.core.somaxconn: 65535\n\nvolumes: \n  data: \n\n\n\n# redis.conf\n\n# Redis configuration file example.\n#\n# Note that in order to read the configuration file, Redis must be\n# started with the file path as first argument:\n#\n# ./redis-server /path/to/redis.conf\n\n# Note on units: when memory size is needed, it is possible to specify\n# it in the usual form of 1k 5GB 4M and so forth:\n#\n# 1k => 1000 bytes\n# 1kb => 1024 bytes\n# 1m => 1000000 bytes\n# 1mb => 1024*1024 bytes\n# 1g => 1000000000 bytes\n# 1gb => 1024*1024*1024 bytes\n#\n# units are case insensitive so 1GB 1Gb 1gB are all the same.\n\n################################## INCLUDES ###################################\n\n# Include one or more other config files here.  This is useful if you\n# have a standard template that goes to all Redis servers but also need\n# to customize a few per-server settings.  Include files can include\n# other files, so use this wisely.\n#\n# Notice option "include" won\'t be rewritten by command "CONFIG REWRITE"\n# from admin or Redis Sentinel. Since Redis always uses the last processed\n# line as value of a configuration directive, you\'d better put includes\n# at the beginning of this file to avoid overwriting config change at runtime.\n#\n# If instead you are interested in using includes to override configuration\n# options, it is better to use include as the last line.\n#\n# include /path/to/local.conf\n# include /path/to/other.conf\n\n################################## MODULES #####################################\n\n# Load modules at startup. If the server is not able to load modules\n# it will abort. It is possible to use multiple loadmodule directives.\n#\n# loadmodule /path/to/my_module.so\n# loadmodule /path/to/other_module.so\n\n################################## NETWORK #####################################\n\n# By default, if no "bind" configuration directive is specified, Redis listens\n# for connections from all the network interfaces available on the server.\n# It is possible to listen to just one or multiple selected interfaces using\n# the "bind" configuration directive, followed by one or more IP addresses.\n#\n# Examples:\n#\n# bind 192.168.1.100 10.0.0.1\n# bind 127.0.0.1 ::1\n#\n# ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the\n# internet, binding to all the interfaces is dangerous and will expose the\n# instance to everybody on the internet. So by default we uncomment the\n# following bind directive, that will force Redis to listen only into\n# the IPv4 loopback interface address (this means Redis will be able to\n# accept connections only from clients running into the same computer it\n# is running).\n#\n# IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES\n# JUST COMMENT THE FOLLOWING LINE.\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# bind 127.0.0.1\n\n# Protected mode is a layer of security protection, in order to avoid that\n# Redis instances left open on the internet are accessed and exploited.\n#\n# When protected mode is on and if:\n#\n# 1) The server is not binding explicitly to a set of addresses using the\n#    "bind" directive.\n# 2) No password is configured.\n#\n# The server only accepts connections from clients connecting from the\n# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain\n# sockets.\n#\n# By default protected mode is enabled. You should disable it only if\n# you are sure you want clients from other hosts to connect to Redis\n# even if no authentication is configured, nor a specific set of interfaces\n# are explicitly listed using the "bind" directive.\nprotected-mode no\n\n# Accept connections on the specified port, default is 6379 (IANA #815344).\n# If port 0 is specified Redis will not listen on a TCP socket.\nport 6379\n\n# TCP listen() backlog.\n#\n# In high requests-per-second environments you need an high backlog in order\n# to avoid slow clients connections issues. Note that the Linux kernel\n# will silently truncate it to the value of /proc/sys/net/core/somaxconn so\n# make sure to raise both the value of somaxconn and tcp_max_syn_backlog\n# in order to get the desired effect.\ntcp-backlog 511\n\n# Unix socket.\n#\n# Specify the path for the Unix socket that will be used to listen for\n# incoming connections. There is no default, so Redis will not listen\n# on a unix socket when not specified.\n#\n# unixsocket /tmp/redis.sock\n# unixsocketperm 700\n\n# Close the connection after a client is idle for N seconds (0 to disable)\ntimeout 0\n\n# TCP keepalive.\n#\n# If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence\n# of communication. This is useful for two reasons:\n#\n# 1) Detect dead peers.\n# 2) Take the connection alive from the point of view of network\n#    equipment in the middle.\n#\n# On Linux, the specified value (in seconds) is the period used to send ACKs.\n# Note that to close the connection the double of the time is needed.\n# On other kernels the period depends on the kernel configuration.\n#\n# A reasonable value for this option is 300 seconds, which is the new\n# Redis default starting with Redis 3.2.1.\ntcp-keepalive 300\n\n################################# GENERAL #####################################\n\n# By default Redis does not run as a daemon. Use \'yes\' if you need it.\n# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.\ndaemonize no\n\n# If you run Redis from upstart or systemd, Redis can interact with your\n# supervision tree. Options:\n#   supervised no      - no supervision interaction\n#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode\n#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET\n#   supervised auto    - detect upstart or systemd method based on\n#                        UPSTART_JOB or NOTIFY_SOCKET environment variables\n# Note: these supervision methods only signal "process is ready."\n#       They do not enable continuous liveness pings back to your supervisor.\nsupervised no\n\n# If a pid file is specified, Redis writes it where specified at startup\n# and removes it at exit.\n#\n# When the server runs non daemonized, no pid file is created if none is\n# specified in the configuration. When the server is daemonized, the pid file\n# is used even if not specified, defaulting to "/var/run/redis.pid".\n#\n# Creating a pid file is best effort: if Redis is not able to create it\n# nothing bad happens, the server will start and run normally.\npidfile /var/run/redis_6379.pid\n\n# Specify the server verbosity level.\n# This can be one of:\n# debug (a lot of information, useful for development/testing)\n# verbose (many rarely useful info, but not a mess like the debug level)\n# notice (moderately verbose, what you want in production probably)\n# warning (only very important / critical messages are logged)\nloglevel notice\n\n# Specify the log file name. Also the empty string can be used to force\n# Redis to log on the standard output. Note that if you use standard\n# output for logging but daemonize, logs will be sent to /dev/null\nlogfile ""\n\n# To enable logging to the system logger, just set \'syslog-enabled\' to yes,\n# and optionally update the other syslog parameters to suit your needs.\n# syslog-enabled no\n\n# Specify the syslog identity.\n# syslog-ident redis\n\n# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.\n# syslog-facility local0\n\n# Set the number of databases. The default database is DB 0, you can select\n# a different one on a per-connection basis using SELECT <dbid> where\n# dbid is a number between 0 and \'databases\'-1\ndatabases 20\n\n# By default Redis shows an ASCII art logo only when started to log to the\n# standard output and if the standard output is a TTY. Basically this means\n# that normally a logo is displayed only in interactive sessions.\n#\n# However it is possible to force the pre-4.0 behavior and always show a\n# ASCII art logo in startup logs by setting the following option to yes.\nalways-show-logo yes\n\n################################ SNAPSHOTTING  ################################\n#\n# Save the DB on disk:\n#\n#   save <seconds> <changes>\n#\n#   Will save the DB if both the given number of seconds and the given\n#   number of write operations against the DB occurred.\n#\n#   In the example below the behaviour will be to save:\n#   after 900 sec (15 min) if at least 1 key changed\n#   after 300 sec (5 min) if at least 10 keys changed\n#   after 60 sec if at least 10000 keys changed\n#\n#   Note: you can disable saving completely by commenting out all "save" lines.\n#\n#   It is also possible to remove all the previously configured save\n#   points by adding a save directive with a single empty string argument\n#   like in the following example:\n#\n#   save ""\n\nsave 900 1\nsave 300 10\nsave 60 10000\n\n# By default Redis will stop accepting writes if RDB snapshots are enabled\n# (at least one save point) and the latest background save failed.\n# This will make the user aware (in a hard way) that data is not persisting\n# on disk properly, otherwise chances are that no one will notice and some\n# disaster will happen.\n#\n# If the background saving process will start working again Redis will\n# automatically allow writes again.\n#\n# However if you have setup your proper monitoring of the Redis server\n# and persistence, you may want to disable this feature so that Redis will\n# continue to work as usual even if there are problems with disk,\n# permissions, and so forth.\nstop-writes-on-bgsave-error yes\n\n# Compress string objects using LZF when dump .rdb databases?\n# For default that\'s set to \'yes\' as it\'s almost always a win.\n# If you want to save some CPU in the saving child set it to \'no\' but\n# the dataset will likely be bigger if you have compressible values or keys.\nrdbcompression yes\n\n# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.\n# This makes the format more resistant to corruption but there is a performance\n# hit to pay (around 10%) when saving and loading RDB files, so you can disable it\n# for maximum performances.\n#\n# RDB files created with checksum disabled have a checksum of zero that will\n# tell the loading code to skip the check.\nrdbchecksum yes\n\n# The filename where to dump the DB\ndbfilename dump.rdb\n\n# The working directory.\n#\n# The DB will be written inside this directory, with the filename specified\n# above using the \'dbfilename\' configuration directive.\n#\n# The Append Only File will also be created inside this directory.\n#\n# Note that you must specify a directory here, not a file name.\ndir /data/\n\n################################# REPLICATION #################################\n\n# Master-Replica replication. Use replicaof to make a Redis instance a copy of\n# another Redis server. A few things to understand ASAP about Redis replication.\n#\n#   +------------------+      +---------------+\n#   |      Master      | ---\x3e |    Replica    |\n#   | (receive writes) |      |  (exact copy) |\n#   +------------------+      +---------------+\n#\n# 1) Redis replication is asynchronous, but you can configure a master to\n#    stop accepting writes if it appears to be not connected with at least\n#    a given number of replicas.\n# 2) Redis replicas are able to perform a partial resynchronization with the\n#    master if the replication link is lost for a relatively small amount of\n#    time. You may want to configure the replication backlog size (see the next\n#    sections of this file) with a sensible value depending on your needs.\n# 3) Replication is automatic and does not need user intervention. After a\n#    network partition replicas automatically try to reconnect to masters\n#    and resynchronize with them.\n#\n# replicaof <masterip> <masterport>\n\n# If the master is password protected (using the "requirepass" configuration\n# directive below) it is possible to tell the replica to authenticate before\n# starting the replication synchronization process, otherwise the master will\n# refuse the replica request.\n#\n# masterauth <master-password>\n\n# When a replica loses its connection with the master, or when the replication\n# is still in progress, the replica can act in two different ways:\n#\n# 1) if replica-serve-stale-data is set to \'yes\' (the default) the replica will\n#    still reply to client requests, possibly with out of date data, or the\n#    data set may just be empty if this is the first synchronization.\n#\n# 2) if replica-serve-stale-data is set to \'no\' the replica will reply with\n#    an error "SYNC with master in progress" to all the kind of commands\n#    but to INFO, replicaOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG,\n#    SUBSCRIBE, UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB,\n#    COMMAND, POST, HOST: and LATENCY.\n#\nreplica-serve-stale-data yes\n\n# You can configure a replica instance to accept writes or not. Writing against\n# a replica instance may be useful to store some ephemeral data (because data\n# written on a replica will be easily deleted after resync with the master) but\n# may also cause problems if clients are writing to it because of a\n# misconfiguration.\n#\n# Since Redis 2.6 by default replicas are read-only.\n#\n# Note: read only replicas are not designed to be exposed to untrusted clients\n# on the internet. It\'s just a protection layer against misuse of the instance.\n# Still a read only replica exports by default all the administrative commands\n# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve\n# security of read only replicas using \'rename-command\' to shadow all the\n# administrative / dangerous commands.\nreplica-read-only yes\n\n# Replication SYNC strategy: disk or socket.\n#\n# -------------------------------------------------------\n# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY\n# -------------------------------------------------------\n#\n# New replicas and reconnecting replicas that are not able to continue the replication\n# process just receiving differences, need to do what is called a "full\n# synchronization". An RDB file is transmitted from the master to the replicas.\n# The transmission can happen in two different ways:\n#\n# 1) Disk-backed: The Redis master creates a new process that writes the RDB\n#                 file on disk. Later the file is transferred by the parent\n#                 process to the replicas incrementally.\n# 2) Diskless: The Redis master creates a new process that directly writes the\n#              RDB file to replica sockets, without touching the disk at all.\n#\n# With disk-backed replication, while the RDB file is generated, more replicas\n# can be queued and served with the RDB file as soon as the current child producing\n# the RDB file finishes its work. With diskless replication instead once\n# the transfer starts, new replicas arriving will be queued and a new transfer\n# will start when the current one terminates.\n#\n# When diskless replication is used, the master waits a configurable amount of\n# time (in seconds) before starting the transfer in the hope that multiple replicas\n# will arrive and the transfer can be parallelized.\n#\n# With slow disks and fast (large bandwidth) networks, diskless replication\n# works better.\nrepl-diskless-sync no\n\n# When diskless replication is enabled, it is possible to configure the delay\n# the server waits in order to spawn the child that transfers the RDB via socket\n# to the replicas.\n#\n# This is important since once the transfer starts, it is not possible to serve\n# new replicas arriving, that will be queued for the next RDB transfer, so the server\n# waits a delay in order to let more replicas arrive.\n#\n# The delay is specified in seconds, and by default is 5 seconds. To disable\n# it entirely just set it to 0 seconds and the transfer will start ASAP.\nrepl-diskless-sync-delay 5\n\n# Replicas send PINGs to server in a predefined interval. It\'s possible to change\n# this interval with the repl_ping_replica_period option. The default value is 10\n# seconds.\n#\n# repl-ping-replica-period 10\n\n# The following option sets the replication timeout for:\n#\n# 1) Bulk transfer I/O during SYNC, from the point of view of replica.\n# 2) Master timeout from the point of view of replicas (data, pings).\n# 3) Replica timeout from the point of view of masters (REPLCONF ACK pings).\n#\n# It is important to make sure that this value is greater than the value\n# specified for repl-ping-replica-period otherwise a timeout will be detected\n# every time there is low traffic between the master and the replica.\n#\n# repl-timeout 60\n\n# Disable TCP_NODELAY on the replica socket after SYNC?\n#\n# If you select "yes" Redis will use a smaller number of TCP packets and\n# less bandwidth to send data to replicas. But this can add a delay for\n# the data to appear on the replica side, up to 40 milliseconds with\n# Linux kernels using a default configuration.\n#\n# If you select "no" the delay for data to appear on the replica side will\n# be reduced but more bandwidth will be used for replication.\n#\n# By default we optimize for low latency, but in very high traffic conditions\n# or when the master and replicas are many hops away, turning this to "yes" may\n# be a good idea.\nrepl-disable-tcp-nodelay no\n\n# Set the replication backlog size. The backlog is a buffer that accumulates\n# replica data when replicas are disconnected for some time, so that when a replica\n# wants to reconnect again, often a full resync is not needed, but a partial\n# resync is enough, just passing the portion of data the replica missed while\n# disconnected.\n#\n# The bigger the replication backlog, the longer the time the replica can be\n# disconnected and later be able to perform a partial resynchronization.\n#\n# The backlog is only allocated once there is at least a replica connected.\n#\n# repl-backlog-size 1mb\n\n# After a master has no longer connected replicas for some time, the backlog\n# will be freed. The following option configures the amount of seconds that\n# need to elapse, starting from the time the last replica disconnected, for\n# the backlog buffer to be freed.\n#\n# Note that replicas never free the backlog for timeout, since they may be\n# promoted to masters later, and should be able to correctly "partially\n# resynchronize" with the replicas: hence they should always accumulate backlog.\n#\n# A value of 0 means to never release the backlog.\n#\n# repl-backlog-ttl 3600\n\n# The replica priority is an integer number published by Redis in the INFO output.\n# It is used by Redis Sentinel in order to select a replica to promote into a\n# master if the master is no longer working correctly.\n#\n# A replica with a low priority number is considered better for promotion, so\n# for instance if there are three replicas with priority 10, 100, 25 Sentinel will\n# pick the one with priority 10, that is the lowest.\n#\n# However a special priority of 0 marks the replica as not able to perform the\n# role of master, so a replica with priority of 0 will never be selected by\n# Redis Sentinel for promotion.\n#\n# By default the priority is 100.\nreplica-priority 100\n\n# It is possible for a master to stop accepting writes if there are less than\n# N replicas connected, having a lag less or equal than M seconds.\n#\n# The N replicas need to be in "online" state.\n#\n# The lag in seconds, that must be <= the specified value, is calculated from\n# the last ping received from the replica, that is usually sent every second.\n#\n# This option does not GUARANTEE that N replicas will accept the write, but\n# will limit the window of exposure for lost writes in case not enough replicas\n# are available, to the specified number of seconds.\n#\n# For example to require at least 3 replicas with a lag <= 10 seconds use:\n#\n# min-replicas-to-write 3\n# min-replicas-max-lag 10\n#\n# Setting one or the other to 0 disables the feature.\n#\n# By default min-replicas-to-write is set to 0 (feature disabled) and\n# min-replicas-max-lag is set to 10.\n\n# A Redis master is able to list the address and port of the attached\n# replicas in different ways. For example the "INFO replication" section\n# offers this information, which is used, among other tools, by\n# Redis Sentinel in order to discover replica instances.\n# Another place where this info is available is in the output of the\n# "ROLE" command of a master.\n#\n# The listed IP and address normally reported by a replica is obtained\n# in the following way:\n#\n#   IP: The address is auto detected by checking the peer address\n#   of the socket used by the replica to connect with the master.\n#\n#   Port: The port is communicated by the replica during the replication\n#   handshake, and is normally the port that the replica is using to\n#   listen for connections.\n#\n# However when port forwarding or Network Address Translation (NAT) is\n# used, the replica may be actually reachable via different IP and port\n# pairs. The following two options can be used by a replica in order to\n# report to its master a specific set of IP and port, so that both INFO\n# and ROLE will report those values.\n#\n# There is no need to use both the options if you need to override just\n# the port or the IP address.\n#\n# replica-announce-ip 5.5.5.5\n# replica-announce-port 1234\n\n################################## SECURITY ###################################\n\n# Require clients to issue AUTH <PASSWORD> before processing any other\n# commands.  This might be useful in environments in which you do not trust\n# others with access to the host running redis-server.\n#\n# This should stay commented out for backward compatibility and because most\n# people do not need auth (e.g. they run their own servers).\n#\n# Warning: since Redis is pretty fast an outside user can try up to\n# 150k passwords per second against a good box. This means that you should\n# use a very strong password otherwise it will be very easy to break.\n#\nrequirepass 123456\n\n# Command renaming.\n#\n# It is possible to change the name of dangerous commands in a shared\n# environment. For instance the CONFIG command may be renamed into something\n# hard to guess so that it will still be available for internal-use tools\n# but not available for general clients.\n#\n# Example:\n#\n# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52\n#\n# It is also possible to completely kill a command by renaming it into\n# an empty string:\n#\n# rename-command CONFIG ""\n#\n# Please note that changing the name of commands that are logged into the\n# AOF file or transmitted to replicas may cause problems.\n\n################################### CLIENTS ####################################\n\n# Set the max number of connected clients at the same time. By default\n# this limit is set to 10000 clients, however if the Redis server is not\n# able to configure the process file limit to allow for the specified limit\n# the max number of allowed clients is set to the current file limit\n# minus 32 (as Redis reserves a few file descriptors for internal uses).\n#\n# Once the limit is reached Redis will close all the new connections sending\n# an error \'max number of clients reached\'.\n#\n# maxclients 10000\n\n############################## MEMORY MANAGEMENT ################################\n\n# Set a memory usage limit to the specified amount of bytes.\n# When the memory limit is reached Redis will try to remove keys\n# according to the eviction policy selected (see maxmemory-policy).\n#\n# If Redis can\'t remove keys according to the policy, or if the policy is\n# set to \'noeviction\', Redis will start to reply with errors to commands\n# that would use more memory, like SET, LPUSH, and so on, and will continue\n# to reply to read-only commands like GET.\n#\n# This option is usually useful when using Redis as an LRU or LFU cache, or to\n# set a hard memory limit for an instance (using the \'noeviction\' policy).\n#\n# WARNING: If you have replicas attached to an instance with maxmemory on,\n# the size of the output buffers needed to feed the replicas are subtracted\n# from the used memory count, so that network problems / resyncs will\n# not trigger a loop where keys are evicted, and in turn the output\n# buffer of replicas is full with DELs of keys evicted triggering the deletion\n# of more keys, and so forth until the database is completely emptied.\n#\n# In short... if you have replicas attached it is suggested that you set a lower\n# limit for maxmemory so that there is some free RAM on the system for replica\n# output buffers (but this is not needed if the policy is \'noeviction\').\n#\n# maxmemory <bytes>\n\n# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory\n# is reached. You can select among five behaviors:\n#\n# volatile-lru -> Evict using approximated LRU among the keys with an expire set.\n# allkeys-lru -> Evict any key using approximated LRU.\n# volatile-lfu -> Evict using approximated LFU among the keys with an expire set.\n# allkeys-lfu -> Evict any key using approximated LFU.\n# volatile-random -> Remove a random key among the ones with an expire set.\n# allkeys-random -> Remove a random key, any key.\n# volatile-ttl -> Remove the key with the nearest expire time (minor TTL)\n# noeviction -> Don\'t evict anything, just return an error on write operations.\n#\n# LRU means Least Recently Used\n# LFU means Least Frequently Used\n#\n# Both LRU, LFU and volatile-ttl are implemented using approximated\n# randomized algorithms.\n#\n# Note: with any of the above policies, Redis will return an error on write\n#       operations, when there are no suitable keys for eviction.\n#\n#       At the date of writing these commands are: set setnx setex append\n#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd\n#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby\n#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby\n#       getset mset msetnx exec sort\n#\n# The default is:\n#\n# maxmemory-policy noeviction\n\n# LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated\n# algorithms (in order to save memory), so you can tune it for speed or\n# accuracy. For default Redis will check five keys and pick the one that was\n# used less recently, you can change the sample size using the following\n# configuration directive.\n#\n# The default of 5 produces good enough results. 10 Approximates very closely\n# true LRU but costs more CPU. 3 is faster but not very accurate.\n#\n# maxmemory-samples 5\n\n# Starting from Redis 5, by default a replica will ignore its maxmemory setting\n# (unless it is promoted to master after a failover or manually). It means\n# that the eviction of keys will be just handled by the master, sending the\n# DEL commands to the replica as keys evict in the master side.\n#\n# This behavior ensures that masters and replicas stay consistent, and is usually\n# what you want, however if your replica is writable, or you want the replica to have\n# a different memory setting, and you are sure all the writes performed to the\n# replica are idempotent, then you may change this default (but be sure to understand\n# what you are doing).\n#\n# Note that since the replica by default does not evict, it may end using more\n# memory than the one set via maxmemory (there are certain buffers that may\n# be larger on the replica, or data structures may sometimes take more memory and so\n# forth). So make sure you monitor your replicas and make sure they have enough\n# memory to never hit a real out-of-memory condition before the master hits\n# the configured maxmemory setting.\n#\n# replica-ignore-maxmemory yes\n\n############################# LAZY FREEING ####################################\n\n# Redis has two primitives to delete keys. One is called DEL and is a blocking\n# deletion of the object. It means that the server stops processing new commands\n# in order to reclaim all the memory associated with an object in a synchronous\n# way. If the key deleted is associated with a small object, the time needed\n# in order to execute the DEL command is very small and comparable to most other\n# O(1) or O(log_N) commands in Redis. However if the key is associated with an\n# aggregated value containing millions of elements, the server can block for\n# a long time (even seconds) in order to complete the operation.\n#\n# For the above reasons Redis also offers non blocking deletion primitives\n# such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and\n# FLUSHDB commands, in order to reclaim memory in background. Those commands\n# are executed in constant time. Another thread will incrementally free the\n# object in the background as fast as possible.\n#\n# DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.\n# It\'s up to the design of the application to understand when it is a good\n# idea to use one or the other. However the Redis server sometimes has to\n# delete keys or flush the whole database as a side effect of other operations.\n# Specifically Redis deletes objects independently of a user call in the\n# following scenarios:\n#\n# 1) On eviction, because of the maxmemory and maxmemory policy configurations,\n#    in order to make room for new data, without going over the specified\n#    memory limit.\n# 2) Because of expire: when a key with an associated time to live (see the\n#    EXPIRE command) must be deleted from memory.\n# 3) Because of a side effect of a command that stores data on a key that may\n#    already exist. For example the RENAME command may delete the old key\n#    content when it is replaced with another one. Similarly SUNIONSTORE\n#    or SORT with STORE option may delete existing keys. The SET command\n#    itself removes any old content of the specified key in order to replace\n#    it with the specified string.\n# 4) During replication, when a replica performs a full resynchronization with\n#    its master, the content of the whole database is removed in order to\n#    load the RDB file just transferred.\n#\n# In all the above cases the default is to delete objects in a blocking way,\n# like if DEL was called. However you can configure each case specifically\n# in order to instead release memory in a non-blocking way like if UNLINK\n# was called, using the following configuration directives:\n\nlazyfree-lazy-eviction no\nlazyfree-lazy-expire no\nlazyfree-lazy-server-del no\nreplica-lazy-flush no\n\n############################## APPEND ONLY MODE ###############################\n\n# By default Redis asynchronously dumps the dataset on disk. This mode is\n# good enough in many applications, but an issue with the Redis process or\n# a power outage may result into a few minutes of writes lost (depending on\n# the configured save points).\n#\n# The Append Only File is an alternative persistence mode that provides\n# much better durability. For instance using the default data fsync policy\n# (see later in the config file) Redis can lose just one second of writes in a\n# dramatic event like a server power outage, or a single write if something\n# wrong with the Redis process itself happens, but the operating system is\n# still running correctly.\n#\n# AOF and RDB persistence can be enabled at the same time without problems.\n# If the AOF is enabled on startup Redis will load the AOF, that is the file\n# with the better durability guarantees.\n#\n# Please check http://redis.io/topics/persistence for more information.\n\nappendonly no\n\n# The name of the append only file (default: "appendonly.aof")\n\nappendfilename "appendonly.aof"\n\n# The fsync() call tells the Operating System to actually write data on disk\n# instead of waiting for more data in the output buffer. Some OS will really flush\n# data on disk, some other OS will just try to do it ASAP.\n#\n# Redis supports three different modes:\n#\n# no: don\'t fsync, just let the OS flush the data when it wants. Faster.\n# always: fsync after every write to the append only log. Slow, Safest.\n# everysec: fsync only one time every second. Compromise.\n#\n# The default is "everysec", as that\'s usually the right compromise between\n# speed and data safety. It\'s up to you to understand if you can relax this to\n# "no" that will let the operating system flush the output buffer when\n# it wants, for better performances (but if you can live with the idea of\n# some data loss consider the default persistence mode that\'s snapshotting),\n# or on the contrary, use "always" that\'s very slow but a bit safer than\n# everysec.\n#\n# More details please check the following article:\n# http://antirez.com/post/redis-persistence-demystified.html\n#\n# If unsure, use "everysec".\n\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n\n# When the AOF fsync policy is set to always or everysec, and a background\n# saving process (a background save or AOF log background rewriting) is\n# performing a lot of I/O against the disk, in some Linux configurations\n# Redis may block too long on the fsync() call. Note that there is no fix for\n# this currently, as even performing fsync in a different thread will block\n# our synchronous write(2) call.\n#\n# In order to mitigate this problem it\'s possible to use the following option\n# that will prevent fsync() from being called in the main process while a\n# BGSAVE or BGREWRITEAOF is in progress.\n#\n# This means that while another child is saving, the durability of Redis is\n# the same as "appendfsync none". In practical terms, this means that it is\n# possible to lose up to 30 seconds of log in the worst scenario (with the\n# default Linux settings).\n#\n# If you have latency problems turn this to "yes". Otherwise leave it as\n# "no" that is the safest pick from the point of view of durability.\n\nno-appendfsync-on-rewrite no\n\n# Automatic rewrite of the append only file.\n# Redis is able to automatically rewrite the log file implicitly calling\n# BGREWRITEAOF when the AOF log size grows by the specified percentage.\n#\n# This is how it works: Redis remembers the size of the AOF file after the\n# latest rewrite (if no rewrite has happened since the restart, the size of\n# the AOF at startup is used).\n#\n# This base size is compared to the current size. If the current size is\n# bigger than the specified percentage, the rewrite is triggered. Also\n# you need to specify a minimal size for the AOF file to be rewritten, this\n# is useful to avoid rewriting the AOF file even if the percentage increase\n# is reached but it is still pretty small.\n#\n# Specify a percentage of zero in order to disable the automatic AOF\n# rewrite feature.\n\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n\n# An AOF file may be found to be truncated at the end during the Redis\n# startup process, when the AOF data gets loaded back into memory.\n# This may happen when the system where Redis is running\n# crashes, especially when an ext4 filesystem is mounted without the\n# data=ordered option (however this can\'t happen when Redis itself\n# crashes or aborts but the operating system still works correctly).\n#\n# Redis can either exit with an error when this happens, or load as much\n# data as possible (the default now) and start if the AOF file is found\n# to be truncated at the end. The following option controls this behavior.\n#\n# If aof-load-truncated is set to yes, a truncated AOF file is loaded and\n# the Redis server starts emitting a log to inform the user of the event.\n# Otherwise if the option is set to no, the server aborts with an error\n# and refuses to start. When the option is set to no, the user requires\n# to fix the AOF file using the "redis-check-aof" utility before to restart\n# the server.\n#\n# Note that if the AOF file will be found to be corrupted in the middle\n# the server will still exit with an error. This option only applies when\n# Redis will try to read more data from the AOF file but not enough bytes\n# will be found.\naof-load-truncated yes\n\n# When rewriting the AOF file, Redis is able to use an RDB preamble in the\n# AOF file for faster rewrites and recoveries. When this option is turned\n# on the rewritten AOF file is composed of two different stanzas:\n#\n#   [RDB file][AOF tail]\n#\n# When loading Redis recognizes that the AOF file starts with the "REDIS"\n# string and loads the prefixed RDB file, and continues loading the AOF\n# tail.\naof-use-rdb-preamble yes\n\n################################ LUA SCRIPTING  ###############################\n\n# Max execution time of a Lua script in milliseconds.\n#\n# If the maximum execution time is reached Redis will log that a script is\n# still in execution after the maximum allowed time and will start to\n# reply to queries with an error.\n#\n# When a long running script exceeds the maximum execution time only the\n# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be\n# used to stop a script that did not yet called write commands. The second\n# is the only way to shut down the server in the case a write command was\n# already issued by the script but the user doesn\'t want to wait for the natural\n# termination of the script.\n#\n# Set it to 0 or a negative value for unlimited execution without warnings.\nlua-time-limit 5000\n\n################################ REDIS CLUSTER  ###############################\n\n# Normal Redis instances can\'t be part of a Redis Cluster; only nodes that are\n# started as cluster nodes can. In order to start a Redis instance as a\n# cluster node enable the cluster support uncommenting the following:\n#\n# cluster-enabled yes\n\n# Every cluster node has a cluster configuration file. This file is not\n# intended to be edited by hand. It is created and updated by Redis nodes.\n# Every Redis Cluster node requires a different cluster configuration file.\n# Make sure that instances running in the same system do not have\n# overlapping cluster configuration file names.\n#\n# cluster-config-file nodes-6379.conf\n\n# Cluster node timeout is the amount of milliseconds a node must be unreachable\n# for it to be considered in failure state.\n# Most other internal time limits are multiple of the node timeout.\n#\n# cluster-node-timeout 15000\n\n# A replica of a failing master will avoid to start a failover if its data\n# looks too old.\n#\n# There is no simple way for a replica to actually have an exact measure of\n# its "data age", so the following two checks are performed:\n#\n# 1) If there are multiple replicas able to failover, they exchange messages\n#    in order to try to give an advantage to the replica with the best\n#    replication offset (more data from the master processed).\n#    Replicas will try to get their rank by offset, and apply to the start\n#    of the failover a delay proportional to their rank.\n#\n# 2) Every single replica computes the time of the last interaction with\n#    its master. This can be the last ping or command received (if the master\n#    is still in the "connected" state), or the time that elapsed since the\n#    disconnection with the master (if the replication link is currently down).\n#    If the last interaction is too old, the replica will not try to failover\n#    at all.\n#\n# The point "2" can be tuned by user. Specifically a replica will not perform\n# the failover if, since the last interaction with the master, the time\n# elapsed is greater than:\n#\n#   (node-timeout * replica-validity-factor) + repl-ping-replica-period\n#\n# So for example if node-timeout is 30 seconds, and the replica-validity-factor\n# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the\n# replica will not try to failover if it was not able to talk with the master\n# for longer than 310 seconds.\n#\n# A large replica-validity-factor may allow replicas with too old data to failover\n# a master, while a too small value may prevent the cluster from being able to\n# elect a replica at all.\n#\n# For maximum availability, it is possible to set the replica-validity-factor\n# to a value of 0, which means, that replicas will always try to failover the\n# master regardless of the last time they interacted with the master.\n# (However they\'ll always try to apply a delay proportional to their\n# offset rank).\n#\n# Zero is the only value able to guarantee that when all the partitions heal\n# the cluster will always be able to continue.\n#\n# cluster-replica-validity-factor 10\n\n# Cluster replicas are able to migrate to orphaned masters, that are masters\n# that are left without working replicas. This improves the cluster ability\n# to resist to failures as otherwise an orphaned master can\'t be failed over\n# in case of failure if it has no working replicas.\n#\n# Replicas migrate to orphaned masters only if there are still at least a\n# given number of other working replicas for their old master. This number\n# is the "migration barrier". A migration barrier of 1 means that a replica\n# will migrate only if there is at least 1 other working replica for its master\n# and so forth. It usually reflects the number of replicas you want for every\n# master in your cluster.\n#\n# Default is 1 (replicas migrate only if their masters remain with at least\n# one replica). To disable migration just set it to a very large value.\n# A value of 0 can be set but is useful only for debugging and dangerous\n# in production.\n#\n# cluster-migration-barrier 1\n\n# By default Redis Cluster nodes stop accepting queries if they detect there\n# is at least an hash slot uncovered (no available node is serving it).\n# This way if the cluster is partially down (for example a range of hash slots\n# are no longer covered) all the cluster becomes, eventually, unavailable.\n# It automatically returns available as soon as all the slots are covered again.\n#\n# However sometimes you want the subset of the cluster which is working,\n# to continue to accept queries for the part of the key space that is still\n# covered. In order to do so, just set the cluster-require-full-coverage\n# option to no.\n#\n# cluster-require-full-coverage yes\n\n# This option, when set to yes, prevents replicas from trying to failover its\n# master during master failures. However the master can still perform a\n# manual failover, if forced to do so.\n#\n# This is useful in different scenarios, especially in the case of multiple\n# data center operations, where we want one side to never be promoted if not\n# in the case of a total DC failure.\n#\n# cluster-replica-no-failover no\n\n# In order to setup your cluster make sure to read the documentation\n# available at http://redis.io web site.\n\n########################## CLUSTER DOCKER/NAT support  ########################\n\n# In certain deployments, Redis Cluster nodes address discovery fails, because\n# addresses are NAT-ted or because ports are forwarded (the typical case is\n# Docker and other containers).\n#\n# In order to make Redis Cluster working in such environments, a static\n# configuration where each node knows its public address is needed. The\n# following two options are used for this scope, and are:\n#\n# * cluster-announce-ip\n# * cluster-announce-port\n# * cluster-announce-bus-port\n#\n# Each instruct the node about its address, client port, and cluster message\n# bus port. The information is then published in the header of the bus packets\n# so that other nodes will be able to correctly map the address of the node\n# publishing the information.\n#\n# If the above options are not used, the normal Redis Cluster auto-detection\n# will be used instead.\n#\n# Note that when remapped, the bus port may not be at the fixed offset of\n# clients port + 10000, so you can specify any port and bus-port depending\n# on how they get remapped. If the bus-port is not set, a fixed offset of\n# 10000 will be used as usually.\n#\n# Example:\n#\n# cluster-announce-ip 10.1.1.5\n# cluster-announce-port 6379\n# cluster-announce-bus-port 6380\n\n################################## SLOW LOG ###################################\n\n# The Redis Slow Log is a system to log queries that exceeded a specified\n# execution time. The execution time does not include the I/O operations\n# like talking with the client, sending the reply and so forth,\n# but just the time needed to actually execute the command (this is the only\n# stage of command execution where the thread is blocked and can not serve\n# other requests in the meantime).\n#\n# You can configure the slow log with two parameters: one tells Redis\n# what is the execution time, in microseconds, to exceed in order for the\n# command to get logged, and the other parameter is the length of the\n# slow log. When a new command is logged the oldest one is removed from the\n# queue of logged commands.\n\n# The following time is expressed in microseconds, so 1000000 is equivalent\n# to one second. Note that a negative number disables the slow log, while\n# a value of zero forces the logging of every command.\nslowlog-log-slower-than 10000\n\n# There is no limit to this length. Just be aware that it will consume memory.\n# You can reclaim memory used by the slow log with SLOWLOG RESET.\nslowlog-max-len 128\n\n################################ LATENCY MONITOR ##############################\n\n# The Redis latency monitoring subsystem samples different operations\n# at runtime in order to collect data related to possible sources of\n# latency of a Redis instance.\n#\n# Via the LATENCY command this information is available to the user that can\n# print graphs and obtain reports.\n#\n# The system only logs operations that were performed in a time equal or\n# greater than the amount of milliseconds specified via the\n# latency-monitor-threshold configuration directive. When its value is set\n# to zero, the latency monitor is turned off.\n#\n# By default latency monitoring is disabled since it is mostly not needed\n# if you don\'t have latency issues, and collecting data has a performance\n# impact, that while very small, can be measured under big load. Latency\n# monitoring can easily be enabled at runtime using the command\n# "CONFIG SET latency-monitor-threshold <milliseconds>" if needed.\nlatency-monitor-threshold 0\n\n############################# EVENT NOTIFICATION ##############################\n\n# Redis can notify Pub/Sub clients about events happening in the key space.\n# This feature is documented at http://redis.io/topics/notifications\n#\n# For instance if keyspace events notification is enabled, and a client\n# performs a DEL operation on key "foo" stored in the Database 0, two\n# messages will be published via Pub/Sub:\n#\n# PUBLISH __keyspace@0__:foo del\n# PUBLISH __keyevent@0__:del foo\n#\n# It is possible to select the events that Redis will notify among a set\n# of classes. Every class is identified by a single character:\n#\n#  K     Keyspace events, published with __keyspace@<db>__ prefix.\n#  E     Keyevent events, published with __keyevent@<db>__ prefix.\n#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...\n#  $     String commands\n#  l     List commands\n#  s     Set commands\n#  h     Hash commands\n#  z     Sorted set commands\n#  x     Expired events (events generated every time a key expires)\n#  e     Evicted events (events generated when a key is evicted for maxmemory)\n#  A     Alias for g$lshzxe, so that the "AKE" string means all the events.\n#\n#  The "notify-keyspace-events" takes as argument a string that is composed\n#  of zero or multiple characters. The empty string means that notifications\n#  are disabled.\n#\n#  Example: to enable list and generic events, from the point of view of the\n#           event name, use:\n#\n#  notify-keyspace-events Elg\n#\n#  Example 2: to get the stream of the expired keys subscribing to channel\n#             name __keyevent@0__:expired use:\n#\n#  notify-keyspace-events Ex\n#\n#  By default all notifications are disabled because most users don\'t need\n#  this feature and the feature has some overhead. Note that if you don\'t\n#  specify at least one of K or E, no events will be delivered.\nnotify-keyspace-events ""\n\n############################### ADVANCED CONFIG ###############################\n\n# Hashes are encoded using a memory efficient data structure when they have a\n# small number of entries, and the biggest entry does not exceed a given\n# threshold. These thresholds can be configured using the following directives.\nhash-max-ziplist-entries 512\nhash-max-ziplist-value 64\n\n# Lists are also encoded in a special way to save a lot of space.\n# The number of entries allowed per internal list node can be specified\n# as a fixed maximum size or a maximum number of elements.\n# For a fixed maximum size, use -5 through -1, meaning:\n# -5: max size: 64 Kb  <-- not recommended for normal workloads\n# -4: max size: 32 Kb  <-- not recommended\n# -3: max size: 16 Kb  <-- probably not recommended\n# -2: max size: 8 Kb   <-- good\n# -1: max size: 4 Kb   <-- good\n# Positive numbers mean store up to _exactly_ that number of elements\n# per list node.\n# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),\n# but if your use case is unique, adjust the settings as necessary.\nlist-max-ziplist-size -2\n\n# Lists may also be compressed.\n# Compress depth is the number of quicklist ziplist nodes from *each* side of\n# the list to *exclude* from compression.  The head and tail of the list\n# are always uncompressed for fast push/pop operations.  Settings are:\n# 0: disable all list compression\n# 1: depth 1 means "don\'t start compressing until after 1 node into the list,\n#    going from either the head or tail"\n#    So: [head]->node->node->...->node->[tail]\n#    [head], [tail] will always be uncompressed; inner nodes will compress.\n# 2: [head]->[next]->node->node->...->node->[prev]->[tail]\n#    2 here means: don\'t compress head or head->next or tail->prev or tail,\n#    but compress all nodes between them.\n# 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail]\n# etc.\nlist-compress-depth 0\n\n# Sets have a special encoding in just one case: when a set is composed\n# of just strings that happen to be integers in radix 10 in the range\n# of 64 bit signed integers.\n# The following configuration setting sets the limit in the size of the\n# set in order to use this special memory saving encoding.\nset-max-intset-entries 512\n\n# Similarly to hashes and lists, sorted sets are also specially encoded in\n# order to save a lot of space. This encoding is only used when the length and\n# elements of a sorted set are below the following limits:\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\n\n# HyperLogLog sparse representation bytes limit. The limit includes the\n# 16 bytes header. When an HyperLogLog using the sparse representation crosses\n# this limit, it is converted into the dense representation.\n#\n# A value greater than 16000 is totally useless, since at that point the\n# dense representation is more memory efficient.\n#\n# The suggested value is ~ 3000 in order to have the benefits of\n# the space efficient encoding without slowing down too much PFADD,\n# which is O(N) with the sparse encoding. The value can be raised to\n# ~ 10000 when CPU is not a concern, but space is, and the data set is\n# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.\nhll-sparse-max-bytes 3000\n\n# Streams macro node max size / items. The stream data structure is a radix\n# tree of big nodes that encode multiple items inside. Using this configuration\n# it is possible to configure how big a single node can be in bytes, and the\n# maximum number of items it may contain before switching to a new node when\n# appending new stream entries. If any of the following settings are set to\n# zero, the limit is ignored, so for instance it is possible to set just a\n# max entires limit by setting max-bytes to 0 and max-entries to the desired\n# value.\nstream-node-max-bytes 4096\nstream-node-max-entries 100\n\n# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in\n# order to help rehashing the main Redis hash table (the one mapping top-level\n# keys to values). The hash table implementation Redis uses (see dict.c)\n# performs a lazy rehashing: the more operation you run into a hash table\n# that is rehashing, the more rehashing "steps" are performed, so if the\n# server is idle the rehashing is never complete and some more memory is used\n# by the hash table.\n#\n# The default is to use this millisecond 10 times every second in order to\n# actively rehash the main dictionaries, freeing memory when possible.\n#\n# If unsure:\n# use "activerehashing no" if you have hard latency requirements and it is\n# not a good thing in your environment that Redis can reply from time to time\n# to queries with 2 milliseconds delay.\n#\n# use "activerehashing yes" if you don\'t have such hard requirements but\n# want to free memory asap when possible.\nactiverehashing yes\n\n# The client output buffer limits can be used to force disconnection of clients\n# that are not reading data from the server fast enough for some reason (a\n# common reason is that a Pub/Sub client can\'t consume messages as fast as the\n# publisher can produce them).\n#\n# The limit can be set differently for the three different classes of clients:\n#\n# normal -> normal clients including MONITOR clients\n# replica  -> replica clients\n# pubsub -> clients subscribed to at least one pubsub channel or pattern\n#\n# The syntax of every client-output-buffer-limit directive is the following:\n#\n# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>\n#\n# A client is immediately disconnected once the hard limit is reached, or if\n# the soft limit is reached and remains reached for the specified number of\n# seconds (continuously).\n# So for instance if the hard limit is 32 megabytes and the soft limit is\n# 16 megabytes / 10 seconds, the client will get disconnected immediately\n# if the size of the output buffers reach 32 megabytes, but will also get\n# disconnected if the client reaches 16 megabytes and continuously overcomes\n# the limit for 10 seconds.\n#\n# By default normal clients are not limited because they don\'t receive data\n# without asking (in a push way), but just after a request, so only\n# asynchronous clients may create a scenario where data is requested faster\n# than it can read.\n#\n# Instead there is a default limit for pubsub and replica clients, since\n# subscribers and replicas receive data in a push fashion.\n#\n# Both the hard or the soft limit can be disabled by setting them to zero.\nclient-output-buffer-limit normal 0 0 0\nclient-output-buffer-limit replica 256mb 64mb 60\nclient-output-buffer-limit pubsub 32mb 8mb 60\n\n# Client query buffers accumulate new commands. They are limited to a fixed\n# amount by default in order to avoid that a protocol desynchronization (for\n# instance due to a bug in the client) will lead to unbound memory usage in\n# the query buffer. However you can configure it here if you have very special\n# needs, such us huge multi/exec requests or alike.\n#\n# client-query-buffer-limit 1gb\n\n# In the Redis protocol, bulk requests, that are, elements representing single\n# strings, are normally limited ot 512 mb. However you can change this limit\n# here.\n#\n# proto-max-bulk-len 512mb\n\n# Redis calls an internal function to perform many background tasks, like\n# closing connections of clients in timeout, purging expired keys that are\n# never requested, and so forth.\n#\n# Not all tasks are performed with the same frequency, but Redis checks for\n# tasks to perform according to the specified "hz" value.\n#\n# By default "hz" is set to 10. Raising the value will use more CPU when\n# Redis is idle, but at the same time will make Redis more responsive when\n# there are many keys expiring at the same time, and timeouts may be\n# handled with more precision.\n#\n# The range is between 1 and 500, however a value over 100 is usually not\n# a good idea. Most users should use the default of 10 and raise this up to\n# 100 only in environments where very low latency is required.\nhz 10\n\n# Normally it is useful to have an HZ value which is proportional to the\n# number of clients connected. This is useful in order, for instance, to\n# avoid too many clients are processed for each background task invocation\n# in order to avoid latency spikes.\n#\n# Since the default HZ value by default is conservatively set to 10, Redis\n# offers, and enables by default, the ability to use an adaptive HZ value\n# which will temporary raise when there are many connected clients.\n#\n# When dynamic HZ is enabled, the actual configured HZ will be used as\n# as a baseline, but multiples of the configured HZ value will be actually\n# used as needed once more clients are connected. In this way an idle\n# instance will use very little CPU time while a busy instance will be\n# more responsive.\ndynamic-hz yes\n\n# When a child rewrites the AOF file, if the following option is enabled\n# the file will be fsync-ed every 32 MB of data generated. This is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\naof-rewrite-incremental-fsync yes\n\n# When redis saves RDB file, if the following option is enabled\n# the file will be fsync-ed every 32 MB of data generated. This is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\nrdb-save-incremental-fsync yes\n\n# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good\n# idea to start with the default settings and only change them after investigating\n# how to improve the performances and how the keys LFU change over time, which\n# is possible to inspect via the OBJECT FREQ command.\n#\n# There are two tunable parameters in the Redis LFU implementation: the\n# counter logarithm factor and the counter decay time. It is important to\n# understand what the two parameters mean before changing them.\n#\n# The LFU counter is just 8 bits per key, it\'s maximum value is 255, so Redis\n# uses a probabilistic increment with logarithmic behavior. Given the value\n# of the old counter, when a key is accessed, the counter is incremented in\n# this way:\n#\n# 1. A random number R between 0 and 1 is extracted.\n# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).\n# 3. The counter is incremented only if R < P.\n#\n# The default lfu-log-factor is 10. This is a table of how the frequency\n# counter changes with a different number of accesses with different\n# logarithmic factors:\n#\n# +--------+------------+------------+------------+------------+------------+\n# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |\n# +--------+------------+------------+------------+------------+------------+\n# | 0      | 104        | 255        | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 1      | 18         | 49         | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 10     | 10         | 18         | 142        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 100    | 8          | 11         | 49         | 143        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n#\n# NOTE: The above table was obtained by running the following commands:\n#\n#   redis-benchmark -n 1000000 incr foo\n#   redis-cli object freq foo\n#\n# NOTE 2: The counter initial value is 5 in order to give new objects a chance\n# to accumulate hits.\n#\n# The counter decay time is the time, in minutes, that must elapse in order\n# for the key counter to be divided by two (or decremented if it has a value\n# less <= 10).\n#\n# The default value for the lfu-decay-time is 1. A Special value of 0 means to\n# decay the counter every time it happens to be scanned.\n#\n# lfu-log-factor 10\n# lfu-decay-time 1\n\n########################### ACTIVE DEFRAGMENTATION #######################\n#\n# WARNING THIS FEATURE IS EXPERIMENTAL. However it was stress tested\n# even in production and manually tested by multiple engineers for some\n# time.\n#\n# What is active defragmentation?\n# -------------------------------\n#\n# Active (online) defragmentation allows a Redis server to compact the\n# spaces left between small allocations and deallocations of data in memory,\n# thus allowing to reclaim back memory.\n#\n# Fragmentation is a natural process that happens with every allocator (but\n# less so with Jemalloc, fortunately) and certain workloads. Normally a server\n# restart is needed in order to lower the fragmentation, or at least to flush\n# away all the data and create it again. However thanks to this feature\n# implemented by Oran Agra for Redis 4.0 this process can happen at runtime\n# in an "hot" way, while the server is running.\n#\n# Basically when the fragmentation is over a certain level (see the\n# configuration options below) Redis will start to create new copies of the\n# values in contiguous memory regions by exploiting certain specific Jemalloc\n# features (in order to understand if an allocation is causing fragmentation\n# and to allocate it in a better place), and at the same time, will release the\n# old copies of the data. This process, repeated incrementally for all the keys\n# will cause the fragmentation to drop back to normal values.\n#\n# Important things to understand:\n#\n# 1. This feature is disabled by default, and only works if you compiled Redis\n#    to use the copy of Jemalloc we ship with the source code of Redis.\n#    This is the default with Linux builds.\n#\n# 2. You never need to enable this feature if you don\'t have fragmentation\n#    issues.\n#\n# 3. Once you experience fragmentation, you can enable this feature when\n#    needed with the command "CONFIG SET activedefrag yes".\n#\n# The configuration parameters are able to fine tune the behavior of the\n# defragmentation process. If you are not sure about what they mean it is\n# a good idea to leave the defaults untouched.\n\n# Enabled active defragmentation\n# activedefrag yes\n\n# Minimum amount of fragmentation waste to start active defrag\n# active-defrag-ignore-bytes 100mb\n\n# Minimum percentage of fragmentation to start active defrag\n# active-defrag-threshold-lower 10\n\n# Maximum percentage of fragmentation at which we use maximum effort\n# active-defrag-threshold-upper 100\n\n# Minimal effort for defrag in CPU percentage\n# active-defrag-cycle-min 5\n\n# Maximal effort for defrag in CPU percentage\n# active-defrag-cycle-max 75\n\n# Maximum number of set/hash/zset/list fields that will be processed from\n# the main dictionary scan\n# active-defrag-max-scan-fields 1000\n\n# It is possible to pin different threads and processes of Redis to specific\n# CPUs in your system, in order to maximize the performances of the server.\n# This is useful both in order to pin different Redis threads in different\n# CPUs, but also in order to make sure that multiple Redis instances running\n# in the same host will be pinned to different CPUs.\n#\n# Normally you can do this using the "taskset" command, however it is also\n# possible to this via Redis configuration directly, both in Linux and FreeBSD.\n#\n# You can pin the server/IO threads, bio threads, aof rewrite child process, and\n# the bgsave child process. The syntax to specify the cpu list is the same as\n# the taskset command:\n#\n# Set redis server/io threads to cpu affinity 0,2,4,6:\n# server_cpulist 0-7:2\n#\n# Set bio threads to cpu affinity 1,3:\n# bio_cpulist 1,3\n#\n# Set aof rewrite child process to cpu affinity 8,9,10,11:\n# aof_rewrite_cpulist 8-11\n#\n# Set bgsave child process to cpu affinity 1,10,11\n# bgsave_cpulist 1,10-11\n\n# In some cases redis will emit warnings and even refuse to start if it detects\n# that the system is in bad state, it is possible to suppress these warnings\n# by setting the following config which takes a space delimited list of warnings\n# to suppress\n#\n# ignore-warnings ARM64-COW-BUG\n\n\n\n\n# deploy.sh\n\nmkdir -p /etc/redis/\n\n\\cp ./redis.conf /etc/redis/redis.conf\ndocker-compose up -d\n',normalizedContent:'# redis key-value\n\n\n\nhttps://redis.io/\n\ngithubhttps://github.com/redis/redis\n\n\n# \n\n> redisremote dictionary serverredissalvatore sanfilippo2009\n\n\n# \n\n 1.  redisredis\n 2.  redis\n 3.  redis\n 4.  redis\n 5.  redis\n 6.  redis\n\n\n# \n\n 1.  redis\n 2.  redis\n 3.  redis\n 4.  redis\n 5.  redis\n 6.  redis\n\n\n# \n\nredis\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\nservices: \n  redis:\n    image: redis:7.0.3\n    container_name: redis\n    restart: always\n    environment: \n      tz: asia/shanghai\n    ports:\n      - 6379:6379\n    volumes: \n      - data:/data\n    command: redis-server /usr/local/etc/redis/redis.conf\n    sysctls:\n      net.core.somaxconn: 65535\n\nvolumes: \n  data: \n\n\n\n# redis.conf\n\n# redis configuration file example.\n#\n# note that in order to read the configuration file, redis must be\n# started with the file path as first argument:\n#\n# ./redis-server /path/to/redis.conf\n\n# note on units: when memory size is needed, it is possible to specify\n# it in the usual form of 1k 5gb 4m and so forth:\n#\n# 1k => 1000 bytes\n# 1kb => 1024 bytes\n# 1m => 1000000 bytes\n# 1mb => 1024*1024 bytes\n# 1g => 1000000000 bytes\n# 1gb => 1024*1024*1024 bytes\n#\n# units are case insensitive so 1gb 1gb 1gb are all the same.\n\n################################## includes ###################################\n\n# include one or more other config files here.  this is useful if you\n# have a standard template that goes to all redis servers but also need\n# to customize a few per-server settings.  include files can include\n# other files, so use this wisely.\n#\n# notice option "include" won\'t be rewritten by command "config rewrite"\n# from admin or redis sentinel. since redis always uses the last processed\n# line as value of a configuration directive, you\'d better put includes\n# at the beginning of this file to avoid overwriting config change at runtime.\n#\n# if instead you are interested in using includes to override configuration\n# options, it is better to use include as the last line.\n#\n# include /path/to/local.conf\n# include /path/to/other.conf\n\n################################## modules #####################################\n\n# load modules at startup. if the server is not able to load modules\n# it will abort. it is possible to use multiple loadmodule directives.\n#\n# loadmodule /path/to/my_module.so\n# loadmodule /path/to/other_module.so\n\n################################## network #####################################\n\n# by default, if no "bind" configuration directive is specified, redis listens\n# for connections from all the network interfaces available on the server.\n# it is possible to listen to just one or multiple selected interfaces using\n# the "bind" configuration directive, followed by one or more ip addresses.\n#\n# examples:\n#\n# bind 192.168.1.100 10.0.0.1\n# bind 127.0.0.1 ::1\n#\n# ~~~ warning ~~~ if the computer running redis is directly exposed to the\n# internet, binding to all the interfaces is dangerous and will expose the\n# instance to everybody on the internet. so by default we uncomment the\n# following bind directive, that will force redis to listen only into\n# the ipv4 loopback interface address (this means redis will be able to\n# accept connections only from clients running into the same computer it\n# is running).\n#\n# if you are sure you want your instance to listen to all the interfaces\n# just comment the following line.\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# bind 127.0.0.1\n\n# protected mode is a layer of security protection, in order to avoid that\n# redis instances left open on the internet are accessed and exploited.\n#\n# when protected mode is on and if:\n#\n# 1) the server is not binding explicitly to a set of addresses using the\n#    "bind" directive.\n# 2) no password is configured.\n#\n# the server only accepts connections from clients connecting from the\n# ipv4 and ipv6 loopback addresses 127.0.0.1 and ::1, and from unix domain\n# sockets.\n#\n# by default protected mode is enabled. you should disable it only if\n# you are sure you want clients from other hosts to connect to redis\n# even if no authentication is configured, nor a specific set of interfaces\n# are explicitly listed using the "bind" directive.\nprotected-mode no\n\n# accept connections on the specified port, default is 6379 (iana #815344).\n# if port 0 is specified redis will not listen on a tcp socket.\nport 6379\n\n# tcp listen() backlog.\n#\n# in high requests-per-second environments you need an high backlog in order\n# to avoid slow clients connections issues. note that the linux kernel\n# will silently truncate it to the value of /proc/sys/net/core/somaxconn so\n# make sure to raise both the value of somaxconn and tcp_max_syn_backlog\n# in order to get the desired effect.\ntcp-backlog 511\n\n# unix socket.\n#\n# specify the path for the unix socket that will be used to listen for\n# incoming connections. there is no default, so redis will not listen\n# on a unix socket when not specified.\n#\n# unixsocket /tmp/redis.sock\n# unixsocketperm 700\n\n# close the connection after a client is idle for n seconds (0 to disable)\ntimeout 0\n\n# tcp keepalive.\n#\n# if non-zero, use so_keepalive to send tcp acks to clients in absence\n# of communication. this is useful for two reasons:\n#\n# 1) detect dead peers.\n# 2) take the connection alive from the point of view of network\n#    equipment in the middle.\n#\n# on linux, the specified value (in seconds) is the period used to send acks.\n# note that to close the connection the double of the time is needed.\n# on other kernels the period depends on the kernel configuration.\n#\n# a reasonable value for this option is 300 seconds, which is the new\n# redis default starting with redis 3.2.1.\ntcp-keepalive 300\n\n################################# general #####################################\n\n# by default redis does not run as a daemon. use \'yes\' if you need it.\n# note that redis will write a pid file in /var/run/redis.pid when daemonized.\ndaemonize no\n\n# if you run redis from upstart or systemd, redis can interact with your\n# supervision tree. options:\n#   supervised no      - no supervision interaction\n#   supervised upstart - signal upstart by putting redis into sigstop mode\n#   supervised systemd - signal systemd by writing ready=1 to $notify_socket\n#   supervised auto    - detect upstart or systemd method based on\n#                        upstart_job or notify_socket environment variables\n# note: these supervision methods only signal "process is ready."\n#       they do not enable continuous liveness pings back to your supervisor.\nsupervised no\n\n# if a pid file is specified, redis writes it where specified at startup\n# and removes it at exit.\n#\n# when the server runs non daemonized, no pid file is created if none is\n# specified in the configuration. when the server is daemonized, the pid file\n# is used even if not specified, defaulting to "/var/run/redis.pid".\n#\n# creating a pid file is best effort: if redis is not able to create it\n# nothing bad happens, the server will start and run normally.\npidfile /var/run/redis_6379.pid\n\n# specify the server verbosity level.\n# this can be one of:\n# debug (a lot of information, useful for development/testing)\n# verbose (many rarely useful info, but not a mess like the debug level)\n# notice (moderately verbose, what you want in production probably)\n# warning (only very important / critical messages are logged)\nloglevel notice\n\n# specify the log file name. also the empty string can be used to force\n# redis to log on the standard output. note that if you use standard\n# output for logging but daemonize, logs will be sent to /dev/null\nlogfile ""\n\n# to enable logging to the system logger, just set \'syslog-enabled\' to yes,\n# and optionally update the other syslog parameters to suit your needs.\n# syslog-enabled no\n\n# specify the syslog identity.\n# syslog-ident redis\n\n# specify the syslog facility. must be user or between local0-local7.\n# syslog-facility local0\n\n# set the number of databases. the default database is db 0, you can select\n# a different one on a per-connection basis using select <dbid> where\n# dbid is a number between 0 and \'databases\'-1\ndatabases 20\n\n# by default redis shows an ascii art logo only when started to log to the\n# standard output and if the standard output is a tty. basically this means\n# that normally a logo is displayed only in interactive sessions.\n#\n# however it is possible to force the pre-4.0 behavior and always show a\n# ascii art logo in startup logs by setting the following option to yes.\nalways-show-logo yes\n\n################################ snapshotting  ################################\n#\n# save the db on disk:\n#\n#   save <seconds> <changes>\n#\n#   will save the db if both the given number of seconds and the given\n#   number of write operations against the db occurred.\n#\n#   in the example below the behaviour will be to save:\n#   after 900 sec (15 min) if at least 1 key changed\n#   after 300 sec (5 min) if at least 10 keys changed\n#   after 60 sec if at least 10000 keys changed\n#\n#   note: you can disable saving completely by commenting out all "save" lines.\n#\n#   it is also possible to remove all the previously configured save\n#   points by adding a save directive with a single empty string argument\n#   like in the following example:\n#\n#   save ""\n\nsave 900 1\nsave 300 10\nsave 60 10000\n\n# by default redis will stop accepting writes if rdb snapshots are enabled\n# (at least one save point) and the latest background save failed.\n# this will make the user aware (in a hard way) that data is not persisting\n# on disk properly, otherwise chances are that no one will notice and some\n# disaster will happen.\n#\n# if the background saving process will start working again redis will\n# automatically allow writes again.\n#\n# however if you have setup your proper monitoring of the redis server\n# and persistence, you may want to disable this feature so that redis will\n# continue to work as usual even if there are problems with disk,\n# permissions, and so forth.\nstop-writes-on-bgsave-error yes\n\n# compress string objects using lzf when dump .rdb databases?\n# for default that\'s set to \'yes\' as it\'s almost always a win.\n# if you want to save some cpu in the saving child set it to \'no\' but\n# the dataset will likely be bigger if you have compressible values or keys.\nrdbcompression yes\n\n# since version 5 of rdb a crc64 checksum is placed at the end of the file.\n# this makes the format more resistant to corruption but there is a performance\n# hit to pay (around 10%) when saving and loading rdb files, so you can disable it\n# for maximum performances.\n#\n# rdb files created with checksum disabled have a checksum of zero that will\n# tell the loading code to skip the check.\nrdbchecksum yes\n\n# the filename where to dump the db\ndbfilename dump.rdb\n\n# the working directory.\n#\n# the db will be written inside this directory, with the filename specified\n# above using the \'dbfilename\' configuration directive.\n#\n# the append only file will also be created inside this directory.\n#\n# note that you must specify a directory here, not a file name.\ndir /data/\n\n################################# replication #################################\n\n# master-replica replication. use replicaof to make a redis instance a copy of\n# another redis server. a few things to understand asap about redis replication.\n#\n#   +------------------+      +---------------+\n#   |      master      | ---\x3e |    replica    |\n#   | (receive writes) |      |  (exact copy) |\n#   +------------------+      +---------------+\n#\n# 1) redis replication is asynchronous, but you can configure a master to\n#    stop accepting writes if it appears to be not connected with at least\n#    a given number of replicas.\n# 2) redis replicas are able to perform a partial resynchronization with the\n#    master if the replication link is lost for a relatively small amount of\n#    time. you may want to configure the replication backlog size (see the next\n#    sections of this file) with a sensible value depending on your needs.\n# 3) replication is automatic and does not need user intervention. after a\n#    network partition replicas automatically try to reconnect to masters\n#    and resynchronize with them.\n#\n# replicaof <masterip> <masterport>\n\n# if the master is password protected (using the "requirepass" configuration\n# directive below) it is possible to tell the replica to authenticate before\n# starting the replication synchronization process, otherwise the master will\n# refuse the replica request.\n#\n# masterauth <master-password>\n\n# when a replica loses its connection with the master, or when the replication\n# is still in progress, the replica can act in two different ways:\n#\n# 1) if replica-serve-stale-data is set to \'yes\' (the default) the replica will\n#    still reply to client requests, possibly with out of date data, or the\n#    data set may just be empty if this is the first synchronization.\n#\n# 2) if replica-serve-stale-data is set to \'no\' the replica will reply with\n#    an error "sync with master in progress" to all the kind of commands\n#    but to info, replicaof, auth, ping, shutdown, replconf, role, config,\n#    subscribe, unsubscribe, psubscribe, punsubscribe, publish, pubsub,\n#    command, post, host: and latency.\n#\nreplica-serve-stale-data yes\n\n# you can configure a replica instance to accept writes or not. writing against\n# a replica instance may be useful to store some ephemeral data (because data\n# written on a replica will be easily deleted after resync with the master) but\n# may also cause problems if clients are writing to it because of a\n# misconfiguration.\n#\n# since redis 2.6 by default replicas are read-only.\n#\n# note: read only replicas are not designed to be exposed to untrusted clients\n# on the internet. it\'s just a protection layer against misuse of the instance.\n# still a read only replica exports by default all the administrative commands\n# such as config, debug, and so forth. to a limited extent you can improve\n# security of read only replicas using \'rename-command\' to shadow all the\n# administrative / dangerous commands.\nreplica-read-only yes\n\n# replication sync strategy: disk or socket.\n#\n# -------------------------------------------------------\n# warning: diskless replication is experimental currently\n# -------------------------------------------------------\n#\n# new replicas and reconnecting replicas that are not able to continue the replication\n# process just receiving differences, need to do what is called a "full\n# synchronization". an rdb file is transmitted from the master to the replicas.\n# the transmission can happen in two different ways:\n#\n# 1) disk-backed: the redis master creates a new process that writes the rdb\n#                 file on disk. later the file is transferred by the parent\n#                 process to the replicas incrementally.\n# 2) diskless: the redis master creates a new process that directly writes the\n#              rdb file to replica sockets, without touching the disk at all.\n#\n# with disk-backed replication, while the rdb file is generated, more replicas\n# can be queued and served with the rdb file as soon as the current child producing\n# the rdb file finishes its work. with diskless replication instead once\n# the transfer starts, new replicas arriving will be queued and a new transfer\n# will start when the current one terminates.\n#\n# when diskless replication is used, the master waits a configurable amount of\n# time (in seconds) before starting the transfer in the hope that multiple replicas\n# will arrive and the transfer can be parallelized.\n#\n# with slow disks and fast (large bandwidth) networks, diskless replication\n# works better.\nrepl-diskless-sync no\n\n# when diskless replication is enabled, it is possible to configure the delay\n# the server waits in order to spawn the child that transfers the rdb via socket\n# to the replicas.\n#\n# this is important since once the transfer starts, it is not possible to serve\n# new replicas arriving, that will be queued for the next rdb transfer, so the server\n# waits a delay in order to let more replicas arrive.\n#\n# the delay is specified in seconds, and by default is 5 seconds. to disable\n# it entirely just set it to 0 seconds and the transfer will start asap.\nrepl-diskless-sync-delay 5\n\n# replicas send pings to server in a predefined interval. it\'s possible to change\n# this interval with the repl_ping_replica_period option. the default value is 10\n# seconds.\n#\n# repl-ping-replica-period 10\n\n# the following option sets the replication timeout for:\n#\n# 1) bulk transfer i/o during sync, from the point of view of replica.\n# 2) master timeout from the point of view of replicas (data, pings).\n# 3) replica timeout from the point of view of masters (replconf ack pings).\n#\n# it is important to make sure that this value is greater than the value\n# specified for repl-ping-replica-period otherwise a timeout will be detected\n# every time there is low traffic between the master and the replica.\n#\n# repl-timeout 60\n\n# disable tcp_nodelay on the replica socket after sync?\n#\n# if you select "yes" redis will use a smaller number of tcp packets and\n# less bandwidth to send data to replicas. but this can add a delay for\n# the data to appear on the replica side, up to 40 milliseconds with\n# linux kernels using a default configuration.\n#\n# if you select "no" the delay for data to appear on the replica side will\n# be reduced but more bandwidth will be used for replication.\n#\n# by default we optimize for low latency, but in very high traffic conditions\n# or when the master and replicas are many hops away, turning this to "yes" may\n# be a good idea.\nrepl-disable-tcp-nodelay no\n\n# set the replication backlog size. the backlog is a buffer that accumulates\n# replica data when replicas are disconnected for some time, so that when a replica\n# wants to reconnect again, often a full resync is not needed, but a partial\n# resync is enough, just passing the portion of data the replica missed while\n# disconnected.\n#\n# the bigger the replication backlog, the longer the time the replica can be\n# disconnected and later be able to perform a partial resynchronization.\n#\n# the backlog is only allocated once there is at least a replica connected.\n#\n# repl-backlog-size 1mb\n\n# after a master has no longer connected replicas for some time, the backlog\n# will be freed. the following option configures the amount of seconds that\n# need to elapse, starting from the time the last replica disconnected, for\n# the backlog buffer to be freed.\n#\n# note that replicas never free the backlog for timeout, since they may be\n# promoted to masters later, and should be able to correctly "partially\n# resynchronize" with the replicas: hence they should always accumulate backlog.\n#\n# a value of 0 means to never release the backlog.\n#\n# repl-backlog-ttl 3600\n\n# the replica priority is an integer number published by redis in the info output.\n# it is used by redis sentinel in order to select a replica to promote into a\n# master if the master is no longer working correctly.\n#\n# a replica with a low priority number is considered better for promotion, so\n# for instance if there are three replicas with priority 10, 100, 25 sentinel will\n# pick the one with priority 10, that is the lowest.\n#\n# however a special priority of 0 marks the replica as not able to perform the\n# role of master, so a replica with priority of 0 will never be selected by\n# redis sentinel for promotion.\n#\n# by default the priority is 100.\nreplica-priority 100\n\n# it is possible for a master to stop accepting writes if there are less than\n# n replicas connected, having a lag less or equal than m seconds.\n#\n# the n replicas need to be in "online" state.\n#\n# the lag in seconds, that must be <= the specified value, is calculated from\n# the last ping received from the replica, that is usually sent every second.\n#\n# this option does not guarantee that n replicas will accept the write, but\n# will limit the window of exposure for lost writes in case not enough replicas\n# are available, to the specified number of seconds.\n#\n# for example to require at least 3 replicas with a lag <= 10 seconds use:\n#\n# min-replicas-to-write 3\n# min-replicas-max-lag 10\n#\n# setting one or the other to 0 disables the feature.\n#\n# by default min-replicas-to-write is set to 0 (feature disabled) and\n# min-replicas-max-lag is set to 10.\n\n# a redis master is able to list the address and port of the attached\n# replicas in different ways. for example the "info replication" section\n# offers this information, which is used, among other tools, by\n# redis sentinel in order to discover replica instances.\n# another place where this info is available is in the output of the\n# "role" command of a master.\n#\n# the listed ip and address normally reported by a replica is obtained\n# in the following way:\n#\n#   ip: the address is auto detected by checking the peer address\n#   of the socket used by the replica to connect with the master.\n#\n#   port: the port is communicated by the replica during the replication\n#   handshake, and is normally the port that the replica is using to\n#   listen for connections.\n#\n# however when port forwarding or network address translation (nat) is\n# used, the replica may be actually reachable via different ip and port\n# pairs. the following two options can be used by a replica in order to\n# report to its master a specific set of ip and port, so that both info\n# and role will report those values.\n#\n# there is no need to use both the options if you need to override just\n# the port or the ip address.\n#\n# replica-announce-ip 5.5.5.5\n# replica-announce-port 1234\n\n################################## security ###################################\n\n# require clients to issue auth <password> before processing any other\n# commands.  this might be useful in environments in which you do not trust\n# others with access to the host running redis-server.\n#\n# this should stay commented out for backward compatibility and because most\n# people do not need auth (e.g. they run their own servers).\n#\n# warning: since redis is pretty fast an outside user can try up to\n# 150k passwords per second against a good box. this means that you should\n# use a very strong password otherwise it will be very easy to break.\n#\nrequirepass 123456\n\n# command renaming.\n#\n# it is possible to change the name of dangerous commands in a shared\n# environment. for instance the config command may be renamed into something\n# hard to guess so that it will still be available for internal-use tools\n# but not available for general clients.\n#\n# example:\n#\n# rename-command config b840fc02d524045429941cc15f59e41cb7be6c52\n#\n# it is also possible to completely kill a command by renaming it into\n# an empty string:\n#\n# rename-command config ""\n#\n# please note that changing the name of commands that are logged into the\n# aof file or transmitted to replicas may cause problems.\n\n################################### clients ####################################\n\n# set the max number of connected clients at the same time. by default\n# this limit is set to 10000 clients, however if the redis server is not\n# able to configure the process file limit to allow for the specified limit\n# the max number of allowed clients is set to the current file limit\n# minus 32 (as redis reserves a few file descriptors for internal uses).\n#\n# once the limit is reached redis will close all the new connections sending\n# an error \'max number of clients reached\'.\n#\n# maxclients 10000\n\n############################## memory management ################################\n\n# set a memory usage limit to the specified amount of bytes.\n# when the memory limit is reached redis will try to remove keys\n# according to the eviction policy selected (see maxmemory-policy).\n#\n# if redis can\'t remove keys according to the policy, or if the policy is\n# set to \'noeviction\', redis will start to reply with errors to commands\n# that would use more memory, like set, lpush, and so on, and will continue\n# to reply to read-only commands like get.\n#\n# this option is usually useful when using redis as an lru or lfu cache, or to\n# set a hard memory limit for an instance (using the \'noeviction\' policy).\n#\n# warning: if you have replicas attached to an instance with maxmemory on,\n# the size of the output buffers needed to feed the replicas are subtracted\n# from the used memory count, so that network problems / resyncs will\n# not trigger a loop where keys are evicted, and in turn the output\n# buffer of replicas is full with dels of keys evicted triggering the deletion\n# of more keys, and so forth until the database is completely emptied.\n#\n# in short... if you have replicas attached it is suggested that you set a lower\n# limit for maxmemory so that there is some free ram on the system for replica\n# output buffers (but this is not needed if the policy is \'noeviction\').\n#\n# maxmemory <bytes>\n\n# maxmemory policy: how redis will select what to remove when maxmemory\n# is reached. you can select among five behaviors:\n#\n# volatile-lru -> evict using approximated lru among the keys with an expire set.\n# allkeys-lru -> evict any key using approximated lru.\n# volatile-lfu -> evict using approximated lfu among the keys with an expire set.\n# allkeys-lfu -> evict any key using approximated lfu.\n# volatile-random -> remove a random key among the ones with an expire set.\n# allkeys-random -> remove a random key, any key.\n# volatile-ttl -> remove the key with the nearest expire time (minor ttl)\n# noeviction -> don\'t evict anything, just return an error on write operations.\n#\n# lru means least recently used\n# lfu means least frequently used\n#\n# both lru, lfu and volatile-ttl are implemented using approximated\n# randomized algorithms.\n#\n# note: with any of the above policies, redis will return an error on write\n#       operations, when there are no suitable keys for eviction.\n#\n#       at the date of writing these commands are: set setnx setex append\n#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd\n#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby\n#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby\n#       getset mset msetnx exec sort\n#\n# the default is:\n#\n# maxmemory-policy noeviction\n\n# lru, lfu and minimal ttl algorithms are not precise algorithms but approximated\n# algorithms (in order to save memory), so you can tune it for speed or\n# accuracy. for default redis will check five keys and pick the one that was\n# used less recently, you can change the sample size using the following\n# configuration directive.\n#\n# the default of 5 produces good enough results. 10 approximates very closely\n# true lru but costs more cpu. 3 is faster but not very accurate.\n#\n# maxmemory-samples 5\n\n# starting from redis 5, by default a replica will ignore its maxmemory setting\n# (unless it is promoted to master after a failover or manually). it means\n# that the eviction of keys will be just handled by the master, sending the\n# del commands to the replica as keys evict in the master side.\n#\n# this behavior ensures that masters and replicas stay consistent, and is usually\n# what you want, however if your replica is writable, or you want the replica to have\n# a different memory setting, and you are sure all the writes performed to the\n# replica are idempotent, then you may change this default (but be sure to understand\n# what you are doing).\n#\n# note that since the replica by default does not evict, it may end using more\n# memory than the one set via maxmemory (there are certain buffers that may\n# be larger on the replica, or data structures may sometimes take more memory and so\n# forth). so make sure you monitor your replicas and make sure they have enough\n# memory to never hit a real out-of-memory condition before the master hits\n# the configured maxmemory setting.\n#\n# replica-ignore-maxmemory yes\n\n############################# lazy freeing ####################################\n\n# redis has two primitives to delete keys. one is called del and is a blocking\n# deletion of the object. it means that the server stops processing new commands\n# in order to reclaim all the memory associated with an object in a synchronous\n# way. if the key deleted is associated with a small object, the time needed\n# in order to execute the del command is very small and comparable to most other\n# o(1) or o(log_n) commands in redis. however if the key is associated with an\n# aggregated value containing millions of elements, the server can block for\n# a long time (even seconds) in order to complete the operation.\n#\n# for the above reasons redis also offers non blocking deletion primitives\n# such as unlink (non blocking del) and the async option of flushall and\n# flushdb commands, in order to reclaim memory in background. those commands\n# are executed in constant time. another thread will incrementally free the\n# object in the background as fast as possible.\n#\n# del, unlink and async option of flushall and flushdb are user-controlled.\n# it\'s up to the design of the application to understand when it is a good\n# idea to use one or the other. however the redis server sometimes has to\n# delete keys or flush the whole database as a side effect of other operations.\n# specifically redis deletes objects independently of a user call in the\n# following scenarios:\n#\n# 1) on eviction, because of the maxmemory and maxmemory policy configurations,\n#    in order to make room for new data, without going over the specified\n#    memory limit.\n# 2) because of expire: when a key with an associated time to live (see the\n#    expire command) must be deleted from memory.\n# 3) because of a side effect of a command that stores data on a key that may\n#    already exist. for example the rename command may delete the old key\n#    content when it is replaced with another one. similarly sunionstore\n#    or sort with store option may delete existing keys. the set command\n#    itself removes any old content of the specified key in order to replace\n#    it with the specified string.\n# 4) during replication, when a replica performs a full resynchronization with\n#    its master, the content of the whole database is removed in order to\n#    load the rdb file just transferred.\n#\n# in all the above cases the default is to delete objects in a blocking way,\n# like if del was called. however you can configure each case specifically\n# in order to instead release memory in a non-blocking way like if unlink\n# was called, using the following configuration directives:\n\nlazyfree-lazy-eviction no\nlazyfree-lazy-expire no\nlazyfree-lazy-server-del no\nreplica-lazy-flush no\n\n############################## append only mode ###############################\n\n# by default redis asynchronously dumps the dataset on disk. this mode is\n# good enough in many applications, but an issue with the redis process or\n# a power outage may result into a few minutes of writes lost (depending on\n# the configured save points).\n#\n# the append only file is an alternative persistence mode that provides\n# much better durability. for instance using the default data fsync policy\n# (see later in the config file) redis can lose just one second of writes in a\n# dramatic event like a server power outage, or a single write if something\n# wrong with the redis process itself happens, but the operating system is\n# still running correctly.\n#\n# aof and rdb persistence can be enabled at the same time without problems.\n# if the aof is enabled on startup redis will load the aof, that is the file\n# with the better durability guarantees.\n#\n# please check http://redis.io/topics/persistence for more information.\n\nappendonly no\n\n# the name of the append only file (default: "appendonly.aof")\n\nappendfilename "appendonly.aof"\n\n# the fsync() call tells the operating system to actually write data on disk\n# instead of waiting for more data in the output buffer. some os will really flush\n# data on disk, some other os will just try to do it asap.\n#\n# redis supports three different modes:\n#\n# no: don\'t fsync, just let the os flush the data when it wants. faster.\n# always: fsync after every write to the append only log. slow, safest.\n# everysec: fsync only one time every second. compromise.\n#\n# the default is "everysec", as that\'s usually the right compromise between\n# speed and data safety. it\'s up to you to understand if you can relax this to\n# "no" that will let the operating system flush the output buffer when\n# it wants, for better performances (but if you can live with the idea of\n# some data loss consider the default persistence mode that\'s snapshotting),\n# or on the contrary, use "always" that\'s very slow but a bit safer than\n# everysec.\n#\n# more details please check the following article:\n# http://antirez.com/post/redis-persistence-demystified.html\n#\n# if unsure, use "everysec".\n\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n\n# when the aof fsync policy is set to always or everysec, and a background\n# saving process (a background save or aof log background rewriting) is\n# performing a lot of i/o against the disk, in some linux configurations\n# redis may block too long on the fsync() call. note that there is no fix for\n# this currently, as even performing fsync in a different thread will block\n# our synchronous write(2) call.\n#\n# in order to mitigate this problem it\'s possible to use the following option\n# that will prevent fsync() from being called in the main process while a\n# bgsave or bgrewriteaof is in progress.\n#\n# this means that while another child is saving, the durability of redis is\n# the same as "appendfsync none". in practical terms, this means that it is\n# possible to lose up to 30 seconds of log in the worst scenario (with the\n# default linux settings).\n#\n# if you have latency problems turn this to "yes". otherwise leave it as\n# "no" that is the safest pick from the point of view of durability.\n\nno-appendfsync-on-rewrite no\n\n# automatic rewrite of the append only file.\n# redis is able to automatically rewrite the log file implicitly calling\n# bgrewriteaof when the aof log size grows by the specified percentage.\n#\n# this is how it works: redis remembers the size of the aof file after the\n# latest rewrite (if no rewrite has happened since the restart, the size of\n# the aof at startup is used).\n#\n# this base size is compared to the current size. if the current size is\n# bigger than the specified percentage, the rewrite is triggered. also\n# you need to specify a minimal size for the aof file to be rewritten, this\n# is useful to avoid rewriting the aof file even if the percentage increase\n# is reached but it is still pretty small.\n#\n# specify a percentage of zero in order to disable the automatic aof\n# rewrite feature.\n\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n\n# an aof file may be found to be truncated at the end during the redis\n# startup process, when the aof data gets loaded back into memory.\n# this may happen when the system where redis is running\n# crashes, especially when an ext4 filesystem is mounted without the\n# data=ordered option (however this can\'t happen when redis itself\n# crashes or aborts but the operating system still works correctly).\n#\n# redis can either exit with an error when this happens, or load as much\n# data as possible (the default now) and start if the aof file is found\n# to be truncated at the end. the following option controls this behavior.\n#\n# if aof-load-truncated is set to yes, a truncated aof file is loaded and\n# the redis server starts emitting a log to inform the user of the event.\n# otherwise if the option is set to no, the server aborts with an error\n# and refuses to start. when the option is set to no, the user requires\n# to fix the aof file using the "redis-check-aof" utility before to restart\n# the server.\n#\n# note that if the aof file will be found to be corrupted in the middle\n# the server will still exit with an error. this option only applies when\n# redis will try to read more data from the aof file but not enough bytes\n# will be found.\naof-load-truncated yes\n\n# when rewriting the aof file, redis is able to use an rdb preamble in the\n# aof file for faster rewrites and recoveries. when this option is turned\n# on the rewritten aof file is composed of two different stanzas:\n#\n#   [rdb file][aof tail]\n#\n# when loading redis recognizes that the aof file starts with the "redis"\n# string and loads the prefixed rdb file, and continues loading the aof\n# tail.\naof-use-rdb-preamble yes\n\n################################ lua scripting  ###############################\n\n# max execution time of a lua script in milliseconds.\n#\n# if the maximum execution time is reached redis will log that a script is\n# still in execution after the maximum allowed time and will start to\n# reply to queries with an error.\n#\n# when a long running script exceeds the maximum execution time only the\n# script kill and shutdown nosave commands are available. the first can be\n# used to stop a script that did not yet called write commands. the second\n# is the only way to shut down the server in the case a write command was\n# already issued by the script but the user doesn\'t want to wait for the natural\n# termination of the script.\n#\n# set it to 0 or a negative value for unlimited execution without warnings.\nlua-time-limit 5000\n\n################################ redis cluster  ###############################\n\n# normal redis instances can\'t be part of a redis cluster; only nodes that are\n# started as cluster nodes can. in order to start a redis instance as a\n# cluster node enable the cluster support uncommenting the following:\n#\n# cluster-enabled yes\n\n# every cluster node has a cluster configuration file. this file is not\n# intended to be edited by hand. it is created and updated by redis nodes.\n# every redis cluster node requires a different cluster configuration file.\n# make sure that instances running in the same system do not have\n# overlapping cluster configuration file names.\n#\n# cluster-config-file nodes-6379.conf\n\n# cluster node timeout is the amount of milliseconds a node must be unreachable\n# for it to be considered in failure state.\n# most other internal time limits are multiple of the node timeout.\n#\n# cluster-node-timeout 15000\n\n# a replica of a failing master will avoid to start a failover if its data\n# looks too old.\n#\n# there is no simple way for a replica to actually have an exact measure of\n# its "data age", so the following two checks are performed:\n#\n# 1) if there are multiple replicas able to failover, they exchange messages\n#    in order to try to give an advantage to the replica with the best\n#    replication offset (more data from the master processed).\n#    replicas will try to get their rank by offset, and apply to the start\n#    of the failover a delay proportional to their rank.\n#\n# 2) every single replica computes the time of the last interaction with\n#    its master. this can be the last ping or command received (if the master\n#    is still in the "connected" state), or the time that elapsed since the\n#    disconnection with the master (if the replication link is currently down).\n#    if the last interaction is too old, the replica will not try to failover\n#    at all.\n#\n# the point "2" can be tuned by user. specifically a replica will not perform\n# the failover if, since the last interaction with the master, the time\n# elapsed is greater than:\n#\n#   (node-timeout * replica-validity-factor) + repl-ping-replica-period\n#\n# so for example if node-timeout is 30 seconds, and the replica-validity-factor\n# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the\n# replica will not try to failover if it was not able to talk with the master\n# for longer than 310 seconds.\n#\n# a large replica-validity-factor may allow replicas with too old data to failover\n# a master, while a too small value may prevent the cluster from being able to\n# elect a replica at all.\n#\n# for maximum availability, it is possible to set the replica-validity-factor\n# to a value of 0, which means, that replicas will always try to failover the\n# master regardless of the last time they interacted with the master.\n# (however they\'ll always try to apply a delay proportional to their\n# offset rank).\n#\n# zero is the only value able to guarantee that when all the partitions heal\n# the cluster will always be able to continue.\n#\n# cluster-replica-validity-factor 10\n\n# cluster replicas are able to migrate to orphaned masters, that are masters\n# that are left without working replicas. this improves the cluster ability\n# to resist to failures as otherwise an orphaned master can\'t be failed over\n# in case of failure if it has no working replicas.\n#\n# replicas migrate to orphaned masters only if there are still at least a\n# given number of other working replicas for their old master. this number\n# is the "migration barrier". a migration barrier of 1 means that a replica\n# will migrate only if there is at least 1 other working replica for its master\n# and so forth. it usually reflects the number of replicas you want for every\n# master in your cluster.\n#\n# default is 1 (replicas migrate only if their masters remain with at least\n# one replica). to disable migration just set it to a very large value.\n# a value of 0 can be set but is useful only for debugging and dangerous\n# in production.\n#\n# cluster-migration-barrier 1\n\n# by default redis cluster nodes stop accepting queries if they detect there\n# is at least an hash slot uncovered (no available node is serving it).\n# this way if the cluster is partially down (for example a range of hash slots\n# are no longer covered) all the cluster becomes, eventually, unavailable.\n# it automatically returns available as soon as all the slots are covered again.\n#\n# however sometimes you want the subset of the cluster which is working,\n# to continue to accept queries for the part of the key space that is still\n# covered. in order to do so, just set the cluster-require-full-coverage\n# option to no.\n#\n# cluster-require-full-coverage yes\n\n# this option, when set to yes, prevents replicas from trying to failover its\n# master during master failures. however the master can still perform a\n# manual failover, if forced to do so.\n#\n# this is useful in different scenarios, especially in the case of multiple\n# data center operations, where we want one side to never be promoted if not\n# in the case of a total dc failure.\n#\n# cluster-replica-no-failover no\n\n# in order to setup your cluster make sure to read the documentation\n# available at http://redis.io web site.\n\n########################## cluster docker/nat support  ########################\n\n# in certain deployments, redis cluster nodes address discovery fails, because\n# addresses are nat-ted or because ports are forwarded (the typical case is\n# docker and other containers).\n#\n# in order to make redis cluster working in such environments, a static\n# configuration where each node knows its public address is needed. the\n# following two options are used for this scope, and are:\n#\n# * cluster-announce-ip\n# * cluster-announce-port\n# * cluster-announce-bus-port\n#\n# each instruct the node about its address, client port, and cluster message\n# bus port. the information is then published in the header of the bus packets\n# so that other nodes will be able to correctly map the address of the node\n# publishing the information.\n#\n# if the above options are not used, the normal redis cluster auto-detection\n# will be used instead.\n#\n# note that when remapped, the bus port may not be at the fixed offset of\n# clients port + 10000, so you can specify any port and bus-port depending\n# on how they get remapped. if the bus-port is not set, a fixed offset of\n# 10000 will be used as usually.\n#\n# example:\n#\n# cluster-announce-ip 10.1.1.5\n# cluster-announce-port 6379\n# cluster-announce-bus-port 6380\n\n################################## slow log ###################################\n\n# the redis slow log is a system to log queries that exceeded a specified\n# execution time. the execution time does not include the i/o operations\n# like talking with the client, sending the reply and so forth,\n# but just the time needed to actually execute the command (this is the only\n# stage of command execution where the thread is blocked and can not serve\n# other requests in the meantime).\n#\n# you can configure the slow log with two parameters: one tells redis\n# what is the execution time, in microseconds, to exceed in order for the\n# command to get logged, and the other parameter is the length of the\n# slow log. when a new command is logged the oldest one is removed from the\n# queue of logged commands.\n\n# the following time is expressed in microseconds, so 1000000 is equivalent\n# to one second. note that a negative number disables the slow log, while\n# a value of zero forces the logging of every command.\nslowlog-log-slower-than 10000\n\n# there is no limit to this length. just be aware that it will consume memory.\n# you can reclaim memory used by the slow log with slowlog reset.\nslowlog-max-len 128\n\n################################ latency monitor ##############################\n\n# the redis latency monitoring subsystem samples different operations\n# at runtime in order to collect data related to possible sources of\n# latency of a redis instance.\n#\n# via the latency command this information is available to the user that can\n# print graphs and obtain reports.\n#\n# the system only logs operations that were performed in a time equal or\n# greater than the amount of milliseconds specified via the\n# latency-monitor-threshold configuration directive. when its value is set\n# to zero, the latency monitor is turned off.\n#\n# by default latency monitoring is disabled since it is mostly not needed\n# if you don\'t have latency issues, and collecting data has a performance\n# impact, that while very small, can be measured under big load. latency\n# monitoring can easily be enabled at runtime using the command\n# "config set latency-monitor-threshold <milliseconds>" if needed.\nlatency-monitor-threshold 0\n\n############################# event notification ##############################\n\n# redis can notify pub/sub clients about events happening in the key space.\n# this feature is documented at http://redis.io/topics/notifications\n#\n# for instance if keyspace events notification is enabled, and a client\n# performs a del operation on key "foo" stored in the database 0, two\n# messages will be published via pub/sub:\n#\n# publish __keyspace@0__:foo del\n# publish __keyevent@0__:del foo\n#\n# it is possible to select the events that redis will notify among a set\n# of classes. every class is identified by a single character:\n#\n#  k     keyspace events, published with __keyspace@<db>__ prefix.\n#  e     keyevent events, published with __keyevent@<db>__ prefix.\n#  g     generic commands (non-type specific) like del, expire, rename, ...\n#  $     string commands\n#  l     list commands\n#  s     set commands\n#  h     hash commands\n#  z     sorted set commands\n#  x     expired events (events generated every time a key expires)\n#  e     evicted events (events generated when a key is evicted for maxmemory)\n#  a     alias for g$lshzxe, so that the "ake" string means all the events.\n#\n#  the "notify-keyspace-events" takes as argument a string that is composed\n#  of zero or multiple characters. the empty string means that notifications\n#  are disabled.\n#\n#  example: to enable list and generic events, from the point of view of the\n#           event name, use:\n#\n#  notify-keyspace-events elg\n#\n#  example 2: to get the stream of the expired keys subscribing to channel\n#             name __keyevent@0__:expired use:\n#\n#  notify-keyspace-events ex\n#\n#  by default all notifications are disabled because most users don\'t need\n#  this feature and the feature has some overhead. note that if you don\'t\n#  specify at least one of k or e, no events will be delivered.\nnotify-keyspace-events ""\n\n############################### advanced config ###############################\n\n# hashes are encoded using a memory efficient data structure when they have a\n# small number of entries, and the biggest entry does not exceed a given\n# threshold. these thresholds can be configured using the following directives.\nhash-max-ziplist-entries 512\nhash-max-ziplist-value 64\n\n# lists are also encoded in a special way to save a lot of space.\n# the number of entries allowed per internal list node can be specified\n# as a fixed maximum size or a maximum number of elements.\n# for a fixed maximum size, use -5 through -1, meaning:\n# -5: max size: 64 kb  <-- not recommended for normal workloads\n# -4: max size: 32 kb  <-- not recommended\n# -3: max size: 16 kb  <-- probably not recommended\n# -2: max size: 8 kb   <-- good\n# -1: max size: 4 kb   <-- good\n# positive numbers mean store up to _exactly_ that number of elements\n# per list node.\n# the highest performing option is usually -2 (8 kb size) or -1 (4 kb size),\n# but if your use case is unique, adjust the settings as necessary.\nlist-max-ziplist-size -2\n\n# lists may also be compressed.\n# compress depth is the number of quicklist ziplist nodes from *each* side of\n# the list to *exclude* from compression.  the head and tail of the list\n# are always uncompressed for fast push/pop operations.  settings are:\n# 0: disable all list compression\n# 1: depth 1 means "don\'t start compressing until after 1 node into the list,\n#    going from either the head or tail"\n#    so: [head]->node->node->...->node->[tail]\n#    [head], [tail] will always be uncompressed; inner nodes will compress.\n# 2: [head]->[next]->node->node->...->node->[prev]->[tail]\n#    2 here means: don\'t compress head or head->next or tail->prev or tail,\n#    but compress all nodes between them.\n# 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail]\n# etc.\nlist-compress-depth 0\n\n# sets have a special encoding in just one case: when a set is composed\n# of just strings that happen to be integers in radix 10 in the range\n# of 64 bit signed integers.\n# the following configuration setting sets the limit in the size of the\n# set in order to use this special memory saving encoding.\nset-max-intset-entries 512\n\n# similarly to hashes and lists, sorted sets are also specially encoded in\n# order to save a lot of space. this encoding is only used when the length and\n# elements of a sorted set are below the following limits:\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\n\n# hyperloglog sparse representation bytes limit. the limit includes the\n# 16 bytes header. when an hyperloglog using the sparse representation crosses\n# this limit, it is converted into the dense representation.\n#\n# a value greater than 16000 is totally useless, since at that point the\n# dense representation is more memory efficient.\n#\n# the suggested value is ~ 3000 in order to have the benefits of\n# the space efficient encoding without slowing down too much pfadd,\n# which is o(n) with the sparse encoding. the value can be raised to\n# ~ 10000 when cpu is not a concern, but space is, and the data set is\n# composed of many hyperloglogs with cardinality in the 0 - 15000 range.\nhll-sparse-max-bytes 3000\n\n# streams macro node max size / items. the stream data structure is a radix\n# tree of big nodes that encode multiple items inside. using this configuration\n# it is possible to configure how big a single node can be in bytes, and the\n# maximum number of items it may contain before switching to a new node when\n# appending new stream entries. if any of the following settings are set to\n# zero, the limit is ignored, so for instance it is possible to set just a\n# max entires limit by setting max-bytes to 0 and max-entries to the desired\n# value.\nstream-node-max-bytes 4096\nstream-node-max-entries 100\n\n# active rehashing uses 1 millisecond every 100 milliseconds of cpu time in\n# order to help rehashing the main redis hash table (the one mapping top-level\n# keys to values). the hash table implementation redis uses (see dict.c)\n# performs a lazy rehashing: the more operation you run into a hash table\n# that is rehashing, the more rehashing "steps" are performed, so if the\n# server is idle the rehashing is never complete and some more memory is used\n# by the hash table.\n#\n# the default is to use this millisecond 10 times every second in order to\n# actively rehash the main dictionaries, freeing memory when possible.\n#\n# if unsure:\n# use "activerehashing no" if you have hard latency requirements and it is\n# not a good thing in your environment that redis can reply from time to time\n# to queries with 2 milliseconds delay.\n#\n# use "activerehashing yes" if you don\'t have such hard requirements but\n# want to free memory asap when possible.\nactiverehashing yes\n\n# the client output buffer limits can be used to force disconnection of clients\n# that are not reading data from the server fast enough for some reason (a\n# common reason is that a pub/sub client can\'t consume messages as fast as the\n# publisher can produce them).\n#\n# the limit can be set differently for the three different classes of clients:\n#\n# normal -> normal clients including monitor clients\n# replica  -> replica clients\n# pubsub -> clients subscribed to at least one pubsub channel or pattern\n#\n# the syntax of every client-output-buffer-limit directive is the following:\n#\n# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>\n#\n# a client is immediately disconnected once the hard limit is reached, or if\n# the soft limit is reached and remains reached for the specified number of\n# seconds (continuously).\n# so for instance if the hard limit is 32 megabytes and the soft limit is\n# 16 megabytes / 10 seconds, the client will get disconnected immediately\n# if the size of the output buffers reach 32 megabytes, but will also get\n# disconnected if the client reaches 16 megabytes and continuously overcomes\n# the limit for 10 seconds.\n#\n# by default normal clients are not limited because they don\'t receive data\n# without asking (in a push way), but just after a request, so only\n# asynchronous clients may create a scenario where data is requested faster\n# than it can read.\n#\n# instead there is a default limit for pubsub and replica clients, since\n# subscribers and replicas receive data in a push fashion.\n#\n# both the hard or the soft limit can be disabled by setting them to zero.\nclient-output-buffer-limit normal 0 0 0\nclient-output-buffer-limit replica 256mb 64mb 60\nclient-output-buffer-limit pubsub 32mb 8mb 60\n\n# client query buffers accumulate new commands. they are limited to a fixed\n# amount by default in order to avoid that a protocol desynchronization (for\n# instance due to a bug in the client) will lead to unbound memory usage in\n# the query buffer. however you can configure it here if you have very special\n# needs, such us huge multi/exec requests or alike.\n#\n# client-query-buffer-limit 1gb\n\n# in the redis protocol, bulk requests, that are, elements representing single\n# strings, are normally limited ot 512 mb. however you can change this limit\n# here.\n#\n# proto-max-bulk-len 512mb\n\n# redis calls an internal function to perform many background tasks, like\n# closing connections of clients in timeout, purging expired keys that are\n# never requested, and so forth.\n#\n# not all tasks are performed with the same frequency, but redis checks for\n# tasks to perform according to the specified "hz" value.\n#\n# by default "hz" is set to 10. raising the value will use more cpu when\n# redis is idle, but at the same time will make redis more responsive when\n# there are many keys expiring at the same time, and timeouts may be\n# handled with more precision.\n#\n# the range is between 1 and 500, however a value over 100 is usually not\n# a good idea. most users should use the default of 10 and raise this up to\n# 100 only in environments where very low latency is required.\nhz 10\n\n# normally it is useful to have an hz value which is proportional to the\n# number of clients connected. this is useful in order, for instance, to\n# avoid too many clients are processed for each background task invocation\n# in order to avoid latency spikes.\n#\n# since the default hz value by default is conservatively set to 10, redis\n# offers, and enables by default, the ability to use an adaptive hz value\n# which will temporary raise when there are many connected clients.\n#\n# when dynamic hz is enabled, the actual configured hz will be used as\n# as a baseline, but multiples of the configured hz value will be actually\n# used as needed once more clients are connected. in this way an idle\n# instance will use very little cpu time while a busy instance will be\n# more responsive.\ndynamic-hz yes\n\n# when a child rewrites the aof file, if the following option is enabled\n# the file will be fsync-ed every 32 mb of data generated. this is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\naof-rewrite-incremental-fsync yes\n\n# when redis saves rdb file, if the following option is enabled\n# the file will be fsync-ed every 32 mb of data generated. this is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\nrdb-save-incremental-fsync yes\n\n# redis lfu eviction (see maxmemory setting) can be tuned. however it is a good\n# idea to start with the default settings and only change them after investigating\n# how to improve the performances and how the keys lfu change over time, which\n# is possible to inspect via the object freq command.\n#\n# there are two tunable parameters in the redis lfu implementation: the\n# counter logarithm factor and the counter decay time. it is important to\n# understand what the two parameters mean before changing them.\n#\n# the lfu counter is just 8 bits per key, it\'s maximum value is 255, so redis\n# uses a probabilistic increment with logarithmic behavior. given the value\n# of the old counter, when a key is accessed, the counter is incremented in\n# this way:\n#\n# 1. a random number r between 0 and 1 is extracted.\n# 2. a probability p is calculated as 1/(old_value*lfu_log_factor+1).\n# 3. the counter is incremented only if r < p.\n#\n# the default lfu-log-factor is 10. this is a table of how the frequency\n# counter changes with a different number of accesses with different\n# logarithmic factors:\n#\n# +--------+------------+------------+------------+------------+------------+\n# | factor | 100 hits   | 1000 hits  | 100k hits  | 1m hits    | 10m hits   |\n# +--------+------------+------------+------------+------------+------------+\n# | 0      | 104        | 255        | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 1      | 18         | 49         | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 10     | 10         | 18         | 142        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 100    | 8          | 11         | 49         | 143        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n#\n# note: the above table was obtained by running the following commands:\n#\n#   redis-benchmark -n 1000000 incr foo\n#   redis-cli object freq foo\n#\n# note 2: the counter initial value is 5 in order to give new objects a chance\n# to accumulate hits.\n#\n# the counter decay time is the time, in minutes, that must elapse in order\n# for the key counter to be divided by two (or decremented if it has a value\n# less <= 10).\n#\n# the default value for the lfu-decay-time is 1. a special value of 0 means to\n# decay the counter every time it happens to be scanned.\n#\n# lfu-log-factor 10\n# lfu-decay-time 1\n\n########################### active defragmentation #######################\n#\n# warning this feature is experimental. however it was stress tested\n# even in production and manually tested by multiple engineers for some\n# time.\n#\n# what is active defragmentation?\n# -------------------------------\n#\n# active (online) defragmentation allows a redis server to compact the\n# spaces left between small allocations and deallocations of data in memory,\n# thus allowing to reclaim back memory.\n#\n# fragmentation is a natural process that happens with every allocator (but\n# less so with jemalloc, fortunately) and certain workloads. normally a server\n# restart is needed in order to lower the fragmentation, or at least to flush\n# away all the data and create it again. however thanks to this feature\n# implemented by oran agra for redis 4.0 this process can happen at runtime\n# in an "hot" way, while the server is running.\n#\n# basically when the fragmentation is over a certain level (see the\n# configuration options below) redis will start to create new copies of the\n# values in contiguous memory regions by exploiting certain specific jemalloc\n# features (in order to understand if an allocation is causing fragmentation\n# and to allocate it in a better place), and at the same time, will release the\n# old copies of the data. this process, repeated incrementally for all the keys\n# will cause the fragmentation to drop back to normal values.\n#\n# important things to understand:\n#\n# 1. this feature is disabled by default, and only works if you compiled redis\n#    to use the copy of jemalloc we ship with the source code of redis.\n#    this is the default with linux builds.\n#\n# 2. you never need to enable this feature if you don\'t have fragmentation\n#    issues.\n#\n# 3. once you experience fragmentation, you can enable this feature when\n#    needed with the command "config set activedefrag yes".\n#\n# the configuration parameters are able to fine tune the behavior of the\n# defragmentation process. if you are not sure about what they mean it is\n# a good idea to leave the defaults untouched.\n\n# enabled active defragmentation\n# activedefrag yes\n\n# minimum amount of fragmentation waste to start active defrag\n# active-defrag-ignore-bytes 100mb\n\n# minimum percentage of fragmentation to start active defrag\n# active-defrag-threshold-lower 10\n\n# maximum percentage of fragmentation at which we use maximum effort\n# active-defrag-threshold-upper 100\n\n# minimal effort for defrag in cpu percentage\n# active-defrag-cycle-min 5\n\n# maximal effort for defrag in cpu percentage\n# active-defrag-cycle-max 75\n\n# maximum number of set/hash/zset/list fields that will be processed from\n# the main dictionary scan\n# active-defrag-max-scan-fields 1000\n\n# it is possible to pin different threads and processes of redis to specific\n# cpus in your system, in order to maximize the performances of the server.\n# this is useful both in order to pin different redis threads in different\n# cpus, but also in order to make sure that multiple redis instances running\n# in the same host will be pinned to different cpus.\n#\n# normally you can do this using the "taskset" command, however it is also\n# possible to this via redis configuration directly, both in linux and freebsd.\n#\n# you can pin the server/io threads, bio threads, aof rewrite child process, and\n# the bgsave child process. the syntax to specify the cpu list is the same as\n# the taskset command:\n#\n# set redis server/io threads to cpu affinity 0,2,4,6:\n# server_cpulist 0-7:2\n#\n# set bio threads to cpu affinity 1,3:\n# bio_cpulist 1,3\n#\n# set aof rewrite child process to cpu affinity 8,9,10,11:\n# aof_rewrite_cpulist 8-11\n#\n# set bgsave child process to cpu affinity 1,10,11\n# bgsave_cpulist 1,10-11\n\n# in some cases redis will emit warnings and even refuse to start if it detects\n# that the system is in bad state, it is possible to suppress these warnings\n# by setting the following config which takes a space delimited list of warnings\n# to suppress\n#\n# ignore-warnings arm64-cow-bug\n\n\n\n\n# deploy.sh\n\nmkdir -p /etc/redis/\n\n\\cp ./redis.conf /etc/redis/redis.conf\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"CentOS7",frontmatter:{title:"CentOS7",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/2cbf35/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/02.CentOS7%E8%B0%83%E6%95%B4%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA.html",relativePath:"05.&/02.Linux/02.CentOS7.md",key:"v-a0880f96",path:"/pages/2cbf35/",headers:[{level:2,title:"",slug:"",normalizedTitle:"",charIndex:20},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:635},{level:2,title:"/home",slug:"-home",normalizedTitle:"/home",charIndex:1170},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:1376}],headersStr:"  /home ",content:"# CentOS7\n\n\n# \n\n100G300G\n\n\n\nfdisk /dev/sdam\n\n\n\nnp100Gw\n\n\n\nfdisk -l/dev/sda3\n\n\n\npartprobe,,\n\npvcreate /dev/sda3\n\n\n\nvgscanclvgextendclvgextend cl /dev/sda3\n\n\n\nlvextendlvextend -L +100G /dev/mapper/cl-root\n\ndf -hxfs_growfs\n\nxfs_growfs /dev/mapper/cl-root\n\n\nresize2fs f\n\n\n\ndf -h\n\n\n\n\n# \n\n200G\n\n\n\n/50G/home141GB\n\n\n\ndf -h/home/rootcl-root\n\n\n\nfdisk -l\n\n\n\n\n\n\n\n/home\n\n/homefuser -m -v -I -k /home/homeumount/home\n\n\n\n/homelv\n\nlvremove /dev/mapper/cl-home\n\n\nlvextend/root141G\n\nlvextend -L +141G /dev/mapper/cl-root\n\n\n\n\nxfs_growfs/root\n\nxfs_growfs /dev/mapper/cl-root\n\n\n\n\n\n# /home\n\n/home\n\nvgdisplayhome\n\n\n\nfdisk -l\n\n\n\nmkfs.xfsxfs\n\n\n\nmount/homedf -h\n\n\n\n\n# \n\n100G\n\n\n\nfdisk -l100Gsdb\n\n\n\nfdiskfdisk /dev/sdbnpw\n\n\n\npartprobepvcreatevgscanvgextendcllvextendxfs_growfsdf -h\n\n",normalizedContent:"# centos7\n\n\n# \n\n100g300g\n\n\n\nfdisk /dev/sdam\n\n\n\nnp100gw\n\n\n\nfdisk -l/dev/sda3\n\n\n\npartprobe,,\n\npvcreate /dev/sda3\n\n\n\nvgscanclvgextendclvgextend cl /dev/sda3\n\n\n\nlvextendlvextend -l +100g /dev/mapper/cl-root\n\ndf -hxfs_growfs\n\nxfs_growfs /dev/mapper/cl-root\n\n\nresize2fs f\n\n\n\ndf -h\n\n\n\n\n# \n\n200g\n\n\n\n/50g/home141gb\n\n\n\ndf -h/home/rootcl-root\n\n\n\nfdisk -l\n\n\n\n\n\n\n\n/home\n\n/homefuser -m -v -i -k /home/homeumount/home\n\n\n\n/homelv\n\nlvremove /dev/mapper/cl-home\n\n\nlvextend/root141g\n\nlvextend -l +141g /dev/mapper/cl-root\n\n\n\n\nxfs_growfs/root\n\nxfs_growfs /dev/mapper/cl-root\n\n\n\n\n\n# /home\n\n/home\n\nvgdisplayhome\n\n\n\nfdisk -l\n\n\n\nmkfs.xfsxfs\n\n\n\nmount/homedf -h\n\n\n\n\n# \n\n100g\n\n\n\nfdisk -l100gsdb\n\n\n\nfdiskfdisk /dev/sdbnpw\n\n\n\npartprobepvcreatevgscanvgextendcllvextendxfs_growfsdf -h\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"IO",frontmatter:{title:"IO",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/42cda4/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/03.IO%E5%8E%8B%E6%B5%8B.html",relativePath:"05.&/02.Linux/03.IO.md",key:"v-6592916c",path:"/pages/42cda4/",headers:[{level:2,title:"",slug:"",normalizedTitle:"",charIndex:20},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:142},{level:2,title:"fio",slug:"fio",normalizedTitle:"fio",charIndex:754},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:1818}],headersStr:"  fio ",content:"# LinuxI/O\n\n\n# \n\n * [] Linuxyumyum install -y fio\n\n * fiofio-2.1.10.tar./configuremakemake install\n\n\n# \n\nfilename=/dev/emcpowerb-filename=/dev/sda2-filename=/dev/sdb\ndirect=1 buffer\nrw=randwread I/O\nrw=randwrite I/O\nrw=randrw I/O\nrw=read I/O\nrw=write I/O\nrw=rw I/O\nbs=4k io4k\nbsrange=512-2048 \nsize=5g 5g4kio\nnumjobs=30 30\nruntime=1000 10005g4k\nioengine=psync iopynclibaioyum install libaio-devel\nrwmixwrite=30 30%\ngroup_reporting \n\n\nlockmem=1g 1g\nzero_buffers 0buffer\nnrfiles=8 \n\n\n\n# fio\n\n> /dev/emcpowerbfdisk -l/dev/sda/dev/sda1/dev/sda2/dev/sda3\n\n * 100%100% 4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=rand_100read_4k\n\n\n * 100%100% 4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=rand_100write_4k\n\n\n * 100%100% 4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=sqe_100read_4k\n\n\n * 100%100% 4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=sqe_100write_4k\n\n\n * 100%70%30% 4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randrw -rwmixread=70 -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=randrw_70read_4k\n\n\n\n# \n\nio=MIO\n\nbw=IO\niops=IOPS\nrunt=\nslat=\nclat=\nlat=\nbw=\ncpu=\nIO depths=io\nIO submit=IOIO\nIO complete=Like the above submit number, but for completions instead.\nIO issued=The number of read/write requests issued, and how many of them were short.\nIO latencies=IO\n\nio=sizeIO\naggrb=group\nminb=..\nmaxb=.\nmint=group.\nmaxt=group.\n\nios=groupIO.\nmerge=IO.\nticks=Number of ticks we kept the disk busy.\nio_queue=.\nutil=\n",normalizedContent:"# linuxi/o\n\n\n# \n\n * [] linuxyumyum install -y fio\n\n * fiofio-2.1.10.tar./configuremakemake install\n\n\n# \n\nfilename=/dev/emcpowerb-filename=/dev/sda2-filename=/dev/sdb\ndirect=1 buffer\nrw=randwread i/o\nrw=randwrite i/o\nrw=randrw i/o\nrw=read i/o\nrw=write i/o\nrw=rw i/o\nbs=4k io4k\nbsrange=512-2048 \nsize=5g 5g4kio\nnumjobs=30 30\nruntime=1000 10005g4k\nioengine=psync iopynclibaioyum install libaio-devel\nrwmixwrite=30 30%\ngroup_reporting \n\n\nlockmem=1g 1g\nzero_buffers 0buffer\nnrfiles=8 \n\n\n\n# fio\n\n> /dev/emcpowerbfdisk -l/dev/sda/dev/sda1/dev/sda2/dev/sda3\n\n * 100%100% 4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=rand_100read_4k\n\n\n * 100%100% 4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=rand_100write_4k\n\n\n * 100%100% 4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=sqe_100read_4k\n\n\n * 100%100% 4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=sqe_100write_4k\n\n\n * 100%70%30% 4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randrw -rwmixread=70 -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=randrw_70read_4k\n\n\n\n# \n\nio=mio\n\nbw=io\niops=iops\nrunt=\nslat=\nclat=\nlat=\nbw=\ncpu=\nio depths=io\nio submit=ioio\nio complete=like the above submit number, but for completions instead.\nio issued=the number of read/write requests issued, and how many of them were short.\nio latencies=io\n\nio=sizeio\naggrb=group\nminb=..\nmaxb=.\nmint=group.\nmaxt=group.\n\nios=groupio.\nmerge=io.\nticks=number of ticks we kept the disk busy.\nio_queue=.\nutil=\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"CentOS7mysql5.7",frontmatter:{title:"CentOS7mysql5.7",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/6db179/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/05.CentOS7%E5%AE%89%E8%A3%85mysql5.7.html",relativePath:"05.&/02.Linux/05.CentOS7mysql5.7.md",key:"v-778ac29c",path:"/pages/6db179/",headersStr:null,content:"# CentOS7mysql5.7\n\n> https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.33-1.el7.x86_64.rpm-bundle.tar\n\n * mariadb\n\nrpm -qa | grep mariadb;\nrpm -e mariadb-libs-5.5.60-1.el7_5.x86_64 --nodeps\n\n\n * \n\nmkdir /usr/local/mysql/\ntar -vxf mysql-5.7.33-1.el7.x86_64.rpm-bundle.tar -C /usr/local/mysql/\n\n\n * \n\ncd /usr/local/mysql/\nrpm -ivh mysql-community-common-5.7.33-1.el7.x86_64.rpm\nrpm -ivh mysql-community-libs-5.7.33-1.el7.x86_64.rpm\nrpm -ivh mysql-community-client-5.7.33-1.el7.x86_64.rpm\nyum -y install perl.x86_64\nrpm -ivh mysql-community-server-5.7.33-1.el7.x86_64.rpm\n\n\n * \n\nrm -rf /var/lib/mysql/*\n\n\n * \n\nservice mysqld start\nsystemctl enable mysqld\n\n\n * \n\ngrep 'temporary password' /var/log/mysqld.log;\n\n\n * \n\nmysql -u root -p aUuTak1Geg!k\n\n\n * \n\nset password for 'root'@'localhost' = password('Root123@');\n#\nset global validate_password_policy=LOW;\nset global validate_password_length=6;\nset password for 'root'@'localhost' = password('123456');\n#\ngrant all privileges on *.* to root@\"%\" identified by '123456' with grant option;\n#\ngrant all privileges on *.* to root@localhost identified by '123456' with grant option;\n#\nflush privileges;\n",normalizedContent:"# centos7mysql5.7\n\n> https://cdn.mysql.com//downloads/mysql-5.7/mysql-5.7.33-1.el7.x86_64.rpm-bundle.tar\n\n * mariadb\n\nrpm -qa | grep mariadb;\nrpm -e mariadb-libs-5.5.60-1.el7_5.x86_64 --nodeps\n\n\n * \n\nmkdir /usr/local/mysql/\ntar -vxf mysql-5.7.33-1.el7.x86_64.rpm-bundle.tar -c /usr/local/mysql/\n\n\n * \n\ncd /usr/local/mysql/\nrpm -ivh mysql-community-common-5.7.33-1.el7.x86_64.rpm\nrpm -ivh mysql-community-libs-5.7.33-1.el7.x86_64.rpm\nrpm -ivh mysql-community-client-5.7.33-1.el7.x86_64.rpm\nyum -y install perl.x86_64\nrpm -ivh mysql-community-server-5.7.33-1.el7.x86_64.rpm\n\n\n * \n\nrm -rf /var/lib/mysql/*\n\n\n * \n\nservice mysqld start\nsystemctl enable mysqld\n\n\n * \n\ngrep 'temporary password' /var/log/mysqld.log;\n\n\n * \n\nmysql -u root -p auutak1geg!k\n\n\n * \n\nset password for 'root'@'localhost' = password('root123@');\n#\nset global validate_password_policy=low;\nset global validate_password_length=6;\nset password for 'root'@'localhost' = password('123456');\n#\ngrant all privileges on *.* to root@\"%\" identified by '123456' with grant option;\n#\ngrant all privileges on *.* to root@localhost identified by '123456' with grant option;\n#\nflush privileges;\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"LinuxCockpit",frontmatter:{title:"LinuxCockpit",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/71dd10/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/04.Linux%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7Cockpit.html",relativePath:"05.&/02.Linux/04.LinuxCockpit.md",key:"v-6c528997",path:"/pages/71dd10/",headers:[{level:2,title:"",slug:"",normalizedTitle:"",charIndex:26},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:274},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:486}],headersStr:"  ",content:"# Cockpit\n\n\n# \n\n\n\nCockpit \n\n * \n *  Cockpit  Cockpit \n * \n * \n * docker\n * \n * web\n * \n\n\n# \n\n```\n# cockpit\nyum -y install cockpit\n# cockpit\nyum -y install cockpit-*\n# \n# rpm -ivh cockpit-195.6-1.el7.centos.x86_64.rpm\nsystemctl start cockpit && systemctl enable cockpit.socket\n```\n\n\n\n# \n\n# web ui\nhttps://127.0.0.1:9090\n",normalizedContent:"# cockpit\n\n\n# \n\n\n\ncockpit \n\n * \n *  cockpit  cockpit \n * \n * \n * docker\n * \n * web\n * \n\n\n# \n\n```\n# cockpit\nyum -y install cockpit\n# cockpit\nyum -y install cockpit-*\n# \n# rpm -ivh cockpit-195.6-1.el7.centos.x86_64.rpm\nsystemctl start cockpit && systemctl enable cockpit.socket\n```\n\n\n\n# \n\n# web ui\nhttps://127.0.0.1:9090\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Linux",frontmatter:{title:"Linux",date:"2024-08-23T06:39:16.000Z",permalink:"/pages/518cfa/"},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/06.%E5%9C%A8%E7%BA%BFLinux%E5%91%BD%E4%BB%A4%E6%9F%A5%E8%AF%A2.html",relativePath:"05.&/02.Linux/06.Linux.md",key:"v-b6061afe",path:"/pages/518cfa/",headersStr:null,content:"Linux ",normalizedContent:"linux ",charsets:{cjk:!0}},{title:"AspNetCore",frontmatter:{title:"AspNetCore",date:"2023-04-20T15:56:28.000Z",permalink:"/pages/86a4e2/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/01.AspNetCore%E9%9D%A2%E8%AF%95%E9%A2%98/01.AspNetCore%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./01.AspNetCore/01.AspNetCore.md",key:"v-4c28040b",path:"/pages/86a4e2/",headersStr:null,content:"# AspNetCore\n\n1dot net corestartup class?\n\nStartup classdot net coredot net coreclass \n\nprogram main\n\n2?\n\n\n\n3application builderuserun?\n\nstart up classconfigureUserun\n\n4dot net core map?\n\n\n\n5dot net core?\n\n\n\nMapRoute\n\n6dot net coresession?\n\nsession. config servicesessionconfigureusesession\n\n7?\n\nasp.net core\n\nAddTransientAddSingleton\n\nAddTransient\n\nAddSingleton\n\nAddTransientAddScoped\n\n\n\n\n\n:\n\nAddTransient\n\nAddScoped\n\nAddSingleton\n\n8dot net coredot net?\n\nwindows LinuxMAC\n\n\n\ndot net core\n\ndot net core\n\n9asp dot core\n\n\n\n\n\nkestreliis, apachenginx\n\n\n\nAPP settings json file\n\nstart up\n\n\n\nweb socketsignal IR\n\n",normalizedContent:"# aspnetcore\n\n1dot net corestartup class?\n\nstartup classdot net coredot net coreclass \n\nprogram main\n\n2?\n\n\n\n3application builderuserun?\n\nstart up classconfigureuserun\n\n4dot net core map?\n\n\n\n5dot net core?\n\n\n\nmaproute\n\n6dot net coresession?\n\nsession. config servicesessionconfigureusesession\n\n7?\n\nasp.net core\n\naddtransientaddsingleton\n\naddtransient\n\naddsingleton\n\naddtransientaddscoped\n\n\n\n\n\n:\n\naddtransient\n\naddscoped\n\naddsingleton\n\n8dot net coredot net?\n\nwindows linuxmac\n\n\n\ndot net core\n\ndot net core\n\n9asp dot core\n\n\n\n\n\nkestreliis, apachenginx\n\n\n\napp settings json file\n\nstart up\n\n\n\nweb socketsignal ir\n\n",charsets:{cjk:!0}},{title:"Net",frontmatter:{title:"Net",date:"2023-04-20T15:58:28.000Z",permalink:"/pages/868a19/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/01.AspNetCore%E9%9D%A2%E8%AF%95%E9%A2%98/02.Net%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./01.AspNetCore/02.Net.md",key:"v-7280ffb2",path:"/pages/868a19/",headersStr:null,content:"# Net\n\n1JIT\n\nJIT JIT \n\n2\n\nSystem.ValueType \n\n3\n\nC++\n\n4\n\n ISerializable  GetObjectData SerializationInfo StreamingContext\n\n5 IFormattable \n\nIFormattableIFormattable ToStringIFormattable.ToStringIFormatProvider\n\n6\n\nSystem.Delegate \n\n7\n\n\n\n8\n\nPE \n\n9\n\n\n\n10 TypeField  Method \n\nSystem.RuntimeTypeHandleSystem.RuntimeMethodHandle  System.RuntimeFieldHandle System.TypeSystem.Reflection.MethodInfo System.Reflection.FieldInfo \n\n11 SQL\n\nSQL  SQL \n\n12\n\nADO.NET \n\n13\n\n\n\n14\n\n, \n\n, , \n\n, , , , \n\n15\n\n, MemoryMappedFile.CreateFromFiles()\n\n16.NET\n\nSystem.GC.Collect()\n\n17.Net\n\n.Net\n\n\n\n18.Net\n\n.Net\n\n * \n * \n\n19\n\n188, 8",normalizedContent:"# net\n\n1jit\n\njit jit \n\n2\n\nsystem.valuetype \n\n3\n\nc++\n\n4\n\n iserializable  getobjectdata serializationinfo streamingcontext\n\n5 iformattable \n\niformattableiformattable tostringiformattable.tostringiformatprovider\n\n6\n\nsystem.delegate \n\n7\n\n\n\n8\n\npe \n\n9\n\n\n\n10 typefield  method \n\nsystem.runtimetypehandlesystem.runtimemethodhandle  system.runtimefieldhandle system.typesystem.reflection.methodinfo system.reflection.fieldinfo \n\n11 sql\n\nsql  sql \n\n12\n\nado.net \n\n13\n\n\n\n14\n\n, \n\n, , \n\n, , , , \n\n15\n\n, memorymappedfile.createfromfiles()\n\n16.net\n\nsystem.gc.collect()\n\n17.net\n\n.net\n\n\n\n18.net\n\n.net\n\n * \n * \n\n19\n\n188, 8",charsets:{cjk:!0}},{title:"Elasticsearch",frontmatter:{title:"Elasticsearch",date:"2023-04-20T15:57:15.000Z",permalink:"/pages/a567cd/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/02.Elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98/01.Elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./02.Elasticsearch/01.Elasticsearch.md",key:"v-01725947",path:"/pages/a567cd/",headersStr:null,content:"# Elasticsearch\n\n1ES\n\n  + \n\n  O(1) \n\n FSTFinite State Transducer\n\nLucene  4+  FSTFST  1 2O(len(str)) \n\n2ESmaster\n\n\n\n 1mastertrue 2min_master_nodes\n\nElasticsearch  ZenDiscovery  PingRPC Unicast ping   findMaster Master null\n\n elasticsearch.yml  discovery.zen.minimum_master_nodes; nodeId0master n/2+1master\n\n * \n   *  id  string \n   * master data  http \n\n3ES\n\n Elasticsearch  20  10  master 10  master \n\n master  3 discovery.zen.minimum_master_nodes  master  data \n\n4ES\n\n ES\n\n/  ID  routing\n\n Memory Buffer 1 F ilesystem Cache Momery Buffer  Filesystem Cache  refresh  Memery Buffer  Filesystem Cache ES  translog  translog  Filesystem cache  flush  flush  fsync  translog  translog flush  30  translog  512 M\n\n Lucene  Segement\n\n * Lucene \n *  Lucene \n *  CPU \n * Elasticsearch \n\n5ES\n\n Elasticsearch \n\n .del  .del  .del \n\nElasticsearch  .del \n\n6ES\n\n Query Then Fetch Query  from + size PSFilesystem CacheMemory Buffer   ID   Fetch  GET   \n\n7ES\n\n quorum/one/allquorum replicationsync()replicationasync_preferenceprimary\n\n8 ES\n\nElasticsearch cardinality distinctuniqueHLLHLL  bits   \n\n9GCES\n\n1GCdata nodesegment memory 2field cache, filter cache, indexing cache, bulk queueheapheapclear cache 3scan & scroll api 4cluster statstribe node 5heapheap\n\n10ES\n\n ES201+200GB   164GB32GB16GB8G 2 3SSD 4 5/232GBexport ES_HEAP_SIZE=32g-Xmx32g -Xms32g 6swap10010 10swapping 765535LuceneElasticsearchHTTP 8CMS 9gateway.recover_after_nodesgateway.expected_nodesgateway.recover_after_time  1 515 MB  2Elasticsearch20MB/sSSD100-200MB/s index.translog.flush_threshold_size 512MB1GB 3index.refresh_interval 30s 4index.number_of_replicas: 0  5scan & scroll apifrom/size  1++ 23force_mergeshrink",normalizedContent:"# elasticsearch\n\n1es\n\n  + \n\n  o(1) \n\n fstfinite state transducer\n\nlucene  4+  fstfst  1 2o(len(str)) \n\n2esmaster\n\n\n\n 1mastertrue 2min_master_nodes\n\nelasticsearch  zendiscovery  pingrpc unicast ping   findmaster master null\n\n elasticsearch.yml  discovery.zen.minimum_master_nodes; nodeid0master n/2+1master\n\n * \n   *  id  string \n   * master data  http \n\n3es\n\n elasticsearch  20  10  master 10  master \n\n master  3 discovery.zen.minimum_master_nodes  master  data \n\n4es\n\n es\n\n/  id  routing\n\n memory buffer 1 f ilesystem cache momery buffer  filesystem cache  refresh  memery buffer  filesystem cache es  translog  translog  filesystem cache  flush  flush  fsync  translog  translog flush  30  translog  512 m\n\n lucene  segement\n\n * lucene \n *  lucene \n *  cpu \n * elasticsearch \n\n5es\n\n elasticsearch \n\n .del  .del  .del \n\nelasticsearch  .del \n\n6es\n\n query then fetch query  from + size psfilesystem cachememory buffer   id   fetch  get   \n\n7es\n\n quorum/one/allquorum replicationsync()replicationasync_preferenceprimary\n\n8 es\n\nelasticsearch cardinality distinctuniquehllhll  bits   \n\n9gces\n\n1gcdata nodesegment memory 2field cache, filter cache, indexing cache, bulk queueheapheapclear cache 3scan & scroll api 4cluster statstribe node 5heapheap\n\n10es\n\n es201+200gb   164gb32gb16gb8g 2 3ssd 4 5/232gbexport es_heap_size=32g-xmx32g -xms32g 6swap10010 10swapping 765535luceneelasticsearchhttp 8cms 9gateway.recover_after_nodesgateway.expected_nodesgateway.recover_after_time  1 515 mb  2elasticsearch20mb/sssd100-200mb/s index.translog.flush_threshold_size 512mb1gb 3index.refresh_interval 30s 4index.number_of_replicas: 0  5scan & scroll apifrom/size  1++ 23force_mergeshrink",charsets:{cjk:!0}},{title:"MongoDB",frontmatter:{title:"MongoDB",date:"2023-04-20T15:57:37.000Z",permalink:"/pages/5201b9/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/03.MongoDB%E9%9D%A2%E8%AF%95%E9%A2%98/01.MongoDB%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./03.MongoDB/01.MongoDB.md",key:"v-3f973327",path:"/pages/5201b9/",headersStr:null,content:"# MongoDB\n\n1MySQLMongoDB?\n\nMySQLMongoDBMySQLMongoDB(data representation)schema(normalization)\n\nMySQLMongoDB\n\n2MongoDBNoSQL?\n\nMongoDBNoSQL\n\n * \n * \n * \n * \n * \n\n3MongoDB?\n\nMongoDB();\n\n4?\n\n(re-save())\n\n5fsync?\n\n(60)\n\n6masterprimary?\n\n(replica set)/(failover)primary\n\n7 (shard)?\n\nMongoDB (range)(collection)(chunk) 64Mb 64 Mb \n\n8(sharding)(replication)?\n\n(shard)(shard)\n\n9(moveChunk)?\n\n(consistent)(deterministic);;(shard)\n\n10Shard\n\nPartialMongoDB\n\n11MongoDBGridFSMongoDBGridFS\n\nGridFSMongoDBGridFSBSON\n\n12MongoDB\n\nMongoDBjavascriptdb.system.js\n\n13Chunk\n\nChunk",normalizedContent:"# mongodb\n\n1mysqlmongodb?\n\nmysqlmongodbmysqlmongodb(data representation)schema(normalization)\n\nmysqlmongodb\n\n2mongodbnosql?\n\nmongodbnosql\n\n * \n * \n * \n * \n * \n\n3mongodb?\n\nmongodb();\n\n4?\n\n(re-save())\n\n5fsync?\n\n(60)\n\n6masterprimary?\n\n(replica set)/(failover)primary\n\n7 (shard)?\n\nmongodb (range)(collection)(chunk) 64mb 64 mb \n\n8(sharding)(replication)?\n\n(shard)(shard)\n\n9(movechunk)?\n\n(consistent)(deterministic);;(shard)\n\n10shard\n\npartialmongodb\n\n11mongodbgridfsmongodbgridfs\n\ngridfsmongodbgridfsbson\n\n12mongodb\n\nmongodbjavascriptdb.system.js\n\n13chunk\n\nchunk",charsets:{cjk:!0}},{title:"MySql",frontmatter:{title:"MySql",date:"2023-04-20T15:57:56.000Z",permalink:"/pages/43b4dd/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/04.MySql%E9%9D%A2%E8%AF%95%E9%A2%98/01.MySql%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./04.MySql/01.MySql.md",key:"v-30230c72",path:"/pages/43b4dd/",headersStr:null,content:"# MySql\n\n1Mysql ,myisaminnodb\n\n\n\n1.MyISAM \n\n2.innodb\n\n2MySQL,\n\na. join b.  c. mysql d.  ememcachedapc f.  g. SQL SELECT * FROM TABEL  SELECT field_1, field_2, field_3 FROM TABLE.\n\n3,\n\na.  b.  c. ,  d.  e.  f. \n\n4\n\n \n\n \n\n \n\n \n\n5\n\nB+B+\n\nInnoDB\n\n6 \n\n %LIKE\n\n OR\n\n varcharint\n\n7MySQL\n\n SQL\n\n \n\n \n\n \n\n8SQL\n\nSQLsqlPOSTGETsql\n\nSQL magic_quotes_gpc  magic_quotes_runtime\n\nsqladdslashessql\n\nSql\n\nsqlupdateinsertdeleteselect * \n\n\n\nPhpregister_globalsoff,\n\n\n\n9\n\n\n\n\n\n\n\n\n\n10\n\n \n\n11\n\n\n\n\n\n12\n\n\n\ntext\n\n13\n\n\n\n\n\n\n\n, , \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",normalizedContent:"# mysql\n\n1mysql ,myisaminnodb\n\n\n\n1.myisam \n\n2.innodb\n\n2mysql,\n\na. join b.  c. mysql d.  ememcachedapc f.  g. sql select * from tabel  select field_1, field_2, field_3 from table.\n\n3,\n\na.  b.  c. ,  d.  e.  f. \n\n4\n\n \n\n \n\n \n\n \n\n5\n\nb+b+\n\ninnodb\n\n6 \n\n %like\n\n or\n\n varcharint\n\n7mysql\n\n sql\n\n \n\n \n\n \n\n8sql\n\nsqlsqlpostgetsql\n\nsql magic_quotes_gpc  magic_quotes_runtime\n\nsqladdslashessql\n\nsql\n\nsqlupdateinsertdeleteselect * \n\n\n\nphpregister_globalsoff,\n\n\n\n9\n\n\n\n\n\n\n\n\n\n10\n\n \n\n11\n\n\n\n\n\n12\n\n\n\ntext\n\n13\n\n\n\n\n\n\n\n, , \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",charsets:{cjk:!0}},{title:"RabbitMQ",frontmatter:{title:"RabbitMQ",date:"2023-04-20T15:59:14.000Z",permalink:"/pages/d74e41/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/06.RabbitMQ%E9%9D%A2%E8%AF%95%E9%A2%98/01.RabbitMQ%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./06.RabbitMQ/01.RabbitMQ.md",key:"v-26d51feb",path:"/pages/d74e41/",headersStr:null,content:"# RabbitMQ\n\n1RabbitMQ\n\n\n\n *  queue() queue()  consumer() queue ()\n *  queue () consumer() consumer() worker \n\n2\n\n\n\n * round-robin\n\n3\n\n\n\n *  TCP RabbitMQ  TCP  TCP \n\n4\n\n\n\n * \n * \n * \n   * \n   * \n\n5 RabbitMQ \n\n\n\n *  confirm  ID\n *  ID\n *  RabbitMQ  nacknotacknowledged\n * \n\n\n\n * RabbitMQ \n * RabbitMQ  Consumer RabbitMQ  Consumer \n\n\n\n * RabbitMQ \n *  RabbitMQ \n\n6RabbitMQ\n\n\n\n * \n * \n\n\n\n 1. RabbitMQtransactionconfirm\n    \n    transactionchannel.txSelect(),channel.txRollback(),channel.txCommit()\n    \n    confirmchannelconfirmID1\n    \n    rabbitMQACKID\n    \n    rabbitMQNack\n\n\n\n 1. \n    \n    \n    \n    confirmAck\n    \n    rabbitMQAck\n    \n    \n    \n    \n    \n    1. queuedurabletrue,\n    2. deliveryMode=2\n    \n    rabbitMQ\n\n\n\n 1. \n    \n    RabbitMQ\n    \n    \n    \n    \n\n7 message \n\n\n\n *  RAM message  10 \n * message  RabbitMQ  cluster  message  persistent  queue  durable  queue  owner node  queue  queue  message  blackholed  message  persistent  queue  durable  queue  owner node  queue  node  owner node  queue  queue  message  blackholed \n *  message  100,000 / RabbitMQ  message  delivery  SSD\n\n8RabbitMQ \n\n\n\n * RabbitMQ  RabbitMQ  MQ RabbitMQ \n\n\n\n 1.  Demo ?\n\n\n\n 1. \n    \n    \n    \n    *  RabbitMQ \n    *  queue RabbitMQ  queue  queue  queue  queue  queue \n\n\n\n 1. \n    *  RabbitMQ  queue queue  RabbitMQ  queue  queue  queue  queue RabbitMQ  queue \n    *  queue  consumer RabbitMQ  queue  queue \n\n8\n\n\n\n * \n *  consumer  cnosumer   topicpartition  10  10  queue   consumer  10  queue  10  consumer consumer  queue  queue  consumer  10  10   consumer  MQ RabbitMQRabbtiMQ  TTL queue  RabbitMQ  mq 12 mq  1  mq  1000  1000  mq \n * mq mq  mq \n\n9\n\n\n\n * \n * \n *  ID ID \n\n10rabbitmq \n\n\n\n1\n\n2\n\n3\n\n4\n\n11RabbitMQ\n\n\n\n * \n * \n\n 1.  \n 2.  \n 3.  A  BCD BD  C ",normalizedContent:"# rabbitmq\n\n1rabbitmq\n\n\n\n *  queue() queue()  consumer() queue ()\n *  queue () consumer() consumer() worker \n\n2\n\n\n\n * round-robin\n\n3\n\n\n\n *  tcp rabbitmq  tcp  tcp \n\n4\n\n\n\n * \n * \n * \n   * \n   * \n\n5 rabbitmq \n\n\n\n *  confirm  id\n *  id\n *  rabbitmq  nacknotacknowledged\n * \n\n\n\n * rabbitmq \n * rabbitmq  consumer rabbitmq  consumer \n\n\n\n * rabbitmq \n *  rabbitmq \n\n6rabbitmq\n\n\n\n * \n * \n\n\n\n 1. rabbitmqtransactionconfirm\n    \n    transactionchannel.txselect(),channel.txrollback(),channel.txcommit()\n    \n    confirmchannelconfirmid1\n    \n    rabbitmqackid\n    \n    rabbitmqnack\n\n\n\n 1. \n    \n    \n    \n    confirmack\n    \n    rabbitmqack\n    \n    \n    \n    \n    \n    1. queuedurabletrue,\n    2. deliverymode=2\n    \n    rabbitmq\n\n\n\n 1. \n    \n    rabbitmq\n    \n    \n    \n    \n\n7 message \n\n\n\n *  ram message  10 \n * message  rabbitmq  cluster  message  persistent  queue  durable  queue  owner node  queue  queue  message  blackholed  message  persistent  queue  durable  queue  owner node  queue  node  owner node  queue  queue  message  blackholed \n *  message  100,000 / rabbitmq  message  delivery  ssd\n\n8rabbitmq \n\n\n\n * rabbitmq  rabbitmq  mq rabbitmq \n\n\n\n 1.  demo ?\n\n\n\n 1. \n    \n    \n    \n    *  rabbitmq \n    *  queue rabbitmq  queue  queue  queue  queue  queue \n\n\n\n 1. \n    *  rabbitmq  queue queue  rabbitmq  queue  queue  queue  queue rabbitmq  queue \n    *  queue  consumer rabbitmq  queue  queue \n\n8\n\n\n\n * \n *  consumer  cnosumer   topicpartition  10  10  queue   consumer  10  queue  10  consumer consumer  queue  queue  consumer  10  10   consumer  mq rabbitmqrabbtimq  ttl queue  rabbitmq  mq 12 mq  1  mq  1000  1000  mq \n * mq mq  mq \n\n9\n\n\n\n * \n * \n *  id id \n\n10rabbitmq \n\n\n\n1\n\n2\n\n3\n\n4\n\n11rabbitmq\n\n\n\n * \n * \n\n 1.  \n 2.  \n 3.  a  bcd bd  c ",charsets:{cjk:!0}},{title:"Nginx",frontmatter:{title:"Nginx",date:"2023-04-20T15:58:51.000Z",permalink:"/pages/27153d/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/05.Nginx%E9%9D%A2%E8%AF%95%E9%A2%98/01.Nginx%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./05.Nginx/01.Nginx.md",key:"v-03d9b432",path:"/pages/27153d/",headersStr:null,content:"# Nginx\n\n1nginx\n\nrequestworkerrequestworkerworkerrequestweb serverrequestserver@skoowebserverio\n\n2NginxHTTP\n\nNginx\n\n3?\n\nwebweb\n\n4Nginx\n\nNginxHTTPSCGIWSGIFastCGI\n\n5NginxMasterWorker?\n\nMaster Worker\n\n6C10K?\n\nC10K(10,000)\n\n7stub_statussub_filter?\n\n1Stub_statusNginx// 2Sub_filter\n\n8\n\nNginx:NginxcpuCPUNginx\n\n9\n\n.jsp,.docsshtmljpgjsHTMLJavaScriptCSSnginxtomcat,Tomcat\n\n10ngx_http_upstream_module?\n\nURLmerge_slashes_off:merge_slashes [on/off]  : merge_slashes on : httpserver",normalizedContent:"# nginx\n\n1nginx\n\nrequestworkerrequestworkerworkerrequestweb serverrequestserver@skoowebserverio\n\n2nginxhttp\n\nnginx\n\n3?\n\nwebweb\n\n4nginx\n\nnginxhttpscgiwsgifastcgi\n\n5nginxmasterworker?\n\nmaster worker\n\n6c10k?\n\nc10k(10,000)\n\n7stub_statussub_filter?\n\n1stub_statusnginx// 2sub_filter\n\n8\n\nnginx:nginxcpucpunginx\n\n9\n\n.jsp,.docsshtmljpgjshtmljavascriptcssnginxtomcat,tomcat\n\n10ngx_http_upstream_module?\n\nurlmerge_slashes_off:merge_slashes [on/off]  : merge_slashes on : httpserver",charsets:{cjk:!0}},{title:"Redis",frontmatter:{title:"Redis",date:"2023-04-20T15:59:40.000Z",permalink:"/pages/97e5f1/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/07.Redis%E9%9D%A2%E8%AF%95%E9%A2%98/01.Redis%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./07.Redis/01.Redis.md",key:"v-d6f86d32",path:"/pages/97e5f1/",headersStr:null,content:"# Redis\n\n1Redis \n\n\n\n * noeviction:\n * allkeys-lru: LRU\n * volatile-lru: LRU,\n * allkeys-random: \n * volatile-random: \n * volatile-ttl: TTL,\n\n2Redis \n\n512M\n\n3 Redis \n\nRedis \n\n redis  I/O  redis \n\nredis  \n\n4Redis \n\n * codis\n *  twemproxy  hash \n * redis cluster3.0  hash hash \n *  redis  key  hash redis  hash \n\n5Redis \n\n ABC ,, B 5501-11000 \n\n6MySQL  2000w redis  20w  redis \n\nredis \n\n7Redis \n\nSession Cache\n\nFPC\n\n\n\n/\n\n/\n\n8 Redis \n\nRedis  hash,Redis  16384  key  CRC16  16384  hash \n\n9Redis \n\n, N-1 .\n\n10Redis \n\nRedis \n\n11Redis \n\n\n\n12Redis \n\n16384 \n\n13Redis \n\nRedis  0 \n\n14Redis \n\nhashes\n\n web  key,\n\n15\n\n\n\n key  valueDB key,\n\n\n\n> 1 key  insert \n> \n> 2 key  key  Bitmap  bitmap \n\n\n\n\n\n\n\n> 1 key \n> \n> 2A1 A2 A1  A2A1 A2 \n> \n> 3 key\n\n16Redis \n\nRedi  maxmemory , \n\n\n\n\n\n17 Redis \n\n setnx  expire \n\n setnx  expire  crash \n\nset  setnx  expire \n\n18 Redis \n\n list rpush lpop  lpop  sleep\n\n\n\n *  rabbitmq \n * \n *  pub/sub  1:N ",normalizedContent:"# redis\n\n1redis \n\n\n\n * noeviction:\n * allkeys-lru: lru\n * volatile-lru: lru,\n * allkeys-random: \n * volatile-random: \n * volatile-ttl: ttl,\n\n2redis \n\n512m\n\n3 redis \n\nredis \n\n redis  i/o  redis \n\nredis  \n\n4redis \n\n * codis\n *  twemproxy  hash \n * redis cluster3.0  hash hash \n *  redis  key  hash redis  hash \n\n5redis \n\n abc ,, b 5501-11000 \n\n6mysql  2000w redis  20w  redis \n\nredis \n\n7redis \n\nsession cache\n\nfpc\n\n\n\n/\n\n/\n\n8 redis \n\nredis  hash,redis  16384  key  crc16  16384  hash \n\n9redis \n\n, n-1 .\n\n10redis \n\nredis \n\n11redis \n\n\n\n12redis \n\n16384 \n\n13redis \n\nredis  0 \n\n14redis \n\nhashes\n\n web  key,\n\n15\n\n\n\n key  valuedb key,\n\n\n\n> 1 key  insert \n> \n> 2 key  key  bitmap  bitmap \n\n\n\n\n\n\n\n> 1 key \n> \n> 2a1 a2 a1  a2a1 a2 \n> \n> 3 key\n\n16redis \n\nredi  maxmemory , \n\n\n\n\n\n17 redis \n\n setnx  expire \n\n setnx  expire  crash \n\nset  setnx  expire \n\n18 redis \n\n list rpush lpop  lpop  sleep\n\n\n\n *  rabbitmq \n * \n *  pub/sub  1:n ",charsets:{cjk:!0}},{title:"",frontmatter:{title:"",date:"2023-04-20T16:00:18.000Z",permalink:"/pages/51830e/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E9%9D%A2%E8%AF%95%E9%A2%98/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./08./01..md",key:"v-6ea4444b",path:"/pages/51830e/",headersStr:null,content:"# \n\n1\n\n\n\n 1. \n 2. \n 3. \n 4. Windows\n 5. windows\n\n2 .Net5(decorator design pattern)  .Net5 IO  Buffered  BufferedStream  Stream   Buffer \n\n3**\n\nAdapter Pattern\n\n4**\n\n\n\n\n\n\n\n\n\n\n\n\n\n5**\n\n\n\n6\n\n \n\n7\n\nNet5 String Integer  Long \n\n8**\n\nChain of Responsibility Pattern\n\n9.Net5\n\nDecorator design pattern.Net5 IOSingleton patternRuntimeCalendarFactory patternHttpClientHttpClientFactoryObserver patternDiagnosticSource",normalizedContent:"# \n\n1\n\n\n\n 1. \n 2. \n 3. \n 4. windows\n 5. windows\n\n2 .net5(decorator design pattern)  .net5 io  buffered  bufferedstream  stream   buffer \n\n3**\n\nadapter pattern\n\n4**\n\n\n\n\n\n\n\n\n\n\n\n\n\n5**\n\n\n\n6\n\n \n\n7\n\nnet5 string integer  long \n\n8**\n\nchain of responsibility pattern\n\n9.net5\n\ndecorator design pattern.net5 iosingleton patternruntimecalendarfactory patternhttpclienthttpclientfactoryobserver patterndiagnosticsource",charsets:{cjk:!0}},{title:"",frontmatter:{title:"",date:"2023-04-20T16:00:37.000Z",permalink:"/pages/11e99f/",article:!1},regularPath:"/06.%E9%9D%A2%E8%AF%95/09.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%9D%A2%E8%AF%95%E9%A2%98/01.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06./09./01..md",key:"v-a493dd52",path:"/pages/11e99f/",headersStr:null,content:"# \n\n1\n\n \n\nMartin Fowler\n\n\n\n intellij idea mavenmodulespringboot \n\n/idea  module\n\n\n\n2?\n\n .Net5 RPC GRPC  REST json \n\nRabbitMqActiveMKafka \n\n3\n\n\n\nfallback\n\n4\n\n htmlcss \n\n\n\n5\n\n   AspnetCore.Net5.Net6  ApolloConsul  EurkaConsulZookeeper  RestRPCGRpc  PollyEnvoy  Nginx  WebAPI  KafkaRabbitMQActiveMQ  ApolloChef API Ocelot  ZabbixNagiosSkywalking  ZipkinBraveSkywalking  DockerOpenStackKubernetes  SpringCloud StreamRedisRabbitkafka CAP\n\n6\n\n    \n\n       \n\n7\n\n\n\n 1. \n 2. \n 3. \n 4. \n 5. \n\n8SOA **\n\n\n\n * \n * SOA\n * \n\n9**\n\n\n\n\n\n * \n * \n * \n * \n\n10DDD\n\n\n\n * \n * \n * \n * \n * \n * \n * \n * \n\n11\n\n\n\n\n\n12Idempotence\n\n\n\n\n\n13\n\n DDD  DDD \n\n14\n\n**\n\n15Canary Releasing\n\n",normalizedContent:"# \n\n1\n\n \n\nmartin fowler\n\n\n\n intellij idea mavenmodulespringboot \n\n/idea  module\n\n\n\n2?\n\n .net5 rpc grpc  rest json \n\nrabbitmqactivemkafka \n\n3\n\n\n\nfallback\n\n4\n\n htmlcss \n\n\n\n5\n\n   aspnetcore.net5.net6  apolloconsul  eurkaconsulzookeeper  restrpcgrpc  pollyenvoy  nginx  webapi  kafkarabbitmqactivemq  apollochef api ocelot  zabbixnagiosskywalking  zipkinbraveskywalking  dockeropenstackkubernetes  springcloud streamredisrabbitkafka cap\n\n6\n\n    \n\n       \n\n7\n\n\n\n 1. \n 2. \n 3. \n 4. \n 5. \n\n8soa **\n\n\n\n * \n * soa\n * \n\n9**\n\n\n\n\n\n * \n * \n * \n * \n\n10ddd\n\n\n\n * \n * \n * \n * \n * \n * \n * \n * \n\n11\n\n\n\n\n\n12idempotence\n\n\n\n\n\n13\n\n ddd  ddd \n\n14\n\n**\n\n15canary releasing\n\n",charsets:{cjk:!0}},{title:"",frontmatter:{archivesPage:!0,title:"",permalink:"/blog/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-d7570fb0",path:"/blog/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/04/26, 22:10:06",lastUpdatedTimestamp:1682518206e3},{title:"Home",frontmatter:{home:!0,heroImage:"/img/logo.png",heroText:"ZYHCODE",tagline:"",bannerBg:"none",features:[{title:"",details:"JavaGoPython; BI; "},{title:"",details:""},{title:"",details:"Notion, "}],postList:"none"},regularPath:"/",relativePath:"index.md",key:"v-49cf9efe",path:"/",headers:[{level:2,title:"",slug:"",normalizedTitle:"",charIndex:6},{level:2,title:" ",slug:"-",normalizedTitle:" ",charIndex:692}],headersStr:"  ",content:"\n\n\n\n# \n\nJava\n\n\n\nJava \n\nJava Platform, Standard Edition Documentation\n\nSpring \n\nSpring \n\n# - name: OpenHarmony\n#   desc: \n#   link: https://docs.openharmony.cn/pages/000000/\n#   bgColor: '#f1f1f1'\n#   textColor: '#2A3344'\n- name: Java\n  desc: \n  link: https://www.oracle.com/java/\n  bgColor: '#9415bf'\n  textColor: '#ffffff'\n- name: Java \n  desc: Java Platform, Standard Edition Documentation \n  link: https://docs.oracle.com/en/java/javase/index.html\n  bgColor: '#9415bf'\n  textColor: '#ffffff'\n- name: Spring \n  desc: Spring \n  link: https://spring.io/\n  bgColor: '#9415bf'\n  textColor: '#ffffff'\n\n\n\n#  \n\n Issue Issue",normalizedContent:"\n\n\n\n# \n\njava\n\n\n\njava \n\njava platform, standard edition documentation\n\nspring \n\nspring \n\n# - name: openharmony\n#   desc: \n#   link: https://docs.openharmony.cn/pages/000000/\n#   bgcolor: '#f1f1f1'\n#   textcolor: '#2a3344'\n- name: java\n  desc: \n  link: https://www.oracle.com/java/\n  bgcolor: '#9415bf'\n  textcolor: '#ffffff'\n- name: java \n  desc: java platform, standard edition documentation \n  link: https://docs.oracle.com/en/java/javase/index.html\n  bgcolor: '#9415bf'\n  textcolor: '#ffffff'\n- name: spring \n  desc: spring \n  link: https://spring.io/\n  bgcolor: '#9415bf'\n  textcolor: '#ffffff'\n\n\n\n#  \n\n issue issue",charsets:{cjk:!0},lastUpdated:"2023/09/21, 10:51:40",lastUpdatedTimestamp:16952647e5}],themeConfig:{nav:[{text:"",link:"/"},{text:"Java",link:"/pages/77d4e2/",items:[{text:"",link:"/pages/77d4e2/",items:[{text:"IO",link:"/pages/77d4e2/"},{text:"IO",link:"/pages/49acab/"},{text:"IO",link:"/pages/a3d832/"},{text:"NIO",link:"/pages/42be26/"}]},{text:"IO",link:"/pages/77d4e2/",items:[{text:"IO",link:"/pages/77d4e2/"},{text:"IO",link:"/pages/49acab/"},{text:"IO",link:"/pages/a3d832/"},{text:"NIO",link:"/pages/42be26/"}]},{text:"",link:"/pages/77d4e2/",items:[{text:"IO",link:"/pages/77d4e2/"},{text:"IO",link:"/pages/49acab/"},{text:"IO",link:"/pages/a3d832/"},{text:"NIO",link:"/pages/42be26/"}]},{text:"JVM",link:"/pages/77d4e2/",items:[{text:"IO",link:"/pages/77d4e2/"},{text:"IO",link:"/pages/49acab/"},{text:"IO",link:"/pages/a3d832/"},{text:"NIO",link:"/pages/42be26/"}]},{text:"",link:"/pages/cd056d/",items:[{text:"Java8",link:"/pages/cd056d/"},{text:"Java8",link:"/pages/b610cd/"},{text:"Java9",link:"/pages/1091ad/"},{text:"Java10",link:"/pages/e43406/"},{text:"Java11",link:"/pages/f37c60/"},{text:"Java12-13",link:"/pages/79a5f6/"},{text:"Java14-15",link:"/pages/683a03/"},{text:"Java16",link:"/pages/fa2c73/"},{text:"Java17",link:"/pages/245aa2/"},{text:"Java18",link:"/pages/ce76de/"},{text:"Java19",link:"/pages/42d550/"},{text:"Java20",link:"/pages/d5208b/"},{text:"Java21",link:"/pages/54087b/"}]},{text:"Springboot",link:"/pages/be9ac8/",items:[{text:"IO",link:"/pages/be9ac8/"},{text:"CookieSessionJWTToken",link:"/pages/c6bced/"}]}]},{text:"",link:"/pages/easytool/",items:[{text:"",link:"/pages/easytool/"},{text:"",link:"/pages/dc4434/"},{text:"",link:"/pages/24d03b/"}]},{text:"",link:"/pages/easytool/",items:[{text:"",link:"/pages/easytool/"},{text:"",link:"/pages/dc4434/"},{text:"",link:"/pages/24d03b/"}]},{text:"",link:"/pages/easytool/",items:[{text:"",link:"/pages/e50dff/",items:[{text:"",link:"/pages/f1d3fb/"}]},{text:"",link:"/pages/e50dff/",items:[{text:"",link:"/pages/e50dff/"},{text:"",link:"/pages/easytool/"}]},{text:"",link:"/pages/e50dff/",items:[{text:"",link:"/pages/e50dff/"},{text:"",link:"/pages/easytool/"}]},{text:"",link:"/pages/e50dff/",items:[{text:"",link:"/pages/e50dff/"},{text:"",link:"/pages/easytool/"}]}]},{text:"|",link:"/pages/e50dff/",items:[{text:"Docker",link:"/pages/e50dff/",items:[{text:"",link:"/pages/e50dff/"},{text:"",link:"/pages/f1d3fb/"},{text:"Apisix",link:"/pages/fbe42b/"},{text:"Apollo",link:"/pages/272684/"},{text:"Cassandra",link:"/pages/01958e/"},{text:"Cerebro",link:"/pages/7e58c5/"},{text:"ClickHouse",link:"/pages/3b4977/"},{text:"Consul",link:"/pages/3d230b/"},{text:"EasyMock",link:"/pages/ca4b88/"},{text:"Elasticsearch",link:"/pages/18fff0/"},{text:"Emqx",link:"/pages/d93c0b/"},{text:"FastDFS",link:"/pages/7bfded/"},{text:"Flink",link:"/pages/53b154/"},{text:"Gitlab",link:"/pages/83a3e2/"},{text:"Jenkins",link:"/pages/f90f99/"},{text:"Jrebel",link:"/pages/8e9d93/"},{text:"MariaDB",link:"/pages/ee069d/"},{text:"MySQL",link:"/pages/cff07b/"},{text:"Percona",link:"/pages/862a97/"},{text:"Phpmyadmin",link:"/pages/a560de/"},{text:"PostgreSQL",link:"/pages/230ca1/"},{text:"Redis",link:"/pages/be7f5d/"}]},{text:"Linux",link:"/pages/aa794b/",items:[{text:"Linux",link:"/pages/518cfa/"},{text:"Linux",link:"/pages/aa794b/"},{text:"CentOS7",link:"/pages/2cbf35/"},{text:"IO",link:"/pages/42cda4/"},{text:"Cockpit",link:"/pages/71dd10/"}]},{text:"Redis",link:"/pages/aa794b/",items:[{text:"Linux",link:"/pages/aa794b/"},{text:"CentOS7",link:"/pages/2cbf35/"},{text:"IO",link:"/pages/42cda4/"},{text:"Cockpit",link:"/pages/71dd10/"}]},{text:"Kafka",link:"/pages/aa794b/",items:[{text:"Linux",link:"/pages/aa794b/"},{text:"CentOS7",link:"/pages/2cbf35/"},{text:"IO",link:"/pages/42cda4/"},{text:"Cockpit",link:"/pages/71dd10/"}]}]},{text:"",link:"/pages/86a4e2/",items:[{text:"AspNetCore",link:"/pages/86a4e2/"},{text:"Elasticsearch",link:"/pages/a567cd/"},{text:"MongoDB",link:"/pages/5201b9/"},{text:"MySql",link:"/pages/43b4dd/"},{text:"Nginx",link:"/pages/27153d/"},{text:"RabbitMQ",link:"/pages/d74e41/"},{text:"Redis",link:"/pages/97e5f1/"},{text:"",link:"/pages/51830e/"},{text:"",link:"/pages/11e99f/"}]},{text:"",link:"https://debug.group/string-diff.html"}],sidebarDepth:2,logo:"/img/logo.png",repo:"Gresdy",searchMaxSuggestions:10,lastUpdated:"",sidebar:{"/01.Java/":[{title:"",collapsable:!1,children:[["01./01..md","","/pages/155b65/"]]},{title:"IO",collapsable:!1,children:[["02.IO/01.IO.md","Java IO ","/pages/77d4e2/"],["02.IO/02.IO.md","Java IO ","/pages/49acab/"],["02.IO/03.IO.md","Java IO ","/pages/a3d832/"],["02.IO/04.NIO.md","Java NIO ","/pages/42be26/"]]},{title:"",collapsable:!1,children:[]},{title:" JVM",collapsable:!1,children:[]},{title:"",collapsable:!1,children:[["05./01.java8-common-new-features.md","Java8 ","/pages/cd056d/"],["05./02.java8-tutorial-translate.md","java8-tutorial-translate","/pages/b610cd/"],["05./03.java9.md","Java 9 ","/pages/1091ad/"],["05./04.java10.md","Java 10 ","/pages/e43406/"],["05./05.java11.md","Java 11 ","/pages/f37c60/"],["05./06.java12-13.md","Java 12  & 13 ","/pages/79a5f6/"],["05./07.java14-15.md","Java 14  & 15 ","/pages/683a03/"],["05./08.java16.md","Java 16 ","/pages/fa2c73/"],["05./09.java17.md","Java 17 ","/pages/245aa2/"],["05./10.java18.md","Java 18 ","/pages/ce76de/"],["05./11.java19.md","Java 19 ","/pages/42d550/"],["05./12.java20.md","Java 20 ","/pages/d5208b/"],["05./13.java21.md","Java 21 ()","/pages/54087b/"]]},{title:"SpringBoot",collapsable:!1,children:[["06.SpringBoot/01.Spring.md","Spring","/pages/be9ac8/"],["06.SpringBoot/02..md","","/pages/5b4265/"],["06.SpringBoot/03.Cookie-Session-Token-JWT.md","Cookie-Session-Token-JWT","/pages/c6bced/"]]}],catalogue:{},"/03./":[["01.-coursera.md","-coursera","/pages/3c4623/"],["02..md","","/pages/cb2190/"]],"/04./":[{title:"",collapsable:!1,children:[["01./01..md","","/pages/f8be69/"]]},{title:"",collapsable:!1,children:[["02./01..md","","/pages/8448ab/"],["02./02.Program.md","Program","/pages/372b2d/"],["02./03.WebApplication.md","WebApplication","/pages/cb2fbc/"],["02./04.Host.md","Host","/pages/78c443/"],["02./05.WebHost.md","WebHost","/pages/840f86/"],["02./06..md","","/pages/0d115d/"],["02./07.Autofac.md","Autofac","/pages/e2d1de/"],["02./08.Middleware.md","Middleware","/pages/899977/"],["02./09.RateLimiter.md","RateLimiter","/pages/5991be/"],["02./10..md","","/pages/bacc57/"]]}],"/05.&/":[{title:"Docker",collapsable:!1,children:[["01.Docker/01..md","","/pages/e50dff/"],["01.Docker/02.-coursera.md","","/pages/f1d3fb/"],["01.Docker/03.Apisix.md","Apisix","/pages/fbe42b/"],["01.Docker/04.Apollo.md","Apollo","/pages/272684/"],["01.Docker/05.Cassandra.md","Cassandra","/pages/01958e/"],["01.Docker/06.Cerebro.md","Cerebro","/pages/7e58c5/"],["01.Docker/07.ClickHouse.md","ClickHouse","/pages/3b4977/"],["01.Docker/08.Consul.md","Consul","/pages/3d230b/"],["01.Docker/09.EasyMock.md","EasyMock","/pages/ca4b88/"],["01.Docker/10.Elasticsearch.md","Elasticsearch","/pages/18fff0/"],["01.Docker/11.Emqx.md","Emqx","/pages/d93c0b/"],["01.Docker/12.FastDFS.md","FastDFS","/pages/7bfded/"],["01.Docker/13.Flink.md","Flink","/pages/53b154/"],["01.Docker/14.Gitlab.md","Gitlab","/pages/83a3e2/"],["01.Docker/15.Jenkins.md","Jenkins","/pages/f90f99/"],["01.Docker/16.Jrebel.md","Jrebel","/pages/8e9d93/"],["01.Docker/17.MariaDB.md","MariaDB","/pages/ee069d/"],["01.Docker/18.MySQL.md","MySQL","/pages/cff07b/"],["01.Docker/19.Percona.md","Percona","/pages/862a97/"],["01.Docker/20.Phpmyadmin.md","Phpmyadmin","/pages/a560de/"],["01.Docker/21.PostgreSQL.md","PostgreSQL","/pages/230ca1/"],["01.Docker/22.Redis.md","Redis","/pages/be7f5d/"]]},{title:"Linux",collapsable:!1,children:[["02.Linux/01.Linux.md","Linux","/pages/aa794b/"],["02.Linux/02.CentOS7.md","CentOS7","/pages/2cbf35/"],["02.Linux/03.IO.md","IO","/pages/42cda4/"],["02.Linux/04.LinuxCockpit.md","LinuxCockpit","/pages/71dd10/"],["02.Linux/05.CentOS7mysql5.7.md","CentOS7mysql5.7","/pages/6db179/"],["02.Linux/06.Linux.md","Linux","/pages/518cfa/"]]}],"/06./":[{title:"AspNetCore",collapsable:!1,children:[["01.AspNetCore/01.AspNetCore.md","AspNetCore","/pages/86a4e2/"],["01.AspNetCore/02.Net.md","Net","/pages/868a19/"]]},{title:"Elasticsearch",collapsable:!1,children:[["02.Elasticsearch/01.Elasticsearch.md","Elasticsearch","/pages/a567cd/"]]},{title:"MongoDB",collapsable:!1,children:[["03.MongoDB/01.MongoDB.md","MongoDB","/pages/5201b9/"]]},{title:"MySql",collapsable:!1,children:[["04.MySql/01.MySql.md","MySql","/pages/43b4dd/"]]},{title:"Nginx",collapsable:!1,children:[["05.Nginx/01.Nginx.md","Nginx","/pages/27153d/"]]},{title:"RabbitMQ",collapsable:!1,children:[["06.RabbitMQ/01.RabbitMQ.md","RabbitMQ","/pages/d74e41/"]]},{title:"Redis",collapsable:!1,children:[["07.Redis/01.Redis.md","Redis","/pages/97e5f1/"]]},{title:"",collapsable:!1,children:[["08./01..md","","/pages/51830e/"]]},{title:"",collapsable:!1,children:[["09./01..md","","/pages/11e99f/"]]}]},updateBar:{showToArticle:!1},pageStyle:"line",category:!1,tag:!1,author:{name:"",href:"https://github.com/Gresdy"},social:{icons:[{iconClass:"icon-youjian",title:"",link:"mailto:1248824030@qq.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/Gresdy"},{iconClass:"icon-gitee",title:"Gitee",link:"https://github.com/Gresdy"}]},footer:{createYear:2023,copyrightInfo:" | MIT License"},htmlModules:{}}};var Tt=t(94),Et=t(95),St=t(12);var It={computed:{$filterPosts(){return this.$site.pages.filter(e=>{const{frontmatter:{pageComponent:n,article:t,home:a}}=e;return!(n||!1===t||!0===a)})},$sortPosts(){return(e=this.$filterPosts).sort((e,n)=>{const t=e.frontmatter.sticky,a=n.frontmatter.sticky;return t&&a?t==a?Object(St.a)(e,n):t-a:t&&!a?-1:!t&&a?1:Object(St.a)(e,n)}),e;var e},$sortPostsByDate(){return(e=this.$filterPosts).sort((e,n)=>Object(St.a)(e,n)),e;var e},$groupPosts(){return function(e){const n={},t={};for(let a=0,r=e.length;a<r;a++){const{frontmatter:{categories:r,tags:i}}=e[a];"array"===Object(St.n)(r)&&r.forEach(t=>{t&&(n[t]||(n[t]=[]),n[t].push(e[a]))}),"array"===Object(St.n)(i)&&i.forEach(n=>{n&&(t[n]||(t[n]=[]),t[n].push(e[a]))})}return{categories:n,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(e){const n=[],t=[];for(let t in e.categories)n.push({key:t,length:e.categories[t].length});for(let n in e.tags)t.push({key:n,length:e.tags[n].length});return{categories:n,tags:t}}(this.$groupPosts)}}};a.default.component(Tt.default),a.default.component(Et.default);function At(e){return e.toString().padStart(2,"0")}t(244);a.default.component("Notice",()=>Promise.all([t.e(0),t.e(2),t.e(5)]).then(t.bind(null,471))),a.default.component("Badge",()=>Promise.all([t.e(0),t.e(6)]).then(t.bind(null,546))),a.default.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,94))),a.default.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,95)));t(245);var Ct=[({Vue:e,options:n,router:t,siteData:a,isServer:r})=>{r||t.afterEach(()=>{var e;e=function(){setTimeout((function(){void 0===window._AdBlockInit&&function(){const e=document.getElementsByClassName("wwads-cn"),n=document.querySelector(".wwads-content");e[0]&&!n&&(e[0].innerHTML="<style>.wwads-horizontal,.wwads-vertical{background-color:#f4f8fa;padding:5px;min-height:120px;margin-top:20px;box-sizing:border-box;border-radius:3px;font-family:sans-serif;display:flex;min-width:150px;position:relative;overflow:hidden;}.wwads-horizontal{flex-wrap:wrap;justify-content:center}.wwads-vertical{flex-direction:column;align-items:center;padding-bottom:32px}.wwads-horizontal a,.wwads-vertical a{text-decoration:none}.wwads-horizontal .wwads-img,.wwads-vertical .wwads-img{margin:5px}.wwads-horizontal .wwads-content,.wwads-vertical .wwads-content{margin:5px}.wwads-horizontal .wwads-content{flex:130px}.wwads-vertical .wwads-content{margin-top:10px}.wwads-horizontal .wwads-text,.wwads-content .wwads-text{font-size:14px;line-height:1.4;color:#0e1011;-webkit-font-smoothing:antialiased}.wwads-horizontal .wwads-poweredby,.wwads-vertical .wwads-poweredby{display:block;font-size:11px;color:#a6b7bf;margin-top:1em}.wwads-vertical .wwads-poweredby{position:absolute;left:10px;bottom:10px}.wwads-horizontal .wwads-poweredby span,.wwads-vertical .wwads-poweredby span{transition:all 0.2s ease-in-out;margin-left:-1em}.wwads-horizontal .wwads-poweredby span:first-child,.wwads-vertical .wwads-poweredby span:first-child{opacity:0}.wwads-horizontal:hover .wwads-poweredby span,.wwads-vertical:hover .wwads-poweredby span{opacity:1;margin-left:0}.wwads-horizontal .wwads-hide,.wwads-vertical .wwads-hide{position:absolute;right:-23px;bottom:-23px;width:46px;height:46px;border-radius:23px;transition:all 0.3s ease-in-out;cursor:pointer;}.wwads-horizontal .wwads-hide:hover,.wwads-vertical .wwads-hide:hover{background:rgb(0 0 0 /0.05)}.wwads-horizontal .wwads-hide svg,.wwads-vertical .wwads-hide svg{position:absolute;left:10px;top:10px;fill:#a6b7bf}.wwads-horizontal .wwads-hide:hover svg,.wwads-vertical .wwads-hide:hover svg{fill:#3E4546}</style><a href='https://wwads.cn/page/whitelist-wwads' class='wwads-img' target='_blank' rel='nofollow'><img src='https://fastly.jsdelivr.net/gh/xugaoyi/image_store@master/blog/wwads.2a3pidhlh4ys.webp' width='130'></a><div class='wwads-content'><a href='https://wwads.cn/page/whitelist-wwads' class='wwads-text' target='_blank' rel='nofollow'><span style='color: #11a8cd'>?</span></a><a href='https://wwads.cn/page/end-user-privacy' class='wwads-poweredby' title='  ' target='_blank'><span></span></a></div><a class='wwads-hide' onclick='parentNode.remove()' title=''><svg xmlns='http://www.w3.org/2000/svg' width='6' height='7'><path d='M.879.672L3 2.793 5.121.672a.5.5 0 11.707.707L3.708 3.5l2.12 2.121a.5.5 0 11-.707.707l-2.12-2.12-2.122 2.12a.5.5 0 11-.707-.707l2.121-2.12L.172 1.378A.5.5 0 01.879.672z'></path></svg></a>")}()}),3e3)},"complete"===document.readyState||"interactive"===document.readyState?setTimeout(e,1):document.addEventListener("DOMContentLoaded",e),setTimeout(()=>{const e=document.querySelector(".page-wwads");if(!e)return;const n=e.querySelector(".wwads-hide");n&&(n.onclick=()=>{e.style.display="none"}),"none"===e.style.display&&(e.style.display="flex")},900)})},({Vue:e,options:n,router:t,siteData:a})=>{a.pages.map(e=>{const{frontmatter:{date:n,author:t}}=e;"string"==typeof n&&"Z"===n.charAt(n.length-1)&&(e.frontmatter.date=function(e){e instanceof Date||(e=new Date(e));return`${e.getUTCFullYear()}-${At(e.getUTCMonth()+1)}-${At(e.getUTCDate())} ${At(e.getUTCHours())}:${At(e.getUTCMinutes())}:${At(e.getUTCSeconds())}`}(n)),t?e.author=t:a.themeConfig.author&&(e.author=a.themeConfig.author)}),e.mixin(It)},{},({Vue:e})=>{e.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({router:e})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?d9b44aca91c27e070324d5276deedc0a";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)}(),e.afterEach((function(e){_hmt.push(["_trackPageview",e.fullPath])})))}],jt=[];class Ot extends class{constructor(){this.store=new a.default({data:{state:{}}})}$get(e){return this.store.state[e]}$set(e,n){a.default.set(this.store.state,e,n)}$emit(...e){this.store.$emit(...e)}$on(...e){this.store.$on(...e)}}{}Object.assign(Ot.prototype,{getPageAsyncComponent:cn,getLayoutAsyncComponent:dn,getAsyncComponent:un,getVueComponent:pn});var Lt={install(e){const n=new Ot;e.$vuepress=n,e.prototype.$vuepress=n}};function Nt(e,n){const t=n.toLowerCase();return e.options.routes.some(e=>e.path.toLowerCase()===t)}var Dt={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(e){const n=this.pageKey||this.$parent.$page.key;return hn("pageKey",n),a.default.component(n)||a.default.component(n,cn(n)),a.default.component(n)?e(n):e("")}},Pt={functional:!0,props:{slotKey:String,required:!0},render:(e,{props:n,slots:t})=>e("div",{class:["content__"+n.slotKey]},t()[n.slotKey])},Mt={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Rt=(t(246),t(247),Object(wt.a)(Mt,(function(){var e=this._self._c;return e("span",[e("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[e("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),e("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),e("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),zt={functional:!0,render(e,{parent:n,children:t}){if(n._isMounted)return t;n.$once("hook:mounted",()=>{n.$forceUpdate()})}};a.default.config.productionTip=!1,a.default.use(Ge),a.default.use(Lt),a.default.mixin(function(e,n,t=a.default){!function(e){e.locales&&Object.keys(e.locales).forEach(n=>{e.locales[n].path=n});Object.freeze(e)}(n),t.$vuepress.$set("siteData",n);const r=new(e(t.$vuepress.$get("siteData"))),i=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),o={};return Object.keys(i).reduce((e,n)=>(n.startsWith("$")&&(e[n]=i[n].get),e),o),{computed:o}}(e=>class{setPage(e){this.__page=e}get $site(){return e}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:e={}}=this.$site;let n,t;for(const a in e)"/"===a?t=e[a]:0===this.$page.path.indexOf(a)&&(n=e[a]);return n||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:e}=this.$page.frontmatter;return"string"==typeof e&&e}get $title(){const e=this.$page,{metaTitle:n}=this.$page.frontmatter;if("string"==typeof n)return n;const t=this.$siteTitle,a=e.frontmatter.home?null:e.frontmatter.title||e.title;return t?a?a+" | "+t:t:a||"VuePress"}get $description(){const e=function(e){if(e){const n=e.filter(e=>"description"===e.name)[0];if(n)return n.content}}(this.$page.frontmatter.meta);return e||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(e,n){for(let t=0;t<e.length;t++){const a=e[t];if(a.path.toLowerCase()===n.toLowerCase())return a}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},kt)),a.default.component("Content",Dt),a.default.component("ContentSlotsDistributor",Pt),a.default.component("OutboundLink",Rt),a.default.component("ClientOnly",zt),a.default.component("Layout",dn("Layout")),a.default.component("NotFound",dn("NotFound")),a.default.prototype.$withBase=function(e){const n=this.$site.base;return"/"===e.charAt(0)?n+e.slice(1):e},window.__VUEPRESS__={version:"1.9.2",hash:"a5ee89d"},async function(e){const n="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:kt.routerBase||kt.base,t=new Ge({base:n,mode:"history",fallback:!1,routes:xt,scrollBehavior:(e,n,t)=>t||(e.hash?!a.default.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(e.hash)}:{x:0,y:0})});!function(e){e.beforeEach((n,t,a)=>{if(Nt(e,n.path))a();else if(/(\/|\.html)$/.test(n.path))if(/\/$/.test(n.path)){const t=n.path.replace(/\/$/,"")+".html";Nt(e,t)?a(t):a()}else a();else{const t=n.path+"/",r=n.path+".html";Nt(e,r)?a(r):Nt(e,t)?a(t):a()}})}(t);const r={};try{await Promise.all(Ct.filter(e=>"function"==typeof e).map(n=>n({Vue:a.default,options:r,router:t,siteData:kt,isServer:e})))}catch(e){console.error(e)}return{app:new a.default(Object.assign(r,{router:t,render:e=>e("div",{attrs:{id:"app"}},[e("RouterView",{ref:"layout"}),e("div",{class:"global-ui"},jt.map(n=>e(n)))])})),router:t}}(!1).then(({app:e,router:n})=>{n.onReady(()=>{e.$mount("#app")})})}]);