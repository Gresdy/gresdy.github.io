(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(e){function n(n){for(var a,o,s=n[0],l=n[1],c=n[2],u=0,p=[];u<s.length;u++)o=s[u],Object.prototype.hasOwnProperty.call(r,o)&&r[o]&&p.push(r[o][0]),r[o]=0;for(a in l)Object.prototype.hasOwnProperty.call(l,a)&&(e[a]=l[a]);for(d&&d(n);p.length;)p.shift()();return i.push.apply(i,c||[]),t()}function t(){for(var e,n=0;n<i.length;n++){for(var t=i[n],a=!0,s=1;s<t.length;s++){var l=t[s];0!==r[l]&&(a=!1)}a&&(i.splice(n--,1),e=o(o.s=t[0]))}return e}var a={},r={1:0},i=[];function o(n){if(a[n])return a[n].exports;var t=a[n]={i:n,l:!1,exports:{}};return e[n].call(t.exports,t,t.exports,o),t.l=!0,t.exports}o.e=function(e){var n=[],t=r[e];if(0!==t)if(t)n.push(t[2]);else{var a=new Promise((function(n,a){t=r[e]=[n,a]}));n.push(t[2]=a);var i,s=document.createElement("script");s.charset="utf-8",s.timeout=120,o.nc&&s.setAttribute("nonce",o.nc),s.src=function(e){return o.p+"assets/js/"+({}[e]||e)+"."+{2:"294e43d0",3:"90e7f4f9",4:"35d0c84a",5:"197e9545",6:"e1ca599c",7:"ce73f7d6",8:"fc4ed1f0",9:"1c569fee",10:"c798c6b8",11:"ee2e4742",12:"02c1d8aa",13:"3deb099f",14:"8b0e3cca",15:"729baa93",16:"ea2228b8",17:"54f8d56b",18:"8295b59a",19:"80ec033a",20:"3a3150a6",21:"2cfb08e7",22:"961ef9c6",23:"af39583b",24:"b2c08c82",25:"794e8dcc",26:"cefdf367",27:"8e7d7bcb",28:"df6604a9",29:"8fc4ee82",30:"6c71ff99",31:"75827cd2",32:"305df95d",33:"d5abdfb7",34:"45ebe537",35:"d96f3878",36:"20c54cb5",37:"70b89b2b",38:"b76f1251",39:"deafc6a5",40:"9169e8bf",41:"6bd6819e",42:"1324b559",43:"37faf093",44:"116021b1",45:"54353d71",46:"9cd75d5d",47:"9f26124c",48:"b7baffbf",49:"21953821",50:"6ccefcc2",51:"5a40c934",52:"029bc53b",53:"665cf685",54:"6a915811",55:"0308b2f7",56:"99755c06",57:"732bd2f2",58:"630b7f9c",59:"7fce3d78",60:"e1e67346",61:"2e2b79f5",62:"495c41cf",63:"2bc8f152",64:"8ec76d2e",65:"3252427b",66:"d051d693",67:"d639c4e2",68:"a3f26102",69:"eafaacec",70:"9985d66c",71:"bff353d0",72:"d34bb386",73:"878497a0",74:"cde9ead1",75:"7b0e2ca8",76:"fda754f1",77:"265ae7f7",78:"67911f34",79:"cefcd8ef",80:"670edf24"}[e]+".js"}(e);var l=new Error;i=function(n){s.onerror=s.onload=null,clearTimeout(c);var t=r[e];if(0!==t){if(t){var a=n&&("load"===n.type?"missing":n.type),i=n&&n.target&&n.target.src;l.message="Loading chunk "+e+" failed.\n("+a+": "+i+")",l.name="ChunkLoadError",l.type=a,l.request=i,t[1](l)}r[e]=void 0}};var c=setTimeout((function(){i({type:"timeout",target:s})}),12e4);s.onerror=s.onload=i,document.head.appendChild(s)}return Promise.all(n)},o.m=e,o.c=a,o.d=function(e,n,t){o.o(e,n)||Object.defineProperty(e,n,{enumerable:!0,get:t})},o.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},o.t=function(e,n){if(1&n&&(e=o(e)),8&n)return e;if(4&n&&"object"==typeof e&&e&&e.__esModule)return e;var t=Object.create(null);if(o.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:e}),2&n&&"string"!=typeof e)for(var a in e)o.d(t,a,function(n){return e[n]}.bind(null,a));return t},o.n=function(e){var n=e&&e.__esModule?function(){return e.default}:function(){return e};return o.d(n,"a",n),n},o.o=function(e,n){return Object.prototype.hasOwnProperty.call(e,n)},o.p="/",o.oe=function(e){throw console.error(e),e};var s=window.webpackJsonp=window.webpackJsonp||[],l=s.push.bind(s);s.push=n,s=s.slice();for(var c=0;c<s.length;c++)n(s[c]);var d=l;i.push([105,0]),t()}([function(e,n,t){"use strict";t.r(n),t.d(n,"EffectScope",(function(){return yn})),t.d(n,"computed",(function(){return ln})),t.d(n,"customRef",(function(){return en})),t.d(n,"default",(function(){return Qa})),t.d(n,"defineAsyncComponent",(function(){return jt})),t.d(n,"defineComponent",(function(){return Gt})),t.d(n,"del",(function(){return Pe})),t.d(n,"effectScope",(function(){return wn})),t.d(n,"getCurrentInstance",(function(){return pe})),t.d(n,"getCurrentScope",(function(){return _n})),t.d(n,"h",(function(){return mt})),t.d(n,"inject",(function(){return En})),t.d(n,"isProxy",(function(){return Ue})),t.d(n,"isReactive",(function(){return Je})),t.d(n,"isReadonly",(function(){return Be})),t.d(n,"isRef",(function(){return Ge})),t.d(n,"isShallow",(function(){return Fe})),t.d(n,"markRaw",(function(){return $e})),t.d(n,"mergeDefaults",(function(){return lt})),t.d(n,"nextTick",(function(){return It})),t.d(n,"onActivated",(function(){return zt})),t.d(n,"onBeforeMount",(function(){return Lt})),t.d(n,"onBeforeUnmount",(function(){return Mt})),t.d(n,"onBeforeUpdate",(function(){return Dt})),t.d(n,"onDeactivated",(function(){return qt})),t.d(n,"onErrorCaptured",(function(){return Ht})),t.d(n,"onMounted",(function(){return Nt})),t.d(n,"onRenderTracked",(function(){return Ft})),t.d(n,"onRenderTriggered",(function(){return Bt})),t.d(n,"onScopeDispose",(function(){return xn})),t.d(n,"onServerPrefetch",(function(){return Jt})),t.d(n,"onUnmounted",(function(){return Rt})),t.d(n,"onUpdated",(function(){return Pt})),t.d(n,"provide",(function(){return kn})),t.d(n,"proxyRefs",(function(){return Qe})),t.d(n,"reactive",(function(){return Re})),t.d(n,"readonly",(function(){return an})),t.d(n,"ref",(function(){return Ke})),t.d(n,"set",(function(){return De})),t.d(n,"shallowReactive",(function(){return ze})),t.d(n,"shallowReadonly",(function(){return sn})),t.d(n,"shallowRef",(function(){return We})),t.d(n,"toRaw",(function(){return He})),t.d(n,"toRef",(function(){return tn})),t.d(n,"toRefs",(function(){return nn})),t.d(n,"triggerRef",(function(){return Ve})),t.d(n,"unref",(function(){return Ze})),t.d(n,"useAttrs",(function(){return it})),t.d(n,"useCssModule",(function(){return At})),t.d(n,"useCssVars",(function(){return Ct})),t.d(n,"useListeners",(function(){return ot})),t.d(n,"useSlots",(function(){return rt})),t.d(n,"version",(function(){return $t})),t.d(n,"watch",(function(){return vn})),t.d(n,"watchEffect",(function(){return pn})),t.d(n,"watchPostEffect",(function(){return mn})),t.d(n,"watchSyncEffect",(function(){return hn}));
/*!
 * Vue.js v2.7.16
 * (c) 2014-2023 Evan You
 * Released under the MIT License.
 */
var a=Object.freeze({}),r=Array.isArray;function i(e){return null==e}function o(e){return null!=e}function s(e){return!0===e}function l(e){return"string"==typeof e||"number"==typeof e||"symbol"==typeof e||"boolean"==typeof e}function c(e){return"function"==typeof e}function d(e){return null!==e&&"object"==typeof e}var u=Object.prototype.toString;function p(e){return"[object Object]"===u.call(e)}function m(e){return"[object RegExp]"===u.call(e)}function h(e){var n=parseFloat(String(e));return n>=0&&Math.floor(n)===n&&isFinite(e)}function f(e){return o(e)&&"function"==typeof e.then&&"function"==typeof e.catch}function g(e){return null==e?"":Array.isArray(e)||p(e)&&e.toString===u?JSON.stringify(e,v,2):String(e)}function v(e,n){return n&&n.__v_isRef?n.value:n}function b(e){var n=parseFloat(e);return isNaN(n)?e:n}function y(e,n){for(var t=Object.create(null),a=e.split(","),r=0;r<a.length;r++)t[a[r]]=!0;return n?function(e){return t[e.toLowerCase()]}:function(e){return t[e]}}y("slot,component",!0);var w=y("key,ref,slot,slot-scope,is");function _(e,n){var t=e.length;if(t){if(n===e[t-1])return void(e.length=t-1);var a=e.indexOf(n);if(a>-1)return e.splice(a,1)}}var x=Object.prototype.hasOwnProperty;function k(e,n){return x.call(e,n)}function T(e){var n=Object.create(null);return function(t){return n[t]||(n[t]=e(t))}}var E=/-(\w)/g,S=T((function(e){return e.replace(E,(function(e,n){return n?n.toUpperCase():""}))})),I=T((function(e){return e.charAt(0).toUpperCase()+e.slice(1)})),A=/\B([A-Z])/g,C=T((function(e){return e.replace(A,"-$1").toLowerCase()}));var j=Function.prototype.bind?function(e,n){return e.bind(n)}:function(e,n){function t(t){var a=arguments.length;return a?a>1?e.apply(n,arguments):e.call(n,t):e.call(n)}return t._length=e.length,t};function O(e,n){n=n||0;for(var t=e.length-n,a=new Array(t);t--;)a[t]=e[t+n];return a}function L(e,n){for(var t in n)e[t]=n[t];return e}function N(e){for(var n={},t=0;t<e.length;t++)e[t]&&L(n,e[t]);return n}function D(e,n,t){}var P=function(e,n,t){return!1},M=function(e){return e};function R(e,n){if(e===n)return!0;var t=d(e),a=d(n);if(!t||!a)return!t&&!a&&String(e)===String(n);try{var r=Array.isArray(e),i=Array.isArray(n);if(r&&i)return e.length===n.length&&e.every((function(e,t){return R(e,n[t])}));if(e instanceof Date&&n instanceof Date)return e.getTime()===n.getTime();if(r||i)return!1;var o=Object.keys(e),s=Object.keys(n);return o.length===s.length&&o.every((function(t){return R(e[t],n[t])}))}catch(e){return!1}}function z(e,n){for(var t=0;t<e.length;t++)if(R(e[t],n))return t;return-1}function q(e){var n=!1;return function(){n||(n=!0,e.apply(this,arguments))}}function J(e,n){return e===n?0===e&&1/e!=1/n:e==e||n==n}var F=["component","directive","filter"],B=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],U={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:P,isReservedAttr:P,isUnknownElement:P,getTagNamespace:D,parsePlatformTagName:M,mustUseProp:P,async:!0,_lifecycleHooks:B},H=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function $(e){var n=(e+"").charCodeAt(0);return 36===n||95===n}function G(e,n,t,a){Object.defineProperty(e,n,{value:t,enumerable:!!a,writable:!0,configurable:!0})}var K=new RegExp("[^".concat(H.source,".$_\\d]"));var W="__proto__"in{},Y="undefined"!=typeof window,V=Y&&window.navigator.userAgent.toLowerCase(),Z=V&&/msie|trident/.test(V),Q=V&&V.indexOf("msie 9.0")>0,X=V&&V.indexOf("edge/")>0;V&&V.indexOf("android");var ee=V&&/iphone|ipad|ipod|ios/.test(V);V&&/chrome\/\d+/.test(V),V&&/phantomjs/.test(V);var ne,te=V&&V.match(/firefox\/(\d+)/),ae={}.watch,re=!1;if(Y)try{var ie={};Object.defineProperty(ie,"passive",{get:function(){re=!0}}),window.addEventListener("test-passive",null,ie)}catch(e){}var oe=function(){return void 0===ne&&(ne=!Y&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),ne},se=Y&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function le(e){return"function"==typeof e&&/native code/.test(e.toString())}var ce,de="undefined"!=typeof Symbol&&le(Symbol)&&"undefined"!=typeof Reflect&&le(Reflect.ownKeys);ce="undefined"!=typeof Set&&le(Set)?Set:function(){function e(){this.set=Object.create(null)}return e.prototype.has=function(e){return!0===this.set[e]},e.prototype.add=function(e){this.set[e]=!0},e.prototype.clear=function(){this.set=Object.create(null)},e}();var ue=null;function pe(){return ue&&{proxy:ue}}function me(e){void 0===e&&(e=null),e||ue&&ue._scope.off(),ue=e,e&&e._scope.on()}var he=function(){function e(e,n,t,a,r,i,o,s){this.tag=e,this.data=n,this.children=t,this.text=a,this.elm=r,this.ns=void 0,this.context=i,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=n&&n.key,this.componentOptions=o,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(e.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),e}(),fe=function(e){void 0===e&&(e="");var n=new he;return n.text=e,n.isComment=!0,n};function ge(e){return new he(void 0,void 0,void 0,String(e))}function ve(e){var n=new he(e.tag,e.data,e.children&&e.children.slice(),e.text,e.elm,e.context,e.componentOptions,e.asyncFactory);return n.ns=e.ns,n.isStatic=e.isStatic,n.key=e.key,n.isComment=e.isComment,n.fnContext=e.fnContext,n.fnOptions=e.fnOptions,n.fnScopeId=e.fnScopeId,n.asyncMeta=e.asyncMeta,n.isCloned=!0,n}"function"==typeof SuppressedError&&SuppressedError;var be=0,ye=[],we=function(){function e(){this._pending=!1,this.id=be++,this.subs=[]}return e.prototype.addSub=function(e){this.subs.push(e)},e.prototype.removeSub=function(e){this.subs[this.subs.indexOf(e)]=null,this._pending||(this._pending=!0,ye.push(this))},e.prototype.depend=function(n){e.target&&e.target.addDep(this)},e.prototype.notify=function(e){var n=this.subs.filter((function(e){return e}));for(var t=0,a=n.length;t<a;t++){0,n[t].update()}},e}();we.target=null;var _e=[];function xe(e){_e.push(e),we.target=e}function ke(){_e.pop(),we.target=_e[_e.length-1]}var Te=Array.prototype,Ee=Object.create(Te);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(e){var n=Te[e];G(Ee,e,(function(){for(var t=[],a=0;a<arguments.length;a++)t[a]=arguments[a];var r,i=n.apply(this,t),o=this.__ob__;switch(e){case"push":case"unshift":r=t;break;case"splice":r=t.slice(2)}return r&&o.observeArray(r),o.dep.notify(),i}))}));var Se=Object.getOwnPropertyNames(Ee),Ie={},Ae=!0;function Ce(e){Ae=e}var je={notify:D,depend:D,addSub:D,removeSub:D},Oe=function(){function e(e,n,t){if(void 0===n&&(n=!1),void 0===t&&(t=!1),this.value=e,this.shallow=n,this.mock=t,this.dep=t?je:new we,this.vmCount=0,G(e,"__ob__",this),r(e)){if(!t)if(W)e.__proto__=Ee;else for(var a=0,i=Se.length;a<i;a++){G(e,s=Se[a],Ee[s])}n||this.observeArray(e)}else{var o=Object.keys(e);for(a=0;a<o.length;a++){var s;Ne(e,s=o[a],Ie,void 0,n,t)}}}return e.prototype.observeArray=function(e){for(var n=0,t=e.length;n<t;n++)Le(e[n],!1,this.mock)},e}();function Le(e,n,t){return e&&k(e,"__ob__")&&e.__ob__ instanceof Oe?e.__ob__:!Ae||!t&&oe()||!r(e)&&!p(e)||!Object.isExtensible(e)||e.__v_skip||Ge(e)||e instanceof he?void 0:new Oe(e,n,t)}function Ne(e,n,t,a,i,o,s){void 0===s&&(s=!1);var l=new we,c=Object.getOwnPropertyDescriptor(e,n);if(!c||!1!==c.configurable){var d=c&&c.get,u=c&&c.set;d&&!u||t!==Ie&&2!==arguments.length||(t=e[n]);var p=i?t&&t.__ob__:Le(t,!1,o);return Object.defineProperty(e,n,{enumerable:!0,configurable:!0,get:function(){var n=d?d.call(e):t;return we.target&&(l.depend(),p&&(p.dep.depend(),r(n)&&Me(n))),Ge(n)&&!i?n.value:n},set:function(n){var a=d?d.call(e):t;if(J(a,n)){if(u)u.call(e,n);else{if(d)return;if(!i&&Ge(a)&&!Ge(n))return void(a.value=n);t=n}p=i?n&&n.__ob__:Le(n,!1,o),l.notify()}}}),l}}function De(e,n,t){if(!Be(e)){var a=e.__ob__;return r(e)&&h(n)?(e.length=Math.max(e.length,n),e.splice(n,1,t),a&&!a.shallow&&a.mock&&Le(t,!1,!0),t):n in e&&!(n in Object.prototype)?(e[n]=t,t):e._isVue||a&&a.vmCount?t:a?(Ne(a.value,n,t,void 0,a.shallow,a.mock),a.dep.notify(),t):(e[n]=t,t)}}function Pe(e,n){if(r(e)&&h(n))e.splice(n,1);else{var t=e.__ob__;e._isVue||t&&t.vmCount||Be(e)||k(e,n)&&(delete e[n],t&&t.dep.notify())}}function Me(e){for(var n=void 0,t=0,a=e.length;t<a;t++)(n=e[t])&&n.__ob__&&n.__ob__.dep.depend(),r(n)&&Me(n)}function Re(e){return qe(e,!1),e}function ze(e){return qe(e,!0),G(e,"__v_isShallow",!0),e}function qe(e,n){if(!Be(e)){Le(e,n,oe());0}}function Je(e){return Be(e)?Je(e.__v_raw):!(!e||!e.__ob__)}function Fe(e){return!(!e||!e.__v_isShallow)}function Be(e){return!(!e||!e.__v_isReadonly)}function Ue(e){return Je(e)||Be(e)}function He(e){var n=e&&e.__v_raw;return n?He(n):e}function $e(e){return Object.isExtensible(e)&&G(e,"__v_skip",!0),e}function Ge(e){return!(!e||!0!==e.__v_isRef)}function Ke(e){return Ye(e,!1)}function We(e){return Ye(e,!0)}function Ye(e,n){if(Ge(e))return e;var t={};return G(t,"__v_isRef",!0),G(t,"__v_isShallow",n),G(t,"dep",Ne(t,"value",e,null,n,oe())),t}function Ve(e){e.dep&&e.dep.notify()}function Ze(e){return Ge(e)?e.value:e}function Qe(e){if(Je(e))return e;for(var n={},t=Object.keys(e),a=0;a<t.length;a++)Xe(n,e,t[a]);return n}function Xe(e,n,t){Object.defineProperty(e,t,{enumerable:!0,configurable:!0,get:function(){var e=n[t];if(Ge(e))return e.value;var a=e&&e.__ob__;return a&&a.dep.depend(),e},set:function(e){var a=n[t];Ge(a)&&!Ge(e)?a.value=e:n[t]=e}})}function en(e){var n=new we,t=e((function(){n.depend()}),(function(){n.notify()})),a=t.get,r=t.set,i={get value(){return a()},set value(e){r(e)}};return G(i,"__v_isRef",!0),i}function nn(e){var n=r(e)?new Array(e.length):{};for(var t in e)n[t]=tn(e,t);return n}function tn(e,n,t){var a=e[n];if(Ge(a))return a;var r={get value(){var a=e[n];return void 0===a?t:a},set value(t){e[n]=t}};return G(r,"__v_isRef",!0),r}function an(e){return rn(e,!1)}function rn(e,n){if(!p(e))return e;if(Be(e))return e;var t=n?"__v_rawToShallowReadonly":"__v_rawToReadonly",a=e[t];if(a)return a;var r=Object.create(Object.getPrototypeOf(e));G(e,t,r),G(r,"__v_isReadonly",!0),G(r,"__v_raw",e),Ge(e)&&G(r,"__v_isRef",!0),(n||Fe(e))&&G(r,"__v_isShallow",!0);for(var i=Object.keys(e),o=0;o<i.length;o++)on(r,e,i[o],n);return r}function on(e,n,t,a){Object.defineProperty(e,t,{enumerable:!0,configurable:!0,get:function(){var e=n[t];return a||!p(e)?e:an(e)},set:function(){}})}function sn(e){return rn(e,!0)}function ln(e,n){var t,a,r=c(e);r?(t=e,a=D):(t=e.get,a=e.set);var i=oe()?null:new Zt(ue,t,D,{lazy:!0});var o={effect:i,get value(){return i?(i.dirty&&i.evaluate(),we.target&&i.depend(),i.value):t()},set value(e){a(e)}};return G(o,"__v_isRef",!0),G(o,"__v_isReadonly",r),o}var cn="".concat("watcher"," callback"),dn="".concat("watcher"," getter"),un="".concat("watcher"," cleanup");function pn(e,n){return bn(e,null,n)}function mn(e,n){return bn(e,null,{flush:"post"})}function hn(e,n){return bn(e,null,{flush:"sync"})}var fn,gn={};function vn(e,n,t){return bn(e,n,t)}function bn(e,n,t){var i=void 0===t?a:t,o=i.immediate,s=i.deep,l=i.flush,d=void 0===l?"pre":l;i.onTrack,i.onTrigger;var u,p,m=ue,h=function(e,n,t){void 0===t&&(t=null);var a=ft(e,null,t,m,n);return s&&a&&a.__ob__&&a.__ob__.dep.depend(),a},f=!1,g=!1;if(Ge(e)?(u=function(){return e.value},f=Fe(e)):Je(e)?(u=function(){return e.__ob__.dep.depend(),e},s=!0):r(e)?(g=!0,f=e.some((function(e){return Je(e)||Fe(e)})),u=function(){return e.map((function(e){return Ge(e)?e.value:Je(e)?(e.__ob__.dep.depend(),Wt(e)):c(e)?h(e,dn):void 0}))}):u=c(e)?n?function(){return h(e,dn)}:function(){if(!m||!m._isDestroyed)return p&&p(),h(e,"watcher",[b])}:D,n&&s){var v=u;u=function(){return Wt(v())}}var b=function(e){p=y.onStop=function(){h(e,un)}};if(oe())return b=D,n?o&&h(n,cn,[u(),g?[]:void 0,b]):u(),D;var y=new Zt(ue,u,D,{lazy:!0});y.noRecurse=!n;var w=g?[]:gn;return y.run=function(){if(y.active)if(n){var e=y.get();(s||f||(g?e.some((function(e,n){return J(e,w[n])})):J(e,w)))&&(p&&p(),h(n,cn,[e,w===gn?void 0:w,b]),w=e)}else y.get()},"sync"===d?y.update=y.run:"post"===d?(y.post=!0,y.update=function(){return ba(y)}):y.update=function(){if(m&&m===ue&&!m._isMounted){var e=m._preWatchers||(m._preWatchers=[]);e.indexOf(y)<0&&e.push(y)}else ba(y)},n?o?y.run():w=y.get():"post"===d&&m?m.$once("hook:mounted",(function(){return y.get()})):y.get(),function(){y.teardown()}}var yn=function(){function e(e){void 0===e&&(e=!1),this.detached=e,this.active=!0,this.effects=[],this.cleanups=[],this.parent=fn,!e&&fn&&(this.index=(fn.scopes||(fn.scopes=[])).push(this)-1)}return e.prototype.run=function(e){if(this.active){var n=fn;try{return fn=this,e()}finally{fn=n}}else 0},e.prototype.on=function(){fn=this},e.prototype.off=function(){fn=this.parent},e.prototype.stop=function(e){if(this.active){var n=void 0,t=void 0;for(n=0,t=this.effects.length;n<t;n++)this.effects[n].teardown();for(n=0,t=this.cleanups.length;n<t;n++)this.cleanups[n]();if(this.scopes)for(n=0,t=this.scopes.length;n<t;n++)this.scopes[n].stop(!0);if(!this.detached&&this.parent&&!e){var a=this.parent.scopes.pop();a&&a!==this&&(this.parent.scopes[this.index]=a,a.index=this.index)}this.parent=void 0,this.active=!1}},e}();function wn(e){return new yn(e)}function _n(){return fn}function xn(e){fn&&fn.cleanups.push(e)}function kn(e,n){ue&&(Tn(ue)[e]=n)}function Tn(e){var n=e._provided,t=e.$parent&&e.$parent._provided;return t===n?e._provided=Object.create(t):n}function En(e,n,t){void 0===t&&(t=!1);var a=ue;if(a){var r=a.$parent&&a.$parent._provided;if(r&&e in r)return r[e];if(arguments.length>1)return t&&c(n)?n.call(a):n}else 0}var Sn=T((function(e){var n="&"===e.charAt(0),t="~"===(e=n?e.slice(1):e).charAt(0),a="!"===(e=t?e.slice(1):e).charAt(0);return{name:e=a?e.slice(1):e,once:t,capture:a,passive:n}}));function In(e,n){function t(){var e=t.fns;if(!r(e))return ft(e,null,arguments,n,"v-on handler");for(var a=e.slice(),i=0;i<a.length;i++)ft(a[i],null,arguments,n,"v-on handler")}return t.fns=e,t}function An(e,n,t,a,r,o){var l,c,d,u;for(l in e)c=e[l],d=n[l],u=Sn(l),i(c)||(i(d)?(i(c.fns)&&(c=e[l]=In(c,o)),s(u.once)&&(c=e[l]=r(u.name,c,u.capture)),t(u.name,c,u.capture,u.passive,u.params)):c!==d&&(d.fns=c,e[l]=d));for(l in n)i(e[l])&&a((u=Sn(l)).name,n[l],u.capture)}function Cn(e,n,t){var a;e instanceof he&&(e=e.data.hook||(e.data.hook={}));var r=e[n];function l(){t.apply(this,arguments),_(a.fns,l)}i(r)?a=In([l]):o(r.fns)&&s(r.merged)?(a=r).fns.push(l):a=In([r,l]),a.merged=!0,e[n]=a}function jn(e,n,t,a,r){if(o(n)){if(k(n,t))return e[t]=n[t],r||delete n[t],!0;if(k(n,a))return e[t]=n[a],r||delete n[a],!0}return!1}function On(e){return l(e)?[ge(e)]:r(e)?function e(n,t){var a,c,d,u,p=[];for(a=0;a<n.length;a++)i(c=n[a])||"boolean"==typeof c||(d=p.length-1,u=p[d],r(c)?c.length>0&&(Ln((c=e(c,"".concat(t||"","_").concat(a)))[0])&&Ln(u)&&(p[d]=ge(u.text+c[0].text),c.shift()),p.push.apply(p,c)):l(c)?Ln(u)?p[d]=ge(u.text+c):""!==c&&p.push(ge(c)):Ln(c)&&Ln(u)?p[d]=ge(u.text+c.text):(s(n._isVList)&&o(c.tag)&&i(c.key)&&o(t)&&(c.key="__vlist".concat(t,"_").concat(a,"__")),p.push(c)));return p}(e):void 0}function Ln(e){return o(e)&&o(e.text)&&!1===e.isComment}function Nn(e,n){var t,a,i,s,l=null;if(r(e)||"string"==typeof e)for(l=new Array(e.length),t=0,a=e.length;t<a;t++)l[t]=n(e[t],t);else if("number"==typeof e)for(l=new Array(e),t=0;t<e;t++)l[t]=n(t+1,t);else if(d(e))if(de&&e[Symbol.iterator]){l=[];for(var c=e[Symbol.iterator](),u=c.next();!u.done;)l.push(n(u.value,l.length)),u=c.next()}else for(i=Object.keys(e),l=new Array(i.length),t=0,a=i.length;t<a;t++)s=i[t],l[t]=n(e[s],s,t);return o(l)||(l=[]),l._isVList=!0,l}function Dn(e,n,t,a){var r,i=this.$scopedSlots[e];i?(t=t||{},a&&(t=L(L({},a),t)),r=i(t)||(c(n)?n():n)):r=this.$slots[e]||(c(n)?n():n);var o=t&&t.slot;return o?this.$createElement("template",{slot:o},r):r}function Pn(e){return Ma(this.$options,"filters",e,!0)||M}function Mn(e,n){return r(e)?-1===e.indexOf(n):e!==n}function Rn(e,n,t,a,r){var i=U.keyCodes[n]||t;return r&&a&&!U.keyCodes[n]?Mn(r,a):i?Mn(i,e):a?C(a)!==n:void 0===e}function zn(e,n,t,a,i){if(t)if(d(t)){r(t)&&(t=N(t));var o=void 0,s=function(r){if("class"===r||"style"===r||w(r))o=e;else{var s=e.attrs&&e.attrs.type;o=a||U.mustUseProp(n,s,r)?e.domProps||(e.domProps={}):e.attrs||(e.attrs={})}var l=S(r),c=C(r);l in o||c in o||(o[r]=t[r],i&&((e.on||(e.on={}))["update:".concat(r)]=function(e){t[r]=e}))};for(var l in t)s(l)}else;return e}function qn(e,n){var t=this._staticTrees||(this._staticTrees=[]),a=t[e];return a&&!n||Fn(a=t[e]=this.$options.staticRenderFns[e].call(this._renderProxy,this._c,this),"__static__".concat(e),!1),a}function Jn(e,n,t){return Fn(e,"__once__".concat(n).concat(t?"_".concat(t):""),!0),e}function Fn(e,n,t){if(r(e))for(var a=0;a<e.length;a++)e[a]&&"string"!=typeof e[a]&&Bn(e[a],"".concat(n,"_").concat(a),t);else Bn(e,n,t)}function Bn(e,n,t){e.isStatic=!0,e.key=n,e.isOnce=t}function Un(e,n){if(n)if(p(n)){var t=e.on=e.on?L({},e.on):{};for(var a in n){var r=t[a],i=n[a];t[a]=r?[].concat(r,i):i}}else;return e}function Hn(e,n,t,a){n=n||{$stable:!t};for(var i=0;i<e.length;i++){var o=e[i];r(o)?Hn(o,n,t):o&&(o.proxy&&(o.fn.proxy=!0),n[o.key]=o.fn)}return a&&(n.$key=a),n}function $n(e,n){for(var t=0;t<n.length;t+=2){var a=n[t];"string"==typeof a&&a&&(e[n[t]]=n[t+1])}return e}function Gn(e,n){return"string"==typeof e?n+e:e}function Kn(e){e._o=Jn,e._n=b,e._s=g,e._l=Nn,e._t=Dn,e._q=R,e._i=z,e._m=qn,e._f=Pn,e._k=Rn,e._b=zn,e._v=ge,e._e=fe,e._u=Hn,e._g=Un,e._d=$n,e._p=Gn}function Wn(e,n){if(!e||!e.length)return{};for(var t={},a=0,r=e.length;a<r;a++){var i=e[a],o=i.data;if(o&&o.attrs&&o.attrs.slot&&delete o.attrs.slot,i.context!==n&&i.fnContext!==n||!o||null==o.slot)(t.default||(t.default=[])).push(i);else{var s=o.slot,l=t[s]||(t[s]=[]);"template"===i.tag?l.push.apply(l,i.children||[]):l.push(i)}}for(var c in t)t[c].every(Yn)&&delete t[c];return t}function Yn(e){return e.isComment&&!e.asyncFactory||" "===e.text}function Vn(e){return e.isComment&&e.asyncFactory}function Zn(e,n,t,r){var i,o=Object.keys(t).length>0,s=n?!!n.$stable:!o,l=n&&n.$key;if(n){if(n._normalized)return n._normalized;if(s&&r&&r!==a&&l===r.$key&&!o&&!r.$hasNormal)return r;for(var c in i={},n)n[c]&&"$"!==c[0]&&(i[c]=Qn(e,t,c,n[c]))}else i={};for(var d in t)d in i||(i[d]=Xn(t,d));return n&&Object.isExtensible(n)&&(n._normalized=i),G(i,"$stable",s),G(i,"$key",l),G(i,"$hasNormal",o),i}function Qn(e,n,t,a){var i=function(){var n=ue;me(e);var t=arguments.length?a.apply(null,arguments):a({}),i=(t=t&&"object"==typeof t&&!r(t)?[t]:On(t))&&t[0];return me(n),t&&(!i||1===t.length&&i.isComment&&!Vn(i))?void 0:t};return a.proxy&&Object.defineProperty(n,t,{get:i,enumerable:!0,configurable:!0}),i}function Xn(e,n){return function(){return e[n]}}function et(e){return{get attrs(){if(!e._attrsProxy){var n=e._attrsProxy={};G(n,"_v_attr_proxy",!0),nt(n,e.$attrs,a,e,"$attrs")}return e._attrsProxy},get listeners(){e._listenersProxy||nt(e._listenersProxy={},e.$listeners,a,e,"$listeners");return e._listenersProxy},get slots(){return function(e){e._slotsProxy||at(e._slotsProxy={},e.$scopedSlots);return e._slotsProxy}(e)},emit:j(e.$emit,e),expose:function(n){n&&Object.keys(n).forEach((function(t){return Xe(e,n,t)}))}}}function nt(e,n,t,a,r){var i=!1;for(var o in n)o in e?n[o]!==t[o]&&(i=!0):(i=!0,tt(e,o,a,r));for(var o in e)o in n||(i=!0,delete e[o]);return i}function tt(e,n,t,a){Object.defineProperty(e,n,{enumerable:!0,configurable:!0,get:function(){return t[a][n]}})}function at(e,n){for(var t in n)e[t]=n[t];for(var t in e)t in n||delete e[t]}function rt(){return st().slots}function it(){return st().attrs}function ot(){return st().listeners}function st(){var e=ue;return e._setupContext||(e._setupContext=et(e))}function lt(e,n){var t=r(e)?e.reduce((function(e,n){return e[n]={},e}),{}):e;for(var a in n){var i=t[a];i?r(i)||c(i)?t[a]={type:i,default:n[a]}:i.default=n[a]:null===i&&(t[a]={default:n[a]})}return t}var ct=null;function dt(e,n){return(e.__esModule||de&&"Module"===e[Symbol.toStringTag])&&(e=e.default),d(e)?n.extend(e):e}function ut(e){if(r(e))for(var n=0;n<e.length;n++){var t=e[n];if(o(t)&&(o(t.componentOptions)||Vn(t)))return t}}function pt(e,n,t,a,u,p){return(r(t)||l(t))&&(u=a,a=t,t=void 0),s(p)&&(u=2),function(e,n,t,a,l){if(o(t)&&o(t.__ob__))return fe();o(t)&&o(t.is)&&(n=t.is);if(!n)return fe();0;r(a)&&c(a[0])&&((t=t||{}).scopedSlots={default:a[0]},a.length=0);2===l?a=On(a):1===l&&(a=function(e){for(var n=0;n<e.length;n++)if(r(e[n]))return Array.prototype.concat.apply([],e);return e}(a));var u,p;if("string"==typeof n){var m=void 0;p=e.$vnode&&e.$vnode.ns||U.getTagNamespace(n),u=U.isReservedTag(n)?new he(U.parsePlatformTagName(n),t,a,void 0,void 0,e):t&&t.pre||!o(m=Ma(e.$options,"components",n))?new he(n,t,a,void 0,void 0,e):Sa(m,t,e,a,n)}else u=Sa(n,t,e,a);return r(u)?u:o(u)?(o(p)&&function e(n,t,a){n.ns=t,"foreignObject"===n.tag&&(t=void 0,a=!0);if(o(n.children))for(var r=0,l=n.children.length;r<l;r++){var c=n.children[r];o(c.tag)&&(i(c.ns)||s(a)&&"svg"!==c.tag)&&e(c,t,a)}}(u,p),o(t)&&function(e){d(e.style)&&Wt(e.style);d(e.class)&&Wt(e.class)}(t),u):fe()}(e,n,t,a,u)}function mt(e,n,t){return pt(ue,e,n,t,2,!0)}function ht(e,n,t){xe();try{if(n)for(var a=n;a=a.$parent;){var r=a.$options.errorCaptured;if(r)for(var i=0;i<r.length;i++)try{if(!1===r[i].call(a,e,n,t))return}catch(e){gt(e,a,"errorCaptured hook")}}gt(e,n,t)}finally{ke()}}function ft(e,n,t,a,r){var i;try{(i=t?e.apply(n,t):e.call(n))&&!i._isVue&&f(i)&&!i._handled&&(i.catch((function(e){return ht(e,a,r+" (Promise/async)")})),i._handled=!0)}catch(e){ht(e,a,r)}return i}function gt(e,n,t){if(U.errorHandler)try{return U.errorHandler.call(null,e,n,t)}catch(n){n!==e&&vt(n,null,"config.errorHandler")}vt(e,n,t)}function vt(e,n,t){if(!Y||"undefined"==typeof console)throw e;console.error(e)}var bt,yt=!1,wt=[],_t=!1;function xt(){_t=!1;var e=wt.slice(0);wt.length=0;for(var n=0;n<e.length;n++)e[n]()}if("undefined"!=typeof Promise&&le(Promise)){var kt=Promise.resolve();bt=function(){kt.then(xt),ee&&setTimeout(D)},yt=!0}else if(Z||"undefined"==typeof MutationObserver||!le(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())bt="undefined"!=typeof setImmediate&&le(setImmediate)?function(){setImmediate(xt)}:function(){setTimeout(xt,0)};else{var Tt=1,Et=new MutationObserver(xt),St=document.createTextNode(String(Tt));Et.observe(St,{characterData:!0}),bt=function(){Tt=(Tt+1)%2,St.data=String(Tt)},yt=!0}function It(e,n){var t;if(wt.push((function(){if(e)try{e.call(n)}catch(e){ht(e,n,"nextTick")}else t&&t(n)})),_t||(_t=!0,bt()),!e&&"undefined"!=typeof Promise)return new Promise((function(e){t=e}))}function At(e){if(void 0===e&&(e="$style"),!ue)return a;var n=ue[e];return n||a}function Ct(e){if(Y){var n=ue;n&&mn((function(){var t=n.$el,a=e(n,n._setupProxy);if(t&&1===t.nodeType){var r=t.style;for(var i in a)r.setProperty("--".concat(i),a[i])}}))}}function jt(e){c(e)&&(e={loader:e});var n=e.loader,t=e.loadingComponent,a=e.errorComponent,r=e.delay,i=void 0===r?200:r,o=e.timeout,s=(e.suspensible,e.onError);var l=null,d=0,u=function(){var e;return l||(e=l=n().catch((function(e){if(e=e instanceof Error?e:new Error(String(e)),s)return new Promise((function(n,t){s(e,(function(){return n((d++,l=null,u()))}),(function(){return t(e)}),d+1)}));throw e})).then((function(n){return e!==l&&l?l:(n&&(n.__esModule||"Module"===n[Symbol.toStringTag])&&(n=n.default),n)})))};return function(){return{component:u(),delay:i,timeout:o,error:a,loading:t}}}function Ot(e){return function(n,t){if(void 0===t&&(t=ue),t)return function(e,n,t){var a=e.$options;a[n]=La(a[n],t)}(t,e,n)}}var Lt=Ot("beforeMount"),Nt=Ot("mounted"),Dt=Ot("beforeUpdate"),Pt=Ot("updated"),Mt=Ot("beforeDestroy"),Rt=Ot("destroyed"),zt=Ot("activated"),qt=Ot("deactivated"),Jt=Ot("serverPrefetch"),Ft=Ot("renderTracked"),Bt=Ot("renderTriggered"),Ut=Ot("errorCaptured");function Ht(e,n){void 0===n&&(n=ue),Ut(e,n)}var $t="2.7.16";function Gt(e){return e}var Kt=new ce;function Wt(e){return function e(n,t){var a,i,o=r(n);if(!o&&!d(n)||n.__v_skip||Object.isFrozen(n)||n instanceof he)return;if(n.__ob__){var s=n.__ob__.dep.id;if(t.has(s))return;t.add(s)}if(o)for(a=n.length;a--;)e(n[a],t);else if(Ge(n))e(n.value,t);else for(i=Object.keys(n),a=i.length;a--;)e(n[i[a]],t)}(e,Kt),Kt.clear(),e}var Yt,Vt=0,Zt=function(){function e(e,n,t,a,r){var i,o;i=this,void 0===(o=fn&&!fn._vm?fn:e?e._scope:void 0)&&(o=fn),o&&o.active&&o.effects.push(i),(this.vm=e)&&r&&(e._watcher=this),a?(this.deep=!!a.deep,this.user=!!a.user,this.lazy=!!a.lazy,this.sync=!!a.sync,this.before=a.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++Vt,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new ce,this.newDepIds=new ce,this.expression="",c(n)?this.getter=n:(this.getter=function(e){if(!K.test(e)){var n=e.split(".");return function(e){for(var t=0;t<n.length;t++){if(!e)return;e=e[n[t]]}return e}}}(n),this.getter||(this.getter=D)),this.value=this.lazy?void 0:this.get()}return e.prototype.get=function(){var e;xe(this);var n=this.vm;try{e=this.getter.call(n,n)}catch(e){if(!this.user)throw e;ht(e,n,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Wt(e),ke(),this.cleanupDeps()}return e},e.prototype.addDep=function(e){var n=e.id;this.newDepIds.has(n)||(this.newDepIds.add(n),this.newDeps.push(e),this.depIds.has(n)||e.addSub(this))},e.prototype.cleanupDeps=function(){for(var e=this.deps.length;e--;){var n=this.deps[e];this.newDepIds.has(n.id)||n.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},e.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():ba(this)},e.prototype.run=function(){if(this.active){var e=this.get();if(e!==this.value||d(e)||this.deep){var n=this.value;if(this.value=e,this.user){var t='callback for watcher "'.concat(this.expression,'"');ft(this.cb,this.vm,[e,n],this.vm,t)}else this.cb.call(this.vm,e,n)}}},e.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},e.prototype.depend=function(){for(var e=this.deps.length;e--;)this.deps[e].depend()},e.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&_(this.vm._scope.effects,this),this.active){for(var e=this.deps.length;e--;)this.deps[e].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},e}();function Qt(e,n){Yt.$on(e,n)}function Xt(e,n){Yt.$off(e,n)}function ea(e,n){var t=Yt;return function a(){var r=n.apply(null,arguments);null!==r&&t.$off(e,a)}}function na(e,n,t){Yt=e,An(n,t||{},Qt,Xt,ea,e),Yt=void 0}var ta=null;function aa(e){var n=ta;return ta=e,function(){ta=n}}function ra(e){for(;e&&(e=e.$parent);)if(e._inactive)return!0;return!1}function ia(e,n){if(n){if(e._directInactive=!1,ra(e))return}else if(e._directInactive)return;if(e._inactive||null===e._inactive){e._inactive=!1;for(var t=0;t<e.$children.length;t++)ia(e.$children[t]);oa(e,"activated")}}function oa(e,n,t,a){void 0===a&&(a=!0),xe();var r=ue,i=_n();a&&me(e);var o=e.$options[n],s="".concat(n," hook");if(o)for(var l=0,c=o.length;l<c;l++)ft(o[l],e,t||null,e,s);e._hasHookEvent&&e.$emit("hook:"+n),a&&(me(r),i&&i.on()),ke()}var sa=[],la=[],ca={},da=!1,ua=!1,pa=0;var ma=0,ha=Date.now;if(Y&&!Z){var fa=window.performance;fa&&"function"==typeof fa.now&&ha()>document.createEvent("Event").timeStamp&&(ha=function(){return fa.now()})}var ga=function(e,n){if(e.post){if(!n.post)return 1}else if(n.post)return-1;return e.id-n.id};function va(){var e,n;for(ma=ha(),ua=!0,sa.sort(ga),pa=0;pa<sa.length;pa++)(e=sa[pa]).before&&e.before(),n=e.id,ca[n]=null,e.run();var t=la.slice(),a=sa.slice();pa=sa.length=la.length=0,ca={},da=ua=!1,function(e){for(var n=0;n<e.length;n++)e[n]._inactive=!0,ia(e[n],!0)}(t),function(e){var n=e.length;for(;n--;){var t=e[n],a=t.vm;a&&a._watcher===t&&a._isMounted&&!a._isDestroyed&&oa(a,"updated")}}(a),function(){for(var e=0;e<ye.length;e++){var n=ye[e];n.subs=n.subs.filter((function(e){return e})),n._pending=!1}ye.length=0}(),se&&U.devtools&&se.emit("flush")}function ba(e){var n=e.id;if(null==ca[n]&&(e!==we.target||!e.noRecurse)){if(ca[n]=!0,ua){for(var t=sa.length-1;t>pa&&sa[t].id>e.id;)t--;sa.splice(t+1,0,e)}else sa.push(e);da||(da=!0,It(va))}}function ya(e,n){if(e){for(var t=Object.create(null),a=de?Reflect.ownKeys(e):Object.keys(e),r=0;r<a.length;r++){var i=a[r];if("__ob__"!==i){var o=e[i].from;if(o in n._provided)t[i]=n._provided[o];else if("default"in e[i]){var s=e[i].default;t[i]=c(s)?s.call(n):s}else 0}}return t}}function wa(e,n,t,i,o){var l,c=this,d=o.options;k(i,"_uid")?(l=Object.create(i))._original=i:(l=i,i=i._original);var u=s(d._compiled),p=!u;this.data=e,this.props=n,this.children=t,this.parent=i,this.listeners=e.on||a,this.injections=ya(d.inject,i),this.slots=function(){return c.$slots||Zn(i,e.scopedSlots,c.$slots=Wn(t,i)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return Zn(i,e.scopedSlots,this.slots())}}),u&&(this.$options=d,this.$slots=this.slots(),this.$scopedSlots=Zn(i,e.scopedSlots,this.$slots)),d._scopeId?this._c=function(e,n,t,a){var o=pt(l,e,n,t,a,p);return o&&!r(o)&&(o.fnScopeId=d._scopeId,o.fnContext=i),o}:this._c=function(e,n,t,a){return pt(l,e,n,t,a,p)}}function _a(e,n,t,a,r){var i=ve(e);return i.fnContext=t,i.fnOptions=a,n.slot&&((i.data||(i.data={})).slot=n.slot),i}function xa(e,n){for(var t in n)e[S(t)]=n[t]}function ka(e){return e.name||e.__name||e._componentTag}Kn(wa.prototype);var Ta={init:function(e,n){if(e.componentInstance&&!e.componentInstance._isDestroyed&&e.data.keepAlive){var t=e;Ta.prepatch(t,t)}else{(e.componentInstance=function(e,n){var t={_isComponent:!0,_parentVnode:e,parent:n},a=e.data.inlineTemplate;o(a)&&(t.render=a.render,t.staticRenderFns=a.staticRenderFns);return new e.componentOptions.Ctor(t)}(e,ta)).$mount(n?e.elm:void 0,n)}},prepatch:function(e,n){var t=n.componentOptions;!function(e,n,t,r,i){var o=r.data.scopedSlots,s=e.$scopedSlots,l=!!(o&&!o.$stable||s!==a&&!s.$stable||o&&e.$scopedSlots.$key!==o.$key||!o&&e.$scopedSlots.$key),c=!!(i||e.$options._renderChildren||l),d=e.$vnode;e.$options._parentVnode=r,e.$vnode=r,e._vnode&&(e._vnode.parent=r),e.$options._renderChildren=i;var u=r.data.attrs||a;e._attrsProxy&&nt(e._attrsProxy,u,d.data&&d.data.attrs||a,e,"$attrs")&&(c=!0),e.$attrs=u,t=t||a;var p=e.$options._parentListeners;if(e._listenersProxy&&nt(e._listenersProxy,t,p||a,e,"$listeners"),e.$listeners=e.$options._parentListeners=t,na(e,t,p),n&&e.$options.props){Ce(!1);for(var m=e._props,h=e.$options._propKeys||[],f=0;f<h.length;f++){var g=h[f],v=e.$options.props;m[g]=Ra(g,v,n,e)}Ce(!0),e.$options.propsData=n}c&&(e.$slots=Wn(i,r.context),e.$forceUpdate())}(n.componentInstance=e.componentInstance,t.propsData,t.listeners,n,t.children)},insert:function(e){var n,t=e.context,a=e.componentInstance;a._isMounted||(a._isMounted=!0,oa(a,"mounted")),e.data.keepAlive&&(t._isMounted?((n=a)._inactive=!1,la.push(n)):ia(a,!0))},destroy:function(e){var n=e.componentInstance;n._isDestroyed||(e.data.keepAlive?function e(n,t){if(!(t&&(n._directInactive=!0,ra(n))||n._inactive)){n._inactive=!0;for(var a=0;a<n.$children.length;a++)e(n.$children[a]);oa(n,"deactivated")}}(n,!0):n.$destroy())}},Ea=Object.keys(Ta);function Sa(e,n,t,l,c){if(!i(e)){var u=t.$options._base;if(d(e)&&(e=u.extend(e)),"function"==typeof e){var p;if(i(e.cid)&&void 0===(e=function(e,n){if(s(e.error)&&o(e.errorComp))return e.errorComp;if(o(e.resolved))return e.resolved;var t=ct;if(t&&o(e.owners)&&-1===e.owners.indexOf(t)&&e.owners.push(t),s(e.loading)&&o(e.loadingComp))return e.loadingComp;if(t&&!o(e.owners)){var a=e.owners=[t],r=!0,l=null,c=null;t.$on("hook:destroyed",(function(){return _(a,t)}));var u=function(e){for(var n=0,t=a.length;n<t;n++)a[n].$forceUpdate();e&&(a.length=0,null!==l&&(clearTimeout(l),l=null),null!==c&&(clearTimeout(c),c=null))},p=q((function(t){e.resolved=dt(t,n),r?a.length=0:u(!0)})),m=q((function(n){o(e.errorComp)&&(e.error=!0,u(!0))})),h=e(p,m);return d(h)&&(f(h)?i(e.resolved)&&h.then(p,m):f(h.component)&&(h.component.then(p,m),o(h.error)&&(e.errorComp=dt(h.error,n)),o(h.loading)&&(e.loadingComp=dt(h.loading,n),0===h.delay?e.loading=!0:l=setTimeout((function(){l=null,i(e.resolved)&&i(e.error)&&(e.loading=!0,u(!1))}),h.delay||200)),o(h.timeout)&&(c=setTimeout((function(){c=null,i(e.resolved)&&m(null)}),h.timeout)))),r=!1,e.loading?e.loadingComp:e.resolved}}(p=e,u)))return function(e,n,t,a,r){var i=fe();return i.asyncFactory=e,i.asyncMeta={data:n,context:t,children:a,tag:r},i}(p,n,t,l,c);n=n||{},Za(e),o(n.model)&&function(e,n){var t=e.model&&e.model.prop||"value",a=e.model&&e.model.event||"input";(n.attrs||(n.attrs={}))[t]=n.model.value;var i=n.on||(n.on={}),s=i[a],l=n.model.callback;o(s)?(r(s)?-1===s.indexOf(l):s!==l)&&(i[a]=[l].concat(s)):i[a]=l}(e.options,n);var m=function(e,n,t){var a=n.options.props;if(!i(a)){var r={},s=e.attrs,l=e.props;if(o(s)||o(l))for(var c in a){var d=C(c);jn(r,l,c,d,!0)||jn(r,s,c,d,!1)}return r}}(n,e);if(s(e.options.functional))return function(e,n,t,i,s){var l=e.options,c={},d=l.props;if(o(d))for(var u in d)c[u]=Ra(u,d,n||a);else o(t.attrs)&&xa(c,t.attrs),o(t.props)&&xa(c,t.props);var p=new wa(t,c,s,i,e),m=l.render.call(null,p._c,p);if(m instanceof he)return _a(m,t,p.parent,l,p);if(r(m)){for(var h=On(m)||[],f=new Array(h.length),g=0;g<h.length;g++)f[g]=_a(h[g],t,p.parent,l,p);return f}}(e,m,n,t,l);var h=n.on;if(n.on=n.nativeOn,s(e.options.abstract)){var g=n.slot;n={},g&&(n.slot=g)}!function(e){for(var n=e.hook||(e.hook={}),t=0;t<Ea.length;t++){var a=Ea[t],r=n[a],i=Ta[a];r===i||r&&r._merged||(n[a]=r?Ia(i,r):i)}}(n);var v=ka(e.options)||c;return new he("vue-component-".concat(e.cid).concat(v?"-".concat(v):""),n,void 0,void 0,void 0,t,{Ctor:e,propsData:m,listeners:h,tag:c,children:l},p)}}}function Ia(e,n){var t=function(t,a){e(t,a),n(t,a)};return t._merged=!0,t}var Aa=D,Ca=U.optionMergeStrategies;function ja(e,n,t){if(void 0===t&&(t=!0),!n)return e;for(var a,r,i,o=de?Reflect.ownKeys(n):Object.keys(n),s=0;s<o.length;s++)"__ob__"!==(a=o[s])&&(r=e[a],i=n[a],t&&k(e,a)?r!==i&&p(r)&&p(i)&&ja(r,i):De(e,a,i));return e}function Oa(e,n,t){return t?function(){var a=c(n)?n.call(t,t):n,r=c(e)?e.call(t,t):e;return a?ja(a,r):r}:n?e?function(){return ja(c(n)?n.call(this,this):n,c(e)?e.call(this,this):e)}:n:e}function La(e,n){var t=n?e?e.concat(n):r(n)?n:[n]:e;return t?function(e){for(var n=[],t=0;t<e.length;t++)-1===n.indexOf(e[t])&&n.push(e[t]);return n}(t):t}function Na(e,n,t,a){var r=Object.create(e||null);return n?L(r,n):r}Ca.data=function(e,n,t){return t?Oa(e,n,t):n&&"function"!=typeof n?e:Oa(e,n)},B.forEach((function(e){Ca[e]=La})),F.forEach((function(e){Ca[e+"s"]=Na})),Ca.watch=function(e,n,t,a){if(e===ae&&(e=void 0),n===ae&&(n=void 0),!n)return Object.create(e||null);if(!e)return n;var i={};for(var o in L(i,e),n){var s=i[o],l=n[o];s&&!r(s)&&(s=[s]),i[o]=s?s.concat(l):r(l)?l:[l]}return i},Ca.props=Ca.methods=Ca.inject=Ca.computed=function(e,n,t,a){if(!e)return n;var r=Object.create(null);return L(r,e),n&&L(r,n),r},Ca.provide=function(e,n){return e?function(){var t=Object.create(null);return ja(t,c(e)?e.call(this):e),n&&ja(t,c(n)?n.call(this):n,!1),t}:n};var Da=function(e,n){return void 0===n?e:n};function Pa(e,n,t){if(c(n)&&(n=n.options),function(e,n){var t=e.props;if(t){var a,i,o={};if(r(t))for(a=t.length;a--;)"string"==typeof(i=t[a])&&(o[S(i)]={type:null});else if(p(t))for(var s in t)i=t[s],o[S(s)]=p(i)?i:{type:i};else 0;e.props=o}}(n),function(e,n){var t=e.inject;if(t){var a=e.inject={};if(r(t))for(var i=0;i<t.length;i++)a[t[i]]={from:t[i]};else if(p(t))for(var o in t){var s=t[o];a[o]=p(s)?L({from:o},s):{from:s}}else 0}}(n),function(e){var n=e.directives;if(n)for(var t in n){var a=n[t];c(a)&&(n[t]={bind:a,update:a})}}(n),!n._base&&(n.extends&&(e=Pa(e,n.extends,t)),n.mixins))for(var a=0,i=n.mixins.length;a<i;a++)e=Pa(e,n.mixins[a],t);var o,s={};for(o in e)l(o);for(o in n)k(e,o)||l(o);function l(a){var r=Ca[a]||Da;s[a]=r(e[a],n[a],t,a)}return s}function Ma(e,n,t,a){if("string"==typeof t){var r=e[n];if(k(r,t))return r[t];var i=S(t);if(k(r,i))return r[i];var o=I(i);return k(r,o)?r[o]:r[t]||r[i]||r[o]}}function Ra(e,n,t,a){var r=n[e],i=!k(t,e),o=t[e],s=Fa(Boolean,r.type);if(s>-1)if(i&&!k(r,"default"))o=!1;else if(""===o||o===C(e)){var l=Fa(String,r.type);(l<0||s<l)&&(o=!0)}if(void 0===o){o=function(e,n,t){if(!k(n,"default"))return;var a=n.default;0;if(e&&e.$options.propsData&&void 0===e.$options.propsData[t]&&void 0!==e._props[t])return e._props[t];return c(a)&&"Function"!==qa(n.type)?a.call(e):a}(a,r,e);var d=Ae;Ce(!0),Le(o),Ce(d)}return o}var za=/^\s*function (\w+)/;function qa(e){var n=e&&e.toString().match(za);return n?n[1]:""}function Ja(e,n){return qa(e)===qa(n)}function Fa(e,n){if(!r(n))return Ja(n,e)?0:-1;for(var t=0,a=n.length;t<a;t++)if(Ja(n[t],e))return t;return-1}var Ba={enumerable:!0,configurable:!0,get:D,set:D};function Ua(e,n,t){Ba.get=function(){return this[n][t]},Ba.set=function(e){this[n][t]=e},Object.defineProperty(e,t,Ba)}function Ha(e){var n=e.$options;if(n.props&&function(e,n){var t=e.$options.propsData||{},a=e._props=ze({}),r=e.$options._propKeys=[];e.$parent&&Ce(!1);var i=function(i){r.push(i);var o=Ra(i,n,t,e);Ne(a,i,o,void 0,!0),i in e||Ua(e,"_props",i)};for(var o in n)i(o);Ce(!0)}(e,n.props),function(e){var n=e.$options,t=n.setup;if(t){var a=e._setupContext=et(e);me(e),xe();var r=ft(t,null,[e._props||ze({}),a],e,"setup");if(ke(),me(),c(r))n.render=r;else if(d(r))if(e._setupState=r,r.__sfc){var i=e._setupProxy={};for(var o in r)"__sfc"!==o&&Xe(i,r,o)}else for(var o in r)$(o)||Xe(e,r,o);else 0}}(e),n.methods&&function(e,n){e.$options.props;for(var t in n)e[t]="function"!=typeof n[t]?D:j(n[t],e)}(e,n.methods),n.data)!function(e){var n=e.$options.data;p(n=e._data=c(n)?function(e,n){xe();try{return e.call(n,n)}catch(e){return ht(e,n,"data()"),{}}finally{ke()}}(n,e):n||{})||(n={});var t=Object.keys(n),a=e.$options.props,r=(e.$options.methods,t.length);for(;r--;){var i=t[r];0,a&&k(a,i)||$(i)||Ua(e,"_data",i)}var o=Le(n);o&&o.vmCount++}(e);else{var t=Le(e._data={});t&&t.vmCount++}n.computed&&function(e,n){var t=e._computedWatchers=Object.create(null),a=oe();for(var r in n){var i=n[r],o=c(i)?i:i.get;0,a||(t[r]=new Zt(e,o||D,D,$a)),r in e||Ga(e,r,i)}}(e,n.computed),n.watch&&n.watch!==ae&&function(e,n){for(var t in n){var a=n[t];if(r(a))for(var i=0;i<a.length;i++)Ya(e,t,a[i]);else Ya(e,t,a)}}(e,n.watch)}var $a={lazy:!0};function Ga(e,n,t){var a=!oe();c(t)?(Ba.get=a?Ka(n):Wa(t),Ba.set=D):(Ba.get=t.get?a&&!1!==t.cache?Ka(n):Wa(t.get):D,Ba.set=t.set||D),Object.defineProperty(e,n,Ba)}function Ka(e){return function(){var n=this._computedWatchers&&this._computedWatchers[e];if(n)return n.dirty&&n.evaluate(),we.target&&n.depend(),n.value}}function Wa(e){return function(){return e.call(this,this)}}function Ya(e,n,t,a){return p(t)&&(a=t,t=t.handler),"string"==typeof t&&(t=e[t]),e.$watch(n,t,a)}var Va=0;function Za(e){var n=e.options;if(e.super){var t=Za(e.super);if(t!==e.superOptions){e.superOptions=t;var a=function(e){var n,t=e.options,a=e.sealedOptions;for(var r in t)t[r]!==a[r]&&(n||(n={}),n[r]=t[r]);return n}(e);a&&L(e.extendOptions,a),(n=e.options=Pa(t,e.extendOptions)).name&&(n.components[n.name]=e)}}return n}function Qa(e){this._init(e)}function Xa(e){e.cid=0;var n=1;e.extend=function(e){e=e||{};var t=this,a=t.cid,r=e._Ctor||(e._Ctor={});if(r[a])return r[a];var i=ka(e)||ka(t.options);var o=function(e){this._init(e)};return(o.prototype=Object.create(t.prototype)).constructor=o,o.cid=n++,o.options=Pa(t.options,e),o.super=t,o.options.props&&function(e){var n=e.options.props;for(var t in n)Ua(e.prototype,"_props",t)}(o),o.options.computed&&function(e){var n=e.options.computed;for(var t in n)Ga(e.prototype,t,n[t])}(o),o.extend=t.extend,o.mixin=t.mixin,o.use=t.use,F.forEach((function(e){o[e]=t[e]})),i&&(o.options.components[i]=o),o.superOptions=t.options,o.extendOptions=e,o.sealedOptions=L({},o.options),r[a]=o,o}}function er(e){return e&&(ka(e.Ctor.options)||e.tag)}function nr(e,n){return r(e)?e.indexOf(n)>-1:"string"==typeof e?e.split(",").indexOf(n)>-1:!!m(e)&&e.test(n)}function tr(e,n){var t=e.cache,a=e.keys,r=e._vnode,i=e.$vnode;for(var o in t){var s=t[o];if(s){var l=s.name;l&&!n(l)&&ar(t,o,a,r)}}i.componentOptions.children=void 0}function ar(e,n,t,a){var r=e[n];!r||a&&r.tag===a.tag||r.componentInstance.$destroy(),e[n]=null,_(t,n)}!function(e){e.prototype._init=function(e){var n=this;n._uid=Va++,n._isVue=!0,n.__v_skip=!0,n._scope=new yn(!0),n._scope.parent=void 0,n._scope._vm=!0,e&&e._isComponent?function(e,n){var t=e.$options=Object.create(e.constructor.options),a=n._parentVnode;t.parent=n.parent,t._parentVnode=a;var r=a.componentOptions;t.propsData=r.propsData,t._parentListeners=r.listeners,t._renderChildren=r.children,t._componentTag=r.tag,n.render&&(t.render=n.render,t.staticRenderFns=n.staticRenderFns)}(n,e):n.$options=Pa(Za(n.constructor),e||{},n),n._renderProxy=n,n._self=n,function(e){var n=e.$options,t=n.parent;if(t&&!n.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(e)}e.$parent=t,e.$root=t?t.$root:e,e.$children=[],e.$refs={},e._provided=t?t._provided:Object.create(null),e._watcher=null,e._inactive=null,e._directInactive=!1,e._isMounted=!1,e._isDestroyed=!1,e._isBeingDestroyed=!1}(n),function(e){e._events=Object.create(null),e._hasHookEvent=!1;var n=e.$options._parentListeners;n&&na(e,n)}(n),function(e){e._vnode=null,e._staticTrees=null;var n=e.$options,t=e.$vnode=n._parentVnode,r=t&&t.context;e.$slots=Wn(n._renderChildren,r),e.$scopedSlots=t?Zn(e.$parent,t.data.scopedSlots,e.$slots):a,e._c=function(n,t,a,r){return pt(e,n,t,a,r,!1)},e.$createElement=function(n,t,a,r){return pt(e,n,t,a,r,!0)};var i=t&&t.data;Ne(e,"$attrs",i&&i.attrs||a,null,!0),Ne(e,"$listeners",n._parentListeners||a,null,!0)}(n),oa(n,"beforeCreate",void 0,!1),function(e){var n=ya(e.$options.inject,e);n&&(Ce(!1),Object.keys(n).forEach((function(t){Ne(e,t,n[t])})),Ce(!0))}(n),Ha(n),function(e){var n=e.$options.provide;if(n){var t=c(n)?n.call(e):n;if(!d(t))return;for(var a=Tn(e),r=de?Reflect.ownKeys(t):Object.keys(t),i=0;i<r.length;i++){var o=r[i];Object.defineProperty(a,o,Object.getOwnPropertyDescriptor(t,o))}}}(n),oa(n,"created"),n.$options.el&&n.$mount(n.$options.el)}}(Qa),function(e){var n={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(e.prototype,"$data",n),Object.defineProperty(e.prototype,"$props",t),e.prototype.$set=De,e.prototype.$delete=Pe,e.prototype.$watch=function(e,n,t){if(p(n))return Ya(this,e,n,t);(t=t||{}).user=!0;var a=new Zt(this,e,n,t);if(t.immediate){var r='callback for immediate watcher "'.concat(a.expression,'"');xe(),ft(n,this,[a.value],this,r),ke()}return function(){a.teardown()}}}(Qa),function(e){var n=/^hook:/;e.prototype.$on=function(e,t){var a=this;if(r(e))for(var i=0,o=e.length;i<o;i++)a.$on(e[i],t);else(a._events[e]||(a._events[e]=[])).push(t),n.test(e)&&(a._hasHookEvent=!0);return a},e.prototype.$once=function(e,n){var t=this;function a(){t.$off(e,a),n.apply(t,arguments)}return a.fn=n,t.$on(e,a),t},e.prototype.$off=function(e,n){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(r(e)){for(var a=0,i=e.length;a<i;a++)t.$off(e[a],n);return t}var o,s=t._events[e];if(!s)return t;if(!n)return t._events[e]=null,t;for(var l=s.length;l--;)if((o=s[l])===n||o.fn===n){s.splice(l,1);break}return t},e.prototype.$emit=function(e){var n=this,t=n._events[e];if(t){t=t.length>1?O(t):t;for(var a=O(arguments,1),r='event handler for "'.concat(e,'"'),i=0,o=t.length;i<o;i++)ft(t[i],n,a,n,r)}return n}}(Qa),function(e){e.prototype._update=function(e,n){var t=this,a=t.$el,r=t._vnode,i=aa(t);t._vnode=e,t.$el=r?t.__patch__(r,e):t.__patch__(t.$el,e,n,!1),i(),a&&(a.__vue__=null),t.$el&&(t.$el.__vue__=t);for(var o=t;o&&o.$vnode&&o.$parent&&o.$vnode===o.$parent._vnode;)o.$parent.$el=o.$el,o=o.$parent},e.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},e.prototype.$destroy=function(){var e=this;if(!e._isBeingDestroyed){oa(e,"beforeDestroy"),e._isBeingDestroyed=!0;var n=e.$parent;!n||n._isBeingDestroyed||e.$options.abstract||_(n.$children,e),e._scope.stop(),e._data.__ob__&&e._data.__ob__.vmCount--,e._isDestroyed=!0,e.__patch__(e._vnode,null),oa(e,"destroyed"),e.$off(),e.$el&&(e.$el.__vue__=null),e.$vnode&&(e.$vnode.parent=null)}}}(Qa),function(e){Kn(e.prototype),e.prototype.$nextTick=function(e){return It(e,this)},e.prototype._render=function(){var e=this,n=e.$options,t=n.render,a=n._parentVnode;a&&e._isMounted&&(e.$scopedSlots=Zn(e.$parent,a.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&at(e._slotsProxy,e.$scopedSlots)),e.$vnode=a;var i,o=ue,s=ct;try{me(e),ct=e,i=t.call(e._renderProxy,e.$createElement)}catch(n){ht(n,e,"render"),i=e._vnode}finally{ct=s,me(o)}return r(i)&&1===i.length&&(i=i[0]),i instanceof he||(i=fe()),i.parent=a,i}}(Qa);var rr=[String,RegExp,Array],ir={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:rr,exclude:rr,max:[String,Number]},methods:{cacheVNode:function(){var e=this.cache,n=this.keys,t=this.vnodeToCache,a=this.keyToCache;if(t){var r=t.tag,i=t.componentInstance,o=t.componentOptions;e[a]={name:er(o),tag:r,componentInstance:i},n.push(a),this.max&&n.length>parseInt(this.max)&&ar(e,n[0],n,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var e in this.cache)ar(this.cache,e,this.keys)},mounted:function(){var e=this;this.cacheVNode(),this.$watch("include",(function(n){tr(e,(function(e){return nr(n,e)}))})),this.$watch("exclude",(function(n){tr(e,(function(e){return!nr(n,e)}))}))},updated:function(){this.cacheVNode()},render:function(){var e=this.$slots.default,n=ut(e),t=n&&n.componentOptions;if(t){var a=er(t),r=this.include,i=this.exclude;if(r&&(!a||!nr(r,a))||i&&a&&nr(i,a))return n;var o=this.cache,s=this.keys,l=null==n.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):n.key;o[l]?(n.componentInstance=o[l].componentInstance,_(s,l),s.push(l)):(this.vnodeToCache=n,this.keyToCache=l),n.data.keepAlive=!0}return n||e&&e[0]}}};!function(e){var n={get:function(){return U}};Object.defineProperty(e,"config",n),e.util={warn:Aa,extend:L,mergeOptions:Pa,defineReactive:Ne},e.set=De,e.delete=Pe,e.nextTick=It,e.observable=function(e){return Le(e),e},e.options=Object.create(null),F.forEach((function(n){e.options[n+"s"]=Object.create(null)})),e.options._base=e,L(e.options.components,ir),function(e){e.use=function(e){var n=this._installedPlugins||(this._installedPlugins=[]);if(n.indexOf(e)>-1)return this;var t=O(arguments,1);return t.unshift(this),c(e.install)?e.install.apply(e,t):c(e)&&e.apply(null,t),n.push(e),this}}(e),function(e){e.mixin=function(e){return this.options=Pa(this.options,e),this}}(e),Xa(e),function(e){F.forEach((function(n){e[n]=function(e,t){return t?("component"===n&&p(t)&&(t.name=t.name||e,t=this.options._base.extend(t)),"directive"===n&&c(t)&&(t={bind:t,update:t}),this.options[n+"s"][e]=t,t):this.options[n+"s"][e]}}))}(e)}(Qa),Object.defineProperty(Qa.prototype,"$isServer",{get:oe}),Object.defineProperty(Qa.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Qa,"FunctionalRenderContext",{value:wa}),Qa.version=$t;var or=y("style,class"),sr=y("input,textarea,option,select,progress"),lr=y("contenteditable,draggable,spellcheck"),cr=y("events,caret,typing,plaintext-only"),dr=y("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ur="http://www.w3.org/1999/xlink",pr=function(e){return":"===e.charAt(5)&&"xlink"===e.slice(0,5)},mr=function(e){return pr(e)?e.slice(6,e.length):""},hr=function(e){return null==e||!1===e};function fr(e){for(var n=e.data,t=e,a=e;o(a.componentInstance);)(a=a.componentInstance._vnode)&&a.data&&(n=gr(a.data,n));for(;o(t=t.parent);)t&&t.data&&(n=gr(n,t.data));return function(e,n){if(o(e)||o(n))return vr(e,br(n));return""}(n.staticClass,n.class)}function gr(e,n){return{staticClass:vr(e.staticClass,n.staticClass),class:o(e.class)?[e.class,n.class]:n.class}}function vr(e,n){return e?n?e+" "+n:e:n||""}function br(e){return Array.isArray(e)?function(e){for(var n,t="",a=0,r=e.length;a<r;a++)o(n=br(e[a]))&&""!==n&&(t&&(t+=" "),t+=n);return t}(e):d(e)?function(e){var n="";for(var t in e)e[t]&&(n&&(n+=" "),n+=t);return n}(e):"string"==typeof e?e:""}var yr={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},wr=y("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),_r=y("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),xr=function(e){return wr(e)||_r(e)};var kr=Object.create(null);var Tr=y("text,number,password,search,email,tel,url");var Er=Object.freeze({__proto__:null,createElement:function(e,n){var t=document.createElement(e);return"select"!==e||n.data&&n.data.attrs&&void 0!==n.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(e,n){return document.createElementNS(yr[e],n)},createTextNode:function(e){return document.createTextNode(e)},createComment:function(e){return document.createComment(e)},insertBefore:function(e,n,t){e.insertBefore(n,t)},removeChild:function(e,n){e.removeChild(n)},appendChild:function(e,n){e.appendChild(n)},parentNode:function(e){return e.parentNode},nextSibling:function(e){return e.nextSibling},tagName:function(e){return e.tagName},setTextContent:function(e,n){e.textContent=n},setStyleScope:function(e,n){e.setAttribute(n,"")}}),Sr={create:function(e,n){Ir(n)},update:function(e,n){e.data.ref!==n.data.ref&&(Ir(e,!0),Ir(n))},destroy:function(e){Ir(e,!0)}};function Ir(e,n){var t=e.data.ref;if(o(t)){var a=e.context,i=e.componentInstance||e.elm,s=n?null:i,l=n?void 0:i;if(c(t))ft(t,a,[s],a,"template ref function");else{var d=e.data.refInFor,u="string"==typeof t||"number"==typeof t,p=Ge(t),m=a.$refs;if(u||p)if(d){var h=u?m[t]:t.value;n?r(h)&&_(h,i):r(h)?h.includes(i)||h.push(i):u?(m[t]=[i],Ar(a,t,m[t])):t.value=[i]}else if(u){if(n&&m[t]!==i)return;m[t]=l,Ar(a,t,s)}else if(p){if(n&&t.value!==i)return;t.value=s}else 0}}}function Ar(e,n,t){var a=e._setupState;a&&k(a,n)&&(Ge(a[n])?a[n].value=t:a[n]=t)}var Cr=new he("",{},[]),jr=["create","activate","update","remove","destroy"];function Or(e,n){return e.key===n.key&&e.asyncFactory===n.asyncFactory&&(e.tag===n.tag&&e.isComment===n.isComment&&o(e.data)===o(n.data)&&function(e,n){if("input"!==e.tag)return!0;var t,a=o(t=e.data)&&o(t=t.attrs)&&t.type,r=o(t=n.data)&&o(t=t.attrs)&&t.type;return a===r||Tr(a)&&Tr(r)}(e,n)||s(e.isAsyncPlaceholder)&&i(n.asyncFactory.error))}function Lr(e,n,t){var a,r,i={};for(a=n;a<=t;++a)o(r=e[a].key)&&(i[r]=a);return i}var Nr={create:Dr,update:Dr,destroy:function(e){Dr(e,Cr)}};function Dr(e,n){(e.data.directives||n.data.directives)&&function(e,n){var t,a,r,i=e===Cr,o=n===Cr,s=Mr(e.data.directives,e.context),l=Mr(n.data.directives,n.context),c=[],d=[];for(t in l)a=s[t],r=l[t],a?(r.oldValue=a.value,r.oldArg=a.arg,zr(r,"update",n,e),r.def&&r.def.componentUpdated&&d.push(r)):(zr(r,"bind",n,e),r.def&&r.def.inserted&&c.push(r));if(c.length){var u=function(){for(var t=0;t<c.length;t++)zr(c[t],"inserted",n,e)};i?Cn(n,"insert",u):u()}d.length&&Cn(n,"postpatch",(function(){for(var t=0;t<d.length;t++)zr(d[t],"componentUpdated",n,e)}));if(!i)for(t in s)l[t]||zr(s[t],"unbind",e,e,o)}(e,n)}var Pr=Object.create(null);function Mr(e,n){var t,a,r=Object.create(null);if(!e)return r;for(t=0;t<e.length;t++){if((a=e[t]).modifiers||(a.modifiers=Pr),r[Rr(a)]=a,n._setupState&&n._setupState.__sfc){var i=a.def||Ma(n,"_setupState","v-"+a.name);a.def="function"==typeof i?{bind:i,update:i}:i}a.def=a.def||Ma(n.$options,"directives",a.name)}return r}function Rr(e){return e.rawName||"".concat(e.name,".").concat(Object.keys(e.modifiers||{}).join("."))}function zr(e,n,t,a,r){var i=e.def&&e.def[n];if(i)try{i(t.elm,e,t,a,r)}catch(a){ht(a,t.context,"directive ".concat(e.name," ").concat(n," hook"))}}var qr=[Sr,Nr];function Jr(e,n){var t=n.componentOptions;if(!(o(t)&&!1===t.Ctor.options.inheritAttrs||i(e.data.attrs)&&i(n.data.attrs))){var a,r,l=n.elm,c=e.data.attrs||{},d=n.data.attrs||{};for(a in(o(d.__ob__)||s(d._v_attr_proxy))&&(d=n.data.attrs=L({},d)),d)r=d[a],c[a]!==r&&Fr(l,a,r,n.data.pre);for(a in(Z||X)&&d.value!==c.value&&Fr(l,"value",d.value),c)i(d[a])&&(pr(a)?l.removeAttributeNS(ur,mr(a)):lr(a)||l.removeAttribute(a))}}function Fr(e,n,t,a){a||e.tagName.indexOf("-")>-1?Br(e,n,t):dr(n)?hr(t)?e.removeAttribute(n):(t="allowfullscreen"===n&&"EMBED"===e.tagName?"true":n,e.setAttribute(n,t)):lr(n)?e.setAttribute(n,function(e,n){return hr(n)||"false"===n?"false":"contenteditable"===e&&cr(n)?n:"true"}(n,t)):pr(n)?hr(t)?e.removeAttributeNS(ur,mr(n)):e.setAttributeNS(ur,n,t):Br(e,n,t)}function Br(e,n,t){if(hr(t))e.removeAttribute(n);else{if(Z&&!Q&&"TEXTAREA"===e.tagName&&"placeholder"===n&&""!==t&&!e.__ieph){var a=function(n){n.stopImmediatePropagation(),e.removeEventListener("input",a)};e.addEventListener("input",a),e.__ieph=!0}e.setAttribute(n,t)}}var Ur={create:Jr,update:Jr};function Hr(e,n){var t=n.elm,a=n.data,r=e.data;if(!(i(a.staticClass)&&i(a.class)&&(i(r)||i(r.staticClass)&&i(r.class)))){var s=fr(n),l=t._transitionClasses;o(l)&&(s=vr(s,br(l))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var $r,Gr={create:Hr,update:Hr};function Kr(e,n,t){var a=$r;return function r(){var i=n.apply(null,arguments);null!==i&&Vr(e,r,t,a)}}var Wr=yt&&!(te&&Number(te[1])<=53);function Yr(e,n,t,a){if(Wr){var r=ma,i=n;n=i._wrapper=function(e){if(e.target===e.currentTarget||e.timeStamp>=r||e.timeStamp<=0||e.target.ownerDocument!==document)return i.apply(this,arguments)}}$r.addEventListener(e,n,re?{capture:t,passive:a}:t)}function Vr(e,n,t,a){(a||$r).removeEventListener(e,n._wrapper||n,t)}function Zr(e,n){if(!i(e.data.on)||!i(n.data.on)){var t=n.data.on||{},a=e.data.on||{};$r=n.elm||e.elm,function(e){if(o(e.__r)){var n=Z?"change":"input";e[n]=[].concat(e.__r,e[n]||[]),delete e.__r}o(e.__c)&&(e.change=[].concat(e.__c,e.change||[]),delete e.__c)}(t),An(t,a,Yr,Vr,Kr,n.context),$r=void 0}}var Qr,Xr={create:Zr,update:Zr,destroy:function(e){return Zr(e,Cr)}};function ei(e,n){if(!i(e.data.domProps)||!i(n.data.domProps)){var t,a,r=n.elm,l=e.data.domProps||{},c=n.data.domProps||{};for(t in(o(c.__ob__)||s(c._v_attr_proxy))&&(c=n.data.domProps=L({},c)),l)t in c||(r[t]="");for(t in c){if(a=c[t],"textContent"===t||"innerHTML"===t){if(n.children&&(n.children.length=0),a===l[t])continue;1===r.childNodes.length&&r.removeChild(r.childNodes[0])}if("value"===t&&"PROGRESS"!==r.tagName){r._value=a;var d=i(a)?"":String(a);ni(r,d)&&(r.value=d)}else if("innerHTML"===t&&_r(r.tagName)&&i(r.innerHTML)){(Qr=Qr||document.createElement("div")).innerHTML="<svg>".concat(a,"</svg>");for(var u=Qr.firstChild;r.firstChild;)r.removeChild(r.firstChild);for(;u.firstChild;)r.appendChild(u.firstChild)}else if(a!==l[t])try{r[t]=a}catch(e){}}}}function ni(e,n){return!e.composing&&("OPTION"===e.tagName||function(e,n){var t=!0;try{t=document.activeElement!==e}catch(e){}return t&&e.value!==n}(e,n)||function(e,n){var t=e.value,a=e._vModifiers;if(o(a)){if(a.number)return b(t)!==b(n);if(a.trim)return t.trim()!==n.trim()}return t!==n}(e,n))}var ti={create:ei,update:ei},ai=T((function(e){var n={},t=/:(.+)/;return e.split(/;(?![^(]*\))/g).forEach((function(e){if(e){var a=e.split(t);a.length>1&&(n[a[0].trim()]=a[1].trim())}})),n}));function ri(e){var n=ii(e.style);return e.staticStyle?L(e.staticStyle,n):n}function ii(e){return Array.isArray(e)?N(e):"string"==typeof e?ai(e):e}var oi,si=/^--/,li=/\s*!important$/,ci=function(e,n,t){if(si.test(n))e.style.setProperty(n,t);else if(li.test(t))e.style.setProperty(C(n),t.replace(li,""),"important");else{var a=ui(n);if(Array.isArray(t))for(var r=0,i=t.length;r<i;r++)e.style[a]=t[r];else e.style[a]=t}},di=["Webkit","Moz","ms"],ui=T((function(e){if(oi=oi||document.createElement("div").style,"filter"!==(e=S(e))&&e in oi)return e;for(var n=e.charAt(0).toUpperCase()+e.slice(1),t=0;t<di.length;t++){var a=di[t]+n;if(a in oi)return a}}));function pi(e,n){var t=n.data,a=e.data;if(!(i(t.staticStyle)&&i(t.style)&&i(a.staticStyle)&&i(a.style))){var r,s,l=n.elm,c=a.staticStyle,d=a.normalizedStyle||a.style||{},u=c||d,p=ii(n.data.style)||{};n.data.normalizedStyle=o(p.__ob__)?L({},p):p;var m=function(e,n){var t,a={};if(n)for(var r=e;r.componentInstance;)(r=r.componentInstance._vnode)&&r.data&&(t=ri(r.data))&&L(a,t);(t=ri(e.data))&&L(a,t);for(var i=e;i=i.parent;)i.data&&(t=ri(i.data))&&L(a,t);return a}(n,!0);for(s in u)i(m[s])&&ci(l,s,"");for(s in m)r=m[s],ci(l,s,null==r?"":r)}}var mi={create:pi,update:pi},hi=/\s+/;function fi(e,n){if(n&&(n=n.trim()))if(e.classList)n.indexOf(" ")>-1?n.split(hi).forEach((function(n){return e.classList.add(n)})):e.classList.add(n);else{var t=" ".concat(e.getAttribute("class")||""," ");t.indexOf(" "+n+" ")<0&&e.setAttribute("class",(t+n).trim())}}function gi(e,n){if(n&&(n=n.trim()))if(e.classList)n.indexOf(" ")>-1?n.split(hi).forEach((function(n){return e.classList.remove(n)})):e.classList.remove(n),e.classList.length||e.removeAttribute("class");else{for(var t=" ".concat(e.getAttribute("class")||""," "),a=" "+n+" ";t.indexOf(a)>=0;)t=t.replace(a," ");(t=t.trim())?e.setAttribute("class",t):e.removeAttribute("class")}}function vi(e){if(e){if("object"==typeof e){var n={};return!1!==e.css&&L(n,bi(e.name||"v")),L(n,e),n}return"string"==typeof e?bi(e):void 0}}var bi=T((function(e){return{enterClass:"".concat(e,"-enter"),enterToClass:"".concat(e,"-enter-to"),enterActiveClass:"".concat(e,"-enter-active"),leaveClass:"".concat(e,"-leave"),leaveToClass:"".concat(e,"-leave-to"),leaveActiveClass:"".concat(e,"-leave-active")}})),yi=Y&&!Q,wi="transition",_i="transitionend",xi="animation",ki="animationend";yi&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(wi="WebkitTransition",_i="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(xi="WebkitAnimation",ki="webkitAnimationEnd"));var Ti=Y?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(e){return e()};function Ei(e){Ti((function(){Ti(e)}))}function Si(e,n){var t=e._transitionClasses||(e._transitionClasses=[]);t.indexOf(n)<0&&(t.push(n),fi(e,n))}function Ii(e,n){e._transitionClasses&&_(e._transitionClasses,n),gi(e,n)}function Ai(e,n,t){var a=ji(e,n),r=a.type,i=a.timeout,o=a.propCount;if(!r)return t();var s="transition"===r?_i:ki,l=0,c=function(){e.removeEventListener(s,d),t()},d=function(n){n.target===e&&++l>=o&&c()};setTimeout((function(){l<o&&c()}),i+1),e.addEventListener(s,d)}var Ci=/\b(transform|all)(,|$)/;function ji(e,n){var t,a=window.getComputedStyle(e),r=(a[wi+"Delay"]||"").split(", "),i=(a[wi+"Duration"]||"").split(", "),o=Oi(r,i),s=(a[xi+"Delay"]||"").split(", "),l=(a[xi+"Duration"]||"").split(", "),c=Oi(s,l),d=0,u=0;return"transition"===n?o>0&&(t="transition",d=o,u=i.length):"animation"===n?c>0&&(t="animation",d=c,u=l.length):u=(t=(d=Math.max(o,c))>0?o>c?"transition":"animation":null)?"transition"===t?i.length:l.length:0,{type:t,timeout:d,propCount:u,hasTransform:"transition"===t&&Ci.test(a[wi+"Property"])}}function Oi(e,n){for(;e.length<n.length;)e=e.concat(e);return Math.max.apply(null,n.map((function(n,t){return Li(n)+Li(e[t])})))}function Li(e){return 1e3*Number(e.slice(0,-1).replace(",","."))}function Ni(e,n){var t=e.elm;o(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var a=vi(e.data.transition);if(!i(a)&&!o(t._enterCb)&&1===t.nodeType){for(var r=a.css,s=a.type,l=a.enterClass,u=a.enterToClass,p=a.enterActiveClass,m=a.appearClass,h=a.appearToClass,f=a.appearActiveClass,g=a.beforeEnter,v=a.enter,y=a.afterEnter,w=a.enterCancelled,_=a.beforeAppear,x=a.appear,k=a.afterAppear,T=a.appearCancelled,E=a.duration,S=ta,I=ta.$vnode;I&&I.parent;)S=I.context,I=I.parent;var A=!S._isMounted||!e.isRootInsert;if(!A||x||""===x){var C=A&&m?m:l,j=A&&f?f:p,O=A&&h?h:u,L=A&&_||g,N=A&&c(x)?x:v,D=A&&k||y,P=A&&T||w,M=b(d(E)?E.enter:E);0;var R=!1!==r&&!Q,z=Mi(N),J=t._enterCb=q((function(){R&&(Ii(t,O),Ii(t,j)),J.cancelled?(R&&Ii(t,C),P&&P(t)):D&&D(t),t._enterCb=null}));e.data.show||Cn(e,"insert",(function(){var n=t.parentNode,a=n&&n._pending&&n._pending[e.key];a&&a.tag===e.tag&&a.elm._leaveCb&&a.elm._leaveCb(),N&&N(t,J)})),L&&L(t),R&&(Si(t,C),Si(t,j),Ei((function(){Ii(t,C),J.cancelled||(Si(t,O),z||(Pi(M)?setTimeout(J,M):Ai(t,s,J)))}))),e.data.show&&(n&&n(),N&&N(t,J)),R||z||J()}}}function Di(e,n){var t=e.elm;o(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var a=vi(e.data.transition);if(i(a)||1!==t.nodeType)return n();if(!o(t._leaveCb)){var r=a.css,s=a.type,l=a.leaveClass,c=a.leaveToClass,u=a.leaveActiveClass,p=a.beforeLeave,m=a.leave,h=a.afterLeave,f=a.leaveCancelled,g=a.delayLeave,v=a.duration,y=!1!==r&&!Q,w=Mi(m),_=b(d(v)?v.leave:v);0;var x=t._leaveCb=q((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[e.key]=null),y&&(Ii(t,c),Ii(t,u)),x.cancelled?(y&&Ii(t,l),f&&f(t)):(n(),h&&h(t)),t._leaveCb=null}));g?g(k):k()}function k(){x.cancelled||(!e.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[e.key]=e),p&&p(t),y&&(Si(t,l),Si(t,u),Ei((function(){Ii(t,l),x.cancelled||(Si(t,c),w||(Pi(_)?setTimeout(x,_):Ai(t,s,x)))}))),m&&m(t,x),y||w||x())}}function Pi(e){return"number"==typeof e&&!isNaN(e)}function Mi(e){if(i(e))return!1;var n=e.fns;return o(n)?Mi(Array.isArray(n)?n[0]:n):(e._length||e.length)>1}function Ri(e,n){!0!==n.data.show&&Ni(n)}var zi=function(e){var n,t,a={},c=e.modules,d=e.nodeOps;for(n=0;n<jr.length;++n)for(a[jr[n]]=[],t=0;t<c.length;++t)o(c[t][jr[n]])&&a[jr[n]].push(c[t][jr[n]]);function u(e){var n=d.parentNode(e);o(n)&&d.removeChild(n,e)}function p(e,n,t,r,i,l,c){if(o(e.elm)&&o(l)&&(e=l[c]=ve(e)),e.isRootInsert=!i,!function(e,n,t,r){var i=e.data;if(o(i)){var l=o(e.componentInstance)&&i.keepAlive;if(o(i=i.hook)&&o(i=i.init)&&i(e,!1),o(e.componentInstance))return m(e,n),h(t,e.elm,r),s(l)&&function(e,n,t,r){var i,s=e;for(;s.componentInstance;)if(s=s.componentInstance._vnode,o(i=s.data)&&o(i=i.transition)){for(i=0;i<a.activate.length;++i)a.activate[i](Cr,s);n.push(s);break}h(t,e.elm,r)}(e,n,t,r),!0}}(e,n,t,r)){var u=e.data,p=e.children,g=e.tag;o(g)?(e.elm=e.ns?d.createElementNS(e.ns,g):d.createElement(g,e),b(e),f(e,p,n),o(u)&&v(e,n),h(t,e.elm,r)):s(e.isComment)?(e.elm=d.createComment(e.text),h(t,e.elm,r)):(e.elm=d.createTextNode(e.text),h(t,e.elm,r))}}function m(e,n){o(e.data.pendingInsert)&&(n.push.apply(n,e.data.pendingInsert),e.data.pendingInsert=null),e.elm=e.componentInstance.$el,g(e)?(v(e,n),b(e)):(Ir(e),n.push(e))}function h(e,n,t){o(e)&&(o(t)?d.parentNode(t)===e&&d.insertBefore(e,n,t):d.appendChild(e,n))}function f(e,n,t){if(r(n)){0;for(var a=0;a<n.length;++a)p(n[a],t,e.elm,null,!0,n,a)}else l(e.text)&&d.appendChild(e.elm,d.createTextNode(String(e.text)))}function g(e){for(;e.componentInstance;)e=e.componentInstance._vnode;return o(e.tag)}function v(e,t){for(var r=0;r<a.create.length;++r)a.create[r](Cr,e);o(n=e.data.hook)&&(o(n.create)&&n.create(Cr,e),o(n.insert)&&t.push(e))}function b(e){var n;if(o(n=e.fnScopeId))d.setStyleScope(e.elm,n);else for(var t=e;t;)o(n=t.context)&&o(n=n.$options._scopeId)&&d.setStyleScope(e.elm,n),t=t.parent;o(n=ta)&&n!==e.context&&n!==e.fnContext&&o(n=n.$options._scopeId)&&d.setStyleScope(e.elm,n)}function w(e,n,t,a,r,i){for(;a<=r;++a)p(t[a],i,e,n,!1,t,a)}function _(e){var n,t,r=e.data;if(o(r))for(o(n=r.hook)&&o(n=n.destroy)&&n(e),n=0;n<a.destroy.length;++n)a.destroy[n](e);if(o(n=e.children))for(t=0;t<e.children.length;++t)_(e.children[t])}function x(e,n,t){for(;n<=t;++n){var a=e[n];o(a)&&(o(a.tag)?(k(a),_(a)):u(a.elm))}}function k(e,n){if(o(n)||o(e.data)){var t,r=a.remove.length+1;for(o(n)?n.listeners+=r:n=function(e,n){function t(){0==--t.listeners&&u(e)}return t.listeners=n,t}(e.elm,r),o(t=e.componentInstance)&&o(t=t._vnode)&&o(t.data)&&k(t,n),t=0;t<a.remove.length;++t)a.remove[t](e,n);o(t=e.data.hook)&&o(t=t.remove)?t(e,n):n()}else u(e.elm)}function T(e,n,t,a){for(var r=t;r<a;r++){var i=n[r];if(o(i)&&Or(e,i))return r}}function E(e,n,t,r,l,c){if(e!==n){o(n.elm)&&o(r)&&(n=r[l]=ve(n));var u=n.elm=e.elm;if(s(e.isAsyncPlaceholder))o(n.asyncFactory.resolved)?A(e.elm,n,t):n.isAsyncPlaceholder=!0;else if(s(n.isStatic)&&s(e.isStatic)&&n.key===e.key&&(s(n.isCloned)||s(n.isOnce)))n.componentInstance=e.componentInstance;else{var m,h=n.data;o(h)&&o(m=h.hook)&&o(m=m.prepatch)&&m(e,n);var f=e.children,v=n.children;if(o(h)&&g(n)){for(m=0;m<a.update.length;++m)a.update[m](e,n);o(m=h.hook)&&o(m=m.update)&&m(e,n)}i(n.text)?o(f)&&o(v)?f!==v&&function(e,n,t,a,r){var s,l,c,u=0,m=0,h=n.length-1,f=n[0],g=n[h],v=t.length-1,b=t[0],y=t[v],_=!r;for(0;u<=h&&m<=v;)i(f)?f=n[++u]:i(g)?g=n[--h]:Or(f,b)?(E(f,b,a,t,m),f=n[++u],b=t[++m]):Or(g,y)?(E(g,y,a,t,v),g=n[--h],y=t[--v]):Or(f,y)?(E(f,y,a,t,v),_&&d.insertBefore(e,f.elm,d.nextSibling(g.elm)),f=n[++u],y=t[--v]):Or(g,b)?(E(g,b,a,t,m),_&&d.insertBefore(e,g.elm,f.elm),g=n[--h],b=t[++m]):(i(s)&&(s=Lr(n,u,h)),i(l=o(b.key)?s[b.key]:T(b,n,u,h))?p(b,a,e,f.elm,!1,t,m):Or(c=n[l],b)?(E(c,b,a,t,m),n[l]=void 0,_&&d.insertBefore(e,c.elm,f.elm)):p(b,a,e,f.elm,!1,t,m),b=t[++m]);u>h?w(e,i(t[v+1])?null:t[v+1].elm,t,m,v,a):m>v&&x(n,u,h)}(u,f,v,t,c):o(v)?(o(e.text)&&d.setTextContent(u,""),w(u,null,v,0,v.length-1,t)):o(f)?x(f,0,f.length-1):o(e.text)&&d.setTextContent(u,""):e.text!==n.text&&d.setTextContent(u,n.text),o(h)&&o(m=h.hook)&&o(m=m.postpatch)&&m(e,n)}}}function S(e,n,t){if(s(t)&&o(e.parent))e.parent.data.pendingInsert=n;else for(var a=0;a<n.length;++a)n[a].data.hook.insert(n[a])}var I=y("attrs,class,staticClass,staticStyle,key");function A(e,n,t,a){var r,i=n.tag,l=n.data,c=n.children;if(a=a||l&&l.pre,n.elm=e,s(n.isComment)&&o(n.asyncFactory))return n.isAsyncPlaceholder=!0,!0;if(o(l)&&(o(r=l.hook)&&o(r=r.init)&&r(n,!0),o(r=n.componentInstance)))return m(n,t),!0;if(o(i)){if(o(c))if(e.hasChildNodes())if(o(r=l)&&o(r=r.domProps)&&o(r=r.innerHTML)){if(r!==e.innerHTML)return!1}else{for(var d=!0,u=e.firstChild,p=0;p<c.length;p++){if(!u||!A(u,c[p],t,a)){d=!1;break}u=u.nextSibling}if(!d||u)return!1}else f(n,c,t);if(o(l)){var h=!1;for(var g in l)if(!I(g)){h=!0,v(n,t);break}!h&&l.class&&Wt(l.class)}}else e.data!==n.text&&(e.data=n.text);return!0}return function(e,n,t,r){if(!i(n)){var l,c=!1,u=[];if(i(e))c=!0,p(n,u);else{var m=o(e.nodeType);if(!m&&Or(e,n))E(e,n,u,null,null,r);else{if(m){if(1===e.nodeType&&e.hasAttribute("data-server-rendered")&&(e.removeAttribute("data-server-rendered"),t=!0),s(t)&&A(e,n,u))return S(n,u,!0),e;l=e,e=new he(d.tagName(l).toLowerCase(),{},[],void 0,l)}var h=e.elm,f=d.parentNode(h);if(p(n,u,h._leaveCb?null:f,d.nextSibling(h)),o(n.parent))for(var v=n.parent,b=g(n);v;){for(var y=0;y<a.destroy.length;++y)a.destroy[y](v);if(v.elm=n.elm,b){for(var w=0;w<a.create.length;++w)a.create[w](Cr,v);var k=v.data.hook.insert;if(k.merged)for(var T=k.fns.slice(1),I=0;I<T.length;I++)T[I]()}else Ir(v);v=v.parent}o(f)?x([e],0,0):o(e.tag)&&_(e)}}return S(n,u,c),n.elm}o(e)&&_(e)}}({nodeOps:Er,modules:[Ur,Gr,Xr,ti,mi,Y?{create:Ri,activate:Ri,remove:function(e,n){!0!==e.data.show?Di(e,n):n()}}:{}].concat(qr)});Q&&document.addEventListener("selectionchange",(function(){var e=document.activeElement;e&&e.vmodel&&Gi(e,"input")}));var qi={inserted:function(e,n,t,a){"select"===t.tag?(a.elm&&!a.elm._vOptions?Cn(t,"postpatch",(function(){qi.componentUpdated(e,n,t)})):Ji(e,n,t.context),e._vOptions=[].map.call(e.options,Ui)):("textarea"===t.tag||Tr(e.type))&&(e._vModifiers=n.modifiers,n.modifiers.lazy||(e.addEventListener("compositionstart",Hi),e.addEventListener("compositionend",$i),e.addEventListener("change",$i),Q&&(e.vmodel=!0)))},componentUpdated:function(e,n,t){if("select"===t.tag){Ji(e,n,t.context);var a=e._vOptions,r=e._vOptions=[].map.call(e.options,Ui);if(r.some((function(e,n){return!R(e,a[n])})))(e.multiple?n.value.some((function(e){return Bi(e,r)})):n.value!==n.oldValue&&Bi(n.value,r))&&Gi(e,"change")}}};function Ji(e,n,t){Fi(e,n,t),(Z||X)&&setTimeout((function(){Fi(e,n,t)}),0)}function Fi(e,n,t){var a=n.value,r=e.multiple;if(!r||Array.isArray(a)){for(var i,o,s=0,l=e.options.length;s<l;s++)if(o=e.options[s],r)i=z(a,Ui(o))>-1,o.selected!==i&&(o.selected=i);else if(R(Ui(o),a))return void(e.selectedIndex!==s&&(e.selectedIndex=s));r||(e.selectedIndex=-1)}}function Bi(e,n){return n.every((function(n){return!R(n,e)}))}function Ui(e){return"_value"in e?e._value:e.value}function Hi(e){e.target.composing=!0}function $i(e){e.target.composing&&(e.target.composing=!1,Gi(e.target,"input"))}function Gi(e,n){var t=document.createEvent("HTMLEvents");t.initEvent(n,!0,!0),e.dispatchEvent(t)}function Ki(e){return!e.componentInstance||e.data&&e.data.transition?e:Ki(e.componentInstance._vnode)}var Wi={model:qi,show:{bind:function(e,n,t){var a=n.value,r=(t=Ki(t)).data&&t.data.transition,i=e.__vOriginalDisplay="none"===e.style.display?"":e.style.display;a&&r?(t.data.show=!0,Ni(t,(function(){e.style.display=i}))):e.style.display=a?i:"none"},update:function(e,n,t){var a=n.value;!a!=!n.oldValue&&((t=Ki(t)).data&&t.data.transition?(t.data.show=!0,a?Ni(t,(function(){e.style.display=e.__vOriginalDisplay})):Di(t,(function(){e.style.display="none"}))):e.style.display=a?e.__vOriginalDisplay:"none")},unbind:function(e,n,t,a,r){r||(e.style.display=e.__vOriginalDisplay)}}},Yi={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Vi(e){var n=e&&e.componentOptions;return n&&n.Ctor.options.abstract?Vi(ut(n.children)):e}function Zi(e){var n={},t=e.$options;for(var a in t.propsData)n[a]=e[a];var r=t._parentListeners;for(var a in r)n[S(a)]=r[a];return n}function Qi(e,n){if(/\d-keep-alive$/.test(n.tag))return e("keep-alive",{props:n.componentOptions.propsData})}var Xi=function(e){return e.tag||Vn(e)},eo=function(e){return"show"===e.name},no={name:"transition",props:Yi,abstract:!0,render:function(e){var n=this,t=this.$slots.default;if(t&&(t=t.filter(Xi)).length){0;var a=this.mode;0;var r=t[0];if(function(e){for(;e=e.parent;)if(e.data.transition)return!0}(this.$vnode))return r;var i=Vi(r);if(!i)return r;if(this._leaving)return Qi(e,r);var o="__transition-".concat(this._uid,"-");i.key=null==i.key?i.isComment?o+"comment":o+i.tag:l(i.key)?0===String(i.key).indexOf(o)?i.key:o+i.key:i.key;var s=(i.data||(i.data={})).transition=Zi(this),c=this._vnode,d=Vi(c);if(i.data.directives&&i.data.directives.some(eo)&&(i.data.show=!0),d&&d.data&&!function(e,n){return n.key===e.key&&n.tag===e.tag}(i,d)&&!Vn(d)&&(!d.componentInstance||!d.componentInstance._vnode.isComment)){var u=d.data.transition=L({},s);if("out-in"===a)return this._leaving=!0,Cn(u,"afterLeave",(function(){n._leaving=!1,n.$forceUpdate()})),Qi(e,r);if("in-out"===a){if(Vn(i))return c;var p,m=function(){p()};Cn(s,"afterEnter",m),Cn(s,"enterCancelled",m),Cn(u,"delayLeave",(function(e){p=e}))}}return r}}},to=L({tag:String,moveClass:String},Yi);function ao(e){e.elm._moveCb&&e.elm._moveCb(),e.elm._enterCb&&e.elm._enterCb()}function ro(e){e.data.newPos=e.elm.getBoundingClientRect()}function io(e){var n=e.data.pos,t=e.data.newPos,a=n.left-t.left,r=n.top-t.top;if(a||r){e.data.moved=!0;var i=e.elm.style;i.transform=i.WebkitTransform="translate(".concat(a,"px,").concat(r,"px)"),i.transitionDuration="0s"}}delete to.mode;var oo={Transition:no,TransitionGroup:{props:to,beforeMount:function(){var e=this,n=this._update;this._update=function(t,a){var r=aa(e);e.__patch__(e._vnode,e.kept,!1,!0),e._vnode=e.kept,r(),n.call(e,t,a)}},render:function(e){for(var n=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),a=this.prevChildren=this.children,r=this.$slots.default||[],i=this.children=[],o=Zi(this),s=0;s<r.length;s++){if((d=r[s]).tag)if(null!=d.key&&0!==String(d.key).indexOf("__vlist"))i.push(d),t[d.key]=d,(d.data||(d.data={})).transition=o;else;}if(a){var l=[],c=[];for(s=0;s<a.length;s++){var d;(d=a[s]).data.transition=o,d.data.pos=d.elm.getBoundingClientRect(),t[d.key]?l.push(d):c.push(d)}this.kept=e(n,null,l),this.removed=c}return e(n,null,i)},updated:function(){var e=this.prevChildren,n=this.moveClass||(this.name||"v")+"-move";e.length&&this.hasMove(e[0].elm,n)&&(e.forEach(ao),e.forEach(ro),e.forEach(io),this._reflow=document.body.offsetHeight,e.forEach((function(e){if(e.data.moved){var t=e.elm,a=t.style;Si(t,n),a.transform=a.WebkitTransform=a.transitionDuration="",t.addEventListener(_i,t._moveCb=function e(a){a&&a.target!==t||a&&!/transform$/.test(a.propertyName)||(t.removeEventListener(_i,e),t._moveCb=null,Ii(t,n))})}})))},methods:{hasMove:function(e,n){if(!yi)return!1;if(this._hasMove)return this._hasMove;var t=e.cloneNode();e._transitionClasses&&e._transitionClasses.forEach((function(e){gi(t,e)})),fi(t,n),t.style.display="none",this.$el.appendChild(t);var a=ji(t);return this.$el.removeChild(t),this._hasMove=a.hasTransform}}}};Qa.config.mustUseProp=function(e,n,t){return"value"===t&&sr(e)&&"button"!==n||"selected"===t&&"option"===e||"checked"===t&&"input"===e||"muted"===t&&"video"===e},Qa.config.isReservedTag=xr,Qa.config.isReservedAttr=or,Qa.config.getTagNamespace=function(e){return _r(e)?"svg":"math"===e?"math":void 0},Qa.config.isUnknownElement=function(e){if(!Y)return!0;if(xr(e))return!1;if(e=e.toLowerCase(),null!=kr[e])return kr[e];var n=document.createElement(e);return e.indexOf("-")>-1?kr[e]=n.constructor===window.HTMLUnknownElement||n.constructor===window.HTMLElement:kr[e]=/HTMLUnknownElement/.test(n.toString())},L(Qa.options.directives,Wi),L(Qa.options.components,oo),Qa.prototype.__patch__=Y?zi:D,Qa.prototype.$mount=function(e,n){return function(e,n,t){var a;e.$el=n,e.$options.render||(e.$options.render=fe),oa(e,"beforeMount"),a=function(){e._update(e._render(),t)},new Zt(e,a,D,{before:function(){e._isMounted&&!e._isDestroyed&&oa(e,"beforeUpdate")}},!0),t=!1;var r=e._preWatchers;if(r)for(var i=0;i<r.length;i++)r[i].run();return null==e.$vnode&&(e._isMounted=!0,oa(e,"mounted")),e}(this,e=e&&Y?function(e){if("string"==typeof e){var n=document.querySelector(e);return n||document.createElement("div")}return e}(e):void 0,n)},Y&&setTimeout((function(){U.devtools&&se&&se.emit("init",Qa)}),0)},function(e,n,t){"use strict";var a=function(e){return e&&e.Math===Math&&e};e.exports=a("object"==typeof globalThis&&globalThis)||a("object"==typeof window&&window)||a("object"==typeof self&&self)||a("object"==typeof global&&global)||a("object"==typeof this&&this)||function(){return this}()||Function("return this")()},function(e,n,t){"use strict";var a="object"==typeof document&&document.all;e.exports=void 0===a&&void 0!==a?function(e){return"function"==typeof e||e===a}:function(e){return"function"==typeof e}},function(e,n,t){"use strict";var a=t(27),r=Function.prototype,i=r.call,o=a&&r.bind.bind(i,i);e.exports=a?o:function(e){return function(){return i.apply(e,arguments)}}},function(e,n,t){"use strict";e.exports=function(e){try{return!!e()}catch(e){return!0}}},function(e,n,t){"use strict";var a=t(4);e.exports=!a((function(){return 7!==Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(e,n){var t=Array.isArray;e.exports=t},function(e,n,t){"use strict";var a=t(2);e.exports=function(e){return"object"==typeof e?null!==e:a(e)}},function(e,n,t){var a=t(69),r="object"==typeof self&&self&&self.Object===Object&&self,i=a||r||Function("return this")();e.exports=i},function(e,n,t){"use strict";function a(e,n,t,a,r,i,o,s){var l,c="function"==typeof e?e.options:e;if(n&&(c.render=n,c.staticRenderFns=t,c._compiled=!0),a&&(c.functional=!0),i&&(c._scopeId="data-v-"+i),o?(l=function(e){(e=e||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(e=__VUE_SSR_CONTEXT__),r&&r.call(this,e),e&&e._registeredComponents&&e._registeredComponents.add(o)},c._ssrRegister=l):r&&(l=s?function(){r.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:r),l)if(c.functional){c._injectStyles=l;var d=c.render;c.render=function(e,n){return l.call(n),d(e,n)}}else{var u=c.beforeCreate;c.beforeCreate=u?[].concat(u,l):[l]}return{exports:e,options:c}}t.d(n,"a",(function(){return a}))},function(e,n,t){"use strict";var a=t(3),r=t(32),i=a({}.hasOwnProperty);e.exports=Object.hasOwn||function(e,n){return i(r(e),n)}},function(e,n,t){var a=t(164),r=t(167);e.exports=function(e,n){var t=r(e,n);return a(t)?t:void 0}},function(e,n,t){"use strict";t.d(n,"e",(function(){return a})),t.d(n,"b",(function(){return i})),t.d(n,"j",(function(){return o})),t.d(n,"g",(function(){return l})),t.d(n,"h",(function(){return c})),t.d(n,"i",(function(){return d})),t.d(n,"c",(function(){return u})),t.d(n,"f",(function(){return p})),t.d(n,"l",(function(){return m})),t.d(n,"m",(function(){return h})),t.d(n,"d",(function(){return g})),t.d(n,"k",(function(){return v})),t.d(n,"n",(function(){return b})),t.d(n,"a",(function(){return w}));t(17);const a=/#.*$/,r=/\.(md|html)$/,i=/\/$/,o=/^[a-z]+:/i;function s(e){return decodeURI(e).replace(a,"").replace(r,"")}function l(e){return o.test(e)}function c(e){return/^mailto:/.test(e)}function d(e){return/^tel:/.test(e)}function u(e){if(l(e))return e;if(!e)return"404";const n=e.match(a),t=n?n[0]:"",r=s(e);return i.test(r)?e:r+".html"+t}function p(e,n){const t=e.hash,r=function(e){const n=e&&e.match(a);if(n)return n[0]}(n);if(r&&t!==r)return!1;return s(e.path)===s(n)}function m(e,n,t){if(l(n))return{type:"external",path:n};t&&(n=function(e,n,t){const a=e.charAt(0);if("/"===a)return e;if("?"===a||"#"===a)return n+e;const r=n.split("/");t&&r[r.length-1]||r.pop();const i=e.replace(/^\//,"").split("/");for(let e=0;e<i.length;e++){const n=i[e];".."===n?r.pop():"."!==n&&r.push(n)}""!==r[0]&&r.unshift("");return r.join("/")}(n,t));const a=s(n);for(let n=0;n<e.length;n++)if(s(e[n].regularPath)===a)return Object.assign({},e[n],{type:"page",path:u(e[n].path)});return console.error(`[vuepress] No matching page found for sidebar item "${n}"`),{}}function h(e,n,t,a){const{pages:r,themeConfig:i}=t,o=a&&i.locales&&i.locales[a]||i;if("auto"===(e.frontmatter.sidebar||o.sidebar||i.sidebar))return f(e);const s=o.sidebar||i.sidebar;if(s){const{base:t,config:a}=function(e,n){if(Array.isArray(n))return{base:"/",config:n};for(const a in n)if(0===(t=e,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(a)))return{base:a,config:n[a]};var t;return{}}(n,s);return"auto"===a?f(e):a?a.map(e=>function e(n,t,a,r=1){if("string"==typeof n)return m(t,n,a);if(Array.isArray(n))return Object.assign(m(t,n[0],a),{title:n[1]});{r>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const i=n.children||[];return 0===i.length&&n.path?Object.assign(m(t,n.path,a),{title:n.title}):{type:"group",path:n.path,title:n.title,sidebarDepth:n.sidebarDepth,initialOpenGroupIndex:n.initialOpenGroupIndex,children:i.map(n=>e(n,t,a,r+1)),collapsable:!1!==n.collapsable}}}(e,r,t)):[]}return[]}function f(e){const n=g(e.headers||[]);return[{type:"group",collapsable:!1,title:e.title,path:null,children:n.map(n=>({type:"auto",title:n.title,basePath:e.path,path:e.path+"#"+n.slug,children:n.children||[]}))}]}function g(e){let n;return(e=e.map(e=>Object.assign({},e))).forEach(e=>{2===e.level?n=e:n&&(n.children||(n.children=[])).push(e)}),e.filter(e=>2===e.level)}function v(e){return Object.assign(e,{type:e.items&&e.items.length?"links":"link"})}function b(e){return Object.prototype.toString.call(e).match(/\[object (.*?)\]/)[1].toLowerCase()}function y(e){let n=e.frontmatter.date||e.lastUpdated||new Date,t=new Date(n);return"Invalid Date"==t&&n&&(t=new Date(n.replace(/-/g,"/"))),t.getTime()}function w(e,n){return y(n)-y(e)}},function(e,n){e.exports=function(e){return null!=e&&"object"==typeof e}},function(e,n,t){var a=t(16),r=t(149),i=t(150),o=a?a.toStringTag:void 0;e.exports=function(e){return null==e?void 0===e?"[object Undefined]":"[object Null]":o&&o in Object(e)?r(e):i(e)}},function(e,n,t){"use strict";var a=t(5),r=t(18),i=t(35);e.exports=a?function(e,n,t){return r.f(e,n,i(1,t))}:function(e,n,t){return e[n]=t,e}},function(e,n,t){var a=t(8).Symbol;e.exports=a},function(e,n,t){"use strict";var a=t(26),r=t(32),i=t(33),o=t(143),s=t(145);a({target:"Array",proto:!0,arity:1,forced:t(4)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(e){return e instanceof TypeError}}()},{push:function(e){var n=r(this),t=i(n),a=arguments.length;s(t+a);for(var l=0;l<a;l++)n[t]=arguments[l],t++;return o(n,t),t}})},function(e,n,t){"use strict";var a=t(5),r=t(64),i=t(100),o=t(48),s=t(55),l=TypeError,c=Object.defineProperty,d=Object.getOwnPropertyDescriptor;n.f=a?i?function(e,n,t){if(o(e),n=s(n),o(t),"function"==typeof e&&"prototype"===n&&"value"in t&&"writable"in t&&!t.writable){var a=d(e,n);a&&a.writable&&(e[n]=t.value,t={configurable:"configurable"in t?t.configurable:a.configurable,enumerable:"enumerable"in t?t.enumerable:a.enumerable,writable:!1})}return c(e,n,t)}:c:function(e,n,t){if(o(e),n=s(n),o(t),r)try{return c(e,n,t)}catch(e){}if("get"in t||"set"in t)throw new l("Accessors not supported");return"value"in t&&(e[n]=t.value),e}},function(e,n,t){"use strict";var a=t(3),r=a({}.toString),i=a("".slice);e.exports=function(e){return i(r(e),8,-1)}},function(e,n,t){var a=t(154),r=t(155),i=t(156),o=t(157),s=t(158);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var a=e[n];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,e.exports=l},function(e,n,t){var a=t(71);e.exports=function(e,n){for(var t=e.length;t--;)if(a(e[t][0],n))return t;return-1}},function(e,n,t){var a=t(11)(Object,"create");e.exports=a},function(e,n,t){var a=t(176);e.exports=function(e,n){var t=e.__data__;return a(n)?t["string"==typeof n?"string":"hash"]:t.map}},function(e,n,t){var a=t(46);e.exports=function(e){if("string"==typeof e||a(e))return e;var n=e+"";return"0"==n&&1/e==-1/0?"-0":n}},function(e,n,t){var a,r;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(r="function"==typeof(a=function(){var e,n,t={version:"0.2.0"},a=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function r(e,n,t){return e<n?n:e>t?t:e}function i(e){return 100*(-1+e)}t.configure=function(e){var n,t;for(n in e)void 0!==(t=e[n])&&e.hasOwnProperty(n)&&(a[n]=t);return this},t.status=null,t.set=function(e){var n=t.isStarted();e=r(e,a.minimum,1),t.status=1===e?null:e;var l=t.render(!n),c=l.querySelector(a.barSelector),d=a.speed,u=a.easing;return l.offsetWidth,o((function(n){""===a.positionUsing&&(a.positionUsing=t.getPositioningCSS()),s(c,function(e,n,t){var r;return(r="translate3d"===a.positionUsing?{transform:"translate3d("+i(e)+"%,0,0)"}:"translate"===a.positionUsing?{transform:"translate("+i(e)+"%,0)"}:{"margin-left":i(e)+"%"}).transition="all "+n+"ms "+t,r}(e,d,u)),1===e?(s(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){s(l,{transition:"all "+d+"ms linear",opacity:0}),setTimeout((function(){t.remove(),n()}),d)}),d)):setTimeout(n,d)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var e=function(){setTimeout((function(){t.status&&(t.trickle(),e())}),a.trickleSpeed)};return a.trickle&&e(),this},t.done=function(e){return e||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(e){var n=t.status;return n?("number"!=typeof e&&(e=(1-n)*r(Math.random()*n,.1,.95)),n=r(n+e,0,.994),t.set(n)):t.start()},t.trickle=function(){return t.inc(Math.random()*a.trickleRate)},e=0,n=0,t.promise=function(a){return a&&"resolved"!==a.state()?(0===n&&t.start(),e++,n++,a.always((function(){0==--n?(e=0,t.done()):t.set((e-n)/e)})),this):this},t.render=function(e){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var n=document.createElement("div");n.id="nprogress",n.innerHTML=a.template;var r,o=n.querySelector(a.barSelector),l=e?"-100":i(t.status||0),d=document.querySelector(a.parent);return s(o,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),a.showSpinner||(r=n.querySelector(a.spinnerSelector))&&p(r),d!=document.body&&c(d,"nprogress-custom-parent"),d.appendChild(n),n},t.remove=function(){d(document.documentElement,"nprogress-busy"),d(document.querySelector(a.parent),"nprogress-custom-parent");var e=document.getElementById("nprogress");e&&p(e)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var e=document.body.style,n="WebkitTransform"in e?"Webkit":"MozTransform"in e?"Moz":"msTransform"in e?"ms":"OTransform"in e?"O":"";return n+"Perspective"in e?"translate3d":n+"Transform"in e?"translate":"margin"};var o=function(){var e=[];function n(){var t=e.shift();t&&t(n)}return function(t){e.push(t),1==e.length&&n()}}(),s=function(){var e=["Webkit","O","Moz","ms"],n={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(e,n){return n.toUpperCase()})),n[t]||(n[t]=function(n){var t=document.body.style;if(n in t)return n;for(var a,r=e.length,i=n.charAt(0).toUpperCase()+n.slice(1);r--;)if((a=e[r]+i)in t)return a;return n}(t))}function a(e,n,a){n=t(n),e.style[n]=a}return function(e,n){var t,r,i=arguments;if(2==i.length)for(t in n)void 0!==(r=n[t])&&n.hasOwnProperty(t)&&a(e,t,r);else a(e,i[1],i[2])}}();function l(e,n){return("string"==typeof e?e:u(e)).indexOf(" "+n+" ")>=0}function c(e,n){var t=u(e),a=t+n;l(t,n)||(e.className=a.substring(1))}function d(e,n){var t,a=u(e);l(e,n)&&(t=a.replace(" "+n+" "," "),e.className=t.substring(1,t.length-1))}function u(e){return(" "+(e.className||"")+" ").replace(/\s+/gi," ")}function p(e){e&&e.parentNode&&e.parentNode.removeChild(e)}return t})?a.call(n,t,n,e):a)||(e.exports=r)},function(e,n,t){"use strict";var a=t(1),r=t(53).f,i=t(15),o=t(96),s=t(38),l=t(65),c=t(124);e.exports=function(e,n){var t,d,u,p,m,h=e.target,f=e.global,g=e.stat;if(t=f?a:g?a[h]||s(h,{}):a[h]&&a[h].prototype)for(d in n){if(p=n[d],u=e.dontCallGetSet?(m=r(t,d))&&m.value:t[d],!c(f?d:h+(g?".":"#")+d,e.forced)&&void 0!==u){if(typeof p==typeof u)continue;l(p,u)}(e.sham||u&&u.sham)&&i(p,"sham",!0),o(t,d,p,e)}}},function(e,n,t){"use strict";var a=t(4);e.exports=!a((function(){var e=function(){}.bind();return"function"!=typeof e||e.hasOwnProperty("prototype")}))},function(e,n,t){"use strict";var a=t(50),r=t(36);e.exports=function(e){return a(r(e))}},function(e,n,t){"use strict";var a=t(1),r=t(2),i=function(e){return r(e)?e:void 0};e.exports=function(e,n){return arguments.length<2?i(a[e]):a[e]&&a[e][n]}},function(e,n,t){"use strict";var a=t(2),r=t(111),i=TypeError;e.exports=function(e){if(a(e))return e;throw new i(r(e)+" is not a function")}},function(e,n,t){"use strict";var a=t(1),r=t(61),i=t(10),o=t(63),s=t(59),l=t(58),c=a.Symbol,d=r("wks"),u=l?c.for||c:c&&c.withoutSetter||o;e.exports=function(e){return i(d,e)||(d[e]=s&&i(c,e)?c[e]:u("Symbol."+e)),d[e]}},function(e,n,t){"use strict";var a=t(36),r=Object;e.exports=function(e){return r(a(e))}},function(e,n,t){"use strict";var a=t(122);e.exports=function(e){return a(e.length)}},function(e,n,t){"use strict";var a=t(27),r=Function.prototype.call;e.exports=a?r.bind(r):function(){return r.apply(r,arguments)}},function(e,n,t){"use strict";e.exports=function(e,n){return{enumerable:!(1&e),configurable:!(2&e),writable:!(4&e),value:n}}},function(e,n,t){"use strict";var a=t(54),r=TypeError;e.exports=function(e){if(a(e))throw new r("Can't call method on "+e);return e}},function(e,n,t){"use strict";var a=t(62),r=t(1),i=t(38),o=e.exports=r["__core-js_shared__"]||i("__core-js_shared__",{});(o.versions||(o.versions=[])).push({version:"3.37.1",mode:a?"pure":"global",copyright:"© 2014-2024 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.37.1/LICENSE",source:"https://github.com/zloirock/core-js"})},function(e,n,t){"use strict";var a=t(1),r=Object.defineProperty;e.exports=function(e,n){try{r(a,e,{value:n,configurable:!0,writable:!0})}catch(t){a[e]=n}return n}},function(e,n,t){var a=t(148),r=t(13),i=Object.prototype,o=i.hasOwnProperty,s=i.propertyIsEnumerable,l=a(function(){return arguments}())?a:function(e){return r(e)&&o.call(e,"callee")&&!s.call(e,"callee")};e.exports=l},function(e,n,t){var a=t(11)(t(8),"Map");e.exports=a},function(e,n){e.exports=function(e){var n=typeof e;return null!=e&&("object"==n||"function"==n)}},function(e,n,t){var a=t(168),r=t(175),i=t(177),o=t(178),s=t(179);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var a=e[n];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,e.exports=l},function(e,n){e.exports=function(e){var n=-1,t=Array(e.size);return e.forEach((function(e){t[++n]=e})),t}},function(e,n){e.exports=function(e){return"number"==typeof e&&e>-1&&e%1==0&&e<=9007199254740991}},function(e,n,t){var a=t(6),r=t(46),i=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,o=/^\w*$/;e.exports=function(e,n){if(a(e))return!1;var t=typeof e;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=e&&!r(e))||(o.test(e)||!i.test(e)||null!=n&&e in Object(n))}},function(e,n,t){var a=t(14),r=t(13);e.exports=function(e){return"symbol"==typeof e||r(e)&&"[object Symbol]"==a(e)}},function(e,n){e.exports=function(e){return e}},function(e,n,t){"use strict";var a=t(7),r=String,i=TypeError;e.exports=function(e){if(a(e))return e;throw new i(r(e)+" is not an object")}},function(e,n){e.exports=function(e){return e.webpackPolyfill||(e.deprecate=function(){},e.paths=[],e.children||(e.children=[]),Object.defineProperty(e,"loaded",{enumerable:!0,get:function(){return e.l}}),Object.defineProperty(e,"id",{enumerable:!0,get:function(){return e.i}}),e.webpackPolyfill=1),e}},function(e,n,t){"use strict";var a=t(3),r=t(4),i=t(19),o=Object,s=a("".split);e.exports=r((function(){return!o("z").propertyIsEnumerable(0)}))?function(e){return"String"===i(e)?s(e,""):o(e)}:o},function(e,n,t){"use strict";e.exports={}},function(e,n){var t=/^\s+|\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,r=/^0b[01]+$/i,i=/^0o[0-7]+$/i,o=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=s||l||Function("return this")(),d=Object.prototype.toString,u=Math.max,p=Math.min,m=function(){return c.Date.now()};function h(e){var n=typeof e;return!!e&&("object"==n||"function"==n)}function f(e){if("number"==typeof e)return e;if(function(e){return"symbol"==typeof e||function(e){return!!e&&"object"==typeof e}(e)&&"[object Symbol]"==d.call(e)}(e))return NaN;if(h(e)){var n="function"==typeof e.valueOf?e.valueOf():e;e=h(n)?n+"":n}if("string"!=typeof e)return 0===e?e:+e;e=e.replace(t,"");var s=r.test(e);return s||i.test(e)?o(e.slice(2),s?2:8):a.test(e)?NaN:+e}e.exports=function(e,n,t){var a,r,i,o,s,l,c=0,d=!1,g=!1,v=!0;if("function"!=typeof e)throw new TypeError("Expected a function");function b(n){var t=a,i=r;return a=r=void 0,c=n,o=e.apply(i,t)}function y(e){return c=e,s=setTimeout(_,n),d?b(e):o}function w(e){var t=e-l;return void 0===l||t>=n||t<0||g&&e-c>=i}function _(){var e=m();if(w(e))return x(e);s=setTimeout(_,function(e){var t=n-(e-l);return g?p(t,i-(e-c)):t}(e))}function x(e){return s=void 0,v&&a?b(e):(a=r=void 0,o)}function k(){var e=m(),t=w(e);if(a=arguments,r=this,l=e,t){if(void 0===s)return y(l);if(g)return s=setTimeout(_,n),b(l)}return void 0===s&&(s=setTimeout(_,n)),o}return n=f(n)||0,h(t)&&(d=!!t.leading,i=(g="maxWait"in t)?u(f(t.maxWait)||0,n):i,v="trailing"in t?!!t.trailing:v),k.cancel=function(){void 0!==s&&clearTimeout(s),c=0,a=l=r=s=void 0},k.flush=function(){return void 0===s?o:x(m())},k}},function(e,n,t){"use strict";var a=t(5),r=t(34),i=t(107),o=t(35),s=t(28),l=t(55),c=t(10),d=t(64),u=Object.getOwnPropertyDescriptor;n.f=a?u:function(e,n){if(e=s(e),n=l(n),d)try{return u(e,n)}catch(e){}if(c(e,n))return o(!r(i.f,e,n),e[n])}},function(e,n,t){"use strict";e.exports=function(e){return null==e}},function(e,n,t){"use strict";var a=t(108),r=t(56);e.exports=function(e){var n=a(e,"string");return r(n)?n:n+""}},function(e,n,t){"use strict";var a=t(29),r=t(2),i=t(57),o=t(58),s=Object;e.exports=o?function(e){return"symbol"==typeof e}:function(e){var n=a("Symbol");return r(n)&&i(n.prototype,s(e))}},function(e,n,t){"use strict";var a=t(3);e.exports=a({}.isPrototypeOf)},function(e,n,t){"use strict";var a=t(59);e.exports=a&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(e,n,t){"use strict";var a=t(60),r=t(4),i=t(1).String;e.exports=!!Object.getOwnPropertySymbols&&!r((function(){var e=Symbol("symbol detection");return!i(e)||!(Object(e)instanceof Symbol)||!Symbol.sham&&a&&a<41}))},function(e,n,t){"use strict";var a,r,i=t(1),o=t(109),s=i.process,l=i.Deno,c=s&&s.versions||l&&l.version,d=c&&c.v8;d&&(r=(a=d.split("."))[0]>0&&a[0]<4?1:+(a[0]+a[1])),!r&&o&&(!(a=o.match(/Edge\/(\d+)/))||a[1]>=74)&&(a=o.match(/Chrome\/(\d+)/))&&(r=+a[1]),e.exports=r},function(e,n,t){"use strict";var a=t(37);e.exports=function(e,n){return a[e]||(a[e]=n||{})}},function(e,n,t){"use strict";e.exports=!1},function(e,n,t){"use strict";var a=t(3),r=0,i=Math.random(),o=a(1..toString);e.exports=function(e){return"Symbol("+(void 0===e?"":e)+")_"+o(++r+i,36)}},function(e,n,t){"use strict";var a=t(5),r=t(4),i=t(99);e.exports=!a&&!r((function(){return 7!==Object.defineProperty(i("div"),"a",{get:function(){return 7}}).a}))},function(e,n,t){"use strict";var a=t(10),r=t(117),i=t(53),o=t(18);e.exports=function(e,n,t){for(var s=r(n),l=o.f,c=i.f,d=0;d<s.length;d++){var u=s[d];a(e,u)||t&&a(t,u)||l(e,u,c(n,u))}}},function(e,n,t){"use strict";var a=t(121);e.exports=function(e){var n=+e;return n!=n||0===n?0:a(n)}},function(e,n,t){"use strict";var a=t(131),r=t(7),i=t(36),o=t(132);e.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var e,n=!1,t={};try{(e=a(Object.prototype,"__proto__","set"))(t,[]),n=t instanceof Array}catch(e){}return function(t,a){return i(t),o(a),r(t)?(n?e(t,a):t.__proto__=a,t):t}}():void 0)},function(e,n){e.exports=function(e,n){for(var t=-1,a=n.length,r=e.length;++t<a;)e[r+t]=n[t];return e}},function(e,n){var t="object"==typeof global&&global&&global.Object===Object&&global;e.exports=t},function(e,n,t){var a=t(20),r=t(159),i=t(160),o=t(161),s=t(162),l=t(163);function c(e){var n=this.__data__=new a(e);this.size=n.size}c.prototype.clear=r,c.prototype.delete=i,c.prototype.get=o,c.prototype.has=s,c.prototype.set=l,e.exports=c},function(e,n){e.exports=function(e,n){return e===n||e!=e&&n!=n}},function(e,n,t){var a=t(14),r=t(41);e.exports=function(e){if(!r(e))return!1;var n=a(e);return"[object Function]"==n||"[object GeneratorFunction]"==n||"[object AsyncFunction]"==n||"[object Proxy]"==n}},function(e,n){var t=Function.prototype.toString;e.exports=function(e){if(null!=e){try{return t.call(e)}catch(e){}try{return e+""}catch(e){}}return""}},function(e,n,t){var a=t(180),r=t(13);e.exports=function e(n,t,i,o,s){return n===t||(null==n||null==t||!r(n)&&!r(t)?n!=n&&t!=t:a(n,t,i,o,e,s))}},function(e,n,t){var a=t(76),r=t(183),i=t(77);e.exports=function(e,n,t,o,s,l){var c=1&t,d=e.length,u=n.length;if(d!=u&&!(c&&u>d))return!1;var p=l.get(e),m=l.get(n);if(p&&m)return p==n&&m==e;var h=-1,f=!0,g=2&t?new a:void 0;for(l.set(e,n),l.set(n,e);++h<d;){var v=e[h],b=n[h];if(o)var y=c?o(b,v,h,n,e,l):o(v,b,h,e,n,l);if(void 0!==y){if(y)continue;f=!1;break}if(g){if(!r(n,(function(e,n){if(!i(g,n)&&(v===e||s(v,e,t,o,l)))return g.push(n)}))){f=!1;break}}else if(v!==b&&!s(v,b,t,o,l)){f=!1;break}}return l.delete(e),l.delete(n),f}},function(e,n,t){var a=t(42),r=t(181),i=t(182);function o(e){var n=-1,t=null==e?0:e.length;for(this.__data__=new a;++n<t;)this.add(e[n])}o.prototype.add=o.prototype.push=r,o.prototype.has=i,e.exports=o},function(e,n){e.exports=function(e,n){return e.has(n)}},function(e,n,t){var a=t(193),r=t(199),i=t(82);e.exports=function(e){return i(e)?a(e):r(e)}},function(e,n,t){(function(e){var a=t(8),r=t(195),i=n&&!n.nodeType&&n,o=i&&"object"==typeof e&&e&&!e.nodeType&&e,s=o&&o.exports===i?a.Buffer:void 0,l=(s?s.isBuffer:void 0)||r;e.exports=l}).call(this,t(49)(e))},function(e,n){var t=/^(?:0|[1-9]\d*)$/;e.exports=function(e,n){var a=typeof e;return!!(n=null==n?9007199254740991:n)&&("number"==a||"symbol"!=a&&t.test(e))&&e>-1&&e%1==0&&e<n}},function(e,n,t){var a=t(196),r=t(197),i=t(198),o=i&&i.isTypedArray,s=o?r(o):a;e.exports=s},function(e,n,t){var a=t(72),r=t(44);e.exports=function(e){return null!=e&&r(e.length)&&!a(e)}},function(e,n,t){var a=t(11)(t(8),"Set");e.exports=a},function(e,n,t){var a=t(41);e.exports=function(e){return e==e&&!a(e)}},function(e,n){e.exports=function(e,n){return function(t){return null!=t&&(t[e]===n&&(void 0!==n||e in Object(t)))}}},function(e,n,t){var a=t(87),r=t(24);e.exports=function(e,n){for(var t=0,i=(n=a(n,e)).length;null!=e&&t<i;)e=e[r(n[t++])];return t&&t==i?e:void 0}},function(e,n,t){var a=t(6),r=t(45),i=t(210),o=t(213);e.exports=function(e,n){return a(e)?e:r(e,n)?[e]:i(o(e))}},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){var a=t(146),r=t(151),i=t(222),o=t(230),s=t(239),l=t(104),c=i((function(e){var n=l(e);return s(n)&&(n=void 0),o(a(e,1,s,!0),r(n,2))}));e.exports=c},function(e,n,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var a=/["'&<>]/;e.exports=function(e){var n,t=""+e,r=a.exec(t);if(!r)return t;var i="",o=0,s=0;for(o=r.index;o<t.length;o++){switch(t.charCodeAt(o)){case 34:n="&quot;";break;case 38:n="&amp;";break;case 39:n="&#39;";break;case 60:n="&lt;";break;case 62:n="&gt;";break;default:continue}s!==o&&(i+=t.substring(s,o)),s=o+1,i+=n}return s!==o?i+t.substring(s,o):i}},function(e,n,t){"use strict";t.r(n);var a={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},r=(t(242),t(9)),i=Object(r.a)(a,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);n.default=i.exports},function(e,n,t){"use strict";t.r(n);var a={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(e){this.codeTabs.forEach(e=>{e.elm.classList.remove("theme-code-block__active")}),this.codeTabs[e].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(e=>Boolean(e.componentOptions)).map((e,n)=>(""===e.componentOptions.propsData.active&&(this.activeCodeTabIndex=n),{title:e.componentOptions.propsData.title,elm:e.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(e){this.activeCodeTabIndex=e}}},r=(t(243),t(9)),i=Object(r.a)(a,(function(){var e=this,n=e._self._c;return n("div",{staticClass:"theme-code-group"},[n("div",{staticClass:"theme-code-group__nav"},[n("ul",{staticClass:"theme-code-group__ul"},e._l(e.codeTabs,(function(t,a){return n("li",{key:t.title,staticClass:"theme-code-group__li"},[n("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":a===e.activeCodeTabIndex},on:{click:function(n){return e.changeCodeTab(a)}}},[e._v("\n            "+e._s(t.title)+"\n          ")])])})),0)]),e._v(" "),e._t("default"),e._v(" "),e.codeTabs.length<1?n("pre",{staticClass:"pre-blank"},[e._v("// Make sure to add code blocks to your code group")]):e._e()],2)}),[],!1,null,"2f5f1757",null);n.default=i.exports},function(e,n,t){"use strict";var a=t(2),r=t(18),i=t(101),o=t(38);e.exports=function(e,n,t,s){s||(s={});var l=s.enumerable,c=void 0!==s.name?s.name:n;if(a(t)&&i(t,c,s),s.global)l?e[n]=t:o(n,t);else{try{s.unsafe?e[n]&&(l=!0):delete e[n]}catch(e){}l?e[n]=t:r.f(e,n,{value:t,enumerable:!1,configurable:!s.nonConfigurable,writable:!s.nonWritable})}return e}},function(e,n,t){"use strict";e.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(e,n,t){"use strict";var a=t(137),r=String;e.exports=function(e){if("Symbol"===a(e))throw new TypeError("Cannot convert a Symbol value to a string");return r(e)}},function(e,n,t){"use strict";var a=t(1),r=t(7),i=a.document,o=r(i)&&r(i.createElement);e.exports=function(e){return o?i.createElement(e):{}}},function(e,n,t){"use strict";var a=t(5),r=t(4);e.exports=a&&r((function(){return 42!==Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(e,n,t){"use strict";var a=t(3),r=t(4),i=t(2),o=t(10),s=t(5),l=t(113).CONFIGURABLE,c=t(114),d=t(115),u=d.enforce,p=d.get,m=String,h=Object.defineProperty,f=a("".slice),g=a("".replace),v=a([].join),b=s&&!r((function(){return 8!==h((function(){}),"length",{value:8}).length})),y=String(String).split("String"),w=e.exports=function(e,n,t){"Symbol("===f(m(n),0,7)&&(n="["+g(m(n),/^Symbol\(([^)]*)\).*$/,"$1")+"]"),t&&t.getter&&(n="get "+n),t&&t.setter&&(n="set "+n),(!o(e,"name")||l&&e.name!==n)&&(s?h(e,"name",{value:n,configurable:!0}):e.name=n),b&&t&&o(t,"arity")&&e.length!==t.arity&&h(e,"length",{value:t.arity});try{t&&o(t,"constructor")&&t.constructor?s&&h(e,"prototype",{writable:!1}):e.prototype&&(e.prototype=void 0)}catch(e){}var a=u(e);return o(a,"source")||(a.source=v(y,"string"==typeof n?n:"")),e};Function.prototype.toString=w((function(){return i(this)&&p(this).source||c(this)}),"toString")},function(e,n,t){"use strict";var a=t(61),r=t(63),i=a("keys");e.exports=function(e){return i[e]||(i[e]=r(e))}},function(e,n,t){"use strict";var a=t(3),r=t(10),i=t(28),o=t(119).indexOf,s=t(51),l=a([].push);e.exports=function(e,n){var t,a=i(e),c=0,d=[];for(t in a)!r(s,t)&&r(a,t)&&l(d,t);for(;n.length>c;)r(a,t=n[c++])&&(~o(d,t)||l(d,t));return d}},function(e,n){e.exports=function(e){var n=null==e?0:e.length;return n?e[n-1]:void 0}},function(e,n,t){e.exports=t(248)},function(e,n,t){"use strict";var a=t(26),r=t(125).left,i=t(126),o=t(60);a({target:"Array",proto:!0,forced:!t(127)&&o>79&&o<83||!i("reduce")},{reduce:function(e){var n=arguments.length;return r(this,e,n,n>1?arguments[1]:void 0)}})},function(e,n,t){"use strict";var a={}.propertyIsEnumerable,r=Object.getOwnPropertyDescriptor,i=r&&!a.call({1:2},1);n.f=i?function(e){var n=r(this,e);return!!n&&n.enumerable}:a},function(e,n,t){"use strict";var a=t(34),r=t(7),i=t(56),o=t(110),s=t(112),l=t(31),c=TypeError,d=l("toPrimitive");e.exports=function(e,n){if(!r(e)||i(e))return e;var t,l=o(e,d);if(l){if(void 0===n&&(n="default"),t=a(l,e,n),!r(t)||i(t))return t;throw new c("Can't convert object to primitive value")}return void 0===n&&(n="number"),s(e,n)}},function(e,n,t){"use strict";e.exports="undefined"!=typeof navigator&&String(navigator.userAgent)||""},function(e,n,t){"use strict";var a=t(30),r=t(54);e.exports=function(e,n){var t=e[n];return r(t)?void 0:a(t)}},function(e,n,t){"use strict";var a=String;e.exports=function(e){try{return a(e)}catch(e){return"Object"}}},function(e,n,t){"use strict";var a=t(34),r=t(2),i=t(7),o=TypeError;e.exports=function(e,n){var t,s;if("string"===n&&r(t=e.toString)&&!i(s=a(t,e)))return s;if(r(t=e.valueOf)&&!i(s=a(t,e)))return s;if("string"!==n&&r(t=e.toString)&&!i(s=a(t,e)))return s;throw new o("Can't convert object to primitive value")}},function(e,n,t){"use strict";var a=t(5),r=t(10),i=Function.prototype,o=a&&Object.getOwnPropertyDescriptor,s=r(i,"name"),l=s&&"something"===function(){}.name,c=s&&(!a||a&&o(i,"name").configurable);e.exports={EXISTS:s,PROPER:l,CONFIGURABLE:c}},function(e,n,t){"use strict";var a=t(3),r=t(2),i=t(37),o=a(Function.toString);r(i.inspectSource)||(i.inspectSource=function(e){return o(e)}),e.exports=i.inspectSource},function(e,n,t){"use strict";var a,r,i,o=t(116),s=t(1),l=t(7),c=t(15),d=t(10),u=t(37),p=t(102),m=t(51),h=s.TypeError,f=s.WeakMap;if(o||u.state){var g=u.state||(u.state=new f);g.get=g.get,g.has=g.has,g.set=g.set,a=function(e,n){if(g.has(e))throw new h("Object already initialized");return n.facade=e,g.set(e,n),n},r=function(e){return g.get(e)||{}},i=function(e){return g.has(e)}}else{var v=p("state");m[v]=!0,a=function(e,n){if(d(e,v))throw new h("Object already initialized");return n.facade=e,c(e,v,n),n},r=function(e){return d(e,v)?e[v]:{}},i=function(e){return d(e,v)}}e.exports={set:a,get:r,has:i,enforce:function(e){return i(e)?r(e):a(e,{})},getterFor:function(e){return function(n){var t;if(!l(n)||(t=r(n)).type!==e)throw new h("Incompatible receiver, "+e+" required");return t}}}},function(e,n,t){"use strict";var a=t(1),r=t(2),i=a.WeakMap;e.exports=r(i)&&/native code/.test(String(i))},function(e,n,t){"use strict";var a=t(29),r=t(3),i=t(118),o=t(123),s=t(48),l=r([].concat);e.exports=a("Reflect","ownKeys")||function(e){var n=i.f(s(e)),t=o.f;return t?l(n,t(e)):n}},function(e,n,t){"use strict";var a=t(103),r=t(97).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(e){return a(e,r)}},function(e,n,t){"use strict";var a=t(28),r=t(120),i=t(33),o=function(e){return function(n,t,o){var s=a(n),l=i(s);if(0===l)return!e&&-1;var c,d=r(o,l);if(e&&t!=t){for(;l>d;)if((c=s[d++])!=c)return!0}else for(;l>d;d++)if((e||d in s)&&s[d]===t)return e||d||0;return!e&&-1}};e.exports={includes:o(!0),indexOf:o(!1)}},function(e,n,t){"use strict";var a=t(66),r=Math.max,i=Math.min;e.exports=function(e,n){var t=a(e);return t<0?r(t+n,0):i(t,n)}},function(e,n,t){"use strict";var a=Math.ceil,r=Math.floor;e.exports=Math.trunc||function(e){var n=+e;return(n>0?r:a)(n)}},function(e,n,t){"use strict";var a=t(66),r=Math.min;e.exports=function(e){var n=a(e);return n>0?r(n,9007199254740991):0}},function(e,n,t){"use strict";n.f=Object.getOwnPropertySymbols},function(e,n,t){"use strict";var a=t(4),r=t(2),i=/#|\.prototype\./,o=function(e,n){var t=l[s(e)];return t===d||t!==c&&(r(n)?a(n):!!n)},s=o.normalize=function(e){return String(e).replace(i,".").toLowerCase()},l=o.data={},c=o.NATIVE="N",d=o.POLYFILL="P";e.exports=o},function(e,n,t){"use strict";var a=t(30),r=t(32),i=t(50),o=t(33),s=TypeError,l="Reduce of empty array with no initial value",c=function(e){return function(n,t,c,d){var u=r(n),p=i(u),m=o(u);if(a(t),0===m&&c<2)throw new s(l);var h=e?m-1:0,f=e?-1:1;if(c<2)for(;;){if(h in p){d=p[h],h+=f;break}if(h+=f,e?h<0:m<=h)throw new s(l)}for(;e?h>=0:m>h;h+=f)h in p&&(d=t(d,p[h],h,u));return d}};e.exports={left:c(!1),right:c(!0)}},function(e,n,t){"use strict";var a=t(4);e.exports=function(e,n){var t=[][e];return!!t&&a((function(){t.call(null,n||function(){return 1},1)}))}},function(e,n,t){"use strict";var a=t(1),r=t(19);e.exports="process"===r(a.process)},function(e,n,t){"use strict";var a=t(26),r=t(1),i=t(129),o=t(130),s=r.WebAssembly,l=7!==new Error("e",{cause:7}).cause,c=function(e,n){var t={};t[e]=o(e,n,l),a({global:!0,constructor:!0,arity:1,forced:l},t)},d=function(e,n){if(s&&s[e]){var t={};t[e]=o("WebAssembly."+e,n,l),a({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:l},t)}};c("Error",(function(e){return function(n){return i(e,this,arguments)}})),c("EvalError",(function(e){return function(n){return i(e,this,arguments)}})),c("RangeError",(function(e){return function(n){return i(e,this,arguments)}})),c("ReferenceError",(function(e){return function(n){return i(e,this,arguments)}})),c("SyntaxError",(function(e){return function(n){return i(e,this,arguments)}})),c("TypeError",(function(e){return function(n){return i(e,this,arguments)}})),c("URIError",(function(e){return function(n){return i(e,this,arguments)}})),d("CompileError",(function(e){return function(n){return i(e,this,arguments)}})),d("LinkError",(function(e){return function(n){return i(e,this,arguments)}})),d("RuntimeError",(function(e){return function(n){return i(e,this,arguments)}}))},function(e,n,t){"use strict";var a=t(27),r=Function.prototype,i=r.apply,o=r.call;e.exports="object"==typeof Reflect&&Reflect.apply||(a?o.bind(i):function(){return o.apply(i,arguments)})},function(e,n,t){"use strict";var a=t(29),r=t(10),i=t(15),o=t(57),s=t(67),l=t(65),c=t(134),d=t(135),u=t(136),p=t(139),m=t(140),h=t(5),f=t(62);e.exports=function(e,n,t,g){var v=g?2:1,b=e.split("."),y=b[b.length-1],w=a.apply(null,b);if(w){var _=w.prototype;if(!f&&r(_,"cause")&&delete _.cause,!t)return w;var x=a("Error"),k=n((function(e,n){var t=u(g?n:e,void 0),a=g?new w(e):new w;return void 0!==t&&i(a,"message",t),m(a,k,a.stack,2),this&&o(_,this)&&d(a,this,k),arguments.length>v&&p(a,arguments[v]),a}));if(k.prototype=_,"Error"!==y?s?s(k,x):l(k,x,{name:!0}):h&&"stackTraceLimit"in w&&(c(k,w,"stackTraceLimit"),c(k,w,"prepareStackTrace")),l(k,w),!f)try{_.name!==y&&i(_,"name",y),_.constructor=k}catch(e){}return k}}},function(e,n,t){"use strict";var a=t(3),r=t(30);e.exports=function(e,n,t){try{return a(r(Object.getOwnPropertyDescriptor(e,n)[t]))}catch(e){}}},function(e,n,t){"use strict";var a=t(133),r=String,i=TypeError;e.exports=function(e){if(a(e))return e;throw new i("Can't set "+r(e)+" as a prototype")}},function(e,n,t){"use strict";var a=t(7);e.exports=function(e){return a(e)||null===e}},function(e,n,t){"use strict";var a=t(18).f;e.exports=function(e,n,t){t in e||a(e,t,{configurable:!0,get:function(){return n[t]},set:function(e){n[t]=e}})}},function(e,n,t){"use strict";var a=t(2),r=t(7),i=t(67);e.exports=function(e,n,t){var o,s;return i&&a(o=n.constructor)&&o!==t&&r(s=o.prototype)&&s!==t.prototype&&i(e,s),e}},function(e,n,t){"use strict";var a=t(98);e.exports=function(e,n){return void 0===e?arguments.length<2?"":n:a(e)}},function(e,n,t){"use strict";var a=t(138),r=t(2),i=t(19),o=t(31)("toStringTag"),s=Object,l="Arguments"===i(function(){return arguments}());e.exports=a?i:function(e){var n,t,a;return void 0===e?"Undefined":null===e?"Null":"string"==typeof(t=function(e,n){try{return e[n]}catch(e){}}(n=s(e),o))?t:l?i(n):"Object"===(a=i(n))&&r(n.callee)?"Arguments":a}},function(e,n,t){"use strict";var a={};a[t(31)("toStringTag")]="z",e.exports="[object z]"===String(a)},function(e,n,t){"use strict";var a=t(7),r=t(15);e.exports=function(e,n){a(n)&&"cause"in n&&r(e,"cause",n.cause)}},function(e,n,t){"use strict";var a=t(15),r=t(141),i=t(142),o=Error.captureStackTrace;e.exports=function(e,n,t,s){i&&(o?o(e,n):a(e,"stack",r(t,s)))}},function(e,n,t){"use strict";var a=t(3),r=Error,i=a("".replace),o=String(new r("zxcasd").stack),s=/\n\s*at [^:]*:[^\n]*/,l=s.test(o);e.exports=function(e,n){if(l&&"string"==typeof e&&!r.prepareStackTrace)for(;n--;)e=i(e,s,"");return e}},function(e,n,t){"use strict";var a=t(4),r=t(35);e.exports=!a((function(){var e=new Error("a");return!("stack"in e)||(Object.defineProperty(e,"stack",r(1,7)),7!==e.stack)}))},function(e,n,t){"use strict";var a=t(5),r=t(144),i=TypeError,o=Object.getOwnPropertyDescriptor,s=a&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(e){return e instanceof TypeError}}();e.exports=s?function(e,n){if(r(e)&&!o(e,"length").writable)throw new i("Cannot set read only .length");return e.length=n}:function(e,n){return e.length=n}},function(e,n,t){"use strict";var a=t(19);e.exports=Array.isArray||function(e){return"Array"===a(e)}},function(e,n,t){"use strict";var a=TypeError;e.exports=function(e){if(e>9007199254740991)throw a("Maximum allowed index exceeded");return e}},function(e,n,t){var a=t(68),r=t(147);e.exports=function e(n,t,i,o,s){var l=-1,c=n.length;for(i||(i=r),s||(s=[]);++l<c;){var d=n[l];t>0&&i(d)?t>1?e(d,t-1,i,o,s):a(s,d):o||(s[s.length]=d)}return s}},function(e,n,t){var a=t(16),r=t(39),i=t(6),o=a?a.isConcatSpreadable:void 0;e.exports=function(e){return i(e)||r(e)||!!(o&&e&&e[o])}},function(e,n,t){var a=t(14),r=t(13);e.exports=function(e){return r(e)&&"[object Arguments]"==a(e)}},function(e,n,t){var a=t(16),r=Object.prototype,i=r.hasOwnProperty,o=r.toString,s=a?a.toStringTag:void 0;e.exports=function(e){var n=i.call(e,s),t=e[s];try{e[s]=void 0;var a=!0}catch(e){}var r=o.call(e);return a&&(n?e[s]=t:delete e[s]),r}},function(e,n){var t=Object.prototype.toString;e.exports=function(e){return t.call(e)}},function(e,n,t){var a=t(152),r=t(208),i=t(47),o=t(6),s=t(219);e.exports=function(e){return"function"==typeof e?e:null==e?i:"object"==typeof e?o(e)?r(e[0],e[1]):a(e):s(e)}},function(e,n,t){var a=t(153),r=t(207),i=t(85);e.exports=function(e){var n=r(e);return 1==n.length&&n[0][2]?i(n[0][0],n[0][1]):function(t){return t===e||a(t,e,n)}}},function(e,n,t){var a=t(70),r=t(74);e.exports=function(e,n,t,i){var o=t.length,s=o,l=!i;if(null==e)return!s;for(e=Object(e);o--;){var c=t[o];if(l&&c[2]?c[1]!==e[c[0]]:!(c[0]in e))return!1}for(;++o<s;){var d=(c=t[o])[0],u=e[d],p=c[1];if(l&&c[2]){if(void 0===u&&!(d in e))return!1}else{var m=new a;if(i)var h=i(u,p,d,e,n,m);if(!(void 0===h?r(p,u,3,i,m):h))return!1}}return!0}},function(e,n){e.exports=function(){this.__data__=[],this.size=0}},function(e,n,t){var a=t(21),r=Array.prototype.splice;e.exports=function(e){var n=this.__data__,t=a(n,e);return!(t<0)&&(t==n.length-1?n.pop():r.call(n,t,1),--this.size,!0)}},function(e,n,t){var a=t(21);e.exports=function(e){var n=this.__data__,t=a(n,e);return t<0?void 0:n[t][1]}},function(e,n,t){var a=t(21);e.exports=function(e){return a(this.__data__,e)>-1}},function(e,n,t){var a=t(21);e.exports=function(e,n){var t=this.__data__,r=a(t,e);return r<0?(++this.size,t.push([e,n])):t[r][1]=n,this}},function(e,n,t){var a=t(20);e.exports=function(){this.__data__=new a,this.size=0}},function(e,n){e.exports=function(e){var n=this.__data__,t=n.delete(e);return this.size=n.size,t}},function(e,n){e.exports=function(e){return this.__data__.get(e)}},function(e,n){e.exports=function(e){return this.__data__.has(e)}},function(e,n,t){var a=t(20),r=t(40),i=t(42);e.exports=function(e,n){var t=this.__data__;if(t instanceof a){var o=t.__data__;if(!r||o.length<199)return o.push([e,n]),this.size=++t.size,this;t=this.__data__=new i(o)}return t.set(e,n),this.size=t.size,this}},function(e,n,t){var a=t(72),r=t(165),i=t(41),o=t(73),s=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,d=l.toString,u=c.hasOwnProperty,p=RegExp("^"+d.call(u).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");e.exports=function(e){return!(!i(e)||r(e))&&(a(e)?p:s).test(o(e))}},function(e,n,t){var a,r=t(166),i=(a=/[^.]+$/.exec(r&&r.keys&&r.keys.IE_PROTO||""))?"Symbol(src)_1."+a:"";e.exports=function(e){return!!i&&i in e}},function(e,n,t){var a=t(8)["__core-js_shared__"];e.exports=a},function(e,n){e.exports=function(e,n){return null==e?void 0:e[n]}},function(e,n,t){var a=t(169),r=t(20),i=t(40);e.exports=function(){this.size=0,this.__data__={hash:new a,map:new(i||r),string:new a}}},function(e,n,t){var a=t(170),r=t(171),i=t(172),o=t(173),s=t(174);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var a=e[n];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,e.exports=l},function(e,n,t){var a=t(22);e.exports=function(){this.__data__=a?a(null):{},this.size=0}},function(e,n){e.exports=function(e){var n=this.has(e)&&delete this.__data__[e];return this.size-=n?1:0,n}},function(e,n,t){var a=t(22),r=Object.prototype.hasOwnProperty;e.exports=function(e){var n=this.__data__;if(a){var t=n[e];return"__lodash_hash_undefined__"===t?void 0:t}return r.call(n,e)?n[e]:void 0}},function(e,n,t){var a=t(22),r=Object.prototype.hasOwnProperty;e.exports=function(e){var n=this.__data__;return a?void 0!==n[e]:r.call(n,e)}},function(e,n,t){var a=t(22);e.exports=function(e,n){var t=this.__data__;return this.size+=this.has(e)?0:1,t[e]=a&&void 0===n?"__lodash_hash_undefined__":n,this}},function(e,n,t){var a=t(23);e.exports=function(e){var n=a(this,e).delete(e);return this.size-=n?1:0,n}},function(e,n){e.exports=function(e){var n=typeof e;return"string"==n||"number"==n||"symbol"==n||"boolean"==n?"__proto__"!==e:null===e}},function(e,n,t){var a=t(23);e.exports=function(e){return a(this,e).get(e)}},function(e,n,t){var a=t(23);e.exports=function(e){return a(this,e).has(e)}},function(e,n,t){var a=t(23);e.exports=function(e,n){var t=a(this,e),r=t.size;return t.set(e,n),this.size+=t.size==r?0:1,this}},function(e,n,t){var a=t(70),r=t(75),i=t(184),o=t(187),s=t(203),l=t(6),c=t(79),d=t(81),u="[object Object]",p=Object.prototype.hasOwnProperty;e.exports=function(e,n,t,m,h,f){var g=l(e),v=l(n),b=g?"[object Array]":s(e),y=v?"[object Array]":s(n),w=(b="[object Arguments]"==b?u:b)==u,_=(y="[object Arguments]"==y?u:y)==u,x=b==y;if(x&&c(e)){if(!c(n))return!1;g=!0,w=!1}if(x&&!w)return f||(f=new a),g||d(e)?r(e,n,t,m,h,f):i(e,n,b,t,m,h,f);if(!(1&t)){var k=w&&p.call(e,"__wrapped__"),T=_&&p.call(n,"__wrapped__");if(k||T){var E=k?e.value():e,S=T?n.value():n;return f||(f=new a),h(E,S,t,m,f)}}return!!x&&(f||(f=new a),o(e,n,t,m,h,f))}},function(e,n){e.exports=function(e){return this.__data__.set(e,"__lodash_hash_undefined__"),this}},function(e,n){e.exports=function(e){return this.__data__.has(e)}},function(e,n){e.exports=function(e,n){for(var t=-1,a=null==e?0:e.length;++t<a;)if(n(e[t],t,e))return!0;return!1}},function(e,n,t){var a=t(16),r=t(185),i=t(71),o=t(75),s=t(186),l=t(43),c=a?a.prototype:void 0,d=c?c.valueOf:void 0;e.exports=function(e,n,t,a,c,u,p){switch(t){case"[object DataView]":if(e.byteLength!=n.byteLength||e.byteOffset!=n.byteOffset)return!1;e=e.buffer,n=n.buffer;case"[object ArrayBuffer]":return!(e.byteLength!=n.byteLength||!u(new r(e),new r(n)));case"[object Boolean]":case"[object Date]":case"[object Number]":return i(+e,+n);case"[object Error]":return e.name==n.name&&e.message==n.message;case"[object RegExp]":case"[object String]":return e==n+"";case"[object Map]":var m=s;case"[object Set]":var h=1&a;if(m||(m=l),e.size!=n.size&&!h)return!1;var f=p.get(e);if(f)return f==n;a|=2,p.set(e,n);var g=o(m(e),m(n),a,c,u,p);return p.delete(e),g;case"[object Symbol]":if(d)return d.call(e)==d.call(n)}return!1}},function(e,n,t){var a=t(8).Uint8Array;e.exports=a},function(e,n){e.exports=function(e){var n=-1,t=Array(e.size);return e.forEach((function(e,a){t[++n]=[a,e]})),t}},function(e,n,t){var a=t(188),r=Object.prototype.hasOwnProperty;e.exports=function(e,n,t,i,o,s){var l=1&t,c=a(e),d=c.length;if(d!=a(n).length&&!l)return!1;for(var u=d;u--;){var p=c[u];if(!(l?p in n:r.call(n,p)))return!1}var m=s.get(e),h=s.get(n);if(m&&h)return m==n&&h==e;var f=!0;s.set(e,n),s.set(n,e);for(var g=l;++u<d;){var v=e[p=c[u]],b=n[p];if(i)var y=l?i(b,v,p,n,e,s):i(v,b,p,e,n,s);if(!(void 0===y?v===b||o(v,b,t,i,s):y)){f=!1;break}g||(g="constructor"==p)}if(f&&!g){var w=e.constructor,_=n.constructor;w==_||!("constructor"in e)||!("constructor"in n)||"function"==typeof w&&w instanceof w&&"function"==typeof _&&_ instanceof _||(f=!1)}return s.delete(e),s.delete(n),f}},function(e,n,t){var a=t(189),r=t(190),i=t(78);e.exports=function(e){return a(e,i,r)}},function(e,n,t){var a=t(68),r=t(6);e.exports=function(e,n,t){var i=n(e);return r(e)?i:a(i,t(e))}},function(e,n,t){var a=t(191),r=t(192),i=Object.prototype.propertyIsEnumerable,o=Object.getOwnPropertySymbols,s=o?function(e){return null==e?[]:(e=Object(e),a(o(e),(function(n){return i.call(e,n)})))}:r;e.exports=s},function(e,n){e.exports=function(e,n){for(var t=-1,a=null==e?0:e.length,r=0,i=[];++t<a;){var o=e[t];n(o,t,e)&&(i[r++]=o)}return i}},function(e,n){e.exports=function(){return[]}},function(e,n,t){var a=t(194),r=t(39),i=t(6),o=t(79),s=t(80),l=t(81),c=Object.prototype.hasOwnProperty;e.exports=function(e,n){var t=i(e),d=!t&&r(e),u=!t&&!d&&o(e),p=!t&&!d&&!u&&l(e),m=t||d||u||p,h=m?a(e.length,String):[],f=h.length;for(var g in e)!n&&!c.call(e,g)||m&&("length"==g||u&&("offset"==g||"parent"==g)||p&&("buffer"==g||"byteLength"==g||"byteOffset"==g)||s(g,f))||h.push(g);return h}},function(e,n){e.exports=function(e,n){for(var t=-1,a=Array(e);++t<e;)a[t]=n(t);return a}},function(e,n){e.exports=function(){return!1}},function(e,n,t){var a=t(14),r=t(44),i=t(13),o={};o["[object Float32Array]"]=o["[object Float64Array]"]=o["[object Int8Array]"]=o["[object Int16Array]"]=o["[object Int32Array]"]=o["[object Uint8Array]"]=o["[object Uint8ClampedArray]"]=o["[object Uint16Array]"]=o["[object Uint32Array]"]=!0,o["[object Arguments]"]=o["[object Array]"]=o["[object ArrayBuffer]"]=o["[object Boolean]"]=o["[object DataView]"]=o["[object Date]"]=o["[object Error]"]=o["[object Function]"]=o["[object Map]"]=o["[object Number]"]=o["[object Object]"]=o["[object RegExp]"]=o["[object Set]"]=o["[object String]"]=o["[object WeakMap]"]=!1,e.exports=function(e){return i(e)&&r(e.length)&&!!o[a(e)]}},function(e,n){e.exports=function(e){return function(n){return e(n)}}},function(e,n,t){(function(e){var a=t(69),r=n&&!n.nodeType&&n,i=r&&"object"==typeof e&&e&&!e.nodeType&&e,o=i&&i.exports===r&&a.process,s=function(){try{var e=i&&i.require&&i.require("util").types;return e||o&&o.binding&&o.binding("util")}catch(e){}}();e.exports=s}).call(this,t(49)(e))},function(e,n,t){var a=t(200),r=t(201),i=Object.prototype.hasOwnProperty;e.exports=function(e){if(!a(e))return r(e);var n=[];for(var t in Object(e))i.call(e,t)&&"constructor"!=t&&n.push(t);return n}},function(e,n){var t=Object.prototype;e.exports=function(e){var n=e&&e.constructor;return e===("function"==typeof n&&n.prototype||t)}},function(e,n,t){var a=t(202)(Object.keys,Object);e.exports=a},function(e,n){e.exports=function(e,n){return function(t){return e(n(t))}}},function(e,n,t){var a=t(204),r=t(40),i=t(205),o=t(83),s=t(206),l=t(14),c=t(73),d=c(a),u=c(r),p=c(i),m=c(o),h=c(s),f=l;(a&&"[object DataView]"!=f(new a(new ArrayBuffer(1)))||r&&"[object Map]"!=f(new r)||i&&"[object Promise]"!=f(i.resolve())||o&&"[object Set]"!=f(new o)||s&&"[object WeakMap]"!=f(new s))&&(f=function(e){var n=l(e),t="[object Object]"==n?e.constructor:void 0,a=t?c(t):"";if(a)switch(a){case d:return"[object DataView]";case u:return"[object Map]";case p:return"[object Promise]";case m:return"[object Set]";case h:return"[object WeakMap]"}return n}),e.exports=f},function(e,n,t){var a=t(11)(t(8),"DataView");e.exports=a},function(e,n,t){var a=t(11)(t(8),"Promise");e.exports=a},function(e,n,t){var a=t(11)(t(8),"WeakMap");e.exports=a},function(e,n,t){var a=t(84),r=t(78);e.exports=function(e){for(var n=r(e),t=n.length;t--;){var i=n[t],o=e[i];n[t]=[i,o,a(o)]}return n}},function(e,n,t){var a=t(74),r=t(209),i=t(216),o=t(45),s=t(84),l=t(85),c=t(24);e.exports=function(e,n){return o(e)&&s(n)?l(c(e),n):function(t){var o=r(t,e);return void 0===o&&o===n?i(t,e):a(n,o,3)}}},function(e,n,t){var a=t(86);e.exports=function(e,n,t){var r=null==e?void 0:a(e,n);return void 0===r?t:r}},function(e,n,t){var a=t(211),r=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,i=/\\(\\)?/g,o=a((function(e){var n=[];return 46===e.charCodeAt(0)&&n.push(""),e.replace(r,(function(e,t,a,r){n.push(a?r.replace(i,"$1"):t||e)})),n}));e.exports=o},function(e,n,t){var a=t(212);e.exports=function(e){var n=a(e,(function(e){return 500===t.size&&t.clear(),e})),t=n.cache;return n}},function(e,n,t){var a=t(42);function r(e,n){if("function"!=typeof e||null!=n&&"function"!=typeof n)throw new TypeError("Expected a function");var t=function(){var a=arguments,r=n?n.apply(this,a):a[0],i=t.cache;if(i.has(r))return i.get(r);var o=e.apply(this,a);return t.cache=i.set(r,o)||i,o};return t.cache=new(r.Cache||a),t}r.Cache=a,e.exports=r},function(e,n,t){var a=t(214);e.exports=function(e){return null==e?"":a(e)}},function(e,n,t){var a=t(16),r=t(215),i=t(6),o=t(46),s=a?a.prototype:void 0,l=s?s.toString:void 0;e.exports=function e(n){if("string"==typeof n)return n;if(i(n))return r(n,e)+"";if(o(n))return l?l.call(n):"";var t=n+"";return"0"==t&&1/n==-1/0?"-0":t}},function(e,n){e.exports=function(e,n){for(var t=-1,a=null==e?0:e.length,r=Array(a);++t<a;)r[t]=n(e[t],t,e);return r}},function(e,n,t){var a=t(217),r=t(218);e.exports=function(e,n){return null!=e&&r(e,n,a)}},function(e,n){e.exports=function(e,n){return null!=e&&n in Object(e)}},function(e,n,t){var a=t(87),r=t(39),i=t(6),o=t(80),s=t(44),l=t(24);e.exports=function(e,n,t){for(var c=-1,d=(n=a(n,e)).length,u=!1;++c<d;){var p=l(n[c]);if(!(u=null!=e&&t(e,p)))break;e=e[p]}return u||++c!=d?u:!!(d=null==e?0:e.length)&&s(d)&&o(p,d)&&(i(e)||r(e))}},function(e,n,t){var a=t(220),r=t(221),i=t(45),o=t(24);e.exports=function(e){return i(e)?a(o(e)):r(e)}},function(e,n){e.exports=function(e){return function(n){return null==n?void 0:n[e]}}},function(e,n,t){var a=t(86);e.exports=function(e){return function(n){return a(n,e)}}},function(e,n,t){var a=t(47),r=t(223),i=t(225);e.exports=function(e,n){return i(r(e,n,a),e+"")}},function(e,n,t){var a=t(224),r=Math.max;e.exports=function(e,n,t){return n=r(void 0===n?e.length-1:n,0),function(){for(var i=arguments,o=-1,s=r(i.length-n,0),l=Array(s);++o<s;)l[o]=i[n+o];o=-1;for(var c=Array(n+1);++o<n;)c[o]=i[o];return c[n]=t(l),a(e,this,c)}}},function(e,n){e.exports=function(e,n,t){switch(t.length){case 0:return e.call(n);case 1:return e.call(n,t[0]);case 2:return e.call(n,t[0],t[1]);case 3:return e.call(n,t[0],t[1],t[2])}return e.apply(n,t)}},function(e,n,t){var a=t(226),r=t(229)(a);e.exports=r},function(e,n,t){var a=t(227),r=t(228),i=t(47),o=r?function(e,n){return r(e,"toString",{configurable:!0,enumerable:!1,value:a(n),writable:!0})}:i;e.exports=o},function(e,n){e.exports=function(e){return function(){return e}}},function(e,n,t){var a=t(11),r=function(){try{var e=a(Object,"defineProperty");return e({},"",{}),e}catch(e){}}();e.exports=r},function(e,n){var t=Date.now;e.exports=function(e){var n=0,a=0;return function(){var r=t(),i=16-(r-a);if(a=r,i>0){if(++n>=800)return arguments[0]}else n=0;return e.apply(void 0,arguments)}}},function(e,n,t){var a=t(76),r=t(231),i=t(236),o=t(77),s=t(237),l=t(43);e.exports=function(e,n,t){var c=-1,d=r,u=e.length,p=!0,m=[],h=m;if(t)p=!1,d=i;else if(u>=200){var f=n?null:s(e);if(f)return l(f);p=!1,d=o,h=new a}else h=n?[]:m;e:for(;++c<u;){var g=e[c],v=n?n(g):g;if(g=t||0!==g?g:0,p&&v==v){for(var b=h.length;b--;)if(h[b]===v)continue e;n&&h.push(v),m.push(g)}else d(h,v,t)||(h!==m&&h.push(v),m.push(g))}return m}},function(e,n,t){var a=t(232);e.exports=function(e,n){return!!(null==e?0:e.length)&&a(e,n,0)>-1}},function(e,n,t){var a=t(233),r=t(234),i=t(235);e.exports=function(e,n,t){return n==n?i(e,n,t):a(e,r,t)}},function(e,n){e.exports=function(e,n,t,a){for(var r=e.length,i=t+(a?1:-1);a?i--:++i<r;)if(n(e[i],i,e))return i;return-1}},function(e,n){e.exports=function(e){return e!=e}},function(e,n){e.exports=function(e,n,t){for(var a=t-1,r=e.length;++a<r;)if(e[a]===n)return a;return-1}},function(e,n){e.exports=function(e,n,t){for(var a=-1,r=null==e?0:e.length;++a<r;)if(t(n,e[a]))return!0;return!1}},function(e,n,t){var a=t(83),r=t(238),i=t(43),o=a&&1/i(new a([,-0]))[1]==1/0?function(e){return new a(e)}:r;e.exports=o},function(e,n){e.exports=function(){}},function(e,n,t){var a=t(82),r=t(13);e.exports=function(e){return r(e)&&a(e)}},function(e,n,t){},function(e,n,t){},function(e,n,t){"use strict";t(88)},function(e,n,t){"use strict";t(89)},function(e,n,t){},function(e,n,t){},function(e,n,t){"use strict";t(90)},function(e,n,t){"use strict";t(91)},function(e,n,t){"use strict";t.r(n);var a=t(0);
/*!
  * vue-router v3.6.5
  * (c) 2022 Evan You
  * @license MIT
  */function r(e,n){for(var t in n)e[t]=n[t];return e}var i=/[!'()*]/g,o=function(e){return"%"+e.charCodeAt(0).toString(16)},s=/%2C/g,l=function(e){return encodeURIComponent(e).replace(i,o).replace(s,",")};function c(e){try{return decodeURIComponent(e)}catch(e){0}return e}var d=function(e){return null==e||"object"==typeof e?e:String(e)};function u(e){var n={};return(e=e.trim().replace(/^(\?|#|&)/,""))?(e.split("&").forEach((function(e){var t=e.replace(/\+/g," ").split("="),a=c(t.shift()),r=t.length>0?c(t.join("=")):null;void 0===n[a]?n[a]=r:Array.isArray(n[a])?n[a].push(r):n[a]=[n[a],r]})),n):n}function p(e){var n=e?Object.keys(e).map((function(n){var t=e[n];if(void 0===t)return"";if(null===t)return l(n);if(Array.isArray(t)){var a=[];return t.forEach((function(e){void 0!==e&&(null===e?a.push(l(n)):a.push(l(n)+"="+l(e)))})),a.join("&")}return l(n)+"="+l(t)})).filter((function(e){return e.length>0})).join("&"):null;return n?"?"+n:""}var m=/\/?$/;function h(e,n,t,a){var r=a&&a.options.stringifyQuery,i=n.query||{};try{i=f(i)}catch(e){}var o={name:n.name||e&&e.name,meta:e&&e.meta||{},path:n.path||"/",hash:n.hash||"",query:i,params:n.params||{},fullPath:b(n,r),matched:e?v(e):[]};return t&&(o.redirectedFrom=b(t,r)),Object.freeze(o)}function f(e){if(Array.isArray(e))return e.map(f);if(e&&"object"==typeof e){var n={};for(var t in e)n[t]=f(e[t]);return n}return e}var g=h(null,{path:"/"});function v(e){for(var n=[];e;)n.unshift(e),e=e.parent;return n}function b(e,n){var t=e.path,a=e.query;void 0===a&&(a={});var r=e.hash;return void 0===r&&(r=""),(t||"/")+(n||p)(a)+r}function y(e,n,t){return n===g?e===n:!!n&&(e.path&&n.path?e.path.replace(m,"")===n.path.replace(m,"")&&(t||e.hash===n.hash&&w(e.query,n.query)):!(!e.name||!n.name)&&(e.name===n.name&&(t||e.hash===n.hash&&w(e.query,n.query)&&w(e.params,n.params))))}function w(e,n){if(void 0===e&&(e={}),void 0===n&&(n={}),!e||!n)return e===n;var t=Object.keys(e).sort(),a=Object.keys(n).sort();return t.length===a.length&&t.every((function(t,r){var i=e[t];if(a[r]!==t)return!1;var o=n[t];return null==i||null==o?i===o:"object"==typeof i&&"object"==typeof o?w(i,o):String(i)===String(o)}))}function _(e){for(var n=0;n<e.matched.length;n++){var t=e.matched[n];for(var a in t.instances){var r=t.instances[a],i=t.enteredCbs[a];if(r&&i){delete t.enteredCbs[a];for(var o=0;o<i.length;o++)r._isBeingDestroyed||i[o](r)}}}}var x={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(e,n){var t=n.props,a=n.children,i=n.parent,o=n.data;o.routerView=!0;for(var s=i.$createElement,l=t.name,c=i.$route,d=i._routerViewCache||(i._routerViewCache={}),u=0,p=!1;i&&i._routerRoot!==i;){var m=i.$vnode?i.$vnode.data:{};m.routerView&&u++,m.keepAlive&&i._directInactive&&i._inactive&&(p=!0),i=i.$parent}if(o.routerViewDepth=u,p){var h=d[l],f=h&&h.component;return f?(h.configProps&&k(f,o,h.route,h.configProps),s(f,o,a)):s()}var g=c.matched[u],v=g&&g.components[l];if(!g||!v)return d[l]=null,s();d[l]={component:v},o.registerRouteInstance=function(e,n){var t=g.instances[l];(n&&t!==e||!n&&t===e)&&(g.instances[l]=n)},(o.hook||(o.hook={})).prepatch=function(e,n){g.instances[l]=n.componentInstance},o.hook.init=function(e){e.data.keepAlive&&e.componentInstance&&e.componentInstance!==g.instances[l]&&(g.instances[l]=e.componentInstance),_(c)};var b=g.props&&g.props[l];return b&&(r(d[l],{route:c,configProps:b}),k(v,o,c,b)),s(v,o,a)}};function k(e,n,t,a){var i=n.props=function(e,n){switch(typeof n){case"undefined":return;case"object":return n;case"function":return n(e);case"boolean":return n?e.params:void 0;default:0}}(t,a);if(i){i=n.props=r({},i);var o=n.attrs=n.attrs||{};for(var s in i)e.props&&s in e.props||(o[s]=i[s],delete i[s])}}function T(e,n,t){var a=e.charAt(0);if("/"===a)return e;if("?"===a||"#"===a)return n+e;var r=n.split("/");t&&r[r.length-1]||r.pop();for(var i=e.replace(/^\//,"").split("/"),o=0;o<i.length;o++){var s=i[o];".."===s?r.pop():"."!==s&&r.push(s)}return""!==r[0]&&r.unshift(""),r.join("/")}function E(e){return e.replace(/\/(?:\s*\/)+/g,"/")}var S=Array.isArray||function(e){return"[object Array]"==Object.prototype.toString.call(e)},I=F,A=N,C=function(e,n){return P(N(e,n),n)},j=P,O=J,L=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function N(e,n){for(var t,a=[],r=0,i=0,o="",s=n&&n.delimiter||"/";null!=(t=L.exec(e));){var l=t[0],c=t[1],d=t.index;if(o+=e.slice(i,d),i=d+l.length,c)o+=c[1];else{var u=e[i],p=t[2],m=t[3],h=t[4],f=t[5],g=t[6],v=t[7];o&&(a.push(o),o="");var b=null!=p&&null!=u&&u!==p,y="+"===g||"*"===g,w="?"===g||"*"===g,_=t[2]||s,x=h||f;a.push({name:m||r++,prefix:p||"",delimiter:_,optional:w,repeat:y,partial:b,asterisk:!!v,pattern:x?R(x):v?".*":"[^"+M(_)+"]+?"})}}return i<e.length&&(o+=e.substr(i)),o&&a.push(o),a}function D(e){return encodeURI(e).replace(/[\/?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()}))}function P(e,n){for(var t=new Array(e.length),a=0;a<e.length;a++)"object"==typeof e[a]&&(t[a]=new RegExp("^(?:"+e[a].pattern+")$",q(n)));return function(n,a){for(var r="",i=n||{},o=(a||{}).pretty?D:encodeURIComponent,s=0;s<e.length;s++){var l=e[s];if("string"!=typeof l){var c,d=i[l.name];if(null==d){if(l.optional){l.partial&&(r+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(S(d)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(d)+"`");if(0===d.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var u=0;u<d.length;u++){if(c=o(d[u]),!t[s].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");r+=(0===u?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(d).replace(/[?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()})):o(d),!t[s].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');r+=l.prefix+c}}else r+=l}return r}}function M(e){return e.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function R(e){return e.replace(/([=!:$\/()])/g,"\\$1")}function z(e,n){return e.keys=n,e}function q(e){return e&&e.sensitive?"":"i"}function J(e,n,t){S(n)||(t=n||t,n=[]);for(var a=(t=t||{}).strict,r=!1!==t.end,i="",o=0;o<e.length;o++){var s=e[o];if("string"==typeof s)i+=M(s);else{var l=M(s.prefix),c="(?:"+s.pattern+")";n.push(s),s.repeat&&(c+="(?:"+l+c+")*"),i+=c=s.optional?s.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var d=M(t.delimiter||"/"),u=i.slice(-d.length)===d;return a||(i=(u?i.slice(0,-d.length):i)+"(?:"+d+"(?=$))?"),i+=r?"$":a&&u?"":"(?="+d+"|$)",z(new RegExp("^"+i,q(t)),n)}function F(e,n,t){return S(n)||(t=n||t,n=[]),t=t||{},e instanceof RegExp?function(e,n){var t=e.source.match(/\((?!\?)/g);if(t)for(var a=0;a<t.length;a++)n.push({name:a,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return z(e,n)}(e,n):S(e)?function(e,n,t){for(var a=[],r=0;r<e.length;r++)a.push(F(e[r],n,t).source);return z(new RegExp("(?:"+a.join("|")+")",q(t)),n)}(e,n,t):function(e,n,t){return J(N(e,t),n,t)}(e,n,t)}I.parse=A,I.compile=C,I.tokensToFunction=j,I.tokensToRegExp=O;var B=Object.create(null);function U(e,n,t){n=n||{};try{var a=B[e]||(B[e]=I.compile(e));return"string"==typeof n.pathMatch&&(n[0]=n.pathMatch),a(n,{pretty:!0})}catch(e){return""}finally{delete n[0]}}function H(e,n,t,a){var i="string"==typeof e?{path:e}:e;if(i._normalized)return i;if(i.name){var o=(i=r({},e)).params;return o&&"object"==typeof o&&(i.params=r({},o)),i}if(!i.path&&i.params&&n){(i=r({},i))._normalized=!0;var s=r(r({},n.params),i.params);if(n.name)i.name=n.name,i.params=s;else if(n.matched.length){var l=n.matched[n.matched.length-1].path;i.path=U(l,s,n.path)}else 0;return i}var c=function(e){var n="",t="",a=e.indexOf("#");a>=0&&(n=e.slice(a),e=e.slice(0,a));var r=e.indexOf("?");return r>=0&&(t=e.slice(r+1),e=e.slice(0,r)),{path:e,query:t,hash:n}}(i.path||""),p=n&&n.path||"/",m=c.path?T(c.path,p,t||i.append):p,h=function(e,n,t){void 0===n&&(n={});var a,r=t||u;try{a=r(e||"")}catch(e){a={}}for(var i in n){var o=n[i];a[i]=Array.isArray(o)?o.map(d):d(o)}return a}(c.query,i.query,a&&a.options.parseQuery),f=i.hash||c.hash;return f&&"#"!==f.charAt(0)&&(f="#"+f),{_normalized:!0,path:m,query:h,hash:f}}var $,G=function(){},K={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(e){var n=this,t=this.$router,a=this.$route,i=t.resolve(this.to,a,this.append),o=i.location,s=i.route,l=i.href,c={},d=t.options.linkActiveClass,u=t.options.linkExactActiveClass,p=null==d?"router-link-active":d,f=null==u?"router-link-exact-active":u,g=null==this.activeClass?p:this.activeClass,v=null==this.exactActiveClass?f:this.exactActiveClass,b=s.redirectedFrom?h(null,H(s.redirectedFrom),null,t):s;c[v]=y(a,b,this.exactPath),c[g]=this.exact||this.exactPath?c[v]:function(e,n){return 0===e.path.replace(m,"/").indexOf(n.path.replace(m,"/"))&&(!n.hash||e.hash===n.hash)&&function(e,n){for(var t in n)if(!(t in e))return!1;return!0}(e.query,n.query)}(a,b);var w=c[v]?this.ariaCurrentValue:null,_=function(e){W(e)&&(n.replace?t.replace(o,G):t.push(o,G))},x={click:W};Array.isArray(this.event)?this.event.forEach((function(e){x[e]=_})):x[this.event]=_;var k={class:c},T=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:l,route:s,navigate:_,isActive:c[g],isExactActive:c[v]});if(T){if(1===T.length)return T[0];if(T.length>1||!T.length)return 0===T.length?e():e("span",{},T)}if("a"===this.tag)k.on=x,k.attrs={href:l,"aria-current":w};else{var E=function e(n){var t;if(n)for(var a=0;a<n.length;a++){if("a"===(t=n[a]).tag)return t;if(t.children&&(t=e(t.children)))return t}}(this.$slots.default);if(E){E.isStatic=!1;var S=E.data=r({},E.data);for(var I in S.on=S.on||{},S.on){var A=S.on[I];I in x&&(S.on[I]=Array.isArray(A)?A:[A])}for(var C in x)C in S.on?S.on[C].push(x[C]):S.on[C]=_;var j=E.data.attrs=r({},E.data.attrs);j.href=l,j["aria-current"]=w}else k.on=x}return e(this.tag,k,this.$slots.default)}};function W(e){if(!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey||e.defaultPrevented||void 0!==e.button&&0!==e.button)){if(e.currentTarget&&e.currentTarget.getAttribute){var n=e.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(n))return}return e.preventDefault&&e.preventDefault(),!0}}var Y="undefined"!=typeof window;function V(e,n,t,a,r){var i=n||[],o=t||Object.create(null),s=a||Object.create(null);e.forEach((function(e){!function e(n,t,a,r,i,o){var s=r.path,l=r.name;0;var c=r.pathToRegexpOptions||{},d=function(e,n,t){t||(e=e.replace(/\/$/,""));if("/"===e[0])return e;if(null==n)return e;return E(n.path+"/"+e)}(s,i,c.strict);"boolean"==typeof r.caseSensitive&&(c.sensitive=r.caseSensitive);var u={path:d,regex:Z(d,c),components:r.components||{default:r.component},alias:r.alias?"string"==typeof r.alias?[r.alias]:r.alias:[],instances:{},enteredCbs:{},name:l,parent:i,matchAs:o,redirect:r.redirect,beforeEnter:r.beforeEnter,meta:r.meta||{},props:null==r.props?{}:r.components?r.props:{default:r.props}};r.children&&r.children.forEach((function(r){var i=o?E(o+"/"+r.path):void 0;e(n,t,a,r,u,i)}));t[u.path]||(n.push(u.path),t[u.path]=u);if(void 0!==r.alias)for(var p=Array.isArray(r.alias)?r.alias:[r.alias],m=0;m<p.length;++m){0;var h={path:p[m],children:r.children};e(n,t,a,h,i,u.path||"/")}l&&(a[l]||(a[l]=u))}(i,o,s,e,r)}));for(var l=0,c=i.length;l<c;l++)"*"===i[l]&&(i.push(i.splice(l,1)[0]),c--,l--);return{pathList:i,pathMap:o,nameMap:s}}function Z(e,n){return I(e,[],n)}function Q(e,n){var t=V(e),a=t.pathList,r=t.pathMap,i=t.nameMap;function o(e,t,o){var s=H(e,t,!1,n),c=s.name;if(c){var d=i[c];if(!d)return l(null,s);var u=d.regex.keys.filter((function(e){return!e.optional})).map((function(e){return e.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var p in t.params)!(p in s.params)&&u.indexOf(p)>-1&&(s.params[p]=t.params[p]);return s.path=U(d.path,s.params),l(d,s,o)}if(s.path){s.params={};for(var m=0;m<a.length;m++){var h=a[m],f=r[h];if(X(f.regex,s.path,s.params))return l(f,s,o)}}return l(null,s)}function s(e,t){var a=e.redirect,r="function"==typeof a?a(h(e,t,null,n)):a;if("string"==typeof r&&(r={path:r}),!r||"object"!=typeof r)return l(null,t);var s=r,c=s.name,d=s.path,u=t.query,p=t.hash,m=t.params;if(u=s.hasOwnProperty("query")?s.query:u,p=s.hasOwnProperty("hash")?s.hash:p,m=s.hasOwnProperty("params")?s.params:m,c){i[c];return o({_normalized:!0,name:c,query:u,hash:p,params:m},void 0,t)}if(d){var f=function(e,n){return T(e,n.parent?n.parent.path:"/",!0)}(d,e);return o({_normalized:!0,path:U(f,m),query:u,hash:p},void 0,t)}return l(null,t)}function l(e,t,a){return e&&e.redirect?s(e,a||t):e&&e.matchAs?function(e,n,t){var a=o({_normalized:!0,path:U(t,n.params)});if(a){var r=a.matched,i=r[r.length-1];return n.params=a.params,l(i,n)}return l(null,n)}(0,t,e.matchAs):h(e,t,a,n)}return{match:o,addRoute:function(e,n){var t="object"!=typeof e?i[e]:void 0;V([n||e],a,r,i,t),t&&t.alias.length&&V(t.alias.map((function(e){return{path:e,children:[n]}})),a,r,i,t)},getRoutes:function(){return a.map((function(e){return r[e]}))},addRoutes:function(e){V(e,a,r,i)}}}function X(e,n,t){var a=n.match(e);if(!a)return!1;if(!t)return!0;for(var r=1,i=a.length;r<i;++r){var o=e.keys[r-1];o&&(t[o.name||"pathMatch"]="string"==typeof a[r]?c(a[r]):a[r])}return!0}var ee=Y&&window.performance&&window.performance.now?window.performance:Date;function ne(){return ee.now().toFixed(3)}var te=ne();function ae(){return te}function re(e){return te=e}var ie=Object.create(null);function oe(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var e=window.location.protocol+"//"+window.location.host,n=window.location.href.replace(e,""),t=r({},window.history.state);return t.key=ae(),window.history.replaceState(t,"",n),window.addEventListener("popstate",ce),function(){window.removeEventListener("popstate",ce)}}function se(e,n,t,a){if(e.app){var r=e.options.scrollBehavior;r&&e.app.$nextTick((function(){var i=function(){var e=ae();if(e)return ie[e]}(),o=r.call(e,n,t,a?i:null);o&&("function"==typeof o.then?o.then((function(e){he(e,i)})).catch((function(e){0})):he(o,i))}))}}function le(){var e=ae();e&&(ie[e]={x:window.pageXOffset,y:window.pageYOffset})}function ce(e){le(),e.state&&e.state.key&&re(e.state.key)}function de(e){return pe(e.x)||pe(e.y)}function ue(e){return{x:pe(e.x)?e.x:window.pageXOffset,y:pe(e.y)?e.y:window.pageYOffset}}function pe(e){return"number"==typeof e}var me=/^#\d/;function he(e,n){var t,a="object"==typeof e;if(a&&"string"==typeof e.selector){var r=me.test(e.selector)?document.getElementById(e.selector.slice(1)):document.querySelector(e.selector);if(r){var i=e.offset&&"object"==typeof e.offset?e.offset:{};n=function(e,n){var t=document.documentElement.getBoundingClientRect(),a=e.getBoundingClientRect();return{x:a.left-t.left-n.x,y:a.top-t.top-n.y}}(r,i={x:pe((t=i).x)?t.x:0,y:pe(t.y)?t.y:0})}else de(e)&&(n=ue(e))}else a&&de(e)&&(n=ue(e));n&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:n.x,top:n.y,behavior:e.behavior}):window.scrollTo(n.x,n.y))}var fe,ge=Y&&((-1===(fe=window.navigator.userAgent).indexOf("Android 2.")&&-1===fe.indexOf("Android 4.0")||-1===fe.indexOf("Mobile Safari")||-1!==fe.indexOf("Chrome")||-1!==fe.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function ve(e,n){le();var t=window.history;try{if(n){var a=r({},t.state);a.key=ae(),t.replaceState(a,"",e)}else t.pushState({key:re(ne())},"",e)}catch(t){window.location[n?"replace":"assign"](e)}}function be(e){ve(e,!0)}var ye={redirected:2,aborted:4,cancelled:8,duplicated:16};function we(e,n){return xe(e,n,ye.redirected,'Redirected when going from "'+e.fullPath+'" to "'+function(e){if("string"==typeof e)return e;if("path"in e)return e.path;var n={};return ke.forEach((function(t){t in e&&(n[t]=e[t])})),JSON.stringify(n,null,2)}(n)+'" via a navigation guard.')}function _e(e,n){return xe(e,n,ye.cancelled,'Navigation cancelled from "'+e.fullPath+'" to "'+n.fullPath+'" with a new navigation.')}function xe(e,n,t,a){var r=new Error(a);return r._isRouter=!0,r.from=e,r.to=n,r.type=t,r}var ke=["params","query","hash"];function Te(e){return Object.prototype.toString.call(e).indexOf("Error")>-1}function Ee(e,n){return Te(e)&&e._isRouter&&(null==n||e.type===n)}function Se(e,n,t){var a=function(r){r>=e.length?t():e[r]?n(e[r],(function(){a(r+1)})):a(r+1)};a(0)}function Ie(e){return function(n,t,a){var r=!1,i=0,o=null;Ae(e,(function(e,n,t,s){if("function"==typeof e&&void 0===e.cid){r=!0,i++;var l,c=Oe((function(n){var r;((r=n).__esModule||je&&"Module"===r[Symbol.toStringTag])&&(n=n.default),e.resolved="function"==typeof n?n:$.extend(n),t.components[s]=n,--i<=0&&a()})),d=Oe((function(e){var n="Failed to resolve async component "+s+": "+e;o||(o=Te(e)?e:new Error(n),a(o))}));try{l=e(c,d)}catch(e){d(e)}if(l)if("function"==typeof l.then)l.then(c,d);else{var u=l.component;u&&"function"==typeof u.then&&u.then(c,d)}}})),r||a()}}function Ae(e,n){return Ce(e.map((function(e){return Object.keys(e.components).map((function(t){return n(e.components[t],e.instances[t],e,t)}))})))}function Ce(e){return Array.prototype.concat.apply([],e)}var je="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Oe(e){var n=!1;return function(){for(var t=[],a=arguments.length;a--;)t[a]=arguments[a];if(!n)return n=!0,e.apply(this,t)}}var Le=function(e,n){this.router=e,this.base=function(e){if(!e)if(Y){var n=document.querySelector("base");e=(e=n&&n.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else e="/";"/"!==e.charAt(0)&&(e="/"+e);return e.replace(/\/$/,"")}(n),this.current=g,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Ne(e,n,t,a){var r=Ae(e,(function(e,a,r,i){var o=function(e,n){"function"!=typeof e&&(e=$.extend(e));return e.options[n]}(e,n);if(o)return Array.isArray(o)?o.map((function(e){return t(e,a,r,i)})):t(o,a,r,i)}));return Ce(a?r.reverse():r)}function De(e,n){if(n)return function(){return e.apply(n,arguments)}}Le.prototype.listen=function(e){this.cb=e},Le.prototype.onReady=function(e,n){this.ready?e():(this.readyCbs.push(e),n&&this.readyErrorCbs.push(n))},Le.prototype.onError=function(e){this.errorCbs.push(e)},Le.prototype.transitionTo=function(e,n,t){var a,r=this;try{a=this.router.match(e,this.current)}catch(e){throw this.errorCbs.forEach((function(n){n(e)})),e}var i=this.current;this.confirmTransition(a,(function(){r.updateRoute(a),n&&n(a),r.ensureURL(),r.router.afterHooks.forEach((function(e){e&&e(a,i)})),r.ready||(r.ready=!0,r.readyCbs.forEach((function(e){e(a)})))}),(function(e){t&&t(e),e&&!r.ready&&(Ee(e,ye.redirected)&&i===g||(r.ready=!0,r.readyErrorCbs.forEach((function(n){n(e)}))))}))},Le.prototype.confirmTransition=function(e,n,t){var a=this,r=this.current;this.pending=e;var i,o,s=function(e){!Ee(e)&&Te(e)&&(a.errorCbs.length?a.errorCbs.forEach((function(n){n(e)})):console.error(e)),t&&t(e)},l=e.matched.length-1,c=r.matched.length-1;if(y(e,r)&&l===c&&e.matched[l]===r.matched[c])return this.ensureURL(),e.hash&&se(this.router,r,e,!1),s(((o=xe(i=r,e,ye.duplicated,'Avoided redundant navigation to current location: "'+i.fullPath+'".')).name="NavigationDuplicated",o));var d=function(e,n){var t,a=Math.max(e.length,n.length);for(t=0;t<a&&e[t]===n[t];t++);return{updated:n.slice(0,t),activated:n.slice(t),deactivated:e.slice(t)}}(this.current.matched,e.matched),u=d.updated,p=d.deactivated,m=d.activated,h=[].concat(function(e){return Ne(e,"beforeRouteLeave",De,!0)}(p),this.router.beforeHooks,function(e){return Ne(e,"beforeRouteUpdate",De)}(u),m.map((function(e){return e.beforeEnter})),Ie(m)),f=function(n,t){if(a.pending!==e)return s(_e(r,e));try{n(e,r,(function(n){!1===n?(a.ensureURL(!0),s(function(e,n){return xe(e,n,ye.aborted,'Navigation aborted from "'+e.fullPath+'" to "'+n.fullPath+'" via a navigation guard.')}(r,e))):Te(n)?(a.ensureURL(!0),s(n)):"string"==typeof n||"object"==typeof n&&("string"==typeof n.path||"string"==typeof n.name)?(s(we(r,e)),"object"==typeof n&&n.replace?a.replace(n):a.push(n)):t(n)}))}catch(e){s(e)}};Se(h,f,(function(){Se(function(e){return Ne(e,"beforeRouteEnter",(function(e,n,t,a){return function(e,n,t){return function(a,r,i){return e(a,r,(function(e){"function"==typeof e&&(n.enteredCbs[t]||(n.enteredCbs[t]=[]),n.enteredCbs[t].push(e)),i(e)}))}}(e,t,a)}))}(m).concat(a.router.resolveHooks),f,(function(){if(a.pending!==e)return s(_e(r,e));a.pending=null,n(e),a.router.app&&a.router.app.$nextTick((function(){_(e)}))}))}))},Le.prototype.updateRoute=function(e){this.current=e,this.cb&&this.cb(e)},Le.prototype.setupListeners=function(){},Le.prototype.teardown=function(){this.listeners.forEach((function(e){e()})),this.listeners=[],this.current=g,this.pending=null};var Pe=function(e){function n(n,t){e.call(this,n,t),this._startLocation=Me(this.base)}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var n=this.router,t=n.options.scrollBehavior,a=ge&&t;a&&this.listeners.push(oe());var r=function(){var t=e.current,r=Me(e.base);e.current===g&&r===e._startLocation||e.transitionTo(r,(function(e){a&&se(n,e,t,!0)}))};window.addEventListener("popstate",r),this.listeners.push((function(){window.removeEventListener("popstate",r)}))}},n.prototype.go=function(e){window.history.go(e)},n.prototype.push=function(e,n,t){var a=this,r=this.current;this.transitionTo(e,(function(e){ve(E(a.base+e.fullPath)),se(a.router,e,r,!1),n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var a=this,r=this.current;this.transitionTo(e,(function(e){be(E(a.base+e.fullPath)),se(a.router,e,r,!1),n&&n(e)}),t)},n.prototype.ensureURL=function(e){if(Me(this.base)!==this.current.fullPath){var n=E(this.base+this.current.fullPath);e?ve(n):be(n)}},n.prototype.getCurrentLocation=function(){return Me(this.base)},n}(Le);function Me(e){var n=window.location.pathname,t=n.toLowerCase(),a=e.toLowerCase();return!e||t!==a&&0!==t.indexOf(E(a+"/"))||(n=n.slice(e.length)),(n||"/")+window.location.search+window.location.hash}var Re=function(e){function n(n,t,a){e.call(this,n,t),a&&function(e){var n=Me(e);if(!/^\/#/.test(n))return window.location.replace(E(e+"/#"+n)),!0}(this.base)||ze()}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var n=this.router.options.scrollBehavior,t=ge&&n;t&&this.listeners.push(oe());var a=function(){var n=e.current;ze()&&e.transitionTo(qe(),(function(a){t&&se(e.router,a,n,!0),ge||Be(a.fullPath)}))},r=ge?"popstate":"hashchange";window.addEventListener(r,a),this.listeners.push((function(){window.removeEventListener(r,a)}))}},n.prototype.push=function(e,n,t){var a=this,r=this.current;this.transitionTo(e,(function(e){Fe(e.fullPath),se(a.router,e,r,!1),n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var a=this,r=this.current;this.transitionTo(e,(function(e){Be(e.fullPath),se(a.router,e,r,!1),n&&n(e)}),t)},n.prototype.go=function(e){window.history.go(e)},n.prototype.ensureURL=function(e){var n=this.current.fullPath;qe()!==n&&(e?Fe(n):Be(n))},n.prototype.getCurrentLocation=function(){return qe()},n}(Le);function ze(){var e=qe();return"/"===e.charAt(0)||(Be("/"+e),!1)}function qe(){var e=window.location.href,n=e.indexOf("#");return n<0?"":e=e.slice(n+1)}function Je(e){var n=window.location.href,t=n.indexOf("#");return(t>=0?n.slice(0,t):n)+"#"+e}function Fe(e){ge?ve(Je(e)):window.location.hash=e}function Be(e){ge?be(Je(e)):window.location.replace(Je(e))}var Ue=function(e){function n(n,t){e.call(this,n,t),this.stack=[],this.index=-1}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.push=function(e,n,t){var a=this;this.transitionTo(e,(function(e){a.stack=a.stack.slice(0,a.index+1).concat(e),a.index++,n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var a=this;this.transitionTo(e,(function(e){a.stack=a.stack.slice(0,a.index).concat(e),n&&n(e)}),t)},n.prototype.go=function(e){var n=this,t=this.index+e;if(!(t<0||t>=this.stack.length)){var a=this.stack[t];this.confirmTransition(a,(function(){var e=n.current;n.index=t,n.updateRoute(a),n.router.afterHooks.forEach((function(n){n&&n(a,e)}))}),(function(e){Ee(e,ye.duplicated)&&(n.index=t)}))}},n.prototype.getCurrentLocation=function(){var e=this.stack[this.stack.length-1];return e?e.fullPath:"/"},n.prototype.ensureURL=function(){},n}(Le),He=function(e){void 0===e&&(e={}),this.app=null,this.apps=[],this.options=e,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Q(e.routes||[],this);var n=e.mode||"hash";switch(this.fallback="history"===n&&!ge&&!1!==e.fallback,this.fallback&&(n="hash"),Y||(n="abstract"),this.mode=n,n){case"history":this.history=new Pe(this,e.base);break;case"hash":this.history=new Re(this,e.base,this.fallback);break;case"abstract":this.history=new Ue(this,e.base);break;default:0}},$e={currentRoute:{configurable:!0}};He.prototype.match=function(e,n,t){return this.matcher.match(e,n,t)},$e.currentRoute.get=function(){return this.history&&this.history.current},He.prototype.init=function(e){var n=this;if(this.apps.push(e),e.$once("hook:destroyed",(function(){var t=n.apps.indexOf(e);t>-1&&n.apps.splice(t,1),n.app===e&&(n.app=n.apps[0]||null),n.app||n.history.teardown()})),!this.app){this.app=e;var t=this.history;if(t instanceof Pe||t instanceof Re){var a=function(e){t.setupListeners(),function(e){var a=t.current,r=n.options.scrollBehavior;ge&&r&&"fullPath"in e&&se(n,e,a,!1)}(e)};t.transitionTo(t.getCurrentLocation(),a,a)}t.listen((function(e){n.apps.forEach((function(n){n._route=e}))}))}},He.prototype.beforeEach=function(e){return Ke(this.beforeHooks,e)},He.prototype.beforeResolve=function(e){return Ke(this.resolveHooks,e)},He.prototype.afterEach=function(e){return Ke(this.afterHooks,e)},He.prototype.onReady=function(e,n){this.history.onReady(e,n)},He.prototype.onError=function(e){this.history.onError(e)},He.prototype.push=function(e,n,t){var a=this;if(!n&&!t&&"undefined"!=typeof Promise)return new Promise((function(n,t){a.history.push(e,n,t)}));this.history.push(e,n,t)},He.prototype.replace=function(e,n,t){var a=this;if(!n&&!t&&"undefined"!=typeof Promise)return new Promise((function(n,t){a.history.replace(e,n,t)}));this.history.replace(e,n,t)},He.prototype.go=function(e){this.history.go(e)},He.prototype.back=function(){this.go(-1)},He.prototype.forward=function(){this.go(1)},He.prototype.getMatchedComponents=function(e){var n=e?e.matched?e:this.resolve(e).route:this.currentRoute;return n?[].concat.apply([],n.matched.map((function(e){return Object.keys(e.components).map((function(n){return e.components[n]}))}))):[]},He.prototype.resolve=function(e,n,t){var a=H(e,n=n||this.history.current,t,this),r=this.match(a,n),i=r.redirectedFrom||r.fullPath;return{location:a,route:r,href:function(e,n,t){var a="hash"===t?"#"+n:n;return e?E(e+"/"+a):a}(this.history.base,i,this.mode),normalizedTo:a,resolved:r}},He.prototype.getRoutes=function(){return this.matcher.getRoutes()},He.prototype.addRoute=function(e,n){this.matcher.addRoute(e,n),this.history.current!==g&&this.history.transitionTo(this.history.getCurrentLocation())},He.prototype.addRoutes=function(e){this.matcher.addRoutes(e),this.history.current!==g&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(He.prototype,$e);var Ge=He;function Ke(e,n){return e.push(n),function(){var t=e.indexOf(n);t>-1&&e.splice(t,1)}}He.install=function e(n){if(!e.installed||$!==n){e.installed=!0,$=n;var t=function(e){return void 0!==e},a=function(e,n){var a=e.$options._parentVnode;t(a)&&t(a=a.data)&&t(a=a.registerRouteInstance)&&a(e,n)};n.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),n.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,a(this,this)},destroyed:function(){a(this)}}),Object.defineProperty(n.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(n.prototype,"$route",{get:function(){return this._routerRoot._route}}),n.component("RouterView",x),n.component("RouterLink",K);var r=n.config.optionMergeStrategies;r.beforeRouteEnter=r.beforeRouteLeave=r.beforeRouteUpdate=r.created}},He.version="3.6.5",He.isNavigationFailure=Ee,He.NavigationFailureType=ye,He.START_LOCATION=g,Y&&window.Vue&&window.Vue.use(He);t(106);t(128),t(17);var We={NotFound:()=>Promise.all([t.e(0),t.e(7)]).then(t.bind(null,470)),Layout:()=>Promise.all([t.e(0),t.e(3)]).then(t.bind(null,469))},Ye={"v-f415ebc0":()=>t.e(8).then(t.bind(null,472)),"v-a6c35a82":()=>t.e(9).then(t.bind(null,473)),"v-998835bc":()=>t.e(10).then(t.bind(null,474)),"v-78bcb4bc":()=>t.e(11).then(t.bind(null,475)),"v-1f0ca540":()=>t.e(12).then(t.bind(null,476)),"v-a6c16d9c":()=>t.e(13).then(t.bind(null,477)),"v-5a234d0e":()=>t.e(14).then(t.bind(null,478)),"v-2dd572b2":()=>t.e(15).then(t.bind(null,479)),"v-31d26f3c":()=>t.e(16).then(t.bind(null,480)),"v-4ad5cd7c":()=>t.e(17).then(t.bind(null,481)),"v-676002b2":()=>t.e(18).then(t.bind(null,482)),"v-f4d1815c":()=>t.e(19).then(t.bind(null,483)),"v-38ca00b8":()=>t.e(20).then(t.bind(null,484)),"v-51cd5ef8":()=>t.e(21).then(t.bind(null,485)),"v-497d7762":()=>t.e(22).then(t.bind(null,486)),"v-6280d5a2":()=>t.e(23).then(t.bind(null,487)),"v-abc39610":()=>t.e(24).then(t.bind(null,488)),"v-79bcd990":()=>t.e(25).then(t.bind(null,489)),"v-1ccb3574":()=>t.e(26).then(t.bind(null,490)),"v-4bad8eff":()=>t.e(27).then(t.bind(null,491)),"v-6ef6bf36":()=>t.e(28).then(t.bind(null,492)),"v-c290b01e":()=>t.e(29).then(t.bind(null,493)),"v-e70761c4":()=>t.e(30).then(t.bind(null,494)),"v-660b1f27":()=>t.e(32).then(t.bind(null,495)),"v-80aef426":()=>t.e(33).then(t.bind(null,496)),"v-639a0f7a":()=>t.e(31).then(t.bind(null,497)),"v-03a6f1e0":()=>t.e(34).then(t.bind(null,498)),"v-4e919d70":()=>t.e(35).then(t.bind(null,499)),"v-4f7e5a56":()=>t.e(36).then(t.bind(null,500)),"v-f7980a44":()=>t.e(37).then(t.bind(null,501)),"v-039b7178":()=>t.e(38).then(t.bind(null,502)),"v-5459eecd":()=>t.e(39).then(t.bind(null,503)),"v-27c64bc0":()=>t.e(40).then(t.bind(null,504)),"v-cd219960":()=>t.e(41).then(t.bind(null,505)),"v-0b12933a":()=>t.e(42).then(t.bind(null,506)),"v-7b9db9b6":()=>t.e(43).then(t.bind(null,507)),"v-098edc32":()=>t.e(44).then(t.bind(null,508)),"v-3fa091ca":()=>t.e(45).then(t.bind(null,509)),"v-54077827":()=>t.e(46).then(t.bind(null,510)),"v-1c067b47":()=>t.e(47).then(t.bind(null,511)),"v-54a5a8f1":()=>t.e(49).then(t.bind(null,512)),"v-4b206a0f":()=>t.e(48).then(t.bind(null,513)),"v-10f613aa":()=>t.e(50).then(t.bind(null,514)),"v-0c164253":()=>t.e(52).then(t.bind(null,515)),"v-65b952f2":()=>t.e(53).then(t.bind(null,516)),"v-672547f2":()=>t.e(51).then(t.bind(null,517)),"v-21a1b472":()=>t.e(54).then(t.bind(null,518)),"v-24c0bbfe":()=>t.e(55).then(t.bind(null,519)),"v-558dc8ba":()=>t.e(57).then(t.bind(null,520)),"v-c8daa3f2":()=>t.e(58).then(t.bind(null,521)),"v-0c46eaa7":()=>t.e(59).then(t.bind(null,522)),"v-20feecc7":()=>t.e(60).then(t.bind(null,523)),"v-1deb9607":()=>t.e(56).then(t.bind(null,524)),"v-ce147052":()=>t.e(61).then(t.bind(null,525)),"v-79dbae07":()=>t.e(62).then(t.bind(null,526)),"v-686ae17b":()=>t.e(64).then(t.bind(null,527)),"v-0a9184e7":()=>t.e(63).then(t.bind(null,528)),"v-a0880f96":()=>t.e(65).then(t.bind(null,529)),"v-6592916c":()=>t.e(66).then(t.bind(null,530)),"v-778ac29c":()=>t.e(68).then(t.bind(null,531)),"v-6c528997":()=>t.e(67).then(t.bind(null,532)),"v-b6061afe":()=>t.e(69).then(t.bind(null,533)),"v-4c28040b":()=>t.e(70).then(t.bind(null,534)),"v-7280ffb2":()=>t.e(71).then(t.bind(null,535)),"v-01725947":()=>t.e(72).then(t.bind(null,536)),"v-3f973327":()=>t.e(73).then(t.bind(null,537)),"v-30230c72":()=>t.e(74).then(t.bind(null,538)),"v-26d51feb":()=>t.e(76).then(t.bind(null,539)),"v-03d9b432":()=>t.e(75).then(t.bind(null,540)),"v-d6f86d32":()=>t.e(77).then(t.bind(null,541)),"v-6ea4444b":()=>t.e(78).then(t.bind(null,542)),"v-a493dd52":()=>t.e(79).then(t.bind(null,543)),"v-d7570fb0":()=>t.e(80).then(t.bind(null,544)),"v-49cf9efe":()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,545))};function Ve(e){const n=Object.create(null);return function(t){return n[t]||(n[t]=e(t))}}const Ze=/-(\w)/g,Qe=Ve(e=>e.replace(Ze,(e,n)=>n?n.toUpperCase():"")),Xe=/\B([A-Z])/g,en=Ve(e=>e.replace(Xe,"-$1").toLowerCase()),nn=Ve(e=>e.charAt(0).toUpperCase()+e.slice(1));function tn(e,n){if(!n)return;if(e(n))return e(n);return n.includes("-")?e(nn(Qe(n))):e(nn(n))||e(en(n))}const an=Object.assign({},We,Ye),rn=e=>an[e],on=e=>Ye[e],sn=e=>We[e],ln=e=>a.default.component(e);function cn(e){return tn(on,e)}function dn(e){return tn(sn,e)}function un(e){return tn(rn,e)}function pn(e){return tn(ln,e)}function mn(...e){return Promise.all(e.filter(e=>e).map(async e=>{if(!pn(e)&&un(e)){const n=await un(e)();a.default.component(e,n.default)}}))}function hn(e,n){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[e]=n)}var fn=t(92),gn=t.n(fn),vn=t(93),bn=t.n(vn),yn={created(){if(this.siteMeta=this.$site.headTags.filter(([e])=>"meta"===e).map(([e,n])=>n),this.$ssrContext){const n=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(e=n)?e.map(e=>{let n="<meta";return Object.keys(e).forEach(t=>{n+=` ${t}="${bn()(e[t])}"`}),n+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=_n(this.$canonicalUrl)}var e},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const e=this.getMergedMetaTags();this.currentMetaTags=xn(e,this.currentMetaTags)},getMergedMetaTags(){const e=this.$page.frontmatter.meta||[];return gn()([{name:"description",content:this.$description}],e,this.siteMeta,kn)},updateCanonicalLink(){wn(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",_n(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){xn(null,this.currentMetaTags),wn()}};function wn(){const e=document.querySelector("link[rel='canonical']");e&&e.remove()}function _n(e=""){return e?`<link href="${e}" rel="canonical" />`:""}function xn(e,n){if(n&&[...n].filter(e=>e.parentNode===document.head).forEach(e=>document.head.removeChild(e)),e)return e.map(e=>{const n=document.createElement("meta");return Object.keys(e).forEach(t=>{n.setAttribute(t,e[t])}),document.head.appendChild(n),n})}function kn(e){for(const n of["name","property","itemprop"])if(e.hasOwnProperty(n))return e[n]+n;return JSON.stringify(e)}var Tn=t(52),En={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(Tn)()((function(){this.setActiveHash()}),300),setActiveHash(){const e=[].slice.call(document.querySelectorAll(".sidebar-link")),n=[].slice.call(document.querySelectorAll(".header-anchor")).filter(n=>e.some(e=>e.hash===n.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),a=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),r=window.innerHeight+t;for(let e=0;e<n.length;e++){const i=n[e],o=n[e+1],s=0===e&&0===t||t>=i.parentElement.offsetTop+10&&(!o||t<o.parentElement.offsetTop-10),l=decodeURIComponent(this.$route.hash);if(s&&l!==decodeURIComponent(i.hash)){const t=i;if(r===a)for(let t=e+1;t<n.length;t++)if(l===decodeURIComponent(n[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},Sn=t(25),In=t.n(Sn),An={mounted(){In.a.configure({showSpinner:!1}),this.$router.beforeEach((e,n,t)=>{e.path===n.path||a.default.component(e.name)||In.a.start(),t()}),this.$router.afterEach(()=>{In.a.done(),this.isSidebarOpen=!1})}};t(240),t(241);class Cn{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:e="",duration:n=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${e}</div>\n    `,this.containerEl.appendChild(t),n>0&&setTimeout(()=>{this.close(t)},n)}close(e){e.className=e.className.replace("move-in",""),e.className+="move-out",e.addEventListener("animationend",()=>{e.remove()})}}var jn={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(e=>{document.querySelectorAll(e).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(e){if(e.classList.contains("codecopy-enabled"))return;const n=document.createElement("i");n.className="code-copy",n.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',n.title="Copy to clipboard",n.addEventListener("click",()=>{this.copyToClipboard(e.innerText)}),e.appendChild(n),e.classList.add("codecopy-enabled")},copyToClipboard(e){const n=document.createElement("textarea");n.value=e,n.setAttribute("readonly",""),n.style.position="absolute",n.style.left="-9999px",document.body.appendChild(n);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);n.select(),document.execCommand("copy");(new Cn).show({text:"复制成功",duration:1e3}),document.body.removeChild(n),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(e,n){void 0===n&&(n={});var t=n.insertAt;if(e&&"undefined"!=typeof document){var a=document.head||document.getElementsByTagName("head")[0],r=document.createElement("style");r.type="text/css","top"===t&&a.firstChild?a.insertBefore(r,a.firstChild):a.appendChild(r),r.styleSheet?r.styleSheet.cssText=e:r.appendChild(document.createTextNode(e))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var On={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Ln={},Nn=function(e){return'<div id="app">\n'.concat(e,"\n</div>")},Dn=function(e){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[e]?window.$VUEPRESS_DEMO_BLOCK[e]:On[e]},Pn=function e(n,t,a){var r=document.createElement(n);return t&&Object.keys(t).forEach((function(e){if(e.indexOf("data"))r[e]=t[e];else{var n=e.replace("data","");r.dataset[n]=t[e]}})),a&&a.forEach((function(n){var t=n.tag,a=n.attrs,i=n.children;r.appendChild(e(t,a,i))})),r},Mn=function(e,n,t){var a,r=(a=e.querySelectorAll(".".concat(n)),Array.prototype.slice.call(a));return 1!==r.length||t?r:r[0]},Rn=function(e,n){var t,a,r=e.match(/<style>([\s\S]+)<\/style>/),i=e.match(/<template>([\s\S]+)<\/template>/),o=e.match(/<script>([\s\S]+)<\/script>/),s={css:r&&r[1].replace(/^\n|\n$/g,""),html:i&&i[1].replace(/^\n|\n$/g,""),js:o&&o[1].replace(/^\n|\n$/g,""),jsLib:n.jsLib||[],cssLib:n.cssLib||[]};s.htmlTpl=Nn(s.html),s.jsTpl=(t=s.js,a=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(a,"\n})")),s.script=function(e,n){var t=e.split(/export\s+default/),a="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),r=window.Babel?window.Babel.transform(a,{presets:["es2015"]}).code:a,i=[eval][0](r);return i.template=n,i}(s.js,s.html);var l=Dn("vue");return s.jsLib.unshift(l),s},zn=function(e,n){var t,a=e.match(/<style>([\s\S]+)<\/style>/),r=e.match(/<html>([\s\S]+)<\/html>/),i=e.match(/<script>([\s\S]+)<\/script>/),o={css:a&&a[1].replace(/^\n|\n$/g,""),html:r&&r[1].replace(/^\n|\n$/g,""),js:i&&i[1].replace(/^\n|\n$/g,""),jsLib:n.jsLib||[],cssLib:n.cssLib||[]};return o.htmlTpl=o.html,o.jsTpl=o.js,o.script=(t=o.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),o},qn=function(e){return e=e.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),e+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function Jn(){var e=Mn(document,"vuepress-plugin-demo-block__wrapper",!0);e.length?e.forEach((function(e){if("true"!==e.dataset.created){e.style.display="block";var n=Mn(e,"vuepress-plugin-demo-block__code"),t=Mn(e,"vuepress-plugin-demo-block__display"),a=Mn(e,"vuepress-plugin-demo-block__footer"),r=Mn(t,"vuepress-plugin-demo-block__app"),i=decodeURIComponent(e.dataset.code),o=decodeURIComponent(e.dataset.config),s=decodeURIComponent(e.dataset.type);o=o?JSON.parse(o):{};var l=n.querySelector("div").clientHeight,c="react"===s?function(e,n){var t=(0,window.Babel.transform)(e,{presets:["es2015","react"]}).code,a="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),r=new Function("return ".concat(a))(),i={js:r,css:r.__style__||"",jsLib:n.jsLib||[],cssLib:n.cssLib||[],jsTpl:qn(e),htmlTpl:Nn("")},o=Dn("react"),s=Dn("reactDOM");return i.jsLib.unshift(o,s),i}(i,o):"vanilla"===s?zn(i,o):Rn(i,o),d=Pn("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(a.appendChild(d),d.addEventListener("click",Fn.bind(null,d,l,n,a)),Dn("jsfiddle")&&a.appendChild(function(e){var n=e.css,t=e.htmlTpl,a=e.jsTpl,r=e.jsLib,i=e.cssLib,o=r.concat(i).concat(Dn("cssLib")).concat(Dn("jsLib")).join(",");return Pn("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:n}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:a}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:o}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(c)),Dn("codepen")&&a.appendChild(function(e){var n=e.css,t=e.htmlTpl,a=e.jsTpl,r=e.jsLib,i=e.cssLib,o=JSON.stringify({css:n,html:t,js:a,js_external:r.concat(Dn("jsLib")).join(";"),css_external:i.concat(Dn("cssLib")).join(";"),layout:Dn("codepenLayout"),js_pre_processor:Dn("codepenJsProcessor"),editors:Dn("codepenEditors")});return Pn("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:o}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(c)),void 0!==o.horizontal?o.horizontal:Dn("horizontal")){e.classList.add("vuepress-plugin-demo-block__horizontal");var u=n.firstChild.cloneNode(!0);u.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(u)}if(c.css&&function(e){if(!Ln[e]){var n=Pn("style",{innerHTML:e});document.body.appendChild(n),Ln[e]=!0}}(c.css),"react"===s)ReactDOM.render(React.createElement(c.js),r);else if("vue"===s){var p=(new(Vue.extend(c.script))).$mount();r.appendChild(p.$el)}else"vanilla"===s&&(r.innerHTML=c.html,new Function("return (function(){".concat(c.script,"})()"))());e.dataset.created="true"}})):setTimeout((function(e){Jn()}),300)}function Fn(e,n,t,a){var r="1"!==e.dataset.isExpand;t.style.height=r?"".concat(n,"px"):0,r?a.classList.add("vuepress-plugin-demo-block__show-link"):a.classList.remove("vuepress-plugin-demo-block__show-link"),e.dataset.isExpand=r?"1":"0"}var Bn={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},Jn()},updated:function(){Jn()}},Un="auto",Hn="zoom-in",$n="zoom-out",Gn="grab",Kn="move";function Wn(e,n,t){var a=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],r={passive:!1};a?e.addEventListener(n,t,r):e.removeEventListener(n,t,r)}function Yn(e,n){if(e){var t=new Image;t.onload=function(){n&&n(t)},t.src=e}}function Vn(e){return e.dataset.original?e.dataset.original:"A"===e.parentNode.tagName?e.parentNode.getAttribute("href"):null}function Zn(e,n,t){!function(e){var n=Qn,t=Xn;if(e.transition){var a=e.transition;delete e.transition,e[n]=a}if(e.transform){var r=e.transform;delete e.transform,e[t]=r}}(n);var a=e.style,r={};for(var i in n)t&&(r[i]=a[i]||""),a[i]=n[i];return r}var Qn="transition",Xn="transform",et="transform",nt="transitionend";var tt=function(){},at={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:tt,onClose:tt,onGrab:tt,onMove:tt,onRelease:tt,onBeforeOpen:tt,onBeforeClose:tt,onBeforeGrab:tt,onBeforeRelease:tt,onImageLoading:tt,onImageLoaded:tt},rt={init:function(e){var n,t;n=this,t=e,Object.getOwnPropertyNames(Object.getPrototypeOf(n)).forEach((function(e){n[e]=n[e].bind(t)}))},click:function(e){if(e.preventDefault(),ot(e))return window.open(this.target.srcOriginal||e.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(e.currentTarget)},scroll:function(){var e=document.documentElement||document.body.parentNode||document.body,n=window.pageXOffset||e.scrollLeft,t=window.pageYOffset||e.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:n,y:t});var a=this.lastScrollPosition.x-n,r=this.lastScrollPosition.y-t,i=this.options.scrollThreshold;(Math.abs(r)>=i||Math.abs(a)>=i)&&(this.lastScrollPosition=null,this.close())},keydown:function(e){(function(e){return"Escape"===(e.key||e.code)||27===e.keyCode})(e)&&(this.released?this.close():this.release(this.close))},mousedown:function(e){if(it(e)&&!ot(e)){e.preventDefault();var n=e.clientX,t=e.clientY;this.pressTimer=setTimeout(function(){this.grab(n,t)}.bind(this),200)}},mousemove:function(e){this.released||this.move(e.clientX,e.clientY)},mouseup:function(e){it(e)&&!ot(e)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(e){e.preventDefault();var n=e.touches[0],t=n.clientX,a=n.clientY;this.pressTimer=setTimeout(function(){this.grab(t,a)}.bind(this),200)},touchmove:function(e){if(!this.released){var n=e.touches[0],t=n.clientX,a=n.clientY;this.move(t,a)}},touchend:function(e){(function(e){e.targetTouches.length})(e)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function it(e){return 0===e.button}function ot(e){return e.metaKey||e.ctrlKey}var st={init:function(e){this.el=document.createElement("div"),this.instance=e,this.parent=document.body,Zn(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(e.options),Wn(this.el,"click",e.handler.clickOverlay.bind(e))},updateStyle:function(e){Zn(this.el,{zIndex:e.zIndex,backgroundColor:e.bgColor,transition:"opacity\n        "+e.transitionDuration+"s\n        "+e.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},lt="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},ct=function(){function e(e,n){for(var t=0;t<n.length;t++){var a=n[t];a.enumerable=a.enumerable||!1,a.configurable=!0,"value"in a&&(a.writable=!0),Object.defineProperty(e,a.key,a)}}return function(n,t,a){return t&&e(n.prototype,t),a&&e(n,a),n}}(),dt=Object.assign||function(e){for(var n=1;n<arguments.length;n++){var t=arguments[n];for(var a in t)Object.prototype.hasOwnProperty.call(t,a)&&(e[a]=t[a])}return e},ut={init:function(e,n){this.el=e,this.instance=n,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Vn(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var e=this.instance.options,n=e.zIndex,t=e.enableGrab,a=e.transitionDuration,r=e.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:n+1,cursor:t?Gn:$n,transition:et+"\n        "+a+"s\n        "+r,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Zn(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Zn(this.el,{transform:"none"})},grab:function(e,n,t){var a=pt(),r=a.x-e,i=a.y-n;Zn(this.el,{cursor:Kn,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(e,n,t){var a=pt(),r=a.x-e,i=a.y-n;Zn(this.el,{transition:et,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Zn(this.el,this.styleClose)},restoreOpenStyle:function(){Zn(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var e=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var n=this.el.cloneNode(!1);n.setAttribute("src",this.srcOriginal),n.style.position="fixed",n.style.visibility="hidden",e.appendChild(n),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),e.removeChild(n)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var e=pt(),n=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:e.x-n,y:e.y-t}},calculateScale:function(){var e=this.el.dataset,n=e.zoomingHeight,t=e.zoomingWidth,a=this.instance.options,r=a.customSize,i=a.scaleBase;if(!r&&n&&t)return{x:t/this.rect.width,y:n/this.rect.height};if(r&&"object"===(void 0===r?"undefined":lt(r)))return{x:r.width/this.rect.width,y:r.height/this.rect.height};var o=this.rect.width/2,s=this.rect.height/2,l=pt(),c={x:l.x-o,y:l.y-s},d=c.x/o,u=c.y/s,p=i+Math.min(d,u);if(r&&"string"==typeof r){var m=t||this.el.naturalWidth,h=n||this.el.naturalHeight,f=parseFloat(r)*m/(100*this.rect.width),g=parseFloat(r)*h/(100*this.rect.height);if(p>f||p>g)return{x:f,y:g}}return{x:p,y:p}}};function pt(){var e=document.documentElement;return{x:Math.min(e.clientWidth,window.innerWidth)/2,y:Math.min(e.clientHeight,window.innerHeight)/2}}function mt(e,n,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(a){Wn(e,a,n[a],t)}))}var ht=function(){function e(n){!function(e,n){if(!(e instanceof n))throw new TypeError("Cannot call a class as a function")}(this,e),this.target=Object.create(ut),this.overlay=Object.create(st),this.handler=Object.create(rt),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=dt({},at,n),this.overlay.init(this),this.handler.init(this)}return ct(e,[{key:"listen",value:function(e){if("string"==typeof e)for(var n=document.querySelectorAll(e),t=n.length;t--;)this.listen(n[t]);else"IMG"===e.tagName&&(e.style.cursor=Hn,Wn(e,"click",this.handler.click),this.options.preloadImage&&Yn(Vn(e)));return this}},{key:"config",value:function(e){return e?(dt(this.options,e),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(e){var n=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var a="string"==typeof e?document.querySelector(e):e;if("IMG"===a.tagName){if(this.options.onBeforeOpen(a),this.target.init(a,this),!this.options.preloadImage){var r=this.target.srcOriginal;null!=r&&(this.options.onImageLoading(a),Yn(r,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Wn(document,"scroll",this.handler.scroll),Wn(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Wn(window,"resize",this.handler.resizeWindow);var i=function e(){Wn(a,nt,e,!1),n.lock=!1,n.target.upgradeSource(),n.options.enableGrab&&mt(document,n.handler,!0),t(a)};return Wn(a,nt,i),this}}}},{key:"close",value:function(){var e=this,n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Un,this.overlay.fadeOut(),this.target.zoomOut(),Wn(document,"scroll",this.handler.scroll,!1),Wn(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Wn(window,"resize",this.handler.resizeWindow,!1);var a=function a(){Wn(t,nt,a,!1),e.shown=!1,e.lock=!1,e.target.downgradeSource(),e.options.enableGrab&&mt(document,e.handler,!1),e.target.restoreCloseStyle(),e.overlay.remove(),n(t)};return Wn(t,nt,a),this}}},{key:"grab",value:function(e,n){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,a=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var r=this.target.el;this.options.onBeforeGrab(r),this.released=!1,this.target.grab(e,n,t);var i=function e(){Wn(r,nt,e,!1),a(r)};return Wn(r,nt,i),this}}},{key:"move",value:function(e,n){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,a=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=Kn,this.target.move(e,n,t);var r=this.target.el,i=function e(){Wn(r,nt,e,!1),a(r)};return Wn(r,nt,i),this}}},{key:"release",value:function(){var e=this,n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Un,this.target.restoreOpenStyle();var a=function a(){Wn(t,nt,a,!1),e.lock=!1,e.released=!0,n(t)};return Wn(t,nt,a),this}}}]),e}();const ft=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),gt=Number("500");class vt{constructor(){this.instance=new ht(ft)}update(e=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(e)}updateDelay(e=".theme-vdoing-content img:not(.no-zoom)",n=gt){setTimeout(()=>this.update(e),n)}}var bt=[yn,En,An,jn,Bn,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new vt,this.$vuepress.zooming.updateDelay()}}],yt={name:"GlobalLayout",computed:{layout(){const e=this.getLayout();return hn("layout",e),a.default.component(e)}},methods:{getLayout(){if(this.$page.path){const e=this.$page.frontmatter.layout;return e&&(this.$vuepress.getLayoutAsyncComponent(e)||this.$vuepress.getVueComponent(e))?e:"Layout"}return"NotFound"}}},wt=t(9),_t=Object(wt.a)(yt,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(e,n,t){switch(n){case"components":e[n]||(e[n]={}),Object.assign(e[n],t);break;case"mixins":e[n]||(e[n]=[]),e[n].push(...t);break;default:throw new Error("Unknown option name.")}}(_t,"mixins",bt);const xt=[{name:"v-f415ebc0",path:"/pages/155b65/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-f415ebc0").then(t)}},{path:"/pages/155b65/index.html",redirect:"/pages/155b65/"},{path:"/01.Java基础/01.集合/01.类型转换.html",redirect:"/pages/155b65/"},{name:"v-a6c35a82",path:"/pages/77d4e2/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-a6c35a82").then(t)}},{path:"/pages/77d4e2/index.html",redirect:"/pages/77d4e2/"},{path:"/01.Java基础/02.IO流/01.IO基础知识.html",redirect:"/pages/77d4e2/"},{name:"v-998835bc",path:"/pages/49acab/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-998835bc").then(t)}},{path:"/pages/49acab/index.html",redirect:"/pages/49acab/"},{path:"/01.Java基础/02.IO流/02.IO设计模式.html",redirect:"/pages/49acab/"},{name:"v-78bcb4bc",path:"/pages/a3d832/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-78bcb4bc").then(t)}},{path:"/pages/a3d832/index.html",redirect:"/pages/a3d832/"},{path:"/01.Java基础/02.IO流/03.IO模型总结.html",redirect:"/pages/a3d832/"},{name:"v-1f0ca540",path:"/pages/42be26/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-1f0ca540").then(t)}},{path:"/pages/42be26/index.html",redirect:"/pages/42be26/"},{path:"/01.Java基础/02.IO流/04.NIO核心知识总结.html",redirect:"/pages/42be26/"},{name:"v-a6c16d9c",path:"/pages/cd056d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-a6c16d9c").then(t)}},{path:"/pages/cd056d/index.html",redirect:"/pages/cd056d/"},{path:"/01.Java基础/05.版本新特性/01.java8-common-new-features.html",redirect:"/pages/cd056d/"},{name:"v-5a234d0e",path:"/pages/b610cd/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-5a234d0e").then(t)}},{path:"/pages/b610cd/index.html",redirect:"/pages/b610cd/"},{path:"/01.Java基础/05.版本新特性/02.java8-tutorial-translate.html",redirect:"/pages/b610cd/"},{name:"v-2dd572b2",path:"/pages/1091ad/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-2dd572b2").then(t)}},{path:"/pages/1091ad/index.html",redirect:"/pages/1091ad/"},{path:"/01.Java基础/05.版本新特性/03.java9.html",redirect:"/pages/1091ad/"},{name:"v-31d26f3c",path:"/pages/e43406/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-31d26f3c").then(t)}},{path:"/pages/e43406/index.html",redirect:"/pages/e43406/"},{path:"/01.Java基础/05.版本新特性/04.java10.html",redirect:"/pages/e43406/"},{name:"v-4ad5cd7c",path:"/pages/f37c60/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4ad5cd7c").then(t)}},{path:"/pages/f37c60/index.html",redirect:"/pages/f37c60/"},{path:"/01.Java基础/05.版本新特性/05.java11.html",redirect:"/pages/f37c60/"},{name:"v-676002b2",path:"/pages/79a5f6/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-676002b2").then(t)}},{path:"/pages/79a5f6/index.html",redirect:"/pages/79a5f6/"},{path:"/01.Java基础/05.版本新特性/06.java12-13.html",redirect:"/pages/79a5f6/"},{name:"v-f4d1815c",path:"/pages/683a03/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-f4d1815c").then(t)}},{path:"/pages/683a03/index.html",redirect:"/pages/683a03/"},{path:"/01.Java基础/05.版本新特性/07.java14-15.html",redirect:"/pages/683a03/"},{name:"v-38ca00b8",path:"/pages/fa2c73/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-38ca00b8").then(t)}},{path:"/pages/fa2c73/index.html",redirect:"/pages/fa2c73/"},{path:"/01.Java基础/05.版本新特性/08.java16.html",redirect:"/pages/fa2c73/"},{name:"v-51cd5ef8",path:"/pages/245aa2/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-51cd5ef8").then(t)}},{path:"/pages/245aa2/index.html",redirect:"/pages/245aa2/"},{path:"/01.Java基础/05.版本新特性/09.java17.html",redirect:"/pages/245aa2/"},{name:"v-497d7762",path:"/pages/ce76de/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-497d7762").then(t)}},{path:"/pages/ce76de/index.html",redirect:"/pages/ce76de/"},{path:"/01.Java基础/05.版本新特性/10.java18.html",redirect:"/pages/ce76de/"},{name:"v-6280d5a2",path:"/pages/42d550/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6280d5a2").then(t)}},{path:"/pages/42d550/index.html",redirect:"/pages/42d550/"},{path:"/01.Java基础/05.版本新特性/11.java19.html",redirect:"/pages/42d550/"},{name:"v-abc39610",path:"/pages/d5208b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-abc39610").then(t)}},{path:"/pages/d5208b/index.html",redirect:"/pages/d5208b/"},{path:"/01.Java基础/05.版本新特性/12.java20.html",redirect:"/pages/d5208b/"},{name:"v-79bcd990",path:"/pages/54087b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-79bcd990").then(t)}},{path:"/pages/54087b/index.html",redirect:"/pages/54087b/"},{path:"/01.Java基础/05.版本新特性/13.java21.html",redirect:"/pages/54087b/"},{name:"v-1ccb3574",path:"/pages/be9ac8/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-1ccb3574").then(t)}},{path:"/pages/be9ac8/index.html",redirect:"/pages/be9ac8/"},{path:"/01.Java基础/06.SpringBoot/01.Spring源码.html",redirect:"/pages/be9ac8/"},{name:"v-4bad8eff",path:"/pages/5b4265/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4bad8eff").then(t)}},{path:"/pages/5b4265/index.html",redirect:"/pages/5b4265/"},{path:"/01.Java基础/06.SpringBoot/02.权限模型.html",redirect:"/pages/5b4265/"},{name:"v-6ef6bf36",path:"/pages/c6bced/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6ef6bf36").then(t)}},{path:"/pages/c6bced/index.html",redirect:"/pages/c6bced/"},{path:"/01.Java基础/06.SpringBoot/03.Cookie-Session-Token-JWT.html",redirect:"/pages/c6bced/"},{name:"v-c290b01e",path:"/pages/3c4623/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-c290b01e").then(t)}},{path:"/pages/3c4623/index.html",redirect:"/pages/3c4623/"},{path:"/03.人工智能/01.监督学习-吴恩达coursera.html",redirect:"/pages/3c4623/"},{name:"v-e70761c4",path:"/pages/cb2190/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-e70761c4").then(t)}},{path:"/pages/cb2190/index.html",redirect:"/pages/cb2190/"},{path:"/03.人工智能/02.吴恩达：机器学习的六个核心算法.html",redirect:"/pages/cb2190/"},{name:"v-660b1f27",path:"/pages/8448ab/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-660b1f27").then(t)}},{path:"/pages/8448ab/index.html",redirect:"/pages/8448ab/"},{path:"/04.知识地图/02.源码脑图/01.总览.html",redirect:"/pages/8448ab/"},{name:"v-80aef426",path:"/pages/372b2d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-80aef426").then(t)}},{path:"/pages/372b2d/index.html",redirect:"/pages/372b2d/"},{path:"/04.知识地图/02.源码脑图/02.Program入口.html",redirect:"/pages/372b2d/"},{name:"v-639a0f7a",path:"/pages/f8be69/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-639a0f7a").then(t)}},{path:"/pages/f8be69/index.html",redirect:"/pages/f8be69/"},{path:"/04.知识地图/01.知识地图/01.知识地图.html",redirect:"/pages/f8be69/"},{name:"v-03a6f1e0",path:"/pages/cb2fbc/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-03a6f1e0").then(t)}},{path:"/pages/cb2fbc/index.html",redirect:"/pages/cb2fbc/"},{path:"/04.知识地图/02.源码脑图/03.WebApplication主机.html",redirect:"/pages/cb2fbc/"},{name:"v-4e919d70",path:"/pages/78c443/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4e919d70").then(t)}},{path:"/pages/78c443/index.html",redirect:"/pages/78c443/"},{path:"/04.知识地图/02.源码脑图/04.Host主机.html",redirect:"/pages/78c443/"},{name:"v-4f7e5a56",path:"/pages/840f86/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4f7e5a56").then(t)}},{path:"/pages/840f86/index.html",redirect:"/pages/840f86/"},{path:"/04.知识地图/02.源码脑图/05.WebHost主机.html",redirect:"/pages/840f86/"},{name:"v-f7980a44",path:"/pages/0d115d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-f7980a44").then(t)}},{path:"/pages/0d115d/index.html",redirect:"/pages/0d115d/"},{path:"/04.知识地图/02.源码脑图/06.依赖注入.html",redirect:"/pages/0d115d/"},{name:"v-039b7178",path:"/pages/e2d1de/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-039b7178").then(t)}},{path:"/pages/e2d1de/index.html",redirect:"/pages/e2d1de/"},{path:"/04.知识地图/02.源码脑图/07.Autofac.html",redirect:"/pages/e2d1de/"},{name:"v-5459eecd",path:"/pages/899977/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-5459eecd").then(t)}},{path:"/pages/899977/index.html",redirect:"/pages/899977/"},{path:"/04.知识地图/02.源码脑图/08.Middleware中间件.html",redirect:"/pages/899977/"},{name:"v-27c64bc0",path:"/pages/5991be/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-27c64bc0").then(t)}},{path:"/pages/5991be/index.html",redirect:"/pages/5991be/"},{path:"/04.知识地图/02.源码脑图/09.RateLimiter限制速率.html",redirect:"/pages/5991be/"},{name:"v-cd219960",path:"/pages/bacc57/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-cd219960").then(t)}},{path:"/pages/bacc57/index.html",redirect:"/pages/bacc57/"},{path:"/04.知识地图/02.源码脑图/10.响应缓存请求解压缩.html",redirect:"/pages/bacc57/"},{name:"v-0b12933a",path:"/pages/e50dff/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-0b12933a").then(t)}},{path:"/pages/e50dff/index.html",redirect:"/pages/e50dff/"},{path:"/05.工具&部署/01.Docker/01.开源简介.html",redirect:"/pages/e50dff/"},{name:"v-7b9db9b6",path:"/pages/f1d3fb/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-7b9db9b6").then(t)}},{path:"/pages/f1d3fb/index.html",redirect:"/pages/f1d3fb/"},{path:"/05.工具&部署/01.Docker/02.监督学习-吴恩达coursera.html",redirect:"/pages/f1d3fb/"},{name:"v-098edc32",path:"/pages/fbe42b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-098edc32").then(t)}},{path:"/pages/fbe42b/index.html",redirect:"/pages/fbe42b/"},{path:"/05.工具&部署/01.Docker/03.Apisix.html",redirect:"/pages/fbe42b/"},{name:"v-3fa091ca",path:"/pages/272684/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-3fa091ca").then(t)}},{path:"/pages/272684/index.html",redirect:"/pages/272684/"},{path:"/05.工具&部署/01.Docker/04.Apollo.html",redirect:"/pages/272684/"},{name:"v-54077827",path:"/pages/01958e/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-54077827").then(t)}},{path:"/pages/01958e/index.html",redirect:"/pages/01958e/"},{path:"/05.工具&部署/01.Docker/05.Cassandra.html",redirect:"/pages/01958e/"},{name:"v-1c067b47",path:"/pages/7e58c5/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-1c067b47").then(t)}},{path:"/pages/7e58c5/index.html",redirect:"/pages/7e58c5/"},{path:"/05.工具&部署/01.Docker/06.Cerebro.html",redirect:"/pages/7e58c5/"},{name:"v-54a5a8f1",path:"/pages/3d230b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-54a5a8f1").then(t)}},{path:"/pages/3d230b/index.html",redirect:"/pages/3d230b/"},{path:"/05.工具&部署/01.Docker/08.Consul.html",redirect:"/pages/3d230b/"},{name:"v-4b206a0f",path:"/pages/3b4977/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4b206a0f").then(t)}},{path:"/pages/3b4977/index.html",redirect:"/pages/3b4977/"},{path:"/05.工具&部署/01.Docker/07.ClickHouse.html",redirect:"/pages/3b4977/"},{name:"v-10f613aa",path:"/pages/ca4b88/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-10f613aa").then(t)}},{path:"/pages/ca4b88/index.html",redirect:"/pages/ca4b88/"},{path:"/05.工具&部署/01.Docker/09.EasyMock.html",redirect:"/pages/ca4b88/"},{name:"v-0c164253",path:"/pages/d93c0b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-0c164253").then(t)}},{path:"/pages/d93c0b/index.html",redirect:"/pages/d93c0b/"},{path:"/05.工具&部署/01.Docker/11.Emqx.html",redirect:"/pages/d93c0b/"},{name:"v-65b952f2",path:"/pages/7bfded/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-65b952f2").then(t)}},{path:"/pages/7bfded/index.html",redirect:"/pages/7bfded/"},{path:"/05.工具&部署/01.Docker/12.FastDFS.html",redirect:"/pages/7bfded/"},{name:"v-672547f2",path:"/pages/18fff0/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-672547f2").then(t)}},{path:"/pages/18fff0/index.html",redirect:"/pages/18fff0/"},{path:"/05.工具&部署/01.Docker/10.Elasticsearch.html",redirect:"/pages/18fff0/"},{name:"v-21a1b472",path:"/pages/53b154/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-21a1b472").then(t)}},{path:"/pages/53b154/index.html",redirect:"/pages/53b154/"},{path:"/05.工具&部署/01.Docker/13.Flink.html",redirect:"/pages/53b154/"},{name:"v-24c0bbfe",path:"/pages/83a3e2/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-24c0bbfe").then(t)}},{path:"/pages/83a3e2/index.html",redirect:"/pages/83a3e2/"},{path:"/05.工具&部署/01.Docker/14.Gitlab.html",redirect:"/pages/83a3e2/"},{name:"v-558dc8ba",path:"/pages/8e9d93/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-558dc8ba").then(t)}},{path:"/pages/8e9d93/index.html",redirect:"/pages/8e9d93/"},{path:"/05.工具&部署/01.Docker/16.Jrebel.html",redirect:"/pages/8e9d93/"},{name:"v-c8daa3f2",path:"/pages/ee069d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-c8daa3f2").then(t)}},{path:"/pages/ee069d/index.html",redirect:"/pages/ee069d/"},{path:"/05.工具&部署/01.Docker/17.MariaDB.html",redirect:"/pages/ee069d/"},{name:"v-0c46eaa7",path:"/pages/cff07b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-0c46eaa7").then(t)}},{path:"/pages/cff07b/index.html",redirect:"/pages/cff07b/"},{path:"/05.工具&部署/01.Docker/18.MySQL.html",redirect:"/pages/cff07b/"},{name:"v-20feecc7",path:"/pages/862a97/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-20feecc7").then(t)}},{path:"/pages/862a97/index.html",redirect:"/pages/862a97/"},{path:"/05.工具&部署/01.Docker/19.Percona.html",redirect:"/pages/862a97/"},{name:"v-1deb9607",path:"/pages/f90f99/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-1deb9607").then(t)}},{path:"/pages/f90f99/index.html",redirect:"/pages/f90f99/"},{path:"/05.工具&部署/01.Docker/15.Jenkins.html",redirect:"/pages/f90f99/"},{name:"v-ce147052",path:"/pages/a560de/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-ce147052").then(t)}},{path:"/pages/a560de/index.html",redirect:"/pages/a560de/"},{path:"/05.工具&部署/01.Docker/20.Phpmyadmin.html",redirect:"/pages/a560de/"},{name:"v-79dbae07",path:"/pages/230ca1/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-79dbae07").then(t)}},{path:"/pages/230ca1/index.html",redirect:"/pages/230ca1/"},{path:"/05.工具&部署/01.Docker/21.PostgreSQL.html",redirect:"/pages/230ca1/"},{name:"v-686ae17b",path:"/pages/aa794b/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-686ae17b").then(t)}},{path:"/pages/aa794b/index.html",redirect:"/pages/aa794b/"},{path:"/05.工具&部署/02.Linux/01.查看Linux系统信息.html",redirect:"/pages/aa794b/"},{name:"v-0a9184e7",path:"/pages/be7f5d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-0a9184e7").then(t)}},{path:"/pages/be7f5d/index.html",redirect:"/pages/be7f5d/"},{path:"/05.工具&部署/01.Docker/22.Redis.html",redirect:"/pages/be7f5d/"},{name:"v-a0880f96",path:"/pages/2cbf35/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-a0880f96").then(t)}},{path:"/pages/2cbf35/index.html",redirect:"/pages/2cbf35/"},{path:"/05.工具&部署/02.Linux/02.CentOS7调整磁盘分区.html",redirect:"/pages/2cbf35/"},{name:"v-6592916c",path:"/pages/42cda4/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6592916c").then(t)}},{path:"/pages/42cda4/index.html",redirect:"/pages/42cda4/"},{path:"/05.工具&部署/02.Linux/03.IO压测.html",redirect:"/pages/42cda4/"},{name:"v-778ac29c",path:"/pages/6db179/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-778ac29c").then(t)}},{path:"/pages/6db179/index.html",redirect:"/pages/6db179/"},{path:"/05.工具&部署/02.Linux/05.CentOS7安装mysql5.7.html",redirect:"/pages/6db179/"},{name:"v-6c528997",path:"/pages/71dd10/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6c528997").then(t)}},{path:"/pages/71dd10/index.html",redirect:"/pages/71dd10/"},{path:"/05.工具&部署/02.Linux/04.Linux图形化监控工具Cockpit.html",redirect:"/pages/71dd10/"},{name:"v-b6061afe",path:"/pages/518cfa/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-b6061afe").then(t)}},{path:"/pages/518cfa/index.html",redirect:"/pages/518cfa/"},{path:"/05.工具&部署/02.Linux/06.在线Linux命令查询.html",redirect:"/pages/518cfa/"},{name:"v-4c28040b",path:"/pages/86a4e2/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-4c28040b").then(t)}},{path:"/pages/86a4e2/index.html",redirect:"/pages/86a4e2/"},{path:"/06.面试/01.AspNetCore面试题/01.AspNetCore面试题.html",redirect:"/pages/86a4e2/"},{name:"v-7280ffb2",path:"/pages/868a19/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-7280ffb2").then(t)}},{path:"/pages/868a19/index.html",redirect:"/pages/868a19/"},{path:"/06.面试/01.AspNetCore面试题/02.Net面试题.html",redirect:"/pages/868a19/"},{name:"v-01725947",path:"/pages/a567cd/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-01725947").then(t)}},{path:"/pages/a567cd/index.html",redirect:"/pages/a567cd/"},{path:"/06.面试/02.Elasticsearch面试题/01.Elasticsearch面试题.html",redirect:"/pages/a567cd/"},{name:"v-3f973327",path:"/pages/5201b9/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-3f973327").then(t)}},{path:"/pages/5201b9/index.html",redirect:"/pages/5201b9/"},{path:"/06.面试/03.MongoDB面试题/01.MongoDB面试题.html",redirect:"/pages/5201b9/"},{name:"v-30230c72",path:"/pages/43b4dd/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-30230c72").then(t)}},{path:"/pages/43b4dd/index.html",redirect:"/pages/43b4dd/"},{path:"/06.面试/04.MySql面试题/01.MySql面试题.html",redirect:"/pages/43b4dd/"},{name:"v-26d51feb",path:"/pages/d74e41/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-26d51feb").then(t)}},{path:"/pages/d74e41/index.html",redirect:"/pages/d74e41/"},{path:"/06.面试/06.RabbitMQ面试题/01.RabbitMQ面试题.html",redirect:"/pages/d74e41/"},{name:"v-03d9b432",path:"/pages/27153d/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-03d9b432").then(t)}},{path:"/pages/27153d/index.html",redirect:"/pages/27153d/"},{path:"/06.面试/05.Nginx面试题/01.Nginx面试题.html",redirect:"/pages/27153d/"},{name:"v-d6f86d32",path:"/pages/97e5f1/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-d6f86d32").then(t)}},{path:"/pages/97e5f1/index.html",redirect:"/pages/97e5f1/"},{path:"/06.面试/07.Redis面试题/01.Redis面试题.html",redirect:"/pages/97e5f1/"},{name:"v-6ea4444b",path:"/pages/51830e/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-6ea4444b").then(t)}},{path:"/pages/51830e/index.html",redirect:"/pages/51830e/"},{path:"/06.面试/08.设计模式面试题/01.设计模式面试题.html",redirect:"/pages/51830e/"},{name:"v-a493dd52",path:"/pages/11e99f/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-a493dd52").then(t)}},{path:"/pages/11e99f/index.html",redirect:"/pages/11e99f/"},{path:"/06.面试/09.微服务面试题/01.微服务面试题.html",redirect:"/pages/11e99f/"},{name:"v-d7570fb0",path:"/blog/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-d7570fb0").then(t)}},{path:"/blog/index.html",redirect:"/blog/"},{path:"/@pages/archivesPage.html",redirect:"/blog/"},{name:"v-49cf9efe",path:"/",component:_t,beforeEnter:(e,n,t)=>{mn("Layout","v-49cf9efe").then(t)}},{path:"/index.html",redirect:"/"},{path:"*",component:_t}],kt={title:"ZYHCODE的博客",description:"Java 全栈知识体系",base:"/",headTags:[["link",{rel:"icon",href:"/img/favicon.ico"}],["meta",{name:"keywords",content:".net,doc,easy,tool"}],["meta",{name:"theme-color",content:"#11a8cd"}]],pages:[{title:"类型转换",frontmatter:{title:"类型转换",date:"2024-08-21T22:56:40.000Z",permalink:"/pages/155b65/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/01.%E9%9B%86%E5%90%88/01.%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2.html",relativePath:"01.Java基础/01.集合/01.类型转换.md",key:"v-f415ebc0",path:"/pages/155b65/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"Java IO 基础知识总结",frontmatter:{title:"Java IO 基础知识总结",category:"Java",tag:["Java IO","Java基础"],date:"2024-08-21T22:31:13.000Z",permalink:"/pages/77d4e2/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/02.IO%E6%B5%81/01.IO%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html",relativePath:"01.Java基础/02.IO流/01.IO基础知识.md",key:"v-a6c35a82",path:"/pages/77d4e2/",headers:[{level:2,title:"IO 流简介",slug:"io-流简介",normalizedTitle:"io 流简介",charIndex:2},{level:2,title:"字节流",slug:"字节流",normalizedTitle:"字节流",charIndex:139},{level:3,title:"InputStream（字节输入流）",slug:"inputstream-字节输入流",normalizedTitle:"inputstream（字节输入流）",charIndex:305},{level:3,title:"OutputStream（字节输出流）",slug:"outputstream-字节输出流",normalizedTitle:"outputstream（字节输出流）",charIndex:2746},{level:2,title:"字符流",slug:"字符流",normalizedTitle:"字符流",charIndex:143},{level:3,title:"Reader（字符输入流）",slug:"reader-字符输入流",normalizedTitle:"reader（字符输入流）",charIndex:4797},{level:3,title:"Writer（字符输出流）",slug:"writer-字符输出流",normalizedTitle:"writer（字符输出流）",charIndex:5927},{level:2,title:"字节缓冲流",slug:"字节缓冲流",normalizedTitle:"字节缓冲流",charIndex:6940},{level:3,title:"BufferedInputStream（字节缓冲输入流）",slug:"bufferedinputstream-字节缓冲输入流",normalizedTitle:"bufferedinputstream（字节缓冲输入流）",charIndex:7077},{level:3,title:"BufferedOutputStream（字节缓冲输出流）",slug:"bufferedoutputstream-字节缓冲输出流",normalizedTitle:"bufferedoutputstream（字节缓冲输出流）",charIndex:11216},{level:2,title:"字符缓冲流",slug:"字符缓冲流",normalizedTitle:"字符缓冲流",charIndex:11665},{level:2,title:"打印流",slug:"打印流",normalizedTitle:"打印流",charIndex:11824},{level:2,title:"随机访问流",slug:"随机访问流",normalizedTitle:"随机访问流",charIndex:12229}],headersStr:"IO 流简介 字节流 InputStream（字节输入流） OutputStream（字节输出流） 字符流 Reader（字符输入流） Writer（字符输出流） 字节缓冲流 BufferedInputStream（字节缓冲输入流） BufferedOutputStream（字节缓冲输出流） 字符缓冲流 打印流 随机访问流",content:'# IO 流简介\n\nIO 即 Input/Output，输入和输出。数据输入到计算机内存的过程即输入，反之输出到外部存储（比如数据库，文件，远程主机）的过程即输出。数据传输过程类似于水流，因此称为 IO 流。IO 流在 Java 中分为输入流和输出流，而根据数据的处理方式又分为字节流和字符流。\n\nJava IO 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。\n\n * InputStream/Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。\n * OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。\n\n\n# 字节流\n\n\n# InputStream（字节输入流）\n\nInputStream用于从源头（通常是文件）读取数据（字节信息）到内存中，java.io.InputStream抽象类是所有字节输入流的父类。\n\nInputStream 常用方法：\n\n * read()：返回输入流中下一个字节的数据。返回的值介于 0 到 255 之间。如果未读取任何字节，则代码返回 -1 ，表示文件结束。\n * read(byte b[ ]) : 从输入流中读取一些字节存储到数组 b 中。如果数组 b 的长度为零，则不读取。如果没有可用字节读取，返回 -1。如果有可用字节读取，则最多读取的字节数最多等于 b.length ， 返回读取的字节数。这个方法等价于 read(b, 0, b.length)。\n * read(byte b[], int off, int len)：在read(byte b[ ]) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字节数）。\n * skip(long n)：忽略输入流中的 n 个字节 ,返回实际忽略的字节数。\n * available()：返回输入流中可以读取的字节数。\n * close()：关闭输入流释放相关的系统资源。\n\n从 Java 9 开始，InputStream 新增加了多个实用的方法：\n\n * readAllBytes()：读取输入流中的所有字节，返回字节数组。\n * readNBytes(byte[] b, int off, int len)：阻塞直到读取 len 个字节。\n * transferTo(OutputStream out)：将所有字节从一个输入流传递到一个输出流。\n\nFileInputStream 是一个比较常用的字节输入流对象，可直接指定文件路径，可以直接读取单字节数据，也可以读取至字节数组中。\n\nFileInputStream 代码示例：\n\ntry (InputStream fis = new FileInputStream("input.txt")) {\n    System.out.println("Number of remaining bytes:"\n            + fis.available());\n    int content;\n    long skip = fis.skip(2);\n    System.out.println("The actual number of bytes skipped:" + skip);\n    System.out.print("The content read from file:");\n    while ((content = fis.read()) != -1) {\n        System.out.print((char) content);\n    }\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\ninput.txt 文件内容：\n\n\n\n输出：\n\nNumber of remaining bytes:11\nThe actual number of bytes skipped:2\nThe content read from file:JavaGuide\n\n\n不过，一般我们是不会直接单独使用 FileInputStream ，通常会配合 BufferedInputStream（字节缓冲输入流，后文会讲到）来使用。\n\n像下面这段代码在我们的项目中就比较常见，我们通过 readAllBytes() 读取输入流所有字节并将其直接赋值给一个 String 对象。\n\n// 新建一个 BufferedInputStream 对象\nBufferedInputStream bufferedInputStream = new BufferedInputStream(new FileInputStream("input.txt"));\n// 读取文件的内容并复制到 String 对象中\nString result = new String(bufferedInputStream.readAllBytes());\nSystem.out.println(result);\n\n\nDataInputStream 用于读取指定类型数据，不能单独使用，必须结合其它流，比如 FileInputStream 。\n\nFileInputStream fileInputStream = new FileInputStream("input.txt");\n//必须将fileInputStream作为构造参数才能使用\nDataInputStream dataInputStream = new DataInputStream(fileInputStream);\n//可以读取任意具体的类型数据\ndataInputStream.readBoolean();\ndataInputStream.readInt();\ndataInputStream.readUTF();\n\n\nObjectInputStream 用于从输入流中读取 Java 对象（反序列化），ObjectOutputStream 用于将对象写入到输出流(序列化)。\n\nObjectInputStream input = new ObjectInputStream(new FileInputStream("object.data"));\nMyClass object = (MyClass) input.readObject();\ninput.close();\n\n\n另外，用于序列化和反序列化的类必须实现 Serializable 接口，对象中如果有属性不想被序列化，使用 transient 修饰。\n\n\n# OutputStream（字节输出流）\n\nOutputStream用于将数据（字节信息）写入到目的地（通常是文件），java.io.OutputStream抽象类是所有字节输出流的父类。\n\nOutputStream 常用方法：\n\n * write(int b)：将特定字节写入输出流。\n * write(byte b[ ]) : 将数组b 写入到输出流，等价于 write(b, 0, b.length) 。\n * write(byte[] b, int off, int len) : 在write(byte b[ ]) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字节数）。\n * flush()：刷新此输出流并强制写出所有缓冲的输出字节。\n * close()：关闭输出流释放相关的系统资源。\n\nFileOutputStream 是最常用的字节输出流对象，可直接指定文件路径，可以直接输出单字节数据，也可以输出指定的字节数组。\n\nFileOutputStream 代码示例：\n\ntry (FileOutputStream output = new FileOutputStream("output.txt")) {\n    byte[] array = "JavaGuide".getBytes();\n    output.write(array);\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\n运行结果：\n\n\n\n类似于 FileInputStream，FileOutputStream 通常也会配合 BufferedOutputStream（字节缓冲输出流，后文会讲到）来使用。\n\nFileOutputStream fileOutputStream = new FileOutputStream("output.txt");\nBufferedOutputStream bos = new BufferedOutputStream(fileOutputStream)\n\n\nDataOutputStream 用于写入指定类型数据，不能单独使用，必须结合其它流，比如 FileOutputStream 。\n\n// 输出流\nFileOutputStream fileOutputStream = new FileOutputStream("out.txt");\nDataOutputStream dataOutputStream = new DataOutputStream(fileOutputStream);\n// 输出任意数据类型\ndataOutputStream.writeBoolean(true);\ndataOutputStream.writeByte(1);\n\n\nObjectInputStream 用于从输入流中读取 Java 对象（ObjectInputStream,反序列化），ObjectOutputStream将对象写入到输出流(ObjectOutputStream，序列化)。\n\nObjectOutputStream output = new ObjectOutputStream(new FileOutputStream("file.txt")\nPerson person = new Person("Guide哥", "JavaGuide作者");\noutput.writeObject(person);\n\n\n\n# 字符流\n\n不管是文件读写还是网络发送接收，信息的最小存储单元都是字节。 那为什么 I/O 流操作要分为字节流操作和字符流操作呢？\n\n个人认为主要有两点原因：\n\n * 字符流是由 Java 虚拟机将字节转换得到的，这个过程还算是比较耗时。\n * 如果我们不知道编码类型就很容易出现乱码问题。\n\n乱码问题这个很容易就可以复现，我们只需要将上面提到的 FileInputStream 代码示例中的 input.txt 文件内容改为中文即可，原代码不需要改动。\n\n\n\n输出：\n\nNumber of remaining bytes:9\nThe actual number of bytes skipped:2\nThe content read from file:§å®¶å¥½\n\n\n可以很明显地看到读取出来的内容已经变成了乱码。\n\n因此，I/O 流就干脆提供了一个直接操作字符的接口，方便我们平时对字符进行流操作。如果音频文件、图片等媒体文件用字节流比较好，如果涉及到字符的话使用字符流比较好。\n\n字符流默认采用的是 Unicode 编码，我们可以通过构造方法自定义编码。顺便分享一下之前遇到的笔试题：常用字符编码所占字节数？utf8 :英文占 1 字节，中文占 3 字节，unicode：任何字符都占 2 个字节，gbk：英文占 1 字节，中文占 2 字节。\n\n\n# Reader（字符输入流）\n\nReader用于从源头（通常是文件）读取数据（字符信息）到内存中，java.io.Reader抽象类是所有字符输入流的父类。\n\nReader 用于读取文本， InputStream 用于读取原始字节。\n\nReader 常用方法：\n\n * read() : 从输入流读取一个字符。\n * read(char[] cbuf) : 从输入流中读取一些字符，并将它们存储到字符数组 cbuf中，等价于 read(cbuf, 0, cbuf.length) 。\n * read(char[] cbuf, int off, int len)：在read(char[] cbuf) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字符数）。\n * skip(long n)：忽略输入流中的 n 个字符 ,返回实际忽略的字符数。\n * close() : 关闭输入流并释放相关的系统资源。\n\nInputStreamReader 是字节流转换为字符流的桥梁，其子类 FileReader 是基于该基础上的封装，可以直接操作字符文件。\n\n// 字节流转换为字符流的桥梁\npublic class InputStreamReader extends Reader {\n}\n// 用于读取字符文件\npublic class FileReader extends InputStreamReader {\n}\n\n\nFileReader 代码示例：\n\ntry (FileReader fileReader = new FileReader("input.txt");) {\n    int content;\n    long skip = fileReader.skip(3);\n    System.out.println("The actual number of bytes skipped:" + skip);\n    System.out.print("The content read from file:");\n    while ((content = fileReader.read()) != -1) {\n        System.out.print((char) content);\n    }\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\ninput.txt 文件内容：\n\n\n\n输出：\n\nThe actual number of bytes skipped:3\nThe content read from file:我是Guide。\n\n\n\n# Writer（字符输出流）\n\nWriter用于将数据（字符信息）写入到目的地（通常是文件），java.io.Writer抽象类是所有字符输出流的父类。\n\nWriter 常用方法：\n\n * write(int c) : 写入单个字符。\n * write(char[] cbuf)：写入字符数组 cbuf，等价于write(cbuf, 0, cbuf.length)。\n * write(char[] cbuf, int off, int len)：在write(char[] cbuf) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字符数）。\n * write(String str)：写入字符串，等价于 write(str, 0, str.length()) 。\n * write(String str, int off, int len)：在write(String str) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字符数）。\n * append(CharSequence csq)：将指定的字符序列附加到指定的 Writer 对象并返回该 Writer 对象。\n * append(char c)：将指定的字符附加到指定的 Writer 对象并返回该 Writer 对象。\n * flush()：刷新此输出流并强制写出所有缓冲的输出字符。\n * close():关闭输出流释放相关的系统资源。\n\nOutputStreamWriter 是字符流转换为字节流的桥梁，其子类 FileWriter 是基于该基础上的封装，可以直接将字符写入到文件。\n\n// 字符流转换为字节流的桥梁\npublic class OutputStreamWriter extends Writer {\n}\n// 用于写入字符到文件\npublic class FileWriter extends OutputStreamWriter {\n}\n\n\nFileWriter 代码示例：\n\ntry (Writer output = new FileWriter("output.txt")) {\n    output.write("你好，我是Guide。");\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\n输出结果：\n\n\n\n\n# 字节缓冲流\n\nIO 操作是很消耗性能的，缓冲流将数据加载至缓冲区，一次性读取/写入多个字节，从而避免频繁的 IO 操作，提高流的传输效率。\n\n字节缓冲流这里采用了装饰器模式来增强 InputStream 和OutputStream子类对象的功能。\n\n举个例子，我们可以通过 BufferedInputStream（字节缓冲输入流）来增强 FileInputStream 的功能。\n\n// 新建一个 BufferedInputStream 对象\nBufferedInputStream bufferedInputStream = new BufferedInputStream(new FileInputStream("input.txt"));\n\n\n字节流和字节缓冲流的性能差别主要体现在我们使用两者的时候都是调用 write(int b) 和 read() 这两个一次只读取一个字节的方法的时候。由于字节缓冲流内部有缓冲区（字节数组），因此，字节缓冲流会先将读取到的字节存放在缓存区，大幅减少 IO 次数，提高读取效率。\n\n我使用 write(int b) 和 read() 方法，分别通过字节流和字节缓冲流复制一个 524.9 mb 的 PDF 文件耗时对比如下：\n\n使用缓冲流复制PDF文件总耗时:15428 毫秒\n使用普通字节流复制PDF文件总耗时:2555062 毫秒\n\n\n两者耗时差别非常大，缓冲流耗费的时间是字节流的 1/165。\n\n测试代码如下:\n\n@Test\nvoid copy_pdf_to_another_pdf_buffer_stream() {\n    // 记录开始时间\n    long start = System.currentTimeMillis();\n    try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream("深入理解计算机操作系统.pdf"));\n         BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream("深入理解计算机操作系统-副本.pdf"))) {\n        int content;\n        while ((content = bis.read()) != -1) {\n            bos.write(content);\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    // 记录结束时间\n    long end = System.currentTimeMillis();\n    System.out.println("使用缓冲流复制PDF文件总耗时:" + (end - start) + " 毫秒");\n}\n\n@Test\nvoid copy_pdf_to_another_pdf_stream() {\n    // 记录开始时间\n    long start = System.currentTimeMillis();\n    try (FileInputStream fis = new FileInputStream("深入理解计算机操作系统.pdf");\n         FileOutputStream fos = new FileOutputStream("深入理解计算机操作系统-副本.pdf")) {\n        int content;\n        while ((content = fis.read()) != -1) {\n            fos.write(content);\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    // 记录结束时间\n    long end = System.currentTimeMillis();\n    System.out.println("使用普通流复制PDF文件总耗时:" + (end - start) + " 毫秒");\n}\n\n\n如果是调用 read(byte b[]) 和 write(byte b[], int off, int len) 这两个写入一个字节数组的方法的话，只要字节数组的大小合适，两者的性能差距其实不大，基本可以忽略。\n\n这次我们使用 read(byte b[]) 和 write(byte b[], int off, int len) 方法，分别通过字节流和字节缓冲流复制一个 524.9 mb 的 PDF 文件耗时对比如下：\n\n使用缓冲流复制PDF文件总耗时:695 毫秒\n使用普通字节流复制PDF文件总耗时:989 毫秒\n\n\n两者耗时差别不是很大，缓冲流的性能要略微好一点点。\n\n测试代码如下：\n\n@Test\nvoid copy_pdf_to_another_pdf_with_byte_array_buffer_stream() {\n    // 记录开始时间\n    long start = System.currentTimeMillis();\n    try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream("深入理解计算机操作系统.pdf"));\n         BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream("深入理解计算机操作系统-副本.pdf"))) {\n        int len;\n        byte[] bytes = new byte[4 * 1024];\n        while ((len = bis.read(bytes)) != -1) {\n            bos.write(bytes, 0, len);\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    // 记录结束时间\n    long end = System.currentTimeMillis();\n    System.out.println("使用缓冲流复制PDF文件总耗时:" + (end - start) + " 毫秒");\n}\n\n@Test\nvoid copy_pdf_to_another_pdf_with_byte_array_stream() {\n    // 记录开始时间\n    long start = System.currentTimeMillis();\n    try (FileInputStream fis = new FileInputStream("深入理解计算机操作系统.pdf");\n         FileOutputStream fos = new FileOutputStream("深入理解计算机操作系统-副本.pdf")) {\n        int len;\n        byte[] bytes = new byte[4 * 1024];\n        while ((len = fis.read(bytes)) != -1) {\n            fos.write(bytes, 0, len);\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    // 记录结束时间\n    long end = System.currentTimeMillis();\n    System.out.println("使用普通流复制PDF文件总耗时:" + (end - start) + " 毫秒");\n}\n\n\n\n# BufferedInputStream（字节缓冲输入流）\n\nBufferedInputStream 从源头（通常是文件）读取数据（字节信息）到内存的过程中不会一个字节一个字节的读取，而是会先将读取到的字节存放在缓存区，并从内部缓冲区中单独读取字节。这样大幅减少了 IO 次数，提高了读取效率。\n\nBufferedInputStream 内部维护了一个缓冲区，这个缓冲区实际就是一个字节数组，通过阅读 BufferedInputStream 源码即可得到这个结论。\n\npublic\nclass BufferedInputStream extends FilterInputStream {\n    // 内部缓冲区数组\n    protected volatile byte buf[];\n    // 缓冲区的默认大小\n    private static int DEFAULT_BUFFER_SIZE = 8192;\n    // 使用默认的缓冲区大小\n    public BufferedInputStream(InputStream in) {\n        this(in, DEFAULT_BUFFER_SIZE);\n    }\n    // 自定义缓冲区大小\n    public BufferedInputStream(InputStream in, int size) {\n        super(in);\n        if (size <= 0) {\n            throw new IllegalArgumentException("Buffer size <= 0");\n        }\n        buf = new byte[size];\n    }\n}\n\n\n缓冲区的大小默认为 8192 字节，当然了，你也可以通过 BufferedInputStream(InputStream in, int size) 这个构造方法来指定缓冲区的大小。\n\n\n# BufferedOutputStream（字节缓冲输出流）\n\nBufferedOutputStream 将数据（字节信息）写入到目的地（通常是文件）的过程中不会一个字节一个字节的写入，而是会先将要写入的字节存放在缓存区，并从内部缓冲区中单独写入字节。这样大幅减少了 IO 次数，提高了读取效率\n\ntry (BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream("output.txt"))) {\n    byte[] array = "JavaGuide".getBytes();\n    bos.write(array);\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\n类似于 BufferedInputStream ，BufferedOutputStream 内部也维护了一个缓冲区，并且，这个缓存区的大小也是 8192 字节。\n\n\n# 字符缓冲流\n\nBufferedReader （字符缓冲输入流）和 BufferedWriter（字符缓冲输出流）类似于 BufferedInputStream（字节缓冲输入流）和BufferedOutputStream（字节缓冲输入流），内部都维护了一个字节数组作为缓冲区。不过，前者主要是用来操作字符信息。\n\n\n# 打印流\n\n下面这段代码大家经常使用吧？\n\nSystem.out.print("Hello！");\nSystem.out.println("Hello！");\n\n\nSystem.out 实际是用于获取一个 PrintStream 对象，print方法实际调用的是 PrintStream 对象的 write 方法。\n\nPrintStream 属于字节打印流，与之对应的是 PrintWriter （字符打印流）。PrintStream 是 OutputStream 的子类，PrintWriter 是 Writer 的子类。\n\npublic class PrintStream extends FilterOutputStream\n    implements Appendable, Closeable {\n}\npublic class PrintWriter extends Writer {\n}\n\n\n\n# 随机访问流\n\n这里要介绍的随机访问流指的是支持随意跳转到文件的任意位置进行读写的 RandomAccessFile 。\n\nRandomAccessFile 的构造方法如下，我们可以指定 mode（读写模式）。\n\n// openAndDelete 参数默认为 false 表示打开文件并且这个文件不会被删除\npublic RandomAccessFile(File file, String mode)\n    throws FileNotFoundException {\n    this(file, mode, false);\n}\n// 私有方法\nprivate RandomAccessFile(File file, String mode, boolean openAndDelete)  throws FileNotFoundException{\n  // 省略大部分代码\n}\n\n\n读写模式主要有下面四种：\n\n * r : 只读模式。\n * rw: 读写模式\n * rws: 相对于 rw，rws 同步更新对“文件的内容”或“元数据”的修改到外部存储设备。\n * rwd : 相对于 rw，rwd 同步更新对“文件的内容”的修改到外部存储设备。\n\n文件内容指的是文件中实际保存的数据，元数据则是用来描述文件属性比如文件的大小信息、创建和修改时间。\n\nRandomAccessFile 中有一个文件指针用来表示下一个将要被写入或者读取的字节所处的位置。我们可以通过 RandomAccessFile 的 seek(long pos) 方法来设置文件指针的偏移量（距文件开头 pos 个字节处）。如果想要获取文件指针当前的位置的话，可以使用 getFilePointer() 方法。\n\nRandomAccessFile 代码示例：\n\nRandomAccessFile randomAccessFile = new RandomAccessFile(new File("input.txt"), "rw");\nSystem.out.println("读取之前的偏移量：" + randomAccessFile.getFilePointer() + ",当前读取到的字符" + (char) randomAccessFile.read() + "，读取之后的偏移量：" + randomAccessFile.getFilePointer());\n// 指针当前偏移量为 6\nrandomAccessFile.seek(6);\nSystem.out.println("读取之前的偏移量：" + randomAccessFile.getFilePointer() + ",当前读取到的字符" + (char) randomAccessFile.read() + "，读取之后的偏移量：" + randomAccessFile.getFilePointer());\n// 从偏移量 7 的位置开始往后写入字节数据\nrandomAccessFile.write(new byte[]{\'H\', \'I\', \'J\', \'K\'});\n// 指针当前偏移量为 0，回到起始位置\nrandomAccessFile.seek(0);\nSystem.out.println("读取之前的偏移量：" + randomAccessFile.getFilePointer() + ",当前读取到的字符" + (char) randomAccessFile.read() + "，读取之后的偏移量：" + randomAccessFile.getFilePointer());\n\n\ninput.txt 文件内容：\n\n\n\n输出：\n\n读取之前的偏移量：0,当前读取到的字符A，读取之后的偏移量：1\n读取之前的偏移量：6,当前读取到的字符G，读取之后的偏移量：7\n读取之前的偏移量：0,当前读取到的字符A，读取之后的偏移量：1\n\n\ninput.txt 文件内容变为 ABCDEFGHIJK 。\n\nRandomAccessFile 的 write 方法在写入对象的时候如果对应的位置已经有数据的话，会将其覆盖掉。\n\nRandomAccessFile randomAccessFile = new RandomAccessFile(new File("input.txt"), "rw");\nrandomAccessFile.write(new byte[]{\'H\', \'I\', \'J\', \'K\'});\n\n\n假设运行上面这段程序之前 input.txt 文件内容变为 ABCD ，运行之后则变为 HIJK 。\n\nRandomAccessFile 比较常见的一个应用就是实现大文件的 断点续传 。何谓断点续传？简单来说就是上传文件中途暂停或失败（比如遇到网络问题）之后，不需要重新上传，只需要上传那些未成功上传的文件分片即可。分片（先将文件切分成多个文件分片）上传是断点续传的基础。\n\nRandomAccessFile 可以帮助我们合并文件分片，示例代码如下：\n\n\n\n我在《Java 面试指北》中详细介绍了大文件的上传问题。\n\n\n\nRandomAccessFile 的实现依赖于 FileDescriptor (文件描述符) 和 FileChannel （内存映射文件）。',normalizedContent:'# io 流简介\n\nio 即 input/output，输入和输出。数据输入到计算机内存的过程即输入，反之输出到外部存储（比如数据库，文件，远程主机）的过程即输出。数据传输过程类似于水流，因此称为 io 流。io 流在 java 中分为输入流和输出流，而根据数据的处理方式又分为字节流和字符流。\n\njava io 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。\n\n * inputstream/reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。\n * outputstream/writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。\n\n\n# 字节流\n\n\n# inputstream（字节输入流）\n\ninputstream用于从源头（通常是文件）读取数据（字节信息）到内存中，java.io.inputstream抽象类是所有字节输入流的父类。\n\ninputstream 常用方法：\n\n * read()：返回输入流中下一个字节的数据。返回的值介于 0 到 255 之间。如果未读取任何字节，则代码返回 -1 ，表示文件结束。\n * read(byte b[ ]) : 从输入流中读取一些字节存储到数组 b 中。如果数组 b 的长度为零，则不读取。如果没有可用字节读取，返回 -1。如果有可用字节读取，则最多读取的字节数最多等于 b.length ， 返回读取的字节数。这个方法等价于 read(b, 0, b.length)。\n * read(byte b[], int off, int len)：在read(byte b[ ]) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字节数）。\n * skip(long n)：忽略输入流中的 n 个字节 ,返回实际忽略的字节数。\n * available()：返回输入流中可以读取的字节数。\n * close()：关闭输入流释放相关的系统资源。\n\n从 java 9 开始，inputstream 新增加了多个实用的方法：\n\n * readallbytes()：读取输入流中的所有字节，返回字节数组。\n * readnbytes(byte[] b, int off, int len)：阻塞直到读取 len 个字节。\n * transferto(outputstream out)：将所有字节从一个输入流传递到一个输出流。\n\nfileinputstream 是一个比较常用的字节输入流对象，可直接指定文件路径，可以直接读取单字节数据，也可以读取至字节数组中。\n\nfileinputstream 代码示例：\n\ntry (inputstream fis = new fileinputstream("input.txt")) {\n    system.out.println("number of remaining bytes:"\n            + fis.available());\n    int content;\n    long skip = fis.skip(2);\n    system.out.println("the actual number of bytes skipped:" + skip);\n    system.out.print("the content read from file:");\n    while ((content = fis.read()) != -1) {\n        system.out.print((char) content);\n    }\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\ninput.txt 文件内容：\n\n\n\n输出：\n\nnumber of remaining bytes:11\nthe actual number of bytes skipped:2\nthe content read from file:javaguide\n\n\n不过，一般我们是不会直接单独使用 fileinputstream ，通常会配合 bufferedinputstream（字节缓冲输入流，后文会讲到）来使用。\n\n像下面这段代码在我们的项目中就比较常见，我们通过 readallbytes() 读取输入流所有字节并将其直接赋值给一个 string 对象。\n\n// 新建一个 bufferedinputstream 对象\nbufferedinputstream bufferedinputstream = new bufferedinputstream(new fileinputstream("input.txt"));\n// 读取文件的内容并复制到 string 对象中\nstring result = new string(bufferedinputstream.readallbytes());\nsystem.out.println(result);\n\n\ndatainputstream 用于读取指定类型数据，不能单独使用，必须结合其它流，比如 fileinputstream 。\n\nfileinputstream fileinputstream = new fileinputstream("input.txt");\n//必须将fileinputstream作为构造参数才能使用\ndatainputstream datainputstream = new datainputstream(fileinputstream);\n//可以读取任意具体的类型数据\ndatainputstream.readboolean();\ndatainputstream.readint();\ndatainputstream.readutf();\n\n\nobjectinputstream 用于从输入流中读取 java 对象（反序列化），objectoutputstream 用于将对象写入到输出流(序列化)。\n\nobjectinputstream input = new objectinputstream(new fileinputstream("object.data"));\nmyclass object = (myclass) input.readobject();\ninput.close();\n\n\n另外，用于序列化和反序列化的类必须实现 serializable 接口，对象中如果有属性不想被序列化，使用 transient 修饰。\n\n\n# outputstream（字节输出流）\n\noutputstream用于将数据（字节信息）写入到目的地（通常是文件），java.io.outputstream抽象类是所有字节输出流的父类。\n\noutputstream 常用方法：\n\n * write(int b)：将特定字节写入输出流。\n * write(byte b[ ]) : 将数组b 写入到输出流，等价于 write(b, 0, b.length) 。\n * write(byte[] b, int off, int len) : 在write(byte b[ ]) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字节数）。\n * flush()：刷新此输出流并强制写出所有缓冲的输出字节。\n * close()：关闭输出流释放相关的系统资源。\n\nfileoutputstream 是最常用的字节输出流对象，可直接指定文件路径，可以直接输出单字节数据，也可以输出指定的字节数组。\n\nfileoutputstream 代码示例：\n\ntry (fileoutputstream output = new fileoutputstream("output.txt")) {\n    byte[] array = "javaguide".getbytes();\n    output.write(array);\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\n运行结果：\n\n\n\n类似于 fileinputstream，fileoutputstream 通常也会配合 bufferedoutputstream（字节缓冲输出流，后文会讲到）来使用。\n\nfileoutputstream fileoutputstream = new fileoutputstream("output.txt");\nbufferedoutputstream bos = new bufferedoutputstream(fileoutputstream)\n\n\ndataoutputstream 用于写入指定类型数据，不能单独使用，必须结合其它流，比如 fileoutputstream 。\n\n// 输出流\nfileoutputstream fileoutputstream = new fileoutputstream("out.txt");\ndataoutputstream dataoutputstream = new dataoutputstream(fileoutputstream);\n// 输出任意数据类型\ndataoutputstream.writeboolean(true);\ndataoutputstream.writebyte(1);\n\n\nobjectinputstream 用于从输入流中读取 java 对象（objectinputstream,反序列化），objectoutputstream将对象写入到输出流(objectoutputstream，序列化)。\n\nobjectoutputstream output = new objectoutputstream(new fileoutputstream("file.txt")\nperson person = new person("guide哥", "javaguide作者");\noutput.writeobject(person);\n\n\n\n# 字符流\n\n不管是文件读写还是网络发送接收，信息的最小存储单元都是字节。 那为什么 i/o 流操作要分为字节流操作和字符流操作呢？\n\n个人认为主要有两点原因：\n\n * 字符流是由 java 虚拟机将字节转换得到的，这个过程还算是比较耗时。\n * 如果我们不知道编码类型就很容易出现乱码问题。\n\n乱码问题这个很容易就可以复现，我们只需要将上面提到的 fileinputstream 代码示例中的 input.txt 文件内容改为中文即可，原代码不需要改动。\n\n\n\n输出：\n\nnumber of remaining bytes:9\nthe actual number of bytes skipped:2\nthe content read from file:§a®¶a¥½\n\n\n可以很明显地看到读取出来的内容已经变成了乱码。\n\n因此，i/o 流就干脆提供了一个直接操作字符的接口，方便我们平时对字符进行流操作。如果音频文件、图片等媒体文件用字节流比较好，如果涉及到字符的话使用字符流比较好。\n\n字符流默认采用的是 unicode 编码，我们可以通过构造方法自定义编码。顺便分享一下之前遇到的笔试题：常用字符编码所占字节数？utf8 :英文占 1 字节，中文占 3 字节，unicode：任何字符都占 2 个字节，gbk：英文占 1 字节，中文占 2 字节。\n\n\n# reader（字符输入流）\n\nreader用于从源头（通常是文件）读取数据（字符信息）到内存中，java.io.reader抽象类是所有字符输入流的父类。\n\nreader 用于读取文本， inputstream 用于读取原始字节。\n\nreader 常用方法：\n\n * read() : 从输入流读取一个字符。\n * read(char[] cbuf) : 从输入流中读取一些字符，并将它们存储到字符数组 cbuf中，等价于 read(cbuf, 0, cbuf.length) 。\n * read(char[] cbuf, int off, int len)：在read(char[] cbuf) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字符数）。\n * skip(long n)：忽略输入流中的 n 个字符 ,返回实际忽略的字符数。\n * close() : 关闭输入流并释放相关的系统资源。\n\ninputstreamreader 是字节流转换为字符流的桥梁，其子类 filereader 是基于该基础上的封装，可以直接操作字符文件。\n\n// 字节流转换为字符流的桥梁\npublic class inputstreamreader extends reader {\n}\n// 用于读取字符文件\npublic class filereader extends inputstreamreader {\n}\n\n\nfilereader 代码示例：\n\ntry (filereader filereader = new filereader("input.txt");) {\n    int content;\n    long skip = filereader.skip(3);\n    system.out.println("the actual number of bytes skipped:" + skip);\n    system.out.print("the content read from file:");\n    while ((content = filereader.read()) != -1) {\n        system.out.print((char) content);\n    }\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\ninput.txt 文件内容：\n\n\n\n输出：\n\nthe actual number of bytes skipped:3\nthe content read from file:我是guide。\n\n\n\n# writer（字符输出流）\n\nwriter用于将数据（字符信息）写入到目的地（通常是文件），java.io.writer抽象类是所有字符输出流的父类。\n\nwriter 常用方法：\n\n * write(int c) : 写入单个字符。\n * write(char[] cbuf)：写入字符数组 cbuf，等价于write(cbuf, 0, cbuf.length)。\n * write(char[] cbuf, int off, int len)：在write(char[] cbuf) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字符数）。\n * write(string str)：写入字符串，等价于 write(str, 0, str.length()) 。\n * write(string str, int off, int len)：在write(string str) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字符数）。\n * append(charsequence csq)：将指定的字符序列附加到指定的 writer 对象并返回该 writer 对象。\n * append(char c)：将指定的字符附加到指定的 writer 对象并返回该 writer 对象。\n * flush()：刷新此输出流并强制写出所有缓冲的输出字符。\n * close():关闭输出流释放相关的系统资源。\n\noutputstreamwriter 是字符流转换为字节流的桥梁，其子类 filewriter 是基于该基础上的封装，可以直接将字符写入到文件。\n\n// 字符流转换为字节流的桥梁\npublic class outputstreamwriter extends writer {\n}\n// 用于写入字符到文件\npublic class filewriter extends outputstreamwriter {\n}\n\n\nfilewriter 代码示例：\n\ntry (writer output = new filewriter("output.txt")) {\n    output.write("你好，我是guide。");\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\n输出结果：\n\n\n\n\n# 字节缓冲流\n\nio 操作是很消耗性能的，缓冲流将数据加载至缓冲区，一次性读取/写入多个字节，从而避免频繁的 io 操作，提高流的传输效率。\n\n字节缓冲流这里采用了装饰器模式来增强 inputstream 和outputstream子类对象的功能。\n\n举个例子，我们可以通过 bufferedinputstream（字节缓冲输入流）来增强 fileinputstream 的功能。\n\n// 新建一个 bufferedinputstream 对象\nbufferedinputstream bufferedinputstream = new bufferedinputstream(new fileinputstream("input.txt"));\n\n\n字节流和字节缓冲流的性能差别主要体现在我们使用两者的时候都是调用 write(int b) 和 read() 这两个一次只读取一个字节的方法的时候。由于字节缓冲流内部有缓冲区（字节数组），因此，字节缓冲流会先将读取到的字节存放在缓存区，大幅减少 io 次数，提高读取效率。\n\n我使用 write(int b) 和 read() 方法，分别通过字节流和字节缓冲流复制一个 524.9 mb 的 pdf 文件耗时对比如下：\n\n使用缓冲流复制pdf文件总耗时:15428 毫秒\n使用普通字节流复制pdf文件总耗时:2555062 毫秒\n\n\n两者耗时差别非常大，缓冲流耗费的时间是字节流的 1/165。\n\n测试代码如下:\n\n@test\nvoid copy_pdf_to_another_pdf_buffer_stream() {\n    // 记录开始时间\n    long start = system.currenttimemillis();\n    try (bufferedinputstream bis = new bufferedinputstream(new fileinputstream("深入理解计算机操作系统.pdf"));\n         bufferedoutputstream bos = new bufferedoutputstream(new fileoutputstream("深入理解计算机操作系统-副本.pdf"))) {\n        int content;\n        while ((content = bis.read()) != -1) {\n            bos.write(content);\n        }\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n    // 记录结束时间\n    long end = system.currenttimemillis();\n    system.out.println("使用缓冲流复制pdf文件总耗时:" + (end - start) + " 毫秒");\n}\n\n@test\nvoid copy_pdf_to_another_pdf_stream() {\n    // 记录开始时间\n    long start = system.currenttimemillis();\n    try (fileinputstream fis = new fileinputstream("深入理解计算机操作系统.pdf");\n         fileoutputstream fos = new fileoutputstream("深入理解计算机操作系统-副本.pdf")) {\n        int content;\n        while ((content = fis.read()) != -1) {\n            fos.write(content);\n        }\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n    // 记录结束时间\n    long end = system.currenttimemillis();\n    system.out.println("使用普通流复制pdf文件总耗时:" + (end - start) + " 毫秒");\n}\n\n\n如果是调用 read(byte b[]) 和 write(byte b[], int off, int len) 这两个写入一个字节数组的方法的话，只要字节数组的大小合适，两者的性能差距其实不大，基本可以忽略。\n\n这次我们使用 read(byte b[]) 和 write(byte b[], int off, int len) 方法，分别通过字节流和字节缓冲流复制一个 524.9 mb 的 pdf 文件耗时对比如下：\n\n使用缓冲流复制pdf文件总耗时:695 毫秒\n使用普通字节流复制pdf文件总耗时:989 毫秒\n\n\n两者耗时差别不是很大，缓冲流的性能要略微好一点点。\n\n测试代码如下：\n\n@test\nvoid copy_pdf_to_another_pdf_with_byte_array_buffer_stream() {\n    // 记录开始时间\n    long start = system.currenttimemillis();\n    try (bufferedinputstream bis = new bufferedinputstream(new fileinputstream("深入理解计算机操作系统.pdf"));\n         bufferedoutputstream bos = new bufferedoutputstream(new fileoutputstream("深入理解计算机操作系统-副本.pdf"))) {\n        int len;\n        byte[] bytes = new byte[4 * 1024];\n        while ((len = bis.read(bytes)) != -1) {\n            bos.write(bytes, 0, len);\n        }\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n    // 记录结束时间\n    long end = system.currenttimemillis();\n    system.out.println("使用缓冲流复制pdf文件总耗时:" + (end - start) + " 毫秒");\n}\n\n@test\nvoid copy_pdf_to_another_pdf_with_byte_array_stream() {\n    // 记录开始时间\n    long start = system.currenttimemillis();\n    try (fileinputstream fis = new fileinputstream("深入理解计算机操作系统.pdf");\n         fileoutputstream fos = new fileoutputstream("深入理解计算机操作系统-副本.pdf")) {\n        int len;\n        byte[] bytes = new byte[4 * 1024];\n        while ((len = fis.read(bytes)) != -1) {\n            fos.write(bytes, 0, len);\n        }\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n    // 记录结束时间\n    long end = system.currenttimemillis();\n    system.out.println("使用普通流复制pdf文件总耗时:" + (end - start) + " 毫秒");\n}\n\n\n\n# bufferedinputstream（字节缓冲输入流）\n\nbufferedinputstream 从源头（通常是文件）读取数据（字节信息）到内存的过程中不会一个字节一个字节的读取，而是会先将读取到的字节存放在缓存区，并从内部缓冲区中单独读取字节。这样大幅减少了 io 次数，提高了读取效率。\n\nbufferedinputstream 内部维护了一个缓冲区，这个缓冲区实际就是一个字节数组，通过阅读 bufferedinputstream 源码即可得到这个结论。\n\npublic\nclass bufferedinputstream extends filterinputstream {\n    // 内部缓冲区数组\n    protected volatile byte buf[];\n    // 缓冲区的默认大小\n    private static int default_buffer_size = 8192;\n    // 使用默认的缓冲区大小\n    public bufferedinputstream(inputstream in) {\n        this(in, default_buffer_size);\n    }\n    // 自定义缓冲区大小\n    public bufferedinputstream(inputstream in, int size) {\n        super(in);\n        if (size <= 0) {\n            throw new illegalargumentexception("buffer size <= 0");\n        }\n        buf = new byte[size];\n    }\n}\n\n\n缓冲区的大小默认为 8192 字节，当然了，你也可以通过 bufferedinputstream(inputstream in, int size) 这个构造方法来指定缓冲区的大小。\n\n\n# bufferedoutputstream（字节缓冲输出流）\n\nbufferedoutputstream 将数据（字节信息）写入到目的地（通常是文件）的过程中不会一个字节一个字节的写入，而是会先将要写入的字节存放在缓存区，并从内部缓冲区中单独写入字节。这样大幅减少了 io 次数，提高了读取效率\n\ntry (bufferedoutputstream bos = new bufferedoutputstream(new fileoutputstream("output.txt"))) {\n    byte[] array = "javaguide".getbytes();\n    bos.write(array);\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\n类似于 bufferedinputstream ，bufferedoutputstream 内部也维护了一个缓冲区，并且，这个缓存区的大小也是 8192 字节。\n\n\n# 字符缓冲流\n\nbufferedreader （字符缓冲输入流）和 bufferedwriter（字符缓冲输出流）类似于 bufferedinputstream（字节缓冲输入流）和bufferedoutputstream（字节缓冲输入流），内部都维护了一个字节数组作为缓冲区。不过，前者主要是用来操作字符信息。\n\n\n# 打印流\n\n下面这段代码大家经常使用吧？\n\nsystem.out.print("hello！");\nsystem.out.println("hello！");\n\n\nsystem.out 实际是用于获取一个 printstream 对象，print方法实际调用的是 printstream 对象的 write 方法。\n\nprintstream 属于字节打印流，与之对应的是 printwriter （字符打印流）。printstream 是 outputstream 的子类，printwriter 是 writer 的子类。\n\npublic class printstream extends filteroutputstream\n    implements appendable, closeable {\n}\npublic class printwriter extends writer {\n}\n\n\n\n# 随机访问流\n\n这里要介绍的随机访问流指的是支持随意跳转到文件的任意位置进行读写的 randomaccessfile 。\n\nrandomaccessfile 的构造方法如下，我们可以指定 mode（读写模式）。\n\n// openanddelete 参数默认为 false 表示打开文件并且这个文件不会被删除\npublic randomaccessfile(file file, string mode)\n    throws filenotfoundexception {\n    this(file, mode, false);\n}\n// 私有方法\nprivate randomaccessfile(file file, string mode, boolean openanddelete)  throws filenotfoundexception{\n  // 省略大部分代码\n}\n\n\n读写模式主要有下面四种：\n\n * r : 只读模式。\n * rw: 读写模式\n * rws: 相对于 rw，rws 同步更新对“文件的内容”或“元数据”的修改到外部存储设备。\n * rwd : 相对于 rw，rwd 同步更新对“文件的内容”的修改到外部存储设备。\n\n文件内容指的是文件中实际保存的数据，元数据则是用来描述文件属性比如文件的大小信息、创建和修改时间。\n\nrandomaccessfile 中有一个文件指针用来表示下一个将要被写入或者读取的字节所处的位置。我们可以通过 randomaccessfile 的 seek(long pos) 方法来设置文件指针的偏移量（距文件开头 pos 个字节处）。如果想要获取文件指针当前的位置的话，可以使用 getfilepointer() 方法。\n\nrandomaccessfile 代码示例：\n\nrandomaccessfile randomaccessfile = new randomaccessfile(new file("input.txt"), "rw");\nsystem.out.println("读取之前的偏移量：" + randomaccessfile.getfilepointer() + ",当前读取到的字符" + (char) randomaccessfile.read() + "，读取之后的偏移量：" + randomaccessfile.getfilepointer());\n// 指针当前偏移量为 6\nrandomaccessfile.seek(6);\nsystem.out.println("读取之前的偏移量：" + randomaccessfile.getfilepointer() + ",当前读取到的字符" + (char) randomaccessfile.read() + "，读取之后的偏移量：" + randomaccessfile.getfilepointer());\n// 从偏移量 7 的位置开始往后写入字节数据\nrandomaccessfile.write(new byte[]{\'h\', \'i\', \'j\', \'k\'});\n// 指针当前偏移量为 0，回到起始位置\nrandomaccessfile.seek(0);\nsystem.out.println("读取之前的偏移量：" + randomaccessfile.getfilepointer() + ",当前读取到的字符" + (char) randomaccessfile.read() + "，读取之后的偏移量：" + randomaccessfile.getfilepointer());\n\n\ninput.txt 文件内容：\n\n\n\n输出：\n\n读取之前的偏移量：0,当前读取到的字符a，读取之后的偏移量：1\n读取之前的偏移量：6,当前读取到的字符g，读取之后的偏移量：7\n读取之前的偏移量：0,当前读取到的字符a，读取之后的偏移量：1\n\n\ninput.txt 文件内容变为 abcdefghijk 。\n\nrandomaccessfile 的 write 方法在写入对象的时候如果对应的位置已经有数据的话，会将其覆盖掉。\n\nrandomaccessfile randomaccessfile = new randomaccessfile(new file("input.txt"), "rw");\nrandomaccessfile.write(new byte[]{\'h\', \'i\', \'j\', \'k\'});\n\n\n假设运行上面这段程序之前 input.txt 文件内容变为 abcd ，运行之后则变为 hijk 。\n\nrandomaccessfile 比较常见的一个应用就是实现大文件的 断点续传 。何谓断点续传？简单来说就是上传文件中途暂停或失败（比如遇到网络问题）之后，不需要重新上传，只需要上传那些未成功上传的文件分片即可。分片（先将文件切分成多个文件分片）上传是断点续传的基础。\n\nrandomaccessfile 可以帮助我们合并文件分片，示例代码如下：\n\n\n\n我在《java 面试指北》中详细介绍了大文件的上传问题。\n\n\n\nrandomaccessfile 的实现依赖于 filedescriptor (文件描述符) 和 filechannel （内存映射文件）。',charsets:{cjk:!0}},{title:"Java IO 设计模式总结",frontmatter:{title:"Java IO 设计模式总结",category:"Java",tag:["Java IO","Java基础"],date:"2024-08-21T22:33:13.000Z",permalink:"/pages/49acab/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/02.IO%E6%B5%81/02.IO%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java基础/02.IO流/02.IO设计模式.md",key:"v-998835bc",path:"/pages/49acab/",headers:[{level:2,title:"装饰器模式",slug:"装饰器模式",normalizedTitle:"装饰器模式",charIndex:39},{level:2,title:"适配器模式",slug:"适配器模式",normalizedTitle:"适配器模式",charIndex:2389},{level:2,title:"工厂模式",slug:"工厂模式",normalizedTitle:"工厂模式",charIndex:5642},{level:2,title:"观察者模式",slug:"观察者模式",normalizedTitle:"观察者模式",charIndex:5917},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:8313}],headersStr:"装饰器模式 适配器模式 工厂模式 观察者模式 参考",content:'这篇文章我们简单来看看我们从 IO 中能够学习到哪些设计模式的应用。\n\n\n# 装饰器模式\n\n装饰器（Decorator）模式 可以在不改变原有对象的情况下拓展其功能。\n\n装饰器模式通过组合替代继承来扩展原始类的功能，在一些继承关系比较复杂的场景（IO 这一场景各种类的继承关系就比较复杂）更加实用。\n\n对于字节流来说， FilterInputStream （对应输入流）和FilterOutputStream（对应输出流）是装饰器模式的核心，分别用于增强 InputStream 和OutputStream子类对象的功能。\n\n我们常见的BufferedInputStream(字节缓冲输入流)、DataInputStream 等等都是FilterInputStream 的子类，BufferedOutputStream（字节缓冲输出流）、DataOutputStream等等都是FilterOutputStream的子类。\n\n举个例子，我们可以通过 BufferedInputStream（字节缓冲输入流）来增强 FileInputStream 的功能。\n\nBufferedInputStream 构造函数如下：\n\npublic BufferedInputStream(InputStream in) {\n    this(in, DEFAULT_BUFFER_SIZE);\n}\n\npublic BufferedInputStream(InputStream in, int size) {\n    super(in);\n    if (size <= 0) {\n        throw new IllegalArgumentException("Buffer size <= 0");\n    }\n    buf = new byte[size];\n}\n\n\n可以看出，BufferedInputStream 的构造函数其中的一个参数就是 InputStream 。\n\nBufferedInputStream 代码示例：\n\ntry (BufferedInputStream bis = new BufferedInputStream(new FileInputStream("input.txt"))) {\n    int content;\n    long skip = bis.skip(2);\n    while ((content = bis.read()) != -1) {\n        System.out.print((char) content);\n    }\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\n这个时候，你可以会想了：为啥我们直接不弄一个BufferedFileInputStream（字符缓冲文件输入流）呢？\n\nBufferedFileInputStream bfis = new BufferedFileInputStream("input.txt");\n\n\n如果 InputStream的子类比较少的话，这样做是没问题的。不过， InputStream的子类实在太多，继承关系也太复杂了。如果我们为每一个子类都定制一个对应的缓冲输入流，那岂不是太麻烦了。\n\n如果你对 IO 流比较熟悉的话，你会发现ZipInputStream 和ZipOutputStream 还可以分别增强 BufferedInputStream 和 BufferedOutputStream 的能力。\n\nBufferedInputStream bis = new BufferedInputStream(new FileInputStream(fileName));\nZipInputStream zis = new ZipInputStream(bis);\n\nBufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(fileName));\nZipOutputStream zipOut = new ZipOutputStream(bos);\n\n\nZipInputStream 和ZipOutputStream 分别继承自InflaterInputStream 和DeflaterOutputStream。\n\npublic\nclass InflaterInputStream extends FilterInputStream {\n}\n\npublic\nclass DeflaterOutputStream extends FilterOutputStream {\n}\n\n\n\n这也是装饰器模式很重要的一个特征，那就是可以对原始类嵌套使用多个装饰器。\n\n为了实现这一效果，装饰器类需要跟原始类继承相同的抽象类或者实现相同的接口。上面介绍到的这些 IO 相关的装饰类和原始类共同的父类是 InputStream 和OutputStream。\n\n对于字符流来说，BufferedReader 可以用来增加 Reader （字符输入流）子类的功能，BufferedWriter 可以用来增加 Writer （字符输出流）子类的功能。\n\nBufferedWriter bw = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(fileName), "UTF-8"));\n\n\nIO 流中的装饰器模式应用的例子实在是太多了，不需要特意记忆，完全没必要哈！搞清了装饰器模式的核心之后，你在使用的时候自然就会知道哪些地方运用到了装饰器模式。\n\n\n# 适配器模式\n\n适配器（Adapter Pattern）模式 主要用于接口互不兼容的类的协调工作，你可以将其联想到我们日常经常使用的电源适配器。\n\n适配器模式中存在被适配的对象或者类称为 适配者(Adaptee) ，作用于适配者的对象或者类称为适配器(Adapter) 。适配器分为对象适配器和类适配器。类适配器使用继承关系来实现，对象适配器使用组合关系来实现。\n\nIO 流中的字符流和字节流的接口不同，它们之间可以协调工作就是基于适配器模式来做的，更准确点来说是对象适配器。通过适配器，我们可以将字节流对象适配成一个字符流对象，这样我们可以直接通过字节流对象来读取或者写入字符数据。\n\nInputStreamReader 和 OutputStreamWriter 就是两个适配器(Adapter)， 同时，它们两个也是字节流和字符流之间的桥梁。InputStreamReader 使用 StreamDecoder （流解码器）对字节进行解码，实现字节流到字符流的转换， OutputStreamWriter 使用StreamEncoder（流编码器）对字符进行编码，实现字符流到字节流的转换。\n\nInputStream 和 OutputStream 的子类是被适配者， InputStreamReader 和 OutputStreamWriter是适配器。\n\n// InputStreamReader 是适配器，FileInputStream 是被适配的类\nInputStreamReader isr = new InputStreamReader(new FileInputStream(fileName), "UTF-8");\n// BufferedReader 增强 InputStreamReader 的功能（装饰器模式）\nBufferedReader bufferedReader = new BufferedReader(isr);\n\n\njava.io.InputStreamReader 部分源码：\n\npublic class InputStreamReader extends Reader {\n //用于解码的对象\n private final StreamDecoder sd;\n    public InputStreamReader(InputStream in) {\n        super(in);\n        try {\n            // 获取 StreamDecoder 对象\n            sd = StreamDecoder.forInputStreamReader(in, this, (String)null);\n        } catch (UnsupportedEncodingException e) {\n            throw new Error(e);\n        }\n    }\n    // 使用 StreamDecoder 对象做具体的读取工作\n public int read() throws IOException {\n        return sd.read();\n    }\n}\n\n\njava.io.OutputStreamWriter 部分源码：\n\npublic class OutputStreamWriter extends Writer {\n    // 用于编码的对象\n    private final StreamEncoder se;\n    public OutputStreamWriter(OutputStream out) {\n        super(out);\n        try {\n           // 获取 StreamEncoder 对象\n            se = StreamEncoder.forOutputStreamWriter(out, this, (String)null);\n        } catch (UnsupportedEncodingException e) {\n            throw new Error(e);\n        }\n    }\n    // 使用 StreamEncoder 对象做具体的写入工作\n    public void write(int c) throws IOException {\n        se.write(c);\n    }\n}\n\n\n适配器模式和装饰器模式有什么区别呢？\n\n装饰器模式 更侧重于动态地增强原始类的功能，装饰器类需要跟原始类继承相同的抽象类或者实现相同的接口。并且，装饰器模式支持对原始类嵌套使用多个装饰器。\n\n适配器模式 更侧重于让接口不兼容而不能交互的类可以一起工作，当我们调用适配器对应的方法时，适配器内部会调用适配者类或者和适配类相关的类的方法，这个过程透明的。就比如说 StreamDecoder （流解码器）和StreamEncoder（流编码器）就是分别基于 InputStream 和 OutputStream 来获取 FileChannel对象并调用对应的 read 方法和 write 方法进行字节数据的读取和写入。\n\nStreamDecoder(InputStream in, Object lock, CharsetDecoder dec) {\n    // 省略大部分代码\n    // 根据 InputStream 对象获取 FileChannel 对象\n    ch = getChannel((FileInputStream)in);\n}\n\n\n适配器和适配者两者不需要继承相同的抽象类或者实现相同的接口。\n\n另外，FutureTask 类使用了适配器模式，Executors 的内部类 RunnableAdapter 实现属于适配器，用于将 Runnable 适配成 Callable。\n\nFutureTask参数包含 Runnable 的一个构造方法：\n\npublic FutureTask(Runnable runnable, V result) {\n    // 调用 Executors 类的 callable 方法\n    this.callable = Executors.callable(runnable, result);\n    this.state = NEW;\n}\n\n\nExecutors中对应的方法和适配器：\n\n// 实际调用的是 Executors 的内部类 RunnableAdapter 的构造方法\npublic static <T> Callable<T> callable(Runnable task, T result) {\n    if (task == null)\n        throw new NullPointerException();\n    return new RunnableAdapter<T>(task, result);\n}\n// 适配器\nstatic final class RunnableAdapter<T> implements Callable<T> {\n    final Runnable task;\n    final T result;\n    RunnableAdapter(Runnable task, T result) {\n        this.task = task;\n        this.result = result;\n    }\n    public T call() {\n        task.run();\n        return result;\n    }\n}\n\n\n\n# 工厂模式\n\n工厂模式用于创建对象，NIO 中大量用到了工厂模式，比如 Files 类的 newInputStream 方法用于创建 InputStream 对象（静态工厂）、 Paths 类的 get 方法创建 Path 对象（静态工厂）、ZipFileSystem 类（sun.nio包下的类，属于 java.nio 相关的一些内部实现）的 getPath 的方法创建 Path 对象（简单工厂）。\n\nInputStream is = Files.newInputStream(Paths.get(generatorLogoPath))\n\n\n\n# 观察者模式\n\nNIO 中的文件目录监听服务使用到了观察者模式。\n\nNIO 中的文件目录监听服务基于 WatchService 接口和 Watchable 接口。WatchService 属于观察者，Watchable 属于被观察者。\n\nWatchable 接口定义了一个用于将对象注册到 WatchService（监控服务） 并绑定监听事件的方法 register 。\n\npublic interface Path\n    extends Comparable<Path>, Iterable<Path>, Watchable{\n}\n\npublic interface Watchable {\n    WatchKey register(WatchService watcher,\n                      WatchEvent.Kind<?>[] events,\n                      WatchEvent.Modifier... modifiers)\n        throws IOException;\n}\n\n\nWatchService 用于监听文件目录的变化，同一个 WatchService 对象能够监听多个文件目录。\n\n// 创建 WatchService 对象\nWatchService watchService = FileSystems.getDefault().newWatchService();\n\n// 初始化一个被监控文件夹的 Path 类:\nPath path = Paths.get("workingDirectory");\n// 将这个 path 对象注册到 WatchService（监控服务） 中去\nWatchKey watchKey = path.register(\nwatchService, StandardWatchEventKinds...);\n\n\nPath 类 register 方法的第二个参数 events （需要监听的事件）为可变长参数，也就是说我们可以同时监听多种事件。\n\nWatchKey register(WatchService watcher,\n                  WatchEvent.Kind<?>... events)\n    throws IOException;\n\n\n常用的监听事件有 3 种：\n\n * StandardWatchEventKinds.ENTRY_CREATE：文件创建。\n * StandardWatchEventKinds.ENTRY_DELETE : 文件删除。\n * StandardWatchEventKinds.ENTRY_MODIFY : 文件修改。\n\nregister 方法返回 WatchKey 对象，通过WatchKey 对象可以获取事件的具体信息比如文件目录下是创建、删除还是修改了文件、创建、删除或者修改的文件的具体名称是什么。\n\nWatchKey key;\nwhile ((key = watchService.take()) != null) {\n    for (WatchEvent<?> event : key.pollEvents()) {\n      // 可以调用 WatchEvent 对象的方法做一些事情比如输出事件的具体上下文信息\n    }\n    key.reset();\n}\n\n\nWatchService 内部是通过一个 daemon thread（守护线程）采用定期轮询的方式来检测文件的变化，简化后的源码如下所示。\n\nclass PollingWatchService\n    extends AbstractWatchService\n{\n    // 定义一个 daemon thread（守护线程）轮询检测文件变化\n    private final ScheduledExecutorService scheduledExecutor;\n\n    PollingWatchService() {\n        scheduledExecutor = Executors\n            .newSingleThreadScheduledExecutor(new ThreadFactory() {\n                 @Override\n                 public Thread newThread(Runnable r) {\n                     Thread t = new Thread(r);\n                     t.setDaemon(true);\n                     return t;\n                 }});\n    }\n\n  void enable(Set<? extends WatchEvent.Kind<?>> events, long period) {\n    synchronized (this) {\n      // 更新监听事件\n      this.events = events;\n\n        // 开启定期轮询\n      Runnable thunk = new Runnable() { public void run() { poll(); }};\n      this.poller = scheduledExecutor\n        .scheduleAtFixedRate(thunk, period, period, TimeUnit.SECONDS);\n    }\n  }\n}\n\n\n\n# 参考\n\n * Patterns in Java APIs：http://cecs.wright.edu/~tkprasad/courses/ceg860/paper/node26.html\n * 装饰器模式：通过剖析 Java IO 类库源码学习装饰器模式：https://time.geekbang.org/column/article/204845\n * sun.nio 包是什么，是 java 代码么？ - RednaxelaFX https://www.zhihu.com/question/29237781/answer/43653953',normalizedContent:'这篇文章我们简单来看看我们从 io 中能够学习到哪些设计模式的应用。\n\n\n# 装饰器模式\n\n装饰器（decorator）模式 可以在不改变原有对象的情况下拓展其功能。\n\n装饰器模式通过组合替代继承来扩展原始类的功能，在一些继承关系比较复杂的场景（io 这一场景各种类的继承关系就比较复杂）更加实用。\n\n对于字节流来说， filterinputstream （对应输入流）和filteroutputstream（对应输出流）是装饰器模式的核心，分别用于增强 inputstream 和outputstream子类对象的功能。\n\n我们常见的bufferedinputstream(字节缓冲输入流)、datainputstream 等等都是filterinputstream 的子类，bufferedoutputstream（字节缓冲输出流）、dataoutputstream等等都是filteroutputstream的子类。\n\n举个例子，我们可以通过 bufferedinputstream（字节缓冲输入流）来增强 fileinputstream 的功能。\n\nbufferedinputstream 构造函数如下：\n\npublic bufferedinputstream(inputstream in) {\n    this(in, default_buffer_size);\n}\n\npublic bufferedinputstream(inputstream in, int size) {\n    super(in);\n    if (size <= 0) {\n        throw new illegalargumentexception("buffer size <= 0");\n    }\n    buf = new byte[size];\n}\n\n\n可以看出，bufferedinputstream 的构造函数其中的一个参数就是 inputstream 。\n\nbufferedinputstream 代码示例：\n\ntry (bufferedinputstream bis = new bufferedinputstream(new fileinputstream("input.txt"))) {\n    int content;\n    long skip = bis.skip(2);\n    while ((content = bis.read()) != -1) {\n        system.out.print((char) content);\n    }\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\n这个时候，你可以会想了：为啥我们直接不弄一个bufferedfileinputstream（字符缓冲文件输入流）呢？\n\nbufferedfileinputstream bfis = new bufferedfileinputstream("input.txt");\n\n\n如果 inputstream的子类比较少的话，这样做是没问题的。不过， inputstream的子类实在太多，继承关系也太复杂了。如果我们为每一个子类都定制一个对应的缓冲输入流，那岂不是太麻烦了。\n\n如果你对 io 流比较熟悉的话，你会发现zipinputstream 和zipoutputstream 还可以分别增强 bufferedinputstream 和 bufferedoutputstream 的能力。\n\nbufferedinputstream bis = new bufferedinputstream(new fileinputstream(filename));\nzipinputstream zis = new zipinputstream(bis);\n\nbufferedoutputstream bos = new bufferedoutputstream(new fileoutputstream(filename));\nzipoutputstream zipout = new zipoutputstream(bos);\n\n\nzipinputstream 和zipoutputstream 分别继承自inflaterinputstream 和deflateroutputstream。\n\npublic\nclass inflaterinputstream extends filterinputstream {\n}\n\npublic\nclass deflateroutputstream extends filteroutputstream {\n}\n\n\n\n这也是装饰器模式很重要的一个特征，那就是可以对原始类嵌套使用多个装饰器。\n\n为了实现这一效果，装饰器类需要跟原始类继承相同的抽象类或者实现相同的接口。上面介绍到的这些 io 相关的装饰类和原始类共同的父类是 inputstream 和outputstream。\n\n对于字符流来说，bufferedreader 可以用来增加 reader （字符输入流）子类的功能，bufferedwriter 可以用来增加 writer （字符输出流）子类的功能。\n\nbufferedwriter bw = new bufferedwriter(new outputstreamwriter(new fileoutputstream(filename), "utf-8"));\n\n\nio 流中的装饰器模式应用的例子实在是太多了，不需要特意记忆，完全没必要哈！搞清了装饰器模式的核心之后，你在使用的时候自然就会知道哪些地方运用到了装饰器模式。\n\n\n# 适配器模式\n\n适配器（adapter pattern）模式 主要用于接口互不兼容的类的协调工作，你可以将其联想到我们日常经常使用的电源适配器。\n\n适配器模式中存在被适配的对象或者类称为 适配者(adaptee) ，作用于适配者的对象或者类称为适配器(adapter) 。适配器分为对象适配器和类适配器。类适配器使用继承关系来实现，对象适配器使用组合关系来实现。\n\nio 流中的字符流和字节流的接口不同，它们之间可以协调工作就是基于适配器模式来做的，更准确点来说是对象适配器。通过适配器，我们可以将字节流对象适配成一个字符流对象，这样我们可以直接通过字节流对象来读取或者写入字符数据。\n\ninputstreamreader 和 outputstreamwriter 就是两个适配器(adapter)， 同时，它们两个也是字节流和字符流之间的桥梁。inputstreamreader 使用 streamdecoder （流解码器）对字节进行解码，实现字节流到字符流的转换， outputstreamwriter 使用streamencoder（流编码器）对字符进行编码，实现字符流到字节流的转换。\n\ninputstream 和 outputstream 的子类是被适配者， inputstreamreader 和 outputstreamwriter是适配器。\n\n// inputstreamreader 是适配器，fileinputstream 是被适配的类\ninputstreamreader isr = new inputstreamreader(new fileinputstream(filename), "utf-8");\n// bufferedreader 增强 inputstreamreader 的功能（装饰器模式）\nbufferedreader bufferedreader = new bufferedreader(isr);\n\n\njava.io.inputstreamreader 部分源码：\n\npublic class inputstreamreader extends reader {\n //用于解码的对象\n private final streamdecoder sd;\n    public inputstreamreader(inputstream in) {\n        super(in);\n        try {\n            // 获取 streamdecoder 对象\n            sd = streamdecoder.forinputstreamreader(in, this, (string)null);\n        } catch (unsupportedencodingexception e) {\n            throw new error(e);\n        }\n    }\n    // 使用 streamdecoder 对象做具体的读取工作\n public int read() throws ioexception {\n        return sd.read();\n    }\n}\n\n\njava.io.outputstreamwriter 部分源码：\n\npublic class outputstreamwriter extends writer {\n    // 用于编码的对象\n    private final streamencoder se;\n    public outputstreamwriter(outputstream out) {\n        super(out);\n        try {\n           // 获取 streamencoder 对象\n            se = streamencoder.foroutputstreamwriter(out, this, (string)null);\n        } catch (unsupportedencodingexception e) {\n            throw new error(e);\n        }\n    }\n    // 使用 streamencoder 对象做具体的写入工作\n    public void write(int c) throws ioexception {\n        se.write(c);\n    }\n}\n\n\n适配器模式和装饰器模式有什么区别呢？\n\n装饰器模式 更侧重于动态地增强原始类的功能，装饰器类需要跟原始类继承相同的抽象类或者实现相同的接口。并且，装饰器模式支持对原始类嵌套使用多个装饰器。\n\n适配器模式 更侧重于让接口不兼容而不能交互的类可以一起工作，当我们调用适配器对应的方法时，适配器内部会调用适配者类或者和适配类相关的类的方法，这个过程透明的。就比如说 streamdecoder （流解码器）和streamencoder（流编码器）就是分别基于 inputstream 和 outputstream 来获取 filechannel对象并调用对应的 read 方法和 write 方法进行字节数据的读取和写入。\n\nstreamdecoder(inputstream in, object lock, charsetdecoder dec) {\n    // 省略大部分代码\n    // 根据 inputstream 对象获取 filechannel 对象\n    ch = getchannel((fileinputstream)in);\n}\n\n\n适配器和适配者两者不需要继承相同的抽象类或者实现相同的接口。\n\n另外，futuretask 类使用了适配器模式，executors 的内部类 runnableadapter 实现属于适配器，用于将 runnable 适配成 callable。\n\nfuturetask参数包含 runnable 的一个构造方法：\n\npublic futuretask(runnable runnable, v result) {\n    // 调用 executors 类的 callable 方法\n    this.callable = executors.callable(runnable, result);\n    this.state = new;\n}\n\n\nexecutors中对应的方法和适配器：\n\n// 实际调用的是 executors 的内部类 runnableadapter 的构造方法\npublic static <t> callable<t> callable(runnable task, t result) {\n    if (task == null)\n        throw new nullpointerexception();\n    return new runnableadapter<t>(task, result);\n}\n// 适配器\nstatic final class runnableadapter<t> implements callable<t> {\n    final runnable task;\n    final t result;\n    runnableadapter(runnable task, t result) {\n        this.task = task;\n        this.result = result;\n    }\n    public t call() {\n        task.run();\n        return result;\n    }\n}\n\n\n\n# 工厂模式\n\n工厂模式用于创建对象，nio 中大量用到了工厂模式，比如 files 类的 newinputstream 方法用于创建 inputstream 对象（静态工厂）、 paths 类的 get 方法创建 path 对象（静态工厂）、zipfilesystem 类（sun.nio包下的类，属于 java.nio 相关的一些内部实现）的 getpath 的方法创建 path 对象（简单工厂）。\n\ninputstream is = files.newinputstream(paths.get(generatorlogopath))\n\n\n\n# 观察者模式\n\nnio 中的文件目录监听服务使用到了观察者模式。\n\nnio 中的文件目录监听服务基于 watchservice 接口和 watchable 接口。watchservice 属于观察者，watchable 属于被观察者。\n\nwatchable 接口定义了一个用于将对象注册到 watchservice（监控服务） 并绑定监听事件的方法 register 。\n\npublic interface path\n    extends comparable<path>, iterable<path>, watchable{\n}\n\npublic interface watchable {\n    watchkey register(watchservice watcher,\n                      watchevent.kind<?>[] events,\n                      watchevent.modifier... modifiers)\n        throws ioexception;\n}\n\n\nwatchservice 用于监听文件目录的变化，同一个 watchservice 对象能够监听多个文件目录。\n\n// 创建 watchservice 对象\nwatchservice watchservice = filesystems.getdefault().newwatchservice();\n\n// 初始化一个被监控文件夹的 path 类:\npath path = paths.get("workingdirectory");\n// 将这个 path 对象注册到 watchservice（监控服务） 中去\nwatchkey watchkey = path.register(\nwatchservice, standardwatcheventkinds...);\n\n\npath 类 register 方法的第二个参数 events （需要监听的事件）为可变长参数，也就是说我们可以同时监听多种事件。\n\nwatchkey register(watchservice watcher,\n                  watchevent.kind<?>... events)\n    throws ioexception;\n\n\n常用的监听事件有 3 种：\n\n * standardwatcheventkinds.entry_create：文件创建。\n * standardwatcheventkinds.entry_delete : 文件删除。\n * standardwatcheventkinds.entry_modify : 文件修改。\n\nregister 方法返回 watchkey 对象，通过watchkey 对象可以获取事件的具体信息比如文件目录下是创建、删除还是修改了文件、创建、删除或者修改的文件的具体名称是什么。\n\nwatchkey key;\nwhile ((key = watchservice.take()) != null) {\n    for (watchevent<?> event : key.pollevents()) {\n      // 可以调用 watchevent 对象的方法做一些事情比如输出事件的具体上下文信息\n    }\n    key.reset();\n}\n\n\nwatchservice 内部是通过一个 daemon thread（守护线程）采用定期轮询的方式来检测文件的变化，简化后的源码如下所示。\n\nclass pollingwatchservice\n    extends abstractwatchservice\n{\n    // 定义一个 daemon thread（守护线程）轮询检测文件变化\n    private final scheduledexecutorservice scheduledexecutor;\n\n    pollingwatchservice() {\n        scheduledexecutor = executors\n            .newsinglethreadscheduledexecutor(new threadfactory() {\n                 @override\n                 public thread newthread(runnable r) {\n                     thread t = new thread(r);\n                     t.setdaemon(true);\n                     return t;\n                 }});\n    }\n\n  void enable(set<? extends watchevent.kind<?>> events, long period) {\n    synchronized (this) {\n      // 更新监听事件\n      this.events = events;\n\n        // 开启定期轮询\n      runnable thunk = new runnable() { public void run() { poll(); }};\n      this.poller = scheduledexecutor\n        .scheduleatfixedrate(thunk, period, period, timeunit.seconds);\n    }\n  }\n}\n\n\n\n# 参考\n\n * patterns in java apis：http://cecs.wright.edu/~tkprasad/courses/ceg860/paper/node26.html\n * 装饰器模式：通过剖析 java io 类库源码学习装饰器模式：https://time.geekbang.org/column/article/204845\n * sun.nio 包是什么，是 java 代码么？ - rednaxelafx https://www.zhihu.com/question/29237781/answer/43653953',charsets:{cjk:!0}},{title:"Java IO 模型详解",frontmatter:{title:"Java IO 模型详解",category:"Java",tag:["Java IO","Java基础"],date:"2024-08-21T22:33:21.000Z",permalink:"/pages/a3d832/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/02.IO%E6%B5%81/03.IO%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93.html",relativePath:"01.Java基础/02.IO流/03.IO模型总结.md",key:"v-78bcb4bc",path:"/pages/a3d832/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:154},{level:2,title:"I/O",slug:"i-o",normalizedTitle:"i/o",charIndex:158},{level:3,title:"何为 I/O?",slug:"何为-i-o",normalizedTitle:"何为 i/o?",charIndex:227},{level:3,title:"有哪些常见的 IO 模型?",slug:"有哪些常见的-io-模型",normalizedTitle:"有哪些常见的 io 模型?",charIndex:1038},{level:2,title:"Java 中 3 种常见 IO 模型",slug:"java-中-3-种常见-io-模型",normalizedTitle:"java 中 3 种常见 io 模型",charIndex:1149},{level:3,title:"BIO (Blocking I/O)",slug:"bio-blocking-i-o",normalizedTitle:"bio (blocking i/o)",charIndex:1172},{level:3,title:"NIO (Non-blocking/New I/O)",slug:"nio-non-blocking-new-i-o",normalizedTitle:"nio (non-blocking/new i/o)",charIndex:1359},{level:3,title:"AIO (Asynchronous I/O)",slug:"aio-asynchronous-i-o",normalizedTitle:"aio (asynchronous i/o)",charIndex:2321},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:2607}],headersStr:"前言 I/O 何为 I/O? 有哪些常见的 IO 模型? Java 中 3 种常见 IO 模型 BIO (Blocking I/O) NIO (Non-blocking/New I/O) AIO (Asynchronous I/O) 参考",content:"IO 模型这块确实挺难理解的，需要太多计算机底层知识。写这篇文章用了挺久，就非常希望能把我所知道的讲出来吧!希望朋友们能有收获！为了写这篇文章，还翻看了一下《UNIX 网络编程》这本书，太难了，我滴乖乖！心痛~\n\n个人能力有限。如果文章有任何需要补充/完善/修改的地方，欢迎在评论区指出，共同进步！\n\n\n# 前言\n\nI/O 一直是很多小伙伴难以理解的一个知识点，这篇文章我会将我所理解的 I/O 讲给你听，希望可以对你有所帮助。\n\n\n# I/O\n\n\n# 何为 I/O?\n\nI/O（Input/Output） 即输入／输出 。\n\n我们先从计算机结构的角度来解读一下 I/O。\n\n根据冯.诺依曼结构，计算机结构分为 5 大部分：运算器、控制器、存储器、输入设备、输出设备。\n\n\n\n输入设备（比如键盘）和输出设备（比如显示器）都属于外部设备。网卡、硬盘这种既可以属于输入设备，也可以属于输出设备。\n\n输入设备向计算机输入数据，输出设备接收计算机输出的数据。\n\n从计算机结构的视角来看的话， I/O 描述了计算机系统与外部设备之间通信的过程。\n\n我们再先从应用程序的角度来解读一下 I/O。\n\n根据大学里学到的操作系统相关的知识：为了保证操作系统的稳定性和安全性，一个进程的地址空间划分为 用户空间（User space） 和 内核空间（Kernel space ） 。\n\n像我们平常运行的应用程序都是运行在用户空间，只有内核空间才能进行系统态级别的资源有关的操作，比如文件管理、进程通信、内存管理等等。也就是说，我们想要进行 IO 操作，一定是要依赖内核空间的能力。\n\n并且，用户空间的程序不能直接访问内核空间。\n\n当想要执行 IO 操作时，由于没有执行这些操作的权限，只能发起系统调用请求操作系统帮忙完成。\n\n因此，用户进程想要执行 IO 操作的话，必须通过 系统调用 来间接访问内核空间\n\n我们在平常开发过程中接触最多的就是 磁盘 IO（读写文件） 和 网络 IO（网络请求和响应）。\n\n从应用程序的视角来看的话，我们的应用程序对操作系统的内核发起 IO 调用（系统调用），操作系统负责的内核执行具体的 IO 操作。也就是说，我们的应用程序实际上只是发起了 IO 操作的调用而已，具体 IO 的执行是由操作系统的内核来完成的。\n\n当应用程序发起 I/O 调用后，会经历两个步骤：\n\n 1. 内核等待 I/O 设备准备好数据\n 2. 内核将数据从内核空间拷贝到用户空间。\n\n\n# 有哪些常见的 IO 模型?\n\nUNIX 系统下， IO 模型一共有 5 种：同步阻塞 I/O、同步非阻塞 I/O、I/O 多路复用、信号驱动 I/O 和异步 I/O。\n\n这也是我们经常提到的 5 种 IO 模型。\n\n\n# Java 中 3 种常见 IO 模型\n\n\n# BIO (Blocking I/O)\n\nBIO 属于同步阻塞 IO 模型 。\n\n同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。\n\n\n\n在客户端连接数量不高的情况下，是没问题的。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。\n\n\n# NIO (Non-blocking/New I/O)\n\nJava 中的 NIO 于 Java 1.4 中引入，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它是支持面向缓冲的，基于通道的 I/O 操作方法。 对于高负载、高并发的（网络）应用，应使用 NIO 。\n\nJava 中的 NIO 可以看作是 I/O 多路复用模型。也有很多人认为，Java 中的 NIO 属于同步非阻塞 IO 模型。\n\n跟着我的思路往下看看，相信你会得到答案！\n\n我们先来看看 同步非阻塞 IO 模型。\n\n\n\n同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。\n\n相比于同步阻塞 IO 模型，同步非阻塞 IO 模型确实有了很大改进。通过轮询操作，避免了一直阻塞。\n\n但是，这种 IO 模型同样存在问题：应用程序不断进行 I/O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的。\n\n这个时候，I/O 多路复用模型 就上场了。\n\n\n\nIO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -> 用户空间）还是阻塞的。\n\n> 目前支持 IO 多路复用的系统调用，有 select，epoll 等等。select 系统调用，目前几乎在所有的操作系统上都有支持。\n> \n>  * select 调用：内核提供的系统调用，它支持一次查询多个系统调用的可用状态。几乎所有的操作系统都支持。\n>  * epoll 调用：linux 2.6 内核，属于 select 调用的增强版本，优化了 IO 的执行效率。\n\nIO 多路复用模型，通过减少无效的系统调用，减少了对 CPU 资源的消耗。\n\nJava 中的 NIO ，有一个非常重要的选择器 ( Selector ) 的概念，也可以被称为 多路复用器。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。\n\n\n\n\n# AIO (Asynchronous I/O)\n\nAIO 也就是 NIO 2。Java 7 中引入了 NIO 的改进版 NIO 2,它是异步 IO 模型。\n\n异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。\n\n\n\n目前来说 AIO 的应用还不是很广泛。Netty 之前也尝试使用过 AIO，不过又放弃了。这是因为，Netty 使用了 AIO 之后，在 Linux 系统上的性能并没有多少提升。\n\n最后，来一张图，简单总结一下 Java 中的 BIO、NIO、AIO。\n\n\n\n\n# 参考\n\n * 《深入拆解 Tomcat & Jetty》\n * 如何完成一次 IO：https://llc687.top/126.html\n * 程序员应该这样理解 IO：https://www.jianshu.com/p/fa7bdc4f3de7\n * 10 分钟看懂， Java NIO 底层原理：https://www.cnblogs.com/crazymakercircle/p/10225159.html\n * IO 模型知多少 | 理论篇：https://www.cnblogs.com/sheng-jie/p/how-much-you-know-about-io-models.html\n * 《UNIX 网络编程 卷 1；套接字联网 API 》6.2 节 IO 模型",normalizedContent:"io 模型这块确实挺难理解的，需要太多计算机底层知识。写这篇文章用了挺久，就非常希望能把我所知道的讲出来吧!希望朋友们能有收获！为了写这篇文章，还翻看了一下《unix 网络编程》这本书，太难了，我滴乖乖！心痛~\n\n个人能力有限。如果文章有任何需要补充/完善/修改的地方，欢迎在评论区指出，共同进步！\n\n\n# 前言\n\ni/o 一直是很多小伙伴难以理解的一个知识点，这篇文章我会将我所理解的 i/o 讲给你听，希望可以对你有所帮助。\n\n\n# i/o\n\n\n# 何为 i/o?\n\ni/o（input/output） 即输入／输出 。\n\n我们先从计算机结构的角度来解读一下 i/o。\n\n根据冯.诺依曼结构，计算机结构分为 5 大部分：运算器、控制器、存储器、输入设备、输出设备。\n\n\n\n输入设备（比如键盘）和输出设备（比如显示器）都属于外部设备。网卡、硬盘这种既可以属于输入设备，也可以属于输出设备。\n\n输入设备向计算机输入数据，输出设备接收计算机输出的数据。\n\n从计算机结构的视角来看的话， i/o 描述了计算机系统与外部设备之间通信的过程。\n\n我们再先从应用程序的角度来解读一下 i/o。\n\n根据大学里学到的操作系统相关的知识：为了保证操作系统的稳定性和安全性，一个进程的地址空间划分为 用户空间（user space） 和 内核空间（kernel space ） 。\n\n像我们平常运行的应用程序都是运行在用户空间，只有内核空间才能进行系统态级别的资源有关的操作，比如文件管理、进程通信、内存管理等等。也就是说，我们想要进行 io 操作，一定是要依赖内核空间的能力。\n\n并且，用户空间的程序不能直接访问内核空间。\n\n当想要执行 io 操作时，由于没有执行这些操作的权限，只能发起系统调用请求操作系统帮忙完成。\n\n因此，用户进程想要执行 io 操作的话，必须通过 系统调用 来间接访问内核空间\n\n我们在平常开发过程中接触最多的就是 磁盘 io（读写文件） 和 网络 io（网络请求和响应）。\n\n从应用程序的视角来看的话，我们的应用程序对操作系统的内核发起 io 调用（系统调用），操作系统负责的内核执行具体的 io 操作。也就是说，我们的应用程序实际上只是发起了 io 操作的调用而已，具体 io 的执行是由操作系统的内核来完成的。\n\n当应用程序发起 i/o 调用后，会经历两个步骤：\n\n 1. 内核等待 i/o 设备准备好数据\n 2. 内核将数据从内核空间拷贝到用户空间。\n\n\n# 有哪些常见的 io 模型?\n\nunix 系统下， io 模型一共有 5 种：同步阻塞 i/o、同步非阻塞 i/o、i/o 多路复用、信号驱动 i/o 和异步 i/o。\n\n这也是我们经常提到的 5 种 io 模型。\n\n\n# java 中 3 种常见 io 模型\n\n\n# bio (blocking i/o)\n\nbio 属于同步阻塞 io 模型 。\n\n同步阻塞 io 模型中，应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。\n\n\n\n在客户端连接数量不高的情况下，是没问题的。但是，当面对十万甚至百万级连接的时候，传统的 bio 模型是无能为力的。因此，我们需要一种更高效的 i/o 处理模型来应对更高的并发量。\n\n\n# nio (non-blocking/new i/o)\n\njava 中的 nio 于 java 1.4 中引入，对应 java.nio 包，提供了 channel , selector，buffer 等抽象。nio 中的 n 可以理解为 non-blocking，不单纯是 new。它是支持面向缓冲的，基于通道的 i/o 操作方法。 对于高负载、高并发的（网络）应用，应使用 nio 。\n\njava 中的 nio 可以看作是 i/o 多路复用模型。也有很多人认为，java 中的 nio 属于同步非阻塞 io 模型。\n\n跟着我的思路往下看看，相信你会得到答案！\n\n我们先来看看 同步非阻塞 io 模型。\n\n\n\n同步非阻塞 io 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。\n\n相比于同步阻塞 io 模型，同步非阻塞 io 模型确实有了很大改进。通过轮询操作，避免了一直阻塞。\n\n但是，这种 io 模型同样存在问题：应用程序不断进行 i/o 系统调用轮询数据是否已经准备好的过程是十分消耗 cpu 资源的。\n\n这个时候，i/o 多路复用模型 就上场了。\n\n\n\nio 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -> 用户空间）还是阻塞的。\n\n> 目前支持 io 多路复用的系统调用，有 select，epoll 等等。select 系统调用，目前几乎在所有的操作系统上都有支持。\n> \n>  * select 调用：内核提供的系统调用，它支持一次查询多个系统调用的可用状态。几乎所有的操作系统都支持。\n>  * epoll 调用：linux 2.6 内核，属于 select 调用的增强版本，优化了 io 的执行效率。\n\nio 多路复用模型，通过减少无效的系统调用，减少了对 cpu 资源的消耗。\n\njava 中的 nio ，有一个非常重要的选择器 ( selector ) 的概念，也可以被称为 多路复用器。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。\n\n\n\n\n# aio (asynchronous i/o)\n\naio 也就是 nio 2。java 7 中引入了 nio 的改进版 nio 2,它是异步 io 模型。\n\n异步 io 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。\n\n\n\n目前来说 aio 的应用还不是很广泛。netty 之前也尝试使用过 aio，不过又放弃了。这是因为，netty 使用了 aio 之后，在 linux 系统上的性能并没有多少提升。\n\n最后，来一张图，简单总结一下 java 中的 bio、nio、aio。\n\n\n\n\n# 参考\n\n * 《深入拆解 tomcat & jetty》\n * 如何完成一次 io：https://llc687.top/126.html\n * 程序员应该这样理解 io：https://www.jianshu.com/p/fa7bdc4f3de7\n * 10 分钟看懂， java nio 底层原理：https://www.cnblogs.com/crazymakercircle/p/10225159.html\n * io 模型知多少 | 理论篇：https://www.cnblogs.com/sheng-jie/p/how-much-you-know-about-io-models.html\n * 《unix 网络编程 卷 1；套接字联网 api 》6.2 节 io 模型",charsets:{cjk:!0}},{title:"Java NIO 核心知识总结",frontmatter:{title:"Java NIO 核心知识总结",category:"Java",tag:["Java IO","Java基础"],date:"2024-08-21T22:33:27.000Z",permalink:"/pages/42be26/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/02.IO%E6%B5%81/04.NIO%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93.html",relativePath:"01.Java基础/02.IO流/04.NIO核心知识总结.md",key:"v-1f0ca540",path:"/pages/42be26/",headers:[{level:2,title:"NIO 简介",slug:"nio-简介",normalizedTitle:"nio 简介",charIndex:73},{level:2,title:"NIO 核心组件",slug:"nio-核心组件",normalizedTitle:"nio 核心组件",charIndex:562},{level:3,title:"Buffer（缓冲区）",slug:"buffer-缓冲区",normalizedTitle:"buffer（缓冲区）",charIndex:594},{level:3,title:"Channel（通道）",slug:"channel-通道",normalizedTitle:"channel（通道）",charIndex:696},{level:3,title:"Selector（选择器）",slug:"selector-选择器",normalizedTitle:"selector（选择器）",charIndex:800},{level:2,title:"NIO 零拷贝",slug:"nio-零拷贝",normalizedTitle:"nio 零拷贝",charIndex:9693},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:11180},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:45}],headersStr:"NIO 简介 NIO 核心组件 Buffer（缓冲区） Channel（通道） Selector（选择器） NIO 零拷贝 总结 参考",content:'在学习 NIO 之前，需要先了解一下计算机 I/O 模型的基础理论知识。还不了解的话，可以参考我写的这篇文章：Java IO 模型详解。\n\n\n# NIO 简介\n\n在传统的 Java I/O 模型（BIO）中，I/O 操作是以阻塞的方式进行的。也就是说，当一个线程执行一个 I/O 操作时，它会被阻塞直到操作完成。这种阻塞模型在处理多个并发连接时可能会导致性能瓶颈，因为需要为每个连接创建一个线程，而线程的创建和切换都是有开销的。\n\n为了解决这个问题，在 Java1.4 版本引入了一种新的 I/O 模型 — NIO （New IO，也称为 Non-blocking IO） 。NIO 弥补了同步阻塞 I/O 的不足，它在标准 Java 代码中提供了非阻塞、面向缓冲、基于通道的 I/O，可以使用少量的线程来处理多个连接，大大提高了 I/O 效率和并发。\n\n下图是 BIO、NIO 和 AIO 处理客户端请求的简单对比图（关于 AIO 的介绍，可以看我写的这篇文章：Java IO 模型详解，不是重点，了解即可）。\n\n\n\n⚠️需要注意：使用 NIO 并不一定意味着高性能，它的性能优势主要体现在高并发和高延迟的网络环境下。当连接数较少、并发程度较低或者网络传输速度较快时，NIO 的性能并不一定优于传统的 BIO 。\n\n\n# NIO 核心组件\n\nNIO 主要包括以下三个核心组件：\n\n * Buffer（缓冲区）：NIO 读写数据都是通过缓冲区进行操作的。读操作的时候将 Channel 中的数据填充到 Buffer 中，而写操作时将 Buffer 中的数据写入到 Channel 中。\n * Channel（通道）：Channel 是一个双向的、可读可写的数据传输通道，NIO 通过 Channel 来实现数据的输入输出。通道是一个抽象的概念，它可以代表文件、套接字或者其他数据源之间的连接。\n * Selector（选择器）：允许一个线程处理多个 Channel，基于事件驱动的 I/O 多路复用模型。所有的 Channel 都可以注册到 Selector 上，由 Selector 来分配线程来处理事件。\n\n三者的关系如下图所示（暂时不理解没关系，后文会详细介绍）：\n\n\n\n下面详细介绍一下这三个组件。\n\n\n# Buffer（缓冲区）\n\n在传统的 BIO 中，数据的读写是面向流的， 分为字节流和字符流。\n\n在 Java 1.4 的 NIO 库中，所有数据都是用缓冲区处理的，这是新库和之前的 BIO 的一个重要区别，有点类似于 BIO 中的缓冲流。NIO 在读取数据时，它是直接读到缓冲区中的。在写入数据时，写入到缓冲区中。 使用 NIO 在读写数据时，都是通过缓冲区进行操作。\n\nBuffer 的子类如下图所示。其中，最常用的是 ByteBuffer，它可以用来存储和操作字节数据。\n\n\n\n你可以将 Buffer 理解为一个数组，IntBuffer、FloatBuffer、CharBuffer 等分别对应 int[]、float[]、char[] 等。\n\n为了更清晰地认识缓冲区，我们来简单看看Buffer 类中定义的四个成员变量：\n\npublic abstract class Buffer {\n    // Invariants: mark <= position <= limit <= capacity\n    private int mark = -1;\n    private int position = 0;\n    private int limit;\n    private int capacity;\n}\n\n\n这四个成员变量的具体含义如下：\n\n 1. 容量（capacity）：Buffer可以存储的最大数据量，Buffer创建时设置且不可改变；\n 2. 界限（limit）：Buffer 中可以读/写数据的边界。写模式下，limit 代表最多能写入的数据，一般等于 capacity（可以通过limit(int newLimit)方法设置）；读模式下，limit 等于 Buffer 中实际写入的数据大小。\n 3. 位置（position）：下一个可以被读写的数据的位置（索引）。从写操作模式到读操作模式切换的时候（flip），position 都会归零，这样就可以从头开始读写了。\n 4. 标记（mark）：Buffer允许将位置直接定位到该标记处，这是一个可选属性；\n\n并且，上述变量满足如下的关系：0 <= mark <= position <= limit <= capacity 。\n\n另外，Buffer 有读模式和写模式这两种模式，分别用于从 Buffer 中读取数据或者向 Buffer 中写入数据。Buffer 被创建之后默认是写模式，调用 flip() 可以切换到读模式。如果要再次切换回写模式，可以调用 clear() 或者 compact() 方法。\n\n\n\n\n\nBuffer 对象不能通过 new 调用构造方法创建对象 ，只能通过静态方法实例化 Buffer。\n\n这里以 ByteBuffer为例进行介绍：\n\n// 分配堆内存\npublic static ByteBuffer allocate(int capacity);\n// 分配直接内存\npublic static ByteBuffer allocateDirect(int capacity);\n\n\nBuffer 最核心的两个方法：\n\n 1. get : 读取缓冲区的数据\n 2. put ：向缓冲区写入数据\n\n除上述两个方法之外，其他的重要方法：\n\n * flip ：将缓冲区从写模式切换到读模式，它会将 limit 的值设置为当前 position 的值，将 position 的值设置为 0。\n * clear: 清空缓冲区，将缓冲区从读模式切换到写模式，并将 position 的值设置为 0，将 limit 的值设置为 capacity 的值。\n * ……\n\nBuffer 中数据变化的过程：\n\nimport java.nio.*;\n\npublic class CharBufferDemo {\n    public static void main(String[] args) {\n        // 分配一个容量为8的CharBuffer\n        CharBuffer buffer = CharBuffer.allocate(8);\n        System.out.println("初始状态：");\n        printState(buffer);\n\n        // 向buffer写入3个字符\n        buffer.put(\'a\').put(\'b\').put(\'c\');\n        System.out.println("写入3个字符后的状态：");\n        printState(buffer);\n\n        // 调用flip()方法，准备读取buffer中的数据，将 position 置 0,limit 的置 3\n        buffer.flip();\n        System.out.println("调用flip()方法后的状态：");\n        printState(buffer);\n\n        // 读取字符\n        while (buffer.hasRemaining()) {\n            System.out.print(buffer.get());\n        }\n\n        // 调用clear()方法，清空缓冲区，将 position 的值置为 0，将 limit 的值置为 capacity 的值\n        buffer.clear();\n        System.out.println("调用clear()方法后的状态：");\n        printState(buffer);\n\n    }\n\n    // 打印buffer的capacity、limit、position、mark的位置\n    private static void printState(CharBuffer buffer) {\n        System.out.print("capacity: " + buffer.capacity());\n        System.out.print(", limit: " + buffer.limit());\n        System.out.print(", position: " + buffer.position());\n        System.out.print(", mark 开始读取的字符: " + buffer.mark());\n        System.out.println("\\n");\n    }\n}\n\n\n输出:\n\n初始状态：\ncapacity: 8, limit: 8, position: 0\n\n写入3个字符后的状态：\ncapacity: 8, limit: 8, position: 3\n\n准备读取buffer中的数据！\n\n调用flip()方法后的状态：\ncapacity: 8, limit: 3, position: 0\n\n读取到的数据：abc\n\n调用clear()方法后的状态：\ncapacity: 8, limit: 8, position: 0\n\n\n为了帮助理解，我绘制了一张图片展示 capacity、limit和position每一阶段的变化。\n\n\n\n\n# Channel（通道）\n\nChannel 是一个通道，它建立了与数据源（如文件、网络套接字等）之间的连接。我们可以利用它来读取和写入数据，就像打开了一条自来水管，让数据在 Channel 中自由流动。\n\nBIO 中的流是单向的，分为各种 InputStream（输入流）和 OutputStream（输出流），数据只是在一个方向上传输。通道与流的不同之处在于通道是双向的，它可以用于读、写或者同时用于读写。\n\nChannel 与前面介绍的 Buffer 打交道，读操作的时候将 Channel 中的数据填充到 Buffer 中，而写操作时将 Buffer 中的数据写入到 Channel 中。\n\n\n\n另外，因为 Channel 是全双工的，所以它可以比流更好地映射底层操作系统的 API。特别是在 UNIX 网络编程模型中，底层操作系统的通道都是全双工的，同时支持读写操作。\n\nChannel 的子类如下图所示。\n\n\n\n其中，最常用的是以下几种类型的通道：\n\n * FileChannel：文件访问通道；\n * SocketChannel、ServerSocketChannel：TCP 通信通道；\n * DatagramChannel：UDP 通信通道；\n\n\n\nChannel 最核心的两个方法：\n\n 1. read ：读取数据并写入到 Buffer 中。\n 2. write ：将 Buffer 中的数据写入到 Channel 中。\n\n这里我们以 FileChannel 为例演示一下是读取文件数据的。\n\nRandomAccessFile reader = new RandomAccessFile("/Users/guide/Documents/test_read.in", "r"))\nFileChannel channel = reader.getChannel();\nByteBuffer buffer = ByteBuffer.allocate(1024);\nchannel.read(buffer);\n\n\n\n# Selector（选择器）\n\nSelector（选择器） 是 NIO 中的一个关键组件，它允许一个线程处理多个 Channel。Selector 是基于事件驱动的 I/O 多路复用模型，主要运作原理是：通过 Selector 注册通道的事件，Selector 会不断地轮询注册在其上的 Channel。当事件发生时，比如：某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来。Selector 会将相关的 Channel 加入到就绪集合中。通过 SelectionKey 可以获取就绪 Channel 的集合，然后对这些就绪的 Channel 进行相应的 I/O 操作。\n\n\n\n一个多路复用器 Selector 可以同时轮询多个 Channel，由于 JDK 使用了 epoll() 代替传统的 select 实现，所以它并没有最大连接句柄 1024/2048 的限制。这也就意味着只需要一个线程负责 Selector 的轮询，就可以接入成千上万的客户端。\n\nSelector 可以监听以下四种事件类型：\n\n 1. SelectionKey.OP_ACCEPT：表示通道接受连接的事件，这通常用于 ServerSocketChannel。\n 2. SelectionKey.OP_CONNECT：表示通道完成连接的事件，这通常用于 SocketChannel。\n 3. SelectionKey.OP_READ：表示通道准备好进行读取的事件，即有数据可读。\n 4. SelectionKey.OP_WRITE：表示通道准备好进行写入的事件，即可以写入数据。\n\nSelector是抽象类，可以通过调用此类的 open() 静态方法来创建 Selector 实例。Selector 可以同时监控多个 SelectableChannel 的 IO 状况，是非阻塞 IO 的核心。\n\n一个 Selector 实例有三个 SelectionKey 集合：\n\n 1. 所有的 SelectionKey 集合：代表了注册在该 Selector 上的 Channel，这个集合可以通过 keys() 方法返回。\n 2. 被选择的 SelectionKey 集合：代表了所有可通过 select() 方法获取的、需要进行 IO 处理的 Channel，这个集合可以通过 selectedKeys() 返回。\n 3. 被取消的 SelectionKey 集合：代表了所有被取消注册关系的 Channel，在下一次执行 select() 方法时，这些 Channel 对应的 SelectionKey 会被彻底删除，程序通常无须直接访问该集合，也没有暴露访问的方法。\n\n简单演示一下如何遍历被选择的 SelectionKey 集合并进行处理：\n\nSet<SelectionKey> selectedKeys = selector.selectedKeys();\nIterator<SelectionKey> keyIterator = selectedKeys.iterator();\nwhile (keyIterator.hasNext()) {\n    SelectionKey key = keyIterator.next();\n    if (key != null) {\n        if (key.isAcceptable()) {\n            // ServerSocketChannel 接收了一个新连接\n        } else if (key.isConnectable()) {\n            // 表示一个新连接建立\n        } else if (key.isReadable()) {\n            // Channel 有准备好的数据，可以读取\n        } else if (key.isWritable()) {\n            // Channel 有空闲的 Buffer，可以写入数据\n        }\n    }\n    keyIterator.remove();\n}\n\n\nSelector 还提供了一系列和 select() 相关的方法：\n\n * int select()：监控所有注册的 Channel，当它们中间有需要处理的 IO 操作时，该方法返回，并将对应的 SelectionKey 加入被选择的 SelectionKey 集合中，该方法返回这些 Channel 的数量。\n * int select(long timeout)：可以设置超时时长的 select() 操作。\n * int selectNow()：执行一个立即返回的 select() 操作，相对于无参数的 select() 方法而言，该方法不会阻塞线程。\n * Selector wakeup()：使一个还未返回的 select() 方法立刻返回。\n * ……\n\n使用 Selector 实现网络读写的简单示例：\n\nimport java.io.IOException;\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.SelectionKey;\nimport java.nio.channels.Selector;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.util.Iterator;\nimport java.util.Set;\n\npublic class NioSelectorExample {\n\n  public static void main(String[] args) {\n    try {\n      ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n      serverSocketChannel.configureBlocking(false);\n      serverSocketChannel.socket().bind(new InetSocketAddress(8080));\n\n      Selector selector = Selector.open();\n      // 将 ServerSocketChannel 注册到 Selector 并监听 OP_ACCEPT 事件\n      serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n\n      while (true) {\n        int readyChannels = selector.select();\n\n        if (readyChannels == 0) {\n          continue;\n        }\n\n        Set<SelectionKey> selectedKeys = selector.selectedKeys();\n        Iterator<SelectionKey> keyIterator = selectedKeys.iterator();\n\n        while (keyIterator.hasNext()) {\n          SelectionKey key = keyIterator.next();\n\n          if (key.isAcceptable()) {\n            // 处理连接事件\n            ServerSocketChannel server = (ServerSocketChannel) key.channel();\n            SocketChannel client = server.accept();\n            client.configureBlocking(false);\n\n            // 将客户端通道注册到 Selector 并监听 OP_READ 事件\n            client.register(selector, SelectionKey.OP_READ);\n          } else if (key.isReadable()) {\n            // 处理读事件\n            SocketChannel client = (SocketChannel) key.channel();\n            ByteBuffer buffer = ByteBuffer.allocate(1024);\n            int bytesRead = client.read(buffer);\n\n            if (bytesRead > 0) {\n              buffer.flip();\n              System.out.println("收到数据：" +new String(buffer.array(), 0, bytesRead));\n              // 将客户端通道注册到 Selector 并监听 OP_WRITE 事件\n              client.register(selector, SelectionKey.OP_WRITE);\n            } else if (bytesRead < 0) {\n              // 客户端断开连接\n              client.close();\n            }\n          } else if (key.isWritable()) {\n            // 处理写事件\n            SocketChannel client = (SocketChannel) key.channel();\n            ByteBuffer buffer = ByteBuffer.wrap("Hello, Client!".getBytes());\n            client.write(buffer);\n\n            // 将客户端通道注册到 Selector 并监听 OP_READ 事件\n            client.register(selector, SelectionKey.OP_READ);\n          }\n\n          keyIterator.remove();\n        }\n      }\n    } catch (IOException e) {\n      e.printStackTrace();\n    }\n  }\n}\n\n\n在示例中，我们创建了一个简单的服务器，监听 8080 端口，使用 Selector 处理连接、读取和写入事件。当接收到客户端的数据时，服务器将读取数据并将其打印到控制台，然后向客户端回复 "Hello, Client!"。\n\n\n# NIO 零拷贝\n\n零拷贝是提升 IO 操作性能的一个常用手段，像 ActiveMQ、Kafka 、RocketMQ、QMQ、Netty 等顶级开源项目都用到了零拷贝。\n\n零拷贝是指计算机执行 IO 操作时，CPU 不需要将数据从一个存储区域复制到另一个存储区域，从而可以减少上下文切换以及 CPU 的拷贝时间。也就是说，零拷贝主要解决操作系统在处理 I/O 操作时频繁复制数据的问题。零拷贝的常见实现技术有： mmap+write、sendfile和 sendfile + DMA gather copy 。\n\n下图展示了各种零拷贝技术的对比图：\n\n                             CPU 拷贝   DMA 拷贝   系统调用         上下文切换\n传统方法                         2        2        read+write   4\nmmap+write                   1        2        mmap+write   4\nsendfile                     1        2        sendfile     2\nsendfile + DMA gather copy   0        2        sendfile     2\n\n可以看出，无论是传统的 I/O 方式，还是引入了零拷贝之后，2 次 DMA(Direct Memory Access) 拷贝是都少不了的。因为两次 DMA 都是依赖硬件完成的。零拷贝主要是减少了 CPU 拷贝及上下文的切换。\n\nJava 对零拷贝的支持：\n\n * MappedByteBuffer 是 NIO 基于内存映射（mmap）这种零拷⻉⽅式的提供的⼀种实现，底层实际是调用了 Linux 内核的 mmap 系统调用。它可以将一个文件或者文件的一部分映射到内存中，形成一个虚拟内存文件，这样就可以直接操作内存中的数据，而不需要通过系统调用来读写文件。\n * FileChannel 的transferTo()/transferFrom()是 NIO 基于发送文件（sendfile）这种零拷贝方式的提供的一种实现，底层实际是调用了 Linux 内核的 sendfile系统调用。它可以直接将文件数据从磁盘发送到网络，而不需要经过用户空间的缓冲区。关于FileChannel的用法可以看看这篇文章：Java NIO 文件通道 FileChannel 用法。\n\n代码示例：\n\nprivate void loadFileIntoMemory(File xmlFile) throws IOException {\n  FileInputStream fis = new FileInputStream(xmlFile);\n  // 创建 FileChannel 对象\n  FileChannel fc = fis.getChannel();\n  // FileChannel.map() 将文件映射到直接内存并返回 MappedByteBuffer 对象\n  MappedByteBuffer mmb = fc.map(FileChannel.MapMode.READ_ONLY, 0, fc.size());\n  xmlFileBuffer = new byte[(int)fc.size()];\n  mmb.get(xmlFileBuffer);\n  fis.close();\n}\n\n\n\n# 总结\n\n这篇文章我们主要介绍了 NIO 的核心知识点，包括 NIO 的核心组件和零拷贝。\n\n如果我们需要使用 NIO 构建网络程序的话，不建议直接使用原生 NIO，编程复杂且功能性太弱，推荐使用一些成熟的基于 NIO 的网络编程框架比如 Netty。Netty 在 NIO 的基础上进行了一些优化和扩展比如支持多种协议、支持 SSL/TLS 等等。\n\n\n# 参考\n\n * Java NIO 浅析：https://tech.meituan.com/2016/11/04/nio.html\n\n * 面试官：Java NIO 了解？https://mp.weixin.qq.com/s/mZobf-U8OSYQfHfYBEB6KA\n\n * Java NIO：Buffer、Channel 和 Selector：https://www.javadoop.com/post/java-nio',normalizedContent:'在学习 nio 之前，需要先了解一下计算机 i/o 模型的基础理论知识。还不了解的话，可以参考我写的这篇文章：java io 模型详解。\n\n\n# nio 简介\n\n在传统的 java i/o 模型（bio）中，i/o 操作是以阻塞的方式进行的。也就是说，当一个线程执行一个 i/o 操作时，它会被阻塞直到操作完成。这种阻塞模型在处理多个并发连接时可能会导致性能瓶颈，因为需要为每个连接创建一个线程，而线程的创建和切换都是有开销的。\n\n为了解决这个问题，在 java1.4 版本引入了一种新的 i/o 模型 — nio （new io，也称为 non-blocking io） 。nio 弥补了同步阻塞 i/o 的不足，它在标准 java 代码中提供了非阻塞、面向缓冲、基于通道的 i/o，可以使用少量的线程来处理多个连接，大大提高了 i/o 效率和并发。\n\n下图是 bio、nio 和 aio 处理客户端请求的简单对比图（关于 aio 的介绍，可以看我写的这篇文章：java io 模型详解，不是重点，了解即可）。\n\n\n\n⚠️需要注意：使用 nio 并不一定意味着高性能，它的性能优势主要体现在高并发和高延迟的网络环境下。当连接数较少、并发程度较低或者网络传输速度较快时，nio 的性能并不一定优于传统的 bio 。\n\n\n# nio 核心组件\n\nnio 主要包括以下三个核心组件：\n\n * buffer（缓冲区）：nio 读写数据都是通过缓冲区进行操作的。读操作的时候将 channel 中的数据填充到 buffer 中，而写操作时将 buffer 中的数据写入到 channel 中。\n * channel（通道）：channel 是一个双向的、可读可写的数据传输通道，nio 通过 channel 来实现数据的输入输出。通道是一个抽象的概念，它可以代表文件、套接字或者其他数据源之间的连接。\n * selector（选择器）：允许一个线程处理多个 channel，基于事件驱动的 i/o 多路复用模型。所有的 channel 都可以注册到 selector 上，由 selector 来分配线程来处理事件。\n\n三者的关系如下图所示（暂时不理解没关系，后文会详细介绍）：\n\n\n\n下面详细介绍一下这三个组件。\n\n\n# buffer（缓冲区）\n\n在传统的 bio 中，数据的读写是面向流的， 分为字节流和字符流。\n\n在 java 1.4 的 nio 库中，所有数据都是用缓冲区处理的，这是新库和之前的 bio 的一个重要区别，有点类似于 bio 中的缓冲流。nio 在读取数据时，它是直接读到缓冲区中的。在写入数据时，写入到缓冲区中。 使用 nio 在读写数据时，都是通过缓冲区进行操作。\n\nbuffer 的子类如下图所示。其中，最常用的是 bytebuffer，它可以用来存储和操作字节数据。\n\n\n\n你可以将 buffer 理解为一个数组，intbuffer、floatbuffer、charbuffer 等分别对应 int[]、float[]、char[] 等。\n\n为了更清晰地认识缓冲区，我们来简单看看buffer 类中定义的四个成员变量：\n\npublic abstract class buffer {\n    // invariants: mark <= position <= limit <= capacity\n    private int mark = -1;\n    private int position = 0;\n    private int limit;\n    private int capacity;\n}\n\n\n这四个成员变量的具体含义如下：\n\n 1. 容量（capacity）：buffer可以存储的最大数据量，buffer创建时设置且不可改变；\n 2. 界限（limit）：buffer 中可以读/写数据的边界。写模式下，limit 代表最多能写入的数据，一般等于 capacity（可以通过limit(int newlimit)方法设置）；读模式下，limit 等于 buffer 中实际写入的数据大小。\n 3. 位置（position）：下一个可以被读写的数据的位置（索引）。从写操作模式到读操作模式切换的时候（flip），position 都会归零，这样就可以从头开始读写了。\n 4. 标记（mark）：buffer允许将位置直接定位到该标记处，这是一个可选属性；\n\n并且，上述变量满足如下的关系：0 <= mark <= position <= limit <= capacity 。\n\n另外，buffer 有读模式和写模式这两种模式，分别用于从 buffer 中读取数据或者向 buffer 中写入数据。buffer 被创建之后默认是写模式，调用 flip() 可以切换到读模式。如果要再次切换回写模式，可以调用 clear() 或者 compact() 方法。\n\n\n\n\n\nbuffer 对象不能通过 new 调用构造方法创建对象 ，只能通过静态方法实例化 buffer。\n\n这里以 bytebuffer为例进行介绍：\n\n// 分配堆内存\npublic static bytebuffer allocate(int capacity);\n// 分配直接内存\npublic static bytebuffer allocatedirect(int capacity);\n\n\nbuffer 最核心的两个方法：\n\n 1. get : 读取缓冲区的数据\n 2. put ：向缓冲区写入数据\n\n除上述两个方法之外，其他的重要方法：\n\n * flip ：将缓冲区从写模式切换到读模式，它会将 limit 的值设置为当前 position 的值，将 position 的值设置为 0。\n * clear: 清空缓冲区，将缓冲区从读模式切换到写模式，并将 position 的值设置为 0，将 limit 的值设置为 capacity 的值。\n * ……\n\nbuffer 中数据变化的过程：\n\nimport java.nio.*;\n\npublic class charbufferdemo {\n    public static void main(string[] args) {\n        // 分配一个容量为8的charbuffer\n        charbuffer buffer = charbuffer.allocate(8);\n        system.out.println("初始状态：");\n        printstate(buffer);\n\n        // 向buffer写入3个字符\n        buffer.put(\'a\').put(\'b\').put(\'c\');\n        system.out.println("写入3个字符后的状态：");\n        printstate(buffer);\n\n        // 调用flip()方法，准备读取buffer中的数据，将 position 置 0,limit 的置 3\n        buffer.flip();\n        system.out.println("调用flip()方法后的状态：");\n        printstate(buffer);\n\n        // 读取字符\n        while (buffer.hasremaining()) {\n            system.out.print(buffer.get());\n        }\n\n        // 调用clear()方法，清空缓冲区，将 position 的值置为 0，将 limit 的值置为 capacity 的值\n        buffer.clear();\n        system.out.println("调用clear()方法后的状态：");\n        printstate(buffer);\n\n    }\n\n    // 打印buffer的capacity、limit、position、mark的位置\n    private static void printstate(charbuffer buffer) {\n        system.out.print("capacity: " + buffer.capacity());\n        system.out.print(", limit: " + buffer.limit());\n        system.out.print(", position: " + buffer.position());\n        system.out.print(", mark 开始读取的字符: " + buffer.mark());\n        system.out.println("\\n");\n    }\n}\n\n\n输出:\n\n初始状态：\ncapacity: 8, limit: 8, position: 0\n\n写入3个字符后的状态：\ncapacity: 8, limit: 8, position: 3\n\n准备读取buffer中的数据！\n\n调用flip()方法后的状态：\ncapacity: 8, limit: 3, position: 0\n\n读取到的数据：abc\n\n调用clear()方法后的状态：\ncapacity: 8, limit: 8, position: 0\n\n\n为了帮助理解，我绘制了一张图片展示 capacity、limit和position每一阶段的变化。\n\n\n\n\n# channel（通道）\n\nchannel 是一个通道，它建立了与数据源（如文件、网络套接字等）之间的连接。我们可以利用它来读取和写入数据，就像打开了一条自来水管，让数据在 channel 中自由流动。\n\nbio 中的流是单向的，分为各种 inputstream（输入流）和 outputstream（输出流），数据只是在一个方向上传输。通道与流的不同之处在于通道是双向的，它可以用于读、写或者同时用于读写。\n\nchannel 与前面介绍的 buffer 打交道，读操作的时候将 channel 中的数据填充到 buffer 中，而写操作时将 buffer 中的数据写入到 channel 中。\n\n\n\n另外，因为 channel 是全双工的，所以它可以比流更好地映射底层操作系统的 api。特别是在 unix 网络编程模型中，底层操作系统的通道都是全双工的，同时支持读写操作。\n\nchannel 的子类如下图所示。\n\n\n\n其中，最常用的是以下几种类型的通道：\n\n * filechannel：文件访问通道；\n * socketchannel、serversocketchannel：tcp 通信通道；\n * datagramchannel：udp 通信通道；\n\n\n\nchannel 最核心的两个方法：\n\n 1. read ：读取数据并写入到 buffer 中。\n 2. write ：将 buffer 中的数据写入到 channel 中。\n\n这里我们以 filechannel 为例演示一下是读取文件数据的。\n\nrandomaccessfile reader = new randomaccessfile("/users/guide/documents/test_read.in", "r"))\nfilechannel channel = reader.getchannel();\nbytebuffer buffer = bytebuffer.allocate(1024);\nchannel.read(buffer);\n\n\n\n# selector（选择器）\n\nselector（选择器） 是 nio 中的一个关键组件，它允许一个线程处理多个 channel。selector 是基于事件驱动的 i/o 多路复用模型，主要运作原理是：通过 selector 注册通道的事件，selector 会不断地轮询注册在其上的 channel。当事件发生时，比如：某个 channel 上面有新的 tcp 连接接入、读和写事件，这个 channel 就处于就绪状态，会被 selector 轮询出来。selector 会将相关的 channel 加入到就绪集合中。通过 selectionkey 可以获取就绪 channel 的集合，然后对这些就绪的 channel 进行相应的 i/o 操作。\n\n\n\n一个多路复用器 selector 可以同时轮询多个 channel，由于 jdk 使用了 epoll() 代替传统的 select 实现，所以它并没有最大连接句柄 1024/2048 的限制。这也就意味着只需要一个线程负责 selector 的轮询，就可以接入成千上万的客户端。\n\nselector 可以监听以下四种事件类型：\n\n 1. selectionkey.op_accept：表示通道接受连接的事件，这通常用于 serversocketchannel。\n 2. selectionkey.op_connect：表示通道完成连接的事件，这通常用于 socketchannel。\n 3. selectionkey.op_read：表示通道准备好进行读取的事件，即有数据可读。\n 4. selectionkey.op_write：表示通道准备好进行写入的事件，即可以写入数据。\n\nselector是抽象类，可以通过调用此类的 open() 静态方法来创建 selector 实例。selector 可以同时监控多个 selectablechannel 的 io 状况，是非阻塞 io 的核心。\n\n一个 selector 实例有三个 selectionkey 集合：\n\n 1. 所有的 selectionkey 集合：代表了注册在该 selector 上的 channel，这个集合可以通过 keys() 方法返回。\n 2. 被选择的 selectionkey 集合：代表了所有可通过 select() 方法获取的、需要进行 io 处理的 channel，这个集合可以通过 selectedkeys() 返回。\n 3. 被取消的 selectionkey 集合：代表了所有被取消注册关系的 channel，在下一次执行 select() 方法时，这些 channel 对应的 selectionkey 会被彻底删除，程序通常无须直接访问该集合，也没有暴露访问的方法。\n\n简单演示一下如何遍历被选择的 selectionkey 集合并进行处理：\n\nset<selectionkey> selectedkeys = selector.selectedkeys();\niterator<selectionkey> keyiterator = selectedkeys.iterator();\nwhile (keyiterator.hasnext()) {\n    selectionkey key = keyiterator.next();\n    if (key != null) {\n        if (key.isacceptable()) {\n            // serversocketchannel 接收了一个新连接\n        } else if (key.isconnectable()) {\n            // 表示一个新连接建立\n        } else if (key.isreadable()) {\n            // channel 有准备好的数据，可以读取\n        } else if (key.iswritable()) {\n            // channel 有空闲的 buffer，可以写入数据\n        }\n    }\n    keyiterator.remove();\n}\n\n\nselector 还提供了一系列和 select() 相关的方法：\n\n * int select()：监控所有注册的 channel，当它们中间有需要处理的 io 操作时，该方法返回，并将对应的 selectionkey 加入被选择的 selectionkey 集合中，该方法返回这些 channel 的数量。\n * int select(long timeout)：可以设置超时时长的 select() 操作。\n * int selectnow()：执行一个立即返回的 select() 操作，相对于无参数的 select() 方法而言，该方法不会阻塞线程。\n * selector wakeup()：使一个还未返回的 select() 方法立刻返回。\n * ……\n\n使用 selector 实现网络读写的简单示例：\n\nimport java.io.ioexception;\nimport java.net.inetsocketaddress;\nimport java.nio.bytebuffer;\nimport java.nio.channels.selectionkey;\nimport java.nio.channels.selector;\nimport java.nio.channels.serversocketchannel;\nimport java.nio.channels.socketchannel;\nimport java.util.iterator;\nimport java.util.set;\n\npublic class nioselectorexample {\n\n  public static void main(string[] args) {\n    try {\n      serversocketchannel serversocketchannel = serversocketchannel.open();\n      serversocketchannel.configureblocking(false);\n      serversocketchannel.socket().bind(new inetsocketaddress(8080));\n\n      selector selector = selector.open();\n      // 将 serversocketchannel 注册到 selector 并监听 op_accept 事件\n      serversocketchannel.register(selector, selectionkey.op_accept);\n\n      while (true) {\n        int readychannels = selector.select();\n\n        if (readychannels == 0) {\n          continue;\n        }\n\n        set<selectionkey> selectedkeys = selector.selectedkeys();\n        iterator<selectionkey> keyiterator = selectedkeys.iterator();\n\n        while (keyiterator.hasnext()) {\n          selectionkey key = keyiterator.next();\n\n          if (key.isacceptable()) {\n            // 处理连接事件\n            serversocketchannel server = (serversocketchannel) key.channel();\n            socketchannel client = server.accept();\n            client.configureblocking(false);\n\n            // 将客户端通道注册到 selector 并监听 op_read 事件\n            client.register(selector, selectionkey.op_read);\n          } else if (key.isreadable()) {\n            // 处理读事件\n            socketchannel client = (socketchannel) key.channel();\n            bytebuffer buffer = bytebuffer.allocate(1024);\n            int bytesread = client.read(buffer);\n\n            if (bytesread > 0) {\n              buffer.flip();\n              system.out.println("收到数据：" +new string(buffer.array(), 0, bytesread));\n              // 将客户端通道注册到 selector 并监听 op_write 事件\n              client.register(selector, selectionkey.op_write);\n            } else if (bytesread < 0) {\n              // 客户端断开连接\n              client.close();\n            }\n          } else if (key.iswritable()) {\n            // 处理写事件\n            socketchannel client = (socketchannel) key.channel();\n            bytebuffer buffer = bytebuffer.wrap("hello, client!".getbytes());\n            client.write(buffer);\n\n            // 将客户端通道注册到 selector 并监听 op_read 事件\n            client.register(selector, selectionkey.op_read);\n          }\n\n          keyiterator.remove();\n        }\n      }\n    } catch (ioexception e) {\n      e.printstacktrace();\n    }\n  }\n}\n\n\n在示例中，我们创建了一个简单的服务器，监听 8080 端口，使用 selector 处理连接、读取和写入事件。当接收到客户端的数据时，服务器将读取数据并将其打印到控制台，然后向客户端回复 "hello, client!"。\n\n\n# nio 零拷贝\n\n零拷贝是提升 io 操作性能的一个常用手段，像 activemq、kafka 、rocketmq、qmq、netty 等顶级开源项目都用到了零拷贝。\n\n零拷贝是指计算机执行 io 操作时，cpu 不需要将数据从一个存储区域复制到另一个存储区域，从而可以减少上下文切换以及 cpu 的拷贝时间。也就是说，零拷贝主要解决操作系统在处理 i/o 操作时频繁复制数据的问题。零拷贝的常见实现技术有： mmap+write、sendfile和 sendfile + dma gather copy 。\n\n下图展示了各种零拷贝技术的对比图：\n\n                             cpu 拷贝   dma 拷贝   系统调用         上下文切换\n传统方法                         2        2        read+write   4\nmmap+write                   1        2        mmap+write   4\nsendfile                     1        2        sendfile     2\nsendfile + dma gather copy   0        2        sendfile     2\n\n可以看出，无论是传统的 i/o 方式，还是引入了零拷贝之后，2 次 dma(direct memory access) 拷贝是都少不了的。因为两次 dma 都是依赖硬件完成的。零拷贝主要是减少了 cpu 拷贝及上下文的切换。\n\njava 对零拷贝的支持：\n\n * mappedbytebuffer 是 nio 基于内存映射（mmap）这种零拷⻉⽅式的提供的⼀种实现，底层实际是调用了 linux 内核的 mmap 系统调用。它可以将一个文件或者文件的一部分映射到内存中，形成一个虚拟内存文件，这样就可以直接操作内存中的数据，而不需要通过系统调用来读写文件。\n * filechannel 的transferto()/transferfrom()是 nio 基于发送文件（sendfile）这种零拷贝方式的提供的一种实现，底层实际是调用了 linux 内核的 sendfile系统调用。它可以直接将文件数据从磁盘发送到网络，而不需要经过用户空间的缓冲区。关于filechannel的用法可以看看这篇文章：java nio 文件通道 filechannel 用法。\n\n代码示例：\n\nprivate void loadfileintomemory(file xmlfile) throws ioexception {\n  fileinputstream fis = new fileinputstream(xmlfile);\n  // 创建 filechannel 对象\n  filechannel fc = fis.getchannel();\n  // filechannel.map() 将文件映射到直接内存并返回 mappedbytebuffer 对象\n  mappedbytebuffer mmb = fc.map(filechannel.mapmode.read_only, 0, fc.size());\n  xmlfilebuffer = new byte[(int)fc.size()];\n  mmb.get(xmlfilebuffer);\n  fis.close();\n}\n\n\n\n# 总结\n\n这篇文章我们主要介绍了 nio 的核心知识点，包括 nio 的核心组件和零拷贝。\n\n如果我们需要使用 nio 构建网络程序的话，不建议直接使用原生 nio，编程复杂且功能性太弱，推荐使用一些成熟的基于 nio 的网络编程框架比如 netty。netty 在 nio 的基础上进行了一些优化和扩展比如支持多种协议、支持 ssl/tls 等等。\n\n\n# 参考\n\n * java nio 浅析：https://tech.meituan.com/2016/11/04/nio.html\n\n * 面试官：java nio 了解？https://mp.weixin.qq.com/s/mzobf-u8osyqfhfybeb6ka\n\n * java nio：buffer、channel 和 selector：https://www.javadoop.com/post/java-nio',charsets:{cjk:!0}},{title:"Java8 新特性实战",frontmatter:{title:"Java8 新特性实战",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:05:46.000Z",permalink:"/pages/cd056d/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/01.java8-common-new-features.html",relativePath:"01.Java基础/05.版本新特性/01.java8-common-new-features.md",key:"v-a6c16d9c",path:"/pages/cd056d/",headers:[{level:2,title:"Interface",slug:"interface",normalizedTitle:"interface",charIndex:353},{level:2,title:"functional interface 函数式接口",slug:"functional-interface-函数式接口",normalizedTitle:"functional interface 函数式接口",charIndex:2143},{level:2,title:"Lambda 表达式",slug:"lambda-表达式",normalizedTitle:"lambda 表达式",charIndex:268},{level:3,title:"语法格式",slug:"语法格式",normalizedTitle:"语法格式",charIndex:2667},{level:3,title:"Lambda 实战",slug:"lambda-实战",normalizedTitle:"lambda 实战",charIndex:2738},{level:4,title:"替代匿名内部类",slug:"替代匿名内部类",normalizedTitle:"替代匿名内部类",charIndex:2777},{level:4,title:"集合迭代",slug:"集合迭代",normalizedTitle:"集合迭代",charIndex:4297},{level:4,title:"方法的引用",slug:"方法的引用",normalizedTitle:"方法的引用",charIndex:4742},{level:4,title:"访问变量",slug:"访问变量",normalizedTitle:"访问变量",charIndex:5493},{level:2,title:"Stream",slug:"stream",normalizedTitle:"stream",charIndex:5644},{level:3,title:"流类型",slug:"流类型",normalizedTitle:"流类型",charIndex:5917},{level:3,title:"常用方法",slug:"常用方法",normalizedTitle:"常用方法",charIndex:5971},{level:3,title:"实战",slug:"实战",normalizedTitle:"实战",charIndex:2745},{level:3,title:"延迟执行",slug:"延迟执行",normalizedTitle:"延迟执行",charIndex:9307},{level:3,title:"小结",slug:"小结",normalizedTitle:"小结",charIndex:10594},{level:2,title:"Optional",slug:"optional",normalizedTitle:"optional",charIndex:10759},{level:3,title:"如何创建一个 Optional",slug:"如何创建一个-optional",normalizedTitle:"如何创建一个 optional",charIndex:11799},{level:3,title:"判断 value 是否为 null",slug:"判断-value-是否为-null",normalizedTitle:"判断 value 是否为 null",charIndex:15458},{level:3,title:"获取 value",slug:"获取-value",normalizedTitle:"获取 value",charIndex:15707},{level:3,title:"过滤值",slug:"过滤值",normalizedTitle:"过滤值",charIndex:16533},{level:3,title:"小结",slug:"小结-2",normalizedTitle:"小结",charIndex:10594},{level:2,title:"Date-Time API",slug:"date-time-api",normalizedTitle:"date-time api",charIndex:17060},{level:3,title:"java.time 主要类",slug:"java-time-主要类",normalizedTitle:"java.time 主要类",charIndex:17280},{level:3,title:"格式化",slug:"格式化",normalizedTitle:"格式化",charIndex:17145},{level:3,title:"字符串转日期格式",slug:"字符串转日期格式",normalizedTitle:"字符串转日期格式",charIndex:18779},{level:3,title:"日期计算",slug:"日期计算",normalizedTitle:"日期计算",charIndex:19328},{level:3,title:"获取指定日期",slug:"获取指定日期",normalizedTitle:"获取指定日期",charIndex:21076},{level:3,title:"JDBC 和 java8",slug:"jdbc-和-java8",normalizedTitle:"jdbc 和 java8",charIndex:22718},{level:3,title:"时区",slug:"时区",normalizedTitle:"时区",charIndex:17132},{level:3,title:"小结",slug:"小结-3",normalizedTitle:"小结",charIndex:10594},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:160}],headersStr:"Interface functional interface 函数式接口 Lambda 表达式 语法格式 Lambda 实战 替代匿名内部类 集合迭代 方法的引用 访问变量 Stream 流类型 常用方法 实战 延迟执行 小结 Optional 如何创建一个 Optional 判断 value 是否为 null 获取 value 过滤值 小结 Date-Time API java.time 主要类 格式化 字符串转日期格式 日期计算 获取指定日期 JDBC 和 java8 时区 小结 总结",content:'> 本文来自cowbi的投稿~\n\nOracle 于 2014 发布了 Java8（jdk1.8），诸多原因使它成为目前市场上使用最多的 jdk 版本。虽然发布距今已将近 7 年，但很多程序员对其新特性还是不够了解，尤其是用惯了 Java8 之前版本的老程序员，比如我。\n\n为了不脱离队伍太远，还是有必要对这些新特性做一些总结梳理。它较 jdk.7 有很多变化或者说是优化，比如 interface 里可以有静态方法，并且可以有方法体，这一点就颠覆了之前的认知；java.util.HashMap 数据结构里增加了红黑树；还有众所周知的 Lambda 表达式等等。本文不能把所有的新特性都给大家一一分享，只列出比较常用的新特性给大家做详细讲解。更多相关内容请看官网关于 Java8 的新特性的介绍。\n\n\n# Interface\n\ninterface 的设计初衷是面向抽象，提高扩展性。这也留有一点遗憾，Interface 修改的时候，实现它的类也必须跟着改。\n\n为了解决接口的修改与现有的实现不兼容的问题。新 interface 的方法可以用default 或 static修饰，这样就可以有方法体，实现类也不必重写此方法。\n\n一个 interface 中可以有多个方法被它们修饰，这 2 个修饰符的区别主要也是普通方法和静态方法的区别。\n\n 1. default修饰的方法，是普通实例方法，可以用this调用，可以被子类继承、重写。\n 2. static修饰的方法，使用上和一般类静态方法一样。但它不能被子类继承，只能用Interface调用。\n\n我们来看一个实际的例子。\n\npublic interface InterfaceNew {\n    static void sm() {\n        System.out.println("interface提供的方式实现");\n    }\n    static void sm2() {\n        System.out.println("interface提供的方式实现");\n    }\n\n    default void def() {\n        System.out.println("interface default方法");\n    }\n    default void def2() {\n        System.out.println("interface default2方法");\n    }\n    //须要实现类重写\n    void f();\n}\n\npublic interface InterfaceNew1 {\n    default void def() {\n        System.out.println("InterfaceNew1 default方法");\n    }\n}\n\n\n如果有一个类既实现了 InterfaceNew 接口又实现了 InterfaceNew1接口，它们都有def()，并且 InterfaceNew 接口和 InterfaceNew1接口没有继承关系的话，这时就必须重写def()。不然的话，编译的时候就会报错。\n\npublic class InterfaceNewImpl implements InterfaceNew , InterfaceNew1{\n    public static void main(String[] args) {\n        InterfaceNewImpl interfaceNew = new InterfaceNewImpl();\n        interfaceNew.def();\n    }\n\n    @Override\n    public void def() {\n        InterfaceNew1.super.def();\n    }\n\n    @Override\n    public void f() {\n    }\n}\n\n\n在 Java 8 ，接口和抽象类有什么区别的？\n\n很多小伙伴认为：“既然 interface 也可以有自己的方法实现，似乎和 abstract class 没多大区别了。”\n\n其实它们还是有区别的\n\n 1. interface 和 class 的区别，好像是废话，主要有：\n    \n    * 接口多实现，类单继承\n    * 接口的方法是 public abstract 修饰，变量是 public static final 修饰。 abstract class 可以用其他修饰符\n\n 2. interface 的方法是更像是一个扩展插件。而 abstract class 的方法是要继承的。\n\n开始我们也提到，interface 新增default和static修饰的方法，为了解决接口的修改与现有的实现不兼容的问题，并不是为了要替代abstract class。在使用上，该用 abstract class 的地方还是要用 abstract class，不要因为 interface 的新特性而将之替换。\n\n记住接口永远和类不一样。\n\n\n# functional interface 函数式接口\n\n定义：也称 SAM 接口，即 Single Abstract Method interfaces，有且只有一个抽象方法，但可以有多个非抽象方法的接口。\n\n在 java 8 中专门有一个包放函数式接口java.util.function，该包下的所有接口都有 @FunctionalInterface 注解，提供函数式编程。\n\n在其他包中也有函数式接口，其中一些没有@FunctionalInterface 注解，但是只要符合函数式接口的定义就是函数式接口，与是否有\n\n@FunctionalInterface注解无关，注解只是在编译时起到强制规范定义的作用。其在 Lambda 表达式中有广泛的应用。\n\n\n# Lambda 表达式\n\n接下来谈众所周知的 Lambda 表达式。它是推动 Java 8 发布的最重要新特性。是继泛型(Generics)和注解(Annotation)以来最大的变化。\n\n使用 Lambda 表达式可以使代码变的更加简洁紧凑。让 java 也能支持简单的函数式编程。\n\n> Lambda 表达式是一个匿名函数，java 8 允许把函数作为参数传递进方法中。\n\n\n# 语法格式\n\n(parameters) -> expression 或\n(parameters) ->{ statements; }\n\n\n\n# Lambda 实战\n\n我们用常用的实例来感受 Lambda 带来的便利\n\n# 替代匿名内部类\n\n过去给方法传动态参数的唯一方法是使用内部类。比如\n\n1.Runnable 接口\n\nnew Thread(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println("The runable now is using!");\n            }\n}).start();\n//用lambda\nnew Thread(() -> System.out.println("It\'s a lambda function!")).start();\n\n\n2.Comparator 接口\n\nList<Integer> strings = Arrays.asList(1, 2, 3);\n\nCollections.sort(strings, new Comparator<Integer>() {\n@Override\npublic int compare(Integer o1, Integer o2) {\n    return o1 - o2;}\n});\n\n//Lambda\nCollections.sort(strings, (Integer o1, Integer o2) -> o1 - o2);\n//分解开\nComparator<Integer> comparator = (Integer o1, Integer o2) -> o1 - o2;\nCollections.sort(strings, comparator);\n\n\n3.Listener 接口\n\nJButton button = new JButton();\nbutton.addItemListener(new ItemListener() {\n@Override\npublic void itemStateChanged(ItemEvent e) {\n   e.getItem();\n}\n});\n//lambda\nbutton.addItemListener(e -> e.getItem());\n\n\n4.自定义接口\n\n上面的 3 个例子是我们在开发过程中最常见的，从中也能体会到 Lambda 带来的便捷与清爽。它只保留实际用到的代码，把无用代码全部省略。那它对接口有没有要求呢？我们发现这些匿名内部类只重写了接口的一个方法，当然也只有一个方法须要重写。这就是我们上文提到的函数式接口，也就是说只要方法的参数是函数式接口都可以用 Lambda 表达式。\n\n@FunctionalInterface\npublic interface Comparator<T>{}\n\n@FunctionalInterface\npublic interface Runnable{}\n\n\n我们自定义一个函数式接口\n\n@FunctionalInterface\npublic interface LambdaInterface {\n void f();\n}\n//使用\npublic class LambdaClass {\n    public static void forEg() {\n        lambdaInterfaceDemo(()-> System.out.println("自定义函数式接口"));\n    }\n    //函数式接口参数\n    static void lambdaInterfaceDemo(LambdaInterface i){\n        i.f();\n    }\n}\n\n\n# 集合迭代\n\nvoid lamndaFor() {\n        List<String> strings = Arrays.asList("1", "2", "3");\n        //传统foreach\n        for (String s : strings) {\n            System.out.println(s);\n        }\n        //Lambda foreach\n        strings.forEach((s) -> System.out.println(s));\n        //or\n        strings.forEach(System.out::println);\n     //map\n        Map<Integer, String> map = new HashMap<>();\n        map.forEach((k,v)->System.out.println(v));\n}\n\n\n# 方法的引用\n\nJava 8 允许使用 :: 关键字来传递方法或者构造函数引用，无论如何，表达式返回的类型必须是 functional-interface。\n\npublic class LambdaClassSuper {\n    LambdaInterface sf(){\n        return null;\n    }\n}\n\npublic class LambdaClass extends LambdaClassSuper {\n    public static LambdaInterface staticF() {\n        return null;\n    }\n\n    public LambdaInterface f() {\n        return null;\n    }\n\n    void show() {\n        //1.调用静态函数，返回类型必须是functional-interface\n        LambdaInterface t = LambdaClass::staticF;\n\n        //2.实例方法调用\n        LambdaClass lambdaClass = new LambdaClass();\n        LambdaInterface lambdaInterface = lambdaClass::f;\n\n        //3.超类上的方法调用\n        LambdaInterface superf = super::sf;\n\n        //4. 构造方法调用\n        LambdaInterface tt = LambdaClassSuper::new;\n    }\n}\n\n\n# 访问变量\n\nint i = 0;\nCollections.sort(strings, (Integer o1, Integer o2) -> o1 - i);\n//i =3;\n\n\nlambda 表达式可以引用外边变量，但是该变量默认拥有 final 属性，不能被修改，如果修改，编译时就报错。\n\n\n# Stream\n\njava 新增了 java.util.stream 包，它和之前的流大同小异。之前接触最多的是资源流，比如java.io.FileInputStream，通过流把文件从一个地方输入到另一个地方，它只是内容搬运工，对文件内容不做任何CRUD。\n\nStream依然不存储数据，不同的是它可以检索(Retrieve)和逻辑处理集合数据、包括筛选、排序、统计、计数等。可以想象成是 Sql 语句。\n\n它的源数据可以是 Collection、Array 等。由于它的方法参数都是函数式接口类型，所以一般和 Lambda 配合使用。\n\n\n# 流类型\n\n 1. stream 串行流\n 2. parallelStream 并行流，可多线程执行\n\n\n# 常用方法\n\n接下来我们看java.util.stream.Stream常用方法\n\n/**\n* 返回一个串行流\n*/\ndefault Stream<E> stream()\n\n/**\n* 返回一个并行流\n*/\ndefault Stream<E> parallelStream()\n\n/**\n* 返回T的流\n*/\npublic static<T> Stream<T> of(T t)\n\n/**\n* 返回其元素是指定值的顺序流。\n*/\npublic static<T> Stream<T> of(T... values) {\n    return Arrays.stream(values);\n}\n\n\n/**\n* 过滤，返回由与给定predicate匹配的该流的元素组成的流\n*/\nStream<T> filter(Predicate<? super T> predicate);\n\n/**\n* 此流的所有元素是否与提供的predicate匹配。\n*/\nboolean allMatch(Predicate<? super T> predicate)\n\n/**\n* 此流任意元素是否有与提供的predicate匹配。\n*/\nboolean anyMatch(Predicate<? super T> predicate);\n\n/**\n* 返回一个 Stream的构建器。\n*/\npublic static<T> Builder<T> builder();\n\n/**\n* 使用 Collector对此流的元素进行归纳\n*/\n<R, A> R collect(Collector<? super T, A, R> collector);\n\n/**\n * 返回此流中的元素数。\n*/\nlong count();\n\n/**\n* 返回由该流的不同元素（根据 Object.equals(Object) ）组成的流。\n*/\nStream<T> distinct();\n\n/**\n * 遍历\n*/\nvoid forEach(Consumer<? super T> action);\n\n/**\n* 用于获取指定数量的流，截短长度不能超过 maxSize 。\n*/\nStream<T> limit(long maxSize);\n\n/**\n* 用于映射每个元素到对应的结果\n*/\n<R> Stream<R> map(Function<? super T, ? extends R> mapper);\n\n/**\n* 根据提供的 Comparator进行排序。\n*/\nStream<T> sorted(Comparator<? super T> comparator);\n\n/**\n* 在丢弃流的第一个 n元素后，返回由该流的 n元素组成的流。\n*/\nStream<T> skip(long n);\n\n/**\n* 返回一个包含此流的元素的数组。\n*/\nObject[] toArray();\n\n/**\n* 使用提供的 generator函数返回一个包含此流的元素的数组，以分配返回的数组，以及分区执行或调整大小可能需要的任何其他数组。\n*/\n<A> A[] toArray(IntFunction<A[]> generator);\n\n/**\n* 合并流\n*/\npublic static <T> Stream<T> concat(Stream<? extends T> a, Stream<? extends T> b)\n\n\n\n# 实战\n\n本文列出 Stream 具有代表性的方法之使用，更多的使用方法还是要看 Api。\n\n@Test\npublic void test() {\n  List<String> strings = Arrays.asList("abc", "def", "gkh", "abc");\n    //返回符合条件的stream\n    Stream<String> stringStream = strings.stream().filter(s -> "abc".equals(s));\n    //计算流符合条件的流的数量\n    long count = stringStream.count();\n\n    //forEach遍历->打印元素\n    strings.stream().forEach(System.out::println);\n\n    //limit 获取到1个元素的stream\n    Stream<String> limit = strings.stream().limit(1);\n    //toArray 比如我们想看这个limitStream里面是什么，比如转换成String[],比如循环\n    String[] array = limit.toArray(String[]::new);\n\n    //map 对每个元素进行操作返回新流\n    Stream<String> map = strings.stream().map(s -> s + "22");\n\n    //sorted 排序并打印\n    strings.stream().sorted().forEach(System.out::println);\n\n    //Collectors collect 把abc放入容器中\n    List<String> collect = strings.stream().filter(string -> "abc".equals(string)).collect(Collectors.toList());\n    //把list转为string，各元素用，号隔开\n    String mergedString = strings.stream().filter(string -> !string.isEmpty()).collect(Collectors.joining(","));\n\n    //对数组的统计，比如用\n    List<Integer> number = Arrays.asList(1, 2, 5, 4);\n\n    IntSummaryStatistics statistics = number.stream().mapToInt((x) -> x).summaryStatistics();\n    System.out.println("列表中最大的数 : "+statistics.getMax());\n    System.out.println("列表中最小的数 : "+statistics.getMin());\n    System.out.println("平均数 : "+statistics.getAverage());\n    System.out.println("所有数之和 : "+statistics.getSum());\n\n    //concat 合并流\n    List<String> strings2 = Arrays.asList("xyz", "jqx");\n    Stream.concat(strings2.stream(),strings.stream()).count();\n\n    //注意 一个Stream只能操作一次，不能断开，否则会报错。\n    Stream stream = strings.stream();\n    //第一次使用\n    stream.limit(2);\n    //第二次使用\n    stream.forEach(System.out::println);\n    //报错 java.lang.IllegalStateException: stream has already been operated upon or closed\n\n    //但是可以这样, 连续使用\n    stream.limit(2).forEach(System.out::println);\n}\n\n\n\n# 延迟执行\n\n在执行返回 Stream 的方法时，并不立刻执行，而是等返回一个非 Stream 的方法后才执行。因为拿到 Stream 并不能直接用，而是需要处理成一个常规类型。这里的 Stream 可以想象成是二进制流（2 个完全不一样的东东），拿到也看不懂。\n\n我们下面分解一下 filter 方法。\n\n@Test\npublic void laziness(){\n  List<String> strings = Arrays.asList("abc", "def", "gkh", "abc");\n  Stream<Integer> stream = strings.stream().filter(new Predicate() {\n      @Override\n      public boolean test(Object o) {\n        System.out.println("Predicate.test 执行");\n        return true;\n        }\n      });\n\n   System.out.println("count 执行");\n   stream.count();\n}\n/*-------执行结果--------*/\ncount 执行\nPredicate.test 执行\nPredicate.test 执行\nPredicate.test 执行\nPredicate.test 执行\n\n\n按执行顺序应该是先打印 4 次「Predicate.test 执行」，再打印「count 执行」。实际结果恰恰相反。说明 filter 中的方法并没有立刻执行，而是等调用count()方法后才执行。\n\n上面都是串行 Stream 的实例。并行 parallelStream 在使用方法上和串行一样。主要区别是 parallelStream 可多线程执行，是基于 ForkJoin 框架实现的，有时间大家可以了解一下 ForkJoin 框架和 ForkJoinPool。这里可以简单的理解它是通过线程池来实现的，这样就会涉及到线程安全，线程消耗等问题。下面我们通过代码来体验一下并行流的多线程执行。\n\n@Test\npublic void parallelStreamTest(){\n   List<Integer> numbers = Arrays.asList(1, 2, 5, 4);\n   numbers.parallelStream() .forEach(num->System.out.println(Thread.currentThread().getName()+">>"+num));\n}\n//执行结果\nmain>>5\nForkJoinPool.commonPool-worker-2>>4\nForkJoinPool.commonPool-worker-11>>1\nForkJoinPool.commonPool-worker-9>>2\n\n\n从结果中我们看到，for-each 用到的是多线程。\n\n\n# 小结\n\n从源码和实例中我们可以总结出一些 stream 的特点\n\n 1. 通过简单的链式编程，使得它可以方便地对遍历处理后的数据进行再处理。\n 2. 方法参数都是函数式接口类型\n 3. 一个 Stream 只能操作一次，操作完就关闭了，继续使用这个 stream 会报错。\n 4. Stream 不保存数据，不改变数据源\n\n\n# Optional\n\n在阿里巴巴开发手册关于 Optional 的介绍中这样写到：\n\n> 防止 NPE，是程序员的基本修养，注意 NPE 产生的场景：\n> \n> 1） 返回类型为基本数据类型，return 包装数据类型的对象时，自动拆箱有可能产生 NPE。\n> \n> 反例：public int f() { return Integer 对象}， 如果为 null，自动解箱抛 NPE。\n> \n> 2） 数据库的查询结果可能为 null。\n> \n> 3） 集合里的元素即使 isNotEmpty，取出的数据元素也可能为 null。\n> \n> 4） 远程调用返回对象时，一律要求进行空指针判断，防止 NPE。\n> \n> 5） 对于 Session 中获取的数据，建议进行 NPE 检查，避免空指针。\n> \n> 6） 级联调用 obj.getA().getB().getC()；一连串调用，易产生 NPE。\n> \n> 正例：使用 JDK8 的 Optional 类来防止 NPE 问题。\n\n他建议使用 Optional 解决 NPE（java.lang.NullPointerException）问题，它就是为 NPE 而生的，其中可以包含空值或非空值。下面我们通过源码逐步揭开 Optional 的红盖头。\n\n假设有一个 Zoo 类，里面有个属性 Dog，需求要获取 Dog 的 age。\n\nclass Zoo {\n   private Dog dog;\n}\n\nclass Dog {\n   private int age;\n}\n\n\n传统解决 NPE 的办法如下：\n\nZoo zoo = getZoo();\nif(zoo != null){\n   Dog dog = zoo.getDog();\n   if(dog != null){\n      int age = dog.getAge();\n      System.out.println(age);\n   }\n}\n\n\n层层判断对象非空，有人说这种方式很丑陋不优雅，我并不这么认为。反而觉得很整洁，易读，易懂。你们觉得呢？\n\nOptional 是这样的实现的：\n\nOptional.ofNullable(zoo).map(o -> o.getDog()).map(d -> d.getAge()).ifPresent(age ->\n    System.out.println(age)\n);\n\n\n是不是简洁了很多呢？\n\n\n# 如何创建一个 Optional\n\n上例中Optional.ofNullable是其中一种创建 Optional 的方式。我们先看一下它的含义和其他创建 Optional 的源码方法。\n\n/**\n* Common instance for {@code empty()}. 全局EMPTY对象\n*/\nprivate static final Optional<?> EMPTY = new Optional<>();\n\n/**\n* Optional维护的值\n*/\nprivate final T value;\n\n/**\n* 如果value是null就返回EMPTY，否则就返回of(T)\n*/\npublic static <T> Optional<T> ofNullable(T value) {\n   return value == null ? empty() : of(value);\n}\n/**\n* 返回 EMPTY 对象\n*/\npublic static<T> Optional<T> empty() {\n   Optional<T> t = (Optional<T>) EMPTY;\n   return t;\n}\n/**\n* 返回Optional对象\n*/\npublic static <T> Optional<T> of(T value) {\n    return new Optional<>(value);\n}\n/**\n* 私有构造方法，给value赋值\n*/\nprivate Optional(T value) {\n  this.value = Objects.requireNonNull(value);\n}\n/**\n* 所以如果of(T value) 的value是null，会抛出NullPointerException异常，这样貌似就没处理NPE问题\n*/\npublic static <T> T requireNonNull(T obj) {\n  if (obj == null)\n         throw new NullPointerException();\n  return obj;\n}\n\n\nofNullable 方法和of方法唯一区别就是当 value 为 null 时，ofNullable 返回的是EMPTY，of 会抛出 NullPointerException 异常。如果需要把 NullPointerException 暴漏出来就用 of，否则就用 ofNullable。\n\nmap() 和 flatMap() 有什么区别的？\n\nmap 和 flatMap 都是将一个函数应用于集合中的每个元素，但不同的是map返回一个新的集合，flatMap是将每个元素都映射为一个集合，最后再将这个集合展平。\n\n在实际应用场景中，如果map返回的是数组，那么最后得到的是一个二维数组，使用flatMap就是为了将这个二维数组展平变成一个一维数组。\n\npublic class MapAndFlatMapExample {\n    public static void main(String[] args) {\n        List<String[]> listOfArrays = Arrays.asList(\n                new String[]{"apple", "banana", "cherry"},\n                new String[]{"orange", "grape", "pear"},\n                new String[]{"kiwi", "melon", "pineapple"}\n        );\n\n        List<String[]> mapResult = listOfArrays.stream()\n                .map(array -> Arrays.stream(array).map(String::toUpperCase).toArray(String[]::new))\n                .collect(Collectors.toList());\n\n        System.out.println("Using map:");\n        mapResult.forEach(arrays-> System.out.println(Arrays.toString(arrays)));\n\n        List<String> flatMapResult = listOfArrays.stream()\n                .flatMap(array -> Arrays.stream(array).map(String::toUpperCase))\n                .collect(Collectors.toList());\n\n        System.out.println("Using flatMap:");\n        System.out.println(flatMapResult);\n    }\n}\n\n\n\n运行结果:\n\nUsing map:\n[[APPLE, BANANA, CHERRY], [ORANGE, GRAPE, PEAR], [KIWI, MELON, PINEAPPLE]]\n\nUsing flatMap:\n[APPLE, BANANA, CHERRY, ORANGE, GRAPE, PEAR, KIWI, MELON, PINEAPPLE]\n\n\n最简单的理解就是flatMap()可以将map()的结果展开。\n\n在Optional里面，当使用map()时，如果映射函数返回的是一个普通值，它会将这个值包装在一个新的Optional中。而使用flatMap时，如果映射函数返回的是一个Optional，它会将这个返回的Optional展平，不再包装成嵌套的Optional。\n\n下面是一个对比的示例代码：\n\npublic static void main(String[] args) {\n        int userId = 1;\n\n        // 使用flatMap的代码\n        String cityUsingFlatMap = getUserById(userId)\n                .flatMap(OptionalExample::getAddressByUser)\n                .map(Address::getCity)\n                .orElse("Unknown");\n\n        System.out.println("User\'s city using flatMap: " + cityUsingFlatMap);\n\n        // 不使用flatMap的代码\n        Optional<Optional<Address>> optionalAddress = getUserById(userId)\n                .map(OptionalExample::getAddressByUser);\n\n        String cityWithoutFlatMap;\n        if (optionalAddress.isPresent()) {\n            Optional<Address> addressOptional = optionalAddress.get();\n            if (addressOptional.isPresent()) {\n                Address address = addressOptional.get();\n                cityWithoutFlatMap = address.getCity();\n            } else {\n                cityWithoutFlatMap = "Unknown";\n            }\n        } else {\n            cityWithoutFlatMap = "Unknown";\n        }\n\n        System.out.println("User\'s city without flatMap: " + cityWithoutFlatMap);\n    }\n\n\n在Stream和Optional中正确使用flatMap可以减少很多不必要的代码。\n\n\n# 判断 value 是否为 null\n\n/**\n* value是否为null\n*/\npublic boolean isPresent() {\n    return value != null;\n}\n/**\n* 如果value不为null执行consumer.accept\n*/\npublic void ifPresent(Consumer<? super T> consumer) {\n   if (value != null)\n    consumer.accept(value);\n}\n\n\n\n# 获取 value\n\n/**\n* Return the value if present, otherwise invoke {@code other} and return\n* the result of that invocation.\n* 如果value != null 返回value，否则返回other的执行结果\n*/\npublic T orElseGet(Supplier<? extends T> other) {\n    return value != null ? value : other.get();\n}\n\n/**\n* 如果value != null 返回value，否则返回T\n*/\npublic T orElse(T other) {\n    return value != null ? value : other;\n}\n\n/**\n* 如果value != null 返回value，否则抛出参数返回的异常\n*/\npublic <X extends Throwable> T orElseThrow(Supplier<? extends X> exceptionSupplier) throws X {\n        if (value != null) {\n            return value;\n        } else {\n            throw exceptionSupplier.get();\n        }\n}\n/**\n* value为null抛出NoSuchElementException，不为空返回value。\n*/\npublic T get() {\n  if (value == null) {\n      throw new NoSuchElementException("No value present");\n  }\n  return value;\n}\n\n\n\n# 过滤值\n\n/**\n* 1. 如果是empty返回empty\n* 2. predicate.test(value)==true 返回this，否则返回empty\n*/\npublic Optional<T> filter(Predicate<? super T> predicate) {\n        Objects.requireNonNull(predicate);\n        if (!isPresent())\n            return this;\n        else\n            return predicate.test(value) ? this : empty();\n}\n\n\n\n# 小结\n\n看完 Optional 源码，Optional 的方法真的非常简单，值得注意的是如果坚决不想看见 NPE，就不要用 of()、 get()、flatMap(..)。最后再综合用一下 Optional 的高频方法。\n\nOptional.ofNullable(zoo).map(o -> o.getDog()).map(d -> d.getAge()).filter(v->v==1).orElse(3);\n\n\n\n# Date-Time API\n\n这是对java.util.Date强有力的补充，解决了 Date 类的大部分痛点：\n\n 1. 非线程安全\n 2. 时区处理麻烦\n 3. 各种格式化、和时间计算繁琐\n 4. 设计有缺陷，Date 类同时包含日期和时间；还有一个 java.sql.Date，容易混淆。\n\n我们从常用的时间实例来对比 java.util.Date 和新 Date 有什么区别。用java.util.Date的代码该改改了。\n\n\n# java.time 主要类\n\njava.util.Date 既包含日期又包含时间，而 java.time 把它们进行了分离\n\nLocalDateTime.class //日期+时间 format: yyyy-MM-ddTHH:mm:ss.SSS\nLocalDate.class //日期 format: yyyy-MM-dd\nLocalTime.class //时间 format: HH:mm:ss\n\n\n\n# 格式化\n\nJava 8 之前:\n\npublic void oldFormat(){\n    Date now = new Date();\n    //format yyyy-MM-dd\n    SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd");\n    String date  = sdf.format(now);\n    System.out.println(String.format("date format : %s", date));\n\n    //format HH:mm:ss\n    SimpleDateFormat sdft = new SimpleDateFormat("HH:mm:ss");\n    String time = sdft.format(now);\n    System.out.println(String.format("time format : %s", time));\n\n    //format yyyy-MM-dd HH:mm:ss\n    SimpleDateFormat sdfdt = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");\n    String datetime = sdfdt.format(now);\n    System.out.println(String.format("dateTime format : %s", datetime));\n}\n\n\nJava 8 之后:\n\npublic void newFormat(){\n    //format yyyy-MM-dd\n    LocalDate date = LocalDate.now();\n    System.out.println(String.format("date format : %s", date));\n\n    //format HH:mm:ss\n    LocalTime time = LocalTime.now().withNano(0);\n    System.out.println(String.format("time format : %s", time));\n\n    //format yyyy-MM-dd HH:mm:ss\n    LocalDateTime dateTime = LocalDateTime.now();\n    DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");\n    String dateTimeStr = dateTime.format(dateTimeFormatter);\n    System.out.println(String.format("dateTime format : %s", dateTimeStr));\n}\n\n\n\n# 字符串转日期格式\n\nJava 8 之前:\n\n//已弃用\nDate date = new Date("2021-01-26");\n//替换为\nSimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd");\nDate date1 = sdf.parse("2021-01-26");\n\n\nJava 8 之后:\n\nLocalDate date = LocalDate.of(2021, 1, 26);\nLocalDate.parse("2021-01-26");\n\nLocalDateTime dateTime = LocalDateTime.of(2021, 1, 26, 12, 12, 22);\nLocalDateTime.parse("2021-01-26 12:12:22");\n\nLocalTime time = LocalTime.of(12, 12, 22);\nLocalTime.parse("12:12:22");\n\n\nJava 8 之前 转换都需要借助 SimpleDateFormat 类，而Java 8 之后只需要 LocalDate、LocalTime、LocalDateTime的 of 或 parse 方法。\n\n\n# 日期计算\n\n下面仅以一周后日期为例，其他单位（年、月、日、1/2 日、时等等）大同小异。另外，这些单位都在 java.time.temporal.ChronoUnit 枚举中定义。\n\nJava 8 之前:\n\npublic void afterDay(){\n     //一周后的日期\n     SimpleDateFormat formatDate = new SimpleDateFormat("yyyy-MM-dd");\n     Calendar ca = Calendar.getInstance();\n     ca.add(Calendar.DATE, 7);\n     Date d = ca.getTime();\n     String after = formatDate.format(d);\n     System.out.println("一周后日期：" + after);\n\n   //算两个日期间隔多少天，计算间隔多少年，多少月方法类似\n     String dates1 = "2021-12-23";\n   String dates2 = "2021-02-26";\n     SimpleDateFormat format = new SimpleDateFormat("yyyy-MM-dd");\n     Date date1 = format.parse(dates1);\n     Date date2 = format.parse(dates2);\n     int day = (int) ((date1.getTime() - date2.getTime()) / (1000 * 3600 * 24));\n     System.out.println(dates1 + "和" + dates2 + "相差" + day + "天");\n     //结果：2021-02-26和2021-12-23相差300天\n}\n\n\nJava 8 之后:\n\npublic void pushWeek(){\n     //一周后的日期\n     LocalDate localDate = LocalDate.now();\n     //方法1\n     LocalDate after = localDate.plus(1, ChronoUnit.WEEKS);\n     //方法2\n     LocalDate after2 = localDate.plusWeeks(1);\n     System.out.println("一周后日期：" + after);\n\n     //算两个日期间隔多少天，计算间隔多少年，多少月\n     LocalDate date1 = LocalDate.parse("2021-02-26");\n     LocalDate date2 = LocalDate.parse("2021-12-23");\n     Period period = Period.between(date1, date2);\n     System.out.println("date1 到 date2 相隔："\n                + period.getYears() + "年"\n                + period.getMonths() + "月"\n                + period.getDays() + "天");\n   //打印结果是 “date1 到 date2 相隔：0年9月27天”\n     //这里period.getDays()得到的天是抛去年月以外的天数，并不是总天数\n     //如果要获取纯粹的总天数应该用下面的方法\n     long day = date2.toEpochDay() - date1.toEpochDay();\n     System.out.println(date1 + "和" + date2 + "相差" + day + "天");\n     //打印结果：2021-02-26和2021-12-23相差300天\n}\n\n\n\n# 获取指定日期\n\n除了日期计算繁琐，获取特定一个日期也很麻烦，比如获取本月最后一天，第一天。\n\nJava 8 之前:\n\npublic void getDay() {\n\n        SimpleDateFormat format = new SimpleDateFormat("yyyy-MM-dd");\n        //获取当前月第一天：\n        Calendar c = Calendar.getInstance();\n        c.set(Calendar.DAY_OF_MONTH, 1);\n        String first = format.format(c.getTime());\n        System.out.println("first day:" + first);\n\n        //获取当前月最后一天\n        Calendar ca = Calendar.getInstance();\n        ca.set(Calendar.DAY_OF_MONTH, ca.getActualMaximum(Calendar.DAY_OF_MONTH));\n        String last = format.format(ca.getTime());\n        System.out.println("last day:" + last);\n\n        //当年最后一天\n        Calendar currCal = Calendar.getInstance();\n        Calendar calendar = Calendar.getInstance();\n        calendar.clear();\n        calendar.set(Calendar.YEAR, currCal.get(Calendar.YEAR));\n        calendar.roll(Calendar.DAY_OF_YEAR, -1);\n        Date time = calendar.getTime();\n        System.out.println("last day:" + format.format(time));\n}\n\n\nJava 8 之后:\n\npublic void getDayNew() {\n    LocalDate today = LocalDate.now();\n    //获取当前月第一天：\n    LocalDate firstDayOfThisMonth = today.with(TemporalAdjusters.firstDayOfMonth());\n    // 取本月最后一天\n    LocalDate lastDayOfThisMonth = today.with(TemporalAdjusters.lastDayOfMonth());\n    //取下一天：\n    LocalDate nextDay = lastDayOfThisMonth.plusDays(1);\n    //当年最后一天\n    LocalDate lastday = today.with(TemporalAdjusters.lastDayOfYear());\n    //2021年最后一个周日，如果用Calendar是不得烦死。\n    LocalDate lastMondayOf2021 = LocalDate.parse("2021-12-31").with(TemporalAdjusters.lastInMonth(DayOfWeek.SUNDAY));\n}\n\n\njava.time.temporal.TemporalAdjusters 里面还有很多便捷的算法，这里就不带大家看 Api 了，都很简单，看了秒懂。\n\n\n# JDBC 和 java8\n\n现在 jdbc 时间类型和 java8 时间类型对应关系是\n\n 1. Date ---\x3e LocalDate\n 2. Time ---\x3e LocalTime\n 3. Timestamp ---\x3e LocalDateTime\n\n而之前统统对应 Date，也只有 Date。\n\n\n# 时区\n\n> 时区：正式的时区划分为每隔经度 15° 划分一个时区，全球共 24 个时区，每个时区相差 1 小时。但为了行政上的方便，常将 1 个国家或 1 个省份划在一起，比如我国幅员宽广，大概横跨 5 个时区，实际上只用东八时区的标准时即北京时间为准。\n\njava.util.Date 对象实质上存的是 1970 年 1 月 1 日 0 点（ GMT）至 Date 对象所表示时刻所经过的毫秒数。也就是说不管在哪个时区 new Date，它记录的毫秒数都一样，和时区无关。但在使用上应该把它转换成当地时间，这就涉及到了时间的国际化。java.util.Date 本身并不支持国际化，需要借助 TimeZone。\n\n//北京时间：Wed Jan 27 14:05:29 CST 2021\nDate date = new Date();\n\nSimpleDateFormat bjSdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");\n//北京时区\nbjSdf.setTimeZone(TimeZone.getTimeZone("Asia/Shanghai"));\nSystem.out.println("毫秒数:" + date.getTime() + ", 北京时间:" + bjSdf.format(date));\n\n//东京时区\nSimpleDateFormat tokyoSdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");\ntokyoSdf.setTimeZone(TimeZone.getTimeZone("Asia/Tokyo"));  // 设置东京时区\nSystem.out.println("毫秒数:" + date.getTime() + ", 东京时间:" + tokyoSdf.format(date));\n\n//如果直接print会自动转成当前时区的时间\nSystem.out.println(date);\n//Wed Jan 27 14:05:29 CST 2021\n\n\n在新特性中引入了 java.time.ZonedDateTime 来表示带时区的时间。它可以看成是 LocalDateTime + ZoneId。\n\n//当前时区时间\nZonedDateTime zonedDateTime = ZonedDateTime.now();\nSystem.out.println("当前时区时间: " + zonedDateTime);\n\n//东京时间\nZoneId zoneId = ZoneId.of(ZoneId.SHORT_IDS.get("JST"));\nZonedDateTime tokyoTime = zonedDateTime.withZoneSameInstant(zoneId);\nSystem.out.println("东京时间: " + tokyoTime);\n\n// ZonedDateTime 转 LocalDateTime\nLocalDateTime localDateTime = tokyoTime.toLocalDateTime();\nSystem.out.println("东京时间转当地时间: " + localDateTime);\n\n//LocalDateTime 转 ZonedDateTime\nZonedDateTime localZoned = localDateTime.atZone(ZoneId.systemDefault());\nSystem.out.println("本地时区时间: " + localZoned);\n\n//打印结果\n当前时区时间: 2021-01-27T14:43:58.735+08:00[Asia/Shanghai]\n东京时间: 2021-01-27T15:43:58.735+09:00[Asia/Tokyo]\n东京时间转当地时间: 2021-01-27T15:43:58.735\n当地时区时间: 2021-01-27T15:53:35.618+08:00[Asia/Shanghai]\n\n\n\n# 小结\n\n通过上面比较新老 Date 的不同，当然只列出部分功能上的区别，更多功能还得自己去挖掘。总之 date-time-api 给日期操作带来了福利。在日常工作中遇到 date 类型的操作，第一考虑的是 date-time-api，实在解决不了再考虑老的 Date。\n\n\n# 总结\n\n我们梳理总结的 java 8 新特性有\n\n * Interface & functional Interface\n * Lambda\n * Stream\n * Optional\n * Date time-api\n\n这些都是开发当中比较常用的特性。梳理下来发现它们真香，而我却没有更早的应用。总觉得学习 java 8 新特性比较麻烦，一直使用老的实现方式。其实这些新特性几天就可以掌握，一但掌握，效率会有很大的提高。其实我们涨工资也是涨的学习的钱，不学习终究会被淘汰，35 岁危机会提前来临。',normalizedContent:'> 本文来自cowbi的投稿~\n\noracle 于 2014 发布了 java8（jdk1.8），诸多原因使它成为目前市场上使用最多的 jdk 版本。虽然发布距今已将近 7 年，但很多程序员对其新特性还是不够了解，尤其是用惯了 java8 之前版本的老程序员，比如我。\n\n为了不脱离队伍太远，还是有必要对这些新特性做一些总结梳理。它较 jdk.7 有很多变化或者说是优化，比如 interface 里可以有静态方法，并且可以有方法体，这一点就颠覆了之前的认知；java.util.hashmap 数据结构里增加了红黑树；还有众所周知的 lambda 表达式等等。本文不能把所有的新特性都给大家一一分享，只列出比较常用的新特性给大家做详细讲解。更多相关内容请看官网关于 java8 的新特性的介绍。\n\n\n# interface\n\ninterface 的设计初衷是面向抽象，提高扩展性。这也留有一点遗憾，interface 修改的时候，实现它的类也必须跟着改。\n\n为了解决接口的修改与现有的实现不兼容的问题。新 interface 的方法可以用default 或 static修饰，这样就可以有方法体，实现类也不必重写此方法。\n\n一个 interface 中可以有多个方法被它们修饰，这 2 个修饰符的区别主要也是普通方法和静态方法的区别。\n\n 1. default修饰的方法，是普通实例方法，可以用this调用，可以被子类继承、重写。\n 2. static修饰的方法，使用上和一般类静态方法一样。但它不能被子类继承，只能用interface调用。\n\n我们来看一个实际的例子。\n\npublic interface interfacenew {\n    static void sm() {\n        system.out.println("interface提供的方式实现");\n    }\n    static void sm2() {\n        system.out.println("interface提供的方式实现");\n    }\n\n    default void def() {\n        system.out.println("interface default方法");\n    }\n    default void def2() {\n        system.out.println("interface default2方法");\n    }\n    //须要实现类重写\n    void f();\n}\n\npublic interface interfacenew1 {\n    default void def() {\n        system.out.println("interfacenew1 default方法");\n    }\n}\n\n\n如果有一个类既实现了 interfacenew 接口又实现了 interfacenew1接口，它们都有def()，并且 interfacenew 接口和 interfacenew1接口没有继承关系的话，这时就必须重写def()。不然的话，编译的时候就会报错。\n\npublic class interfacenewimpl implements interfacenew , interfacenew1{\n    public static void main(string[] args) {\n        interfacenewimpl interfacenew = new interfacenewimpl();\n        interfacenew.def();\n    }\n\n    @override\n    public void def() {\n        interfacenew1.super.def();\n    }\n\n    @override\n    public void f() {\n    }\n}\n\n\n在 java 8 ，接口和抽象类有什么区别的？\n\n很多小伙伴认为：“既然 interface 也可以有自己的方法实现，似乎和 abstract class 没多大区别了。”\n\n其实它们还是有区别的\n\n 1. interface 和 class 的区别，好像是废话，主要有：\n    \n    * 接口多实现，类单继承\n    * 接口的方法是 public abstract 修饰，变量是 public static final 修饰。 abstract class 可以用其他修饰符\n\n 2. interface 的方法是更像是一个扩展插件。而 abstract class 的方法是要继承的。\n\n开始我们也提到，interface 新增default和static修饰的方法，为了解决接口的修改与现有的实现不兼容的问题，并不是为了要替代abstract class。在使用上，该用 abstract class 的地方还是要用 abstract class，不要因为 interface 的新特性而将之替换。\n\n记住接口永远和类不一样。\n\n\n# functional interface 函数式接口\n\n定义：也称 sam 接口，即 single abstract method interfaces，有且只有一个抽象方法，但可以有多个非抽象方法的接口。\n\n在 java 8 中专门有一个包放函数式接口java.util.function，该包下的所有接口都有 @functionalinterface 注解，提供函数式编程。\n\n在其他包中也有函数式接口，其中一些没有@functionalinterface 注解，但是只要符合函数式接口的定义就是函数式接口，与是否有\n\n@functionalinterface注解无关，注解只是在编译时起到强制规范定义的作用。其在 lambda 表达式中有广泛的应用。\n\n\n# lambda 表达式\n\n接下来谈众所周知的 lambda 表达式。它是推动 java 8 发布的最重要新特性。是继泛型(generics)和注解(annotation)以来最大的变化。\n\n使用 lambda 表达式可以使代码变的更加简洁紧凑。让 java 也能支持简单的函数式编程。\n\n> lambda 表达式是一个匿名函数，java 8 允许把函数作为参数传递进方法中。\n\n\n# 语法格式\n\n(parameters) -> expression 或\n(parameters) ->{ statements; }\n\n\n\n# lambda 实战\n\n我们用常用的实例来感受 lambda 带来的便利\n\n# 替代匿名内部类\n\n过去给方法传动态参数的唯一方法是使用内部类。比如\n\n1.runnable 接口\n\nnew thread(new runnable() {\n            @override\n            public void run() {\n                system.out.println("the runable now is using!");\n            }\n}).start();\n//用lambda\nnew thread(() -> system.out.println("it\'s a lambda function!")).start();\n\n\n2.comparator 接口\n\nlist<integer> strings = arrays.aslist(1, 2, 3);\n\ncollections.sort(strings, new comparator<integer>() {\n@override\npublic int compare(integer o1, integer o2) {\n    return o1 - o2;}\n});\n\n//lambda\ncollections.sort(strings, (integer o1, integer o2) -> o1 - o2);\n//分解开\ncomparator<integer> comparator = (integer o1, integer o2) -> o1 - o2;\ncollections.sort(strings, comparator);\n\n\n3.listener 接口\n\njbutton button = new jbutton();\nbutton.additemlistener(new itemlistener() {\n@override\npublic void itemstatechanged(itemevent e) {\n   e.getitem();\n}\n});\n//lambda\nbutton.additemlistener(e -> e.getitem());\n\n\n4.自定义接口\n\n上面的 3 个例子是我们在开发过程中最常见的，从中也能体会到 lambda 带来的便捷与清爽。它只保留实际用到的代码，把无用代码全部省略。那它对接口有没有要求呢？我们发现这些匿名内部类只重写了接口的一个方法，当然也只有一个方法须要重写。这就是我们上文提到的函数式接口，也就是说只要方法的参数是函数式接口都可以用 lambda 表达式。\n\n@functionalinterface\npublic interface comparator<t>{}\n\n@functionalinterface\npublic interface runnable{}\n\n\n我们自定义一个函数式接口\n\n@functionalinterface\npublic interface lambdainterface {\n void f();\n}\n//使用\npublic class lambdaclass {\n    public static void foreg() {\n        lambdainterfacedemo(()-> system.out.println("自定义函数式接口"));\n    }\n    //函数式接口参数\n    static void lambdainterfacedemo(lambdainterface i){\n        i.f();\n    }\n}\n\n\n# 集合迭代\n\nvoid lamndafor() {\n        list<string> strings = arrays.aslist("1", "2", "3");\n        //传统foreach\n        for (string s : strings) {\n            system.out.println(s);\n        }\n        //lambda foreach\n        strings.foreach((s) -> system.out.println(s));\n        //or\n        strings.foreach(system.out::println);\n     //map\n        map<integer, string> map = new hashmap<>();\n        map.foreach((k,v)->system.out.println(v));\n}\n\n\n# 方法的引用\n\njava 8 允许使用 :: 关键字来传递方法或者构造函数引用，无论如何，表达式返回的类型必须是 functional-interface。\n\npublic class lambdaclasssuper {\n    lambdainterface sf(){\n        return null;\n    }\n}\n\npublic class lambdaclass extends lambdaclasssuper {\n    public static lambdainterface staticf() {\n        return null;\n    }\n\n    public lambdainterface f() {\n        return null;\n    }\n\n    void show() {\n        //1.调用静态函数，返回类型必须是functional-interface\n        lambdainterface t = lambdaclass::staticf;\n\n        //2.实例方法调用\n        lambdaclass lambdaclass = new lambdaclass();\n        lambdainterface lambdainterface = lambdaclass::f;\n\n        //3.超类上的方法调用\n        lambdainterface superf = super::sf;\n\n        //4. 构造方法调用\n        lambdainterface tt = lambdaclasssuper::new;\n    }\n}\n\n\n# 访问变量\n\nint i = 0;\ncollections.sort(strings, (integer o1, integer o2) -> o1 - i);\n//i =3;\n\n\nlambda 表达式可以引用外边变量，但是该变量默认拥有 final 属性，不能被修改，如果修改，编译时就报错。\n\n\n# stream\n\njava 新增了 java.util.stream 包，它和之前的流大同小异。之前接触最多的是资源流，比如java.io.fileinputstream，通过流把文件从一个地方输入到另一个地方，它只是内容搬运工，对文件内容不做任何crud。\n\nstream依然不存储数据，不同的是它可以检索(retrieve)和逻辑处理集合数据、包括筛选、排序、统计、计数等。可以想象成是 sql 语句。\n\n它的源数据可以是 collection、array 等。由于它的方法参数都是函数式接口类型，所以一般和 lambda 配合使用。\n\n\n# 流类型\n\n 1. stream 串行流\n 2. parallelstream 并行流，可多线程执行\n\n\n# 常用方法\n\n接下来我们看java.util.stream.stream常用方法\n\n/**\n* 返回一个串行流\n*/\ndefault stream<e> stream()\n\n/**\n* 返回一个并行流\n*/\ndefault stream<e> parallelstream()\n\n/**\n* 返回t的流\n*/\npublic static<t> stream<t> of(t t)\n\n/**\n* 返回其元素是指定值的顺序流。\n*/\npublic static<t> stream<t> of(t... values) {\n    return arrays.stream(values);\n}\n\n\n/**\n* 过滤，返回由与给定predicate匹配的该流的元素组成的流\n*/\nstream<t> filter(predicate<? super t> predicate);\n\n/**\n* 此流的所有元素是否与提供的predicate匹配。\n*/\nboolean allmatch(predicate<? super t> predicate)\n\n/**\n* 此流任意元素是否有与提供的predicate匹配。\n*/\nboolean anymatch(predicate<? super t> predicate);\n\n/**\n* 返回一个 stream的构建器。\n*/\npublic static<t> builder<t> builder();\n\n/**\n* 使用 collector对此流的元素进行归纳\n*/\n<r, a> r collect(collector<? super t, a, r> collector);\n\n/**\n * 返回此流中的元素数。\n*/\nlong count();\n\n/**\n* 返回由该流的不同元素（根据 object.equals(object) ）组成的流。\n*/\nstream<t> distinct();\n\n/**\n * 遍历\n*/\nvoid foreach(consumer<? super t> action);\n\n/**\n* 用于获取指定数量的流，截短长度不能超过 maxsize 。\n*/\nstream<t> limit(long maxsize);\n\n/**\n* 用于映射每个元素到对应的结果\n*/\n<r> stream<r> map(function<? super t, ? extends r> mapper);\n\n/**\n* 根据提供的 comparator进行排序。\n*/\nstream<t> sorted(comparator<? super t> comparator);\n\n/**\n* 在丢弃流的第一个 n元素后，返回由该流的 n元素组成的流。\n*/\nstream<t> skip(long n);\n\n/**\n* 返回一个包含此流的元素的数组。\n*/\nobject[] toarray();\n\n/**\n* 使用提供的 generator函数返回一个包含此流的元素的数组，以分配返回的数组，以及分区执行或调整大小可能需要的任何其他数组。\n*/\n<a> a[] toarray(intfunction<a[]> generator);\n\n/**\n* 合并流\n*/\npublic static <t> stream<t> concat(stream<? extends t> a, stream<? extends t> b)\n\n\n\n# 实战\n\n本文列出 stream 具有代表性的方法之使用，更多的使用方法还是要看 api。\n\n@test\npublic void test() {\n  list<string> strings = arrays.aslist("abc", "def", "gkh", "abc");\n    //返回符合条件的stream\n    stream<string> stringstream = strings.stream().filter(s -> "abc".equals(s));\n    //计算流符合条件的流的数量\n    long count = stringstream.count();\n\n    //foreach遍历->打印元素\n    strings.stream().foreach(system.out::println);\n\n    //limit 获取到1个元素的stream\n    stream<string> limit = strings.stream().limit(1);\n    //toarray 比如我们想看这个limitstream里面是什么，比如转换成string[],比如循环\n    string[] array = limit.toarray(string[]::new);\n\n    //map 对每个元素进行操作返回新流\n    stream<string> map = strings.stream().map(s -> s + "22");\n\n    //sorted 排序并打印\n    strings.stream().sorted().foreach(system.out::println);\n\n    //collectors collect 把abc放入容器中\n    list<string> collect = strings.stream().filter(string -> "abc".equals(string)).collect(collectors.tolist());\n    //把list转为string，各元素用，号隔开\n    string mergedstring = strings.stream().filter(string -> !string.isempty()).collect(collectors.joining(","));\n\n    //对数组的统计，比如用\n    list<integer> number = arrays.aslist(1, 2, 5, 4);\n\n    intsummarystatistics statistics = number.stream().maptoint((x) -> x).summarystatistics();\n    system.out.println("列表中最大的数 : "+statistics.getmax());\n    system.out.println("列表中最小的数 : "+statistics.getmin());\n    system.out.println("平均数 : "+statistics.getaverage());\n    system.out.println("所有数之和 : "+statistics.getsum());\n\n    //concat 合并流\n    list<string> strings2 = arrays.aslist("xyz", "jqx");\n    stream.concat(strings2.stream(),strings.stream()).count();\n\n    //注意 一个stream只能操作一次，不能断开，否则会报错。\n    stream stream = strings.stream();\n    //第一次使用\n    stream.limit(2);\n    //第二次使用\n    stream.foreach(system.out::println);\n    //报错 java.lang.illegalstateexception: stream has already been operated upon or closed\n\n    //但是可以这样, 连续使用\n    stream.limit(2).foreach(system.out::println);\n}\n\n\n\n# 延迟执行\n\n在执行返回 stream 的方法时，并不立刻执行，而是等返回一个非 stream 的方法后才执行。因为拿到 stream 并不能直接用，而是需要处理成一个常规类型。这里的 stream 可以想象成是二进制流（2 个完全不一样的东东），拿到也看不懂。\n\n我们下面分解一下 filter 方法。\n\n@test\npublic void laziness(){\n  list<string> strings = arrays.aslist("abc", "def", "gkh", "abc");\n  stream<integer> stream = strings.stream().filter(new predicate() {\n      @override\n      public boolean test(object o) {\n        system.out.println("predicate.test 执行");\n        return true;\n        }\n      });\n\n   system.out.println("count 执行");\n   stream.count();\n}\n/*-------执行结果--------*/\ncount 执行\npredicate.test 执行\npredicate.test 执行\npredicate.test 执行\npredicate.test 执行\n\n\n按执行顺序应该是先打印 4 次「predicate.test 执行」，再打印「count 执行」。实际结果恰恰相反。说明 filter 中的方法并没有立刻执行，而是等调用count()方法后才执行。\n\n上面都是串行 stream 的实例。并行 parallelstream 在使用方法上和串行一样。主要区别是 parallelstream 可多线程执行，是基于 forkjoin 框架实现的，有时间大家可以了解一下 forkjoin 框架和 forkjoinpool。这里可以简单的理解它是通过线程池来实现的，这样就会涉及到线程安全，线程消耗等问题。下面我们通过代码来体验一下并行流的多线程执行。\n\n@test\npublic void parallelstreamtest(){\n   list<integer> numbers = arrays.aslist(1, 2, 5, 4);\n   numbers.parallelstream() .foreach(num->system.out.println(thread.currentthread().getname()+">>"+num));\n}\n//执行结果\nmain>>5\nforkjoinpool.commonpool-worker-2>>4\nforkjoinpool.commonpool-worker-11>>1\nforkjoinpool.commonpool-worker-9>>2\n\n\n从结果中我们看到，for-each 用到的是多线程。\n\n\n# 小结\n\n从源码和实例中我们可以总结出一些 stream 的特点\n\n 1. 通过简单的链式编程，使得它可以方便地对遍历处理后的数据进行再处理。\n 2. 方法参数都是函数式接口类型\n 3. 一个 stream 只能操作一次，操作完就关闭了，继续使用这个 stream 会报错。\n 4. stream 不保存数据，不改变数据源\n\n\n# optional\n\n在阿里巴巴开发手册关于 optional 的介绍中这样写到：\n\n> 防止 npe，是程序员的基本修养，注意 npe 产生的场景：\n> \n> 1） 返回类型为基本数据类型，return 包装数据类型的对象时，自动拆箱有可能产生 npe。\n> \n> 反例：public int f() { return integer 对象}， 如果为 null，自动解箱抛 npe。\n> \n> 2） 数据库的查询结果可能为 null。\n> \n> 3） 集合里的元素即使 isnotempty，取出的数据元素也可能为 null。\n> \n> 4） 远程调用返回对象时，一律要求进行空指针判断，防止 npe。\n> \n> 5） 对于 session 中获取的数据，建议进行 npe 检查，避免空指针。\n> \n> 6） 级联调用 obj.geta().getb().getc()；一连串调用，易产生 npe。\n> \n> 正例：使用 jdk8 的 optional 类来防止 npe 问题。\n\n他建议使用 optional 解决 npe（java.lang.nullpointerexception）问题，它就是为 npe 而生的，其中可以包含空值或非空值。下面我们通过源码逐步揭开 optional 的红盖头。\n\n假设有一个 zoo 类，里面有个属性 dog，需求要获取 dog 的 age。\n\nclass zoo {\n   private dog dog;\n}\n\nclass dog {\n   private int age;\n}\n\n\n传统解决 npe 的办法如下：\n\nzoo zoo = getzoo();\nif(zoo != null){\n   dog dog = zoo.getdog();\n   if(dog != null){\n      int age = dog.getage();\n      system.out.println(age);\n   }\n}\n\n\n层层判断对象非空，有人说这种方式很丑陋不优雅，我并不这么认为。反而觉得很整洁，易读，易懂。你们觉得呢？\n\noptional 是这样的实现的：\n\noptional.ofnullable(zoo).map(o -> o.getdog()).map(d -> d.getage()).ifpresent(age ->\n    system.out.println(age)\n);\n\n\n是不是简洁了很多呢？\n\n\n# 如何创建一个 optional\n\n上例中optional.ofnullable是其中一种创建 optional 的方式。我们先看一下它的含义和其他创建 optional 的源码方法。\n\n/**\n* common instance for {@code empty()}. 全局empty对象\n*/\nprivate static final optional<?> empty = new optional<>();\n\n/**\n* optional维护的值\n*/\nprivate final t value;\n\n/**\n* 如果value是null就返回empty，否则就返回of(t)\n*/\npublic static <t> optional<t> ofnullable(t value) {\n   return value == null ? empty() : of(value);\n}\n/**\n* 返回 empty 对象\n*/\npublic static<t> optional<t> empty() {\n   optional<t> t = (optional<t>) empty;\n   return t;\n}\n/**\n* 返回optional对象\n*/\npublic static <t> optional<t> of(t value) {\n    return new optional<>(value);\n}\n/**\n* 私有构造方法，给value赋值\n*/\nprivate optional(t value) {\n  this.value = objects.requirenonnull(value);\n}\n/**\n* 所以如果of(t value) 的value是null，会抛出nullpointerexception异常，这样貌似就没处理npe问题\n*/\npublic static <t> t requirenonnull(t obj) {\n  if (obj == null)\n         throw new nullpointerexception();\n  return obj;\n}\n\n\nofnullable 方法和of方法唯一区别就是当 value 为 null 时，ofnullable 返回的是empty，of 会抛出 nullpointerexception 异常。如果需要把 nullpointerexception 暴漏出来就用 of，否则就用 ofnullable。\n\nmap() 和 flatmap() 有什么区别的？\n\nmap 和 flatmap 都是将一个函数应用于集合中的每个元素，但不同的是map返回一个新的集合，flatmap是将每个元素都映射为一个集合，最后再将这个集合展平。\n\n在实际应用场景中，如果map返回的是数组，那么最后得到的是一个二维数组，使用flatmap就是为了将这个二维数组展平变成一个一维数组。\n\npublic class mapandflatmapexample {\n    public static void main(string[] args) {\n        list<string[]> listofarrays = arrays.aslist(\n                new string[]{"apple", "banana", "cherry"},\n                new string[]{"orange", "grape", "pear"},\n                new string[]{"kiwi", "melon", "pineapple"}\n        );\n\n        list<string[]> mapresult = listofarrays.stream()\n                .map(array -> arrays.stream(array).map(string::touppercase).toarray(string[]::new))\n                .collect(collectors.tolist());\n\n        system.out.println("using map:");\n        mapresult.foreach(arrays-> system.out.println(arrays.tostring(arrays)));\n\n        list<string> flatmapresult = listofarrays.stream()\n                .flatmap(array -> arrays.stream(array).map(string::touppercase))\n                .collect(collectors.tolist());\n\n        system.out.println("using flatmap:");\n        system.out.println(flatmapresult);\n    }\n}\n\n\n\n运行结果:\n\nusing map:\n[[apple, banana, cherry], [orange, grape, pear], [kiwi, melon, pineapple]]\n\nusing flatmap:\n[apple, banana, cherry, orange, grape, pear, kiwi, melon, pineapple]\n\n\n最简单的理解就是flatmap()可以将map()的结果展开。\n\n在optional里面，当使用map()时，如果映射函数返回的是一个普通值，它会将这个值包装在一个新的optional中。而使用flatmap时，如果映射函数返回的是一个optional，它会将这个返回的optional展平，不再包装成嵌套的optional。\n\n下面是一个对比的示例代码：\n\npublic static void main(string[] args) {\n        int userid = 1;\n\n        // 使用flatmap的代码\n        string cityusingflatmap = getuserbyid(userid)\n                .flatmap(optionalexample::getaddressbyuser)\n                .map(address::getcity)\n                .orelse("unknown");\n\n        system.out.println("user\'s city using flatmap: " + cityusingflatmap);\n\n        // 不使用flatmap的代码\n        optional<optional<address>> optionaladdress = getuserbyid(userid)\n                .map(optionalexample::getaddressbyuser);\n\n        string citywithoutflatmap;\n        if (optionaladdress.ispresent()) {\n            optional<address> addressoptional = optionaladdress.get();\n            if (addressoptional.ispresent()) {\n                address address = addressoptional.get();\n                citywithoutflatmap = address.getcity();\n            } else {\n                citywithoutflatmap = "unknown";\n            }\n        } else {\n            citywithoutflatmap = "unknown";\n        }\n\n        system.out.println("user\'s city without flatmap: " + citywithoutflatmap);\n    }\n\n\n在stream和optional中正确使用flatmap可以减少很多不必要的代码。\n\n\n# 判断 value 是否为 null\n\n/**\n* value是否为null\n*/\npublic boolean ispresent() {\n    return value != null;\n}\n/**\n* 如果value不为null执行consumer.accept\n*/\npublic void ifpresent(consumer<? super t> consumer) {\n   if (value != null)\n    consumer.accept(value);\n}\n\n\n\n# 获取 value\n\n/**\n* return the value if present, otherwise invoke {@code other} and return\n* the result of that invocation.\n* 如果value != null 返回value，否则返回other的执行结果\n*/\npublic t orelseget(supplier<? extends t> other) {\n    return value != null ? value : other.get();\n}\n\n/**\n* 如果value != null 返回value，否则返回t\n*/\npublic t orelse(t other) {\n    return value != null ? value : other;\n}\n\n/**\n* 如果value != null 返回value，否则抛出参数返回的异常\n*/\npublic <x extends throwable> t orelsethrow(supplier<? extends x> exceptionsupplier) throws x {\n        if (value != null) {\n            return value;\n        } else {\n            throw exceptionsupplier.get();\n        }\n}\n/**\n* value为null抛出nosuchelementexception，不为空返回value。\n*/\npublic t get() {\n  if (value == null) {\n      throw new nosuchelementexception("no value present");\n  }\n  return value;\n}\n\n\n\n# 过滤值\n\n/**\n* 1. 如果是empty返回empty\n* 2. predicate.test(value)==true 返回this，否则返回empty\n*/\npublic optional<t> filter(predicate<? super t> predicate) {\n        objects.requirenonnull(predicate);\n        if (!ispresent())\n            return this;\n        else\n            return predicate.test(value) ? this : empty();\n}\n\n\n\n# 小结\n\n看完 optional 源码，optional 的方法真的非常简单，值得注意的是如果坚决不想看见 npe，就不要用 of()、 get()、flatmap(..)。最后再综合用一下 optional 的高频方法。\n\noptional.ofnullable(zoo).map(o -> o.getdog()).map(d -> d.getage()).filter(v->v==1).orelse(3);\n\n\n\n# date-time api\n\n这是对java.util.date强有力的补充，解决了 date 类的大部分痛点：\n\n 1. 非线程安全\n 2. 时区处理麻烦\n 3. 各种格式化、和时间计算繁琐\n 4. 设计有缺陷，date 类同时包含日期和时间；还有一个 java.sql.date，容易混淆。\n\n我们从常用的时间实例来对比 java.util.date 和新 date 有什么区别。用java.util.date的代码该改改了。\n\n\n# java.time 主要类\n\njava.util.date 既包含日期又包含时间，而 java.time 把它们进行了分离\n\nlocaldatetime.class //日期+时间 format: yyyy-mm-ddthh:mm:ss.sss\nlocaldate.class //日期 format: yyyy-mm-dd\nlocaltime.class //时间 format: hh:mm:ss\n\n\n\n# 格式化\n\njava 8 之前:\n\npublic void oldformat(){\n    date now = new date();\n    //format yyyy-mm-dd\n    simpledateformat sdf = new simpledateformat("yyyy-mm-dd");\n    string date  = sdf.format(now);\n    system.out.println(string.format("date format : %s", date));\n\n    //format hh:mm:ss\n    simpledateformat sdft = new simpledateformat("hh:mm:ss");\n    string time = sdft.format(now);\n    system.out.println(string.format("time format : %s", time));\n\n    //format yyyy-mm-dd hh:mm:ss\n    simpledateformat sdfdt = new simpledateformat("yyyy-mm-dd hh:mm:ss");\n    string datetime = sdfdt.format(now);\n    system.out.println(string.format("datetime format : %s", datetime));\n}\n\n\njava 8 之后:\n\npublic void newformat(){\n    //format yyyy-mm-dd\n    localdate date = localdate.now();\n    system.out.println(string.format("date format : %s", date));\n\n    //format hh:mm:ss\n    localtime time = localtime.now().withnano(0);\n    system.out.println(string.format("time format : %s", time));\n\n    //format yyyy-mm-dd hh:mm:ss\n    localdatetime datetime = localdatetime.now();\n    datetimeformatter datetimeformatter = datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss");\n    string datetimestr = datetime.format(datetimeformatter);\n    system.out.println(string.format("datetime format : %s", datetimestr));\n}\n\n\n\n# 字符串转日期格式\n\njava 8 之前:\n\n//已弃用\ndate date = new date("2021-01-26");\n//替换为\nsimpledateformat sdf = new simpledateformat("yyyy-mm-dd");\ndate date1 = sdf.parse("2021-01-26");\n\n\njava 8 之后:\n\nlocaldate date = localdate.of(2021, 1, 26);\nlocaldate.parse("2021-01-26");\n\nlocaldatetime datetime = localdatetime.of(2021, 1, 26, 12, 12, 22);\nlocaldatetime.parse("2021-01-26 12:12:22");\n\nlocaltime time = localtime.of(12, 12, 22);\nlocaltime.parse("12:12:22");\n\n\njava 8 之前 转换都需要借助 simpledateformat 类，而java 8 之后只需要 localdate、localtime、localdatetime的 of 或 parse 方法。\n\n\n# 日期计算\n\n下面仅以一周后日期为例，其他单位（年、月、日、1/2 日、时等等）大同小异。另外，这些单位都在 java.time.temporal.chronounit 枚举中定义。\n\njava 8 之前:\n\npublic void afterday(){\n     //一周后的日期\n     simpledateformat formatdate = new simpledateformat("yyyy-mm-dd");\n     calendar ca = calendar.getinstance();\n     ca.add(calendar.date, 7);\n     date d = ca.gettime();\n     string after = formatdate.format(d);\n     system.out.println("一周后日期：" + after);\n\n   //算两个日期间隔多少天，计算间隔多少年，多少月方法类似\n     string dates1 = "2021-12-23";\n   string dates2 = "2021-02-26";\n     simpledateformat format = new simpledateformat("yyyy-mm-dd");\n     date date1 = format.parse(dates1);\n     date date2 = format.parse(dates2);\n     int day = (int) ((date1.gettime() - date2.gettime()) / (1000 * 3600 * 24));\n     system.out.println(dates1 + "和" + dates2 + "相差" + day + "天");\n     //结果：2021-02-26和2021-12-23相差300天\n}\n\n\njava 8 之后:\n\npublic void pushweek(){\n     //一周后的日期\n     localdate localdate = localdate.now();\n     //方法1\n     localdate after = localdate.plus(1, chronounit.weeks);\n     //方法2\n     localdate after2 = localdate.plusweeks(1);\n     system.out.println("一周后日期：" + after);\n\n     //算两个日期间隔多少天，计算间隔多少年，多少月\n     localdate date1 = localdate.parse("2021-02-26");\n     localdate date2 = localdate.parse("2021-12-23");\n     period period = period.between(date1, date2);\n     system.out.println("date1 到 date2 相隔："\n                + period.getyears() + "年"\n                + period.getmonths() + "月"\n                + period.getdays() + "天");\n   //打印结果是 “date1 到 date2 相隔：0年9月27天”\n     //这里period.getdays()得到的天是抛去年月以外的天数，并不是总天数\n     //如果要获取纯粹的总天数应该用下面的方法\n     long day = date2.toepochday() - date1.toepochday();\n     system.out.println(date1 + "和" + date2 + "相差" + day + "天");\n     //打印结果：2021-02-26和2021-12-23相差300天\n}\n\n\n\n# 获取指定日期\n\n除了日期计算繁琐，获取特定一个日期也很麻烦，比如获取本月最后一天，第一天。\n\njava 8 之前:\n\npublic void getday() {\n\n        simpledateformat format = new simpledateformat("yyyy-mm-dd");\n        //获取当前月第一天：\n        calendar c = calendar.getinstance();\n        c.set(calendar.day_of_month, 1);\n        string first = format.format(c.gettime());\n        system.out.println("first day:" + first);\n\n        //获取当前月最后一天\n        calendar ca = calendar.getinstance();\n        ca.set(calendar.day_of_month, ca.getactualmaximum(calendar.day_of_month));\n        string last = format.format(ca.gettime());\n        system.out.println("last day:" + last);\n\n        //当年最后一天\n        calendar currcal = calendar.getinstance();\n        calendar calendar = calendar.getinstance();\n        calendar.clear();\n        calendar.set(calendar.year, currcal.get(calendar.year));\n        calendar.roll(calendar.day_of_year, -1);\n        date time = calendar.gettime();\n        system.out.println("last day:" + format.format(time));\n}\n\n\njava 8 之后:\n\npublic void getdaynew() {\n    localdate today = localdate.now();\n    //获取当前月第一天：\n    localdate firstdayofthismonth = today.with(temporaladjusters.firstdayofmonth());\n    // 取本月最后一天\n    localdate lastdayofthismonth = today.with(temporaladjusters.lastdayofmonth());\n    //取下一天：\n    localdate nextday = lastdayofthismonth.plusdays(1);\n    //当年最后一天\n    localdate lastday = today.with(temporaladjusters.lastdayofyear());\n    //2021年最后一个周日，如果用calendar是不得烦死。\n    localdate lastmondayof2021 = localdate.parse("2021-12-31").with(temporaladjusters.lastinmonth(dayofweek.sunday));\n}\n\n\njava.time.temporal.temporaladjusters 里面还有很多便捷的算法，这里就不带大家看 api 了，都很简单，看了秒懂。\n\n\n# jdbc 和 java8\n\n现在 jdbc 时间类型和 java8 时间类型对应关系是\n\n 1. date ---\x3e localdate\n 2. time ---\x3e localtime\n 3. timestamp ---\x3e localdatetime\n\n而之前统统对应 date，也只有 date。\n\n\n# 时区\n\n> 时区：正式的时区划分为每隔经度 15° 划分一个时区，全球共 24 个时区，每个时区相差 1 小时。但为了行政上的方便，常将 1 个国家或 1 个省份划在一起，比如我国幅员宽广，大概横跨 5 个时区，实际上只用东八时区的标准时即北京时间为准。\n\njava.util.date 对象实质上存的是 1970 年 1 月 1 日 0 点（ gmt）至 date 对象所表示时刻所经过的毫秒数。也就是说不管在哪个时区 new date，它记录的毫秒数都一样，和时区无关。但在使用上应该把它转换成当地时间，这就涉及到了时间的国际化。java.util.date 本身并不支持国际化，需要借助 timezone。\n\n//北京时间：wed jan 27 14:05:29 cst 2021\ndate date = new date();\n\nsimpledateformat bjsdf = new simpledateformat("yyyy-mm-dd hh:mm:ss");\n//北京时区\nbjsdf.settimezone(timezone.gettimezone("asia/shanghai"));\nsystem.out.println("毫秒数:" + date.gettime() + ", 北京时间:" + bjsdf.format(date));\n\n//东京时区\nsimpledateformat tokyosdf = new simpledateformat("yyyy-mm-dd hh:mm:ss");\ntokyosdf.settimezone(timezone.gettimezone("asia/tokyo"));  // 设置东京时区\nsystem.out.println("毫秒数:" + date.gettime() + ", 东京时间:" + tokyosdf.format(date));\n\n//如果直接print会自动转成当前时区的时间\nsystem.out.println(date);\n//wed jan 27 14:05:29 cst 2021\n\n\n在新特性中引入了 java.time.zoneddatetime 来表示带时区的时间。它可以看成是 localdatetime + zoneid。\n\n//当前时区时间\nzoneddatetime zoneddatetime = zoneddatetime.now();\nsystem.out.println("当前时区时间: " + zoneddatetime);\n\n//东京时间\nzoneid zoneid = zoneid.of(zoneid.short_ids.get("jst"));\nzoneddatetime tokyotime = zoneddatetime.withzonesameinstant(zoneid);\nsystem.out.println("东京时间: " + tokyotime);\n\n// zoneddatetime 转 localdatetime\nlocaldatetime localdatetime = tokyotime.tolocaldatetime();\nsystem.out.println("东京时间转当地时间: " + localdatetime);\n\n//localdatetime 转 zoneddatetime\nzoneddatetime localzoned = localdatetime.atzone(zoneid.systemdefault());\nsystem.out.println("本地时区时间: " + localzoned);\n\n//打印结果\n当前时区时间: 2021-01-27t14:43:58.735+08:00[asia/shanghai]\n东京时间: 2021-01-27t15:43:58.735+09:00[asia/tokyo]\n东京时间转当地时间: 2021-01-27t15:43:58.735\n当地时区时间: 2021-01-27t15:53:35.618+08:00[asia/shanghai]\n\n\n\n# 小结\n\n通过上面比较新老 date 的不同，当然只列出部分功能上的区别，更多功能还得自己去挖掘。总之 date-time-api 给日期操作带来了福利。在日常工作中遇到 date 类型的操作，第一考虑的是 date-time-api，实在解决不了再考虑老的 date。\n\n\n# 总结\n\n我们梳理总结的 java 8 新特性有\n\n * interface & functional interface\n * lambda\n * stream\n * optional\n * date time-api\n\n这些都是开发当中比较常用的特性。梳理下来发现它们真香，而我却没有更早的应用。总觉得学习 java 8 新特性比较麻烦，一直使用老的实现方式。其实这些新特性几天就可以掌握，一但掌握，效率会有很大的提高。其实我们涨工资也是涨的学习的钱，不学习终究会被淘汰，35 岁危机会提前来临。',charsets:{cjk:!0}},{title:"java8-tutorial-translate",frontmatter:{title:"java8-tutorial-translate",date:"2024-08-21T23:05:51.000Z",permalink:"/pages/b610cd/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/02.java8-tutorial-translate.html",relativePath:"01.Java基础/05.版本新特性/02.java8-tutorial-translate.md",key:"v-5a234d0e",path:"/pages/b610cd/",headers:[{level:2,title:"接口的默认方法(Default Methods for Interfaces)",slug:"接口的默认方法-default-methods-for-interfaces",normalizedTitle:"接口的默认方法(default methods for interfaces)",charIndex:441},{level:2,title:"Lambda 表达式(Lambda expressions)",slug:"lambda-表达式-lambda-expressions",normalizedTitle:"lambda 表达式(lambda expressions)",charIndex:1393},{level:2,title:"函数式接口(Functional Interfaces)",slug:"函数式接口-functional-interfaces",normalizedTitle:"函数式接口(functional interfaces)",charIndex:363},{level:2,title:"方法和构造函数引用(Method and Constructor References)",slug:"方法和构造函数引用-method-and-constructor-references",normalizedTitle:"方法和构造函数引用(method and constructor references)",charIndex:3019},{level:2,title:"Lambda 表达式作用域(Lambda Scopes)",slug:"lambda-表达式作用域-lambda-scopes",normalizedTitle:"lambda 表达式作用域(lambda scopes)",charIndex:4260},{level:3,title:"访问局部变量",slug:"访问局部变量",normalizedTitle:"访问局部变量",charIndex:4293},{level:3,title:"访问字段和静态变量",slug:"访问字段和静态变量",normalizedTitle:"访问字段和静态变量",charIndex:4872},{level:3,title:"访问默认接口方法",slug:"访问默认接口方法",normalizedTitle:"访问默认接口方法",charIndex:5341},{level:2,title:"内置函数式接口(Built-in Functional Interfaces)",slug:"内置函数式接口-built-in-functional-interfaces",normalizedTitle:"内置函数式接口(built-in functional interfaces)",charIndex:5525},{level:3,title:"Predicate",slug:"predicate",normalizedTitle:"predicate",charIndex:5802},{level:3,title:"Function",slug:"function",normalizedTitle:"function",charIndex:369},{level:3,title:"Supplier",slug:"supplier",normalizedTitle:"supplier",charIndex:8104},{level:3,title:"Consumer",slug:"consumer",normalizedTitle:"consumer",charIndex:8263},{level:3,title:"Comparator",slug:"comparator",normalizedTitle:"comparator",charIndex:1552},{level:2,title:"Optional",slug:"optional",normalizedTitle:"optional",charIndex:8766},{level:2,title:"Streams(流)",slug:"streams-流",normalizedTitle:"streams(流)",charIndex:9477},{level:3,title:"Filter(过滤)",slug:"filter-过滤",normalizedTitle:"filter(过滤)",charIndex:10085},{level:3,title:"Sorted(排序)",slug:"sorted-排序",normalizedTitle:"sorted(排序)",charIndex:10506},{level:3,title:"Map(映射)",slug:"map-映射",normalizedTitle:"map(映射)",charIndex:10945},{level:3,title:"Match(匹配)",slug:"match-匹配",normalizedTitle:"match(匹配)",charIndex:11361},{level:3,title:"Count(计数)",slug:"count-计数",normalizedTitle:"count(计数)",charIndex:12134},{level:3,title:"Reduce(规约)",slug:"reduce-规约",normalizedTitle:"reduce(规约)",charIndex:12445},{level:2,title:"Parallel Streams(并行流)",slug:"parallel-streams-并行流",normalizedTitle:"parallel streams(并行流)",charIndex:13838},{level:3,title:"Sequential Sort(串行排序)",slug:"sequential-sort-串行排序",normalizedTitle:"sequential sort(串行排序)",charIndex:14191},{level:3,title:"Parallel Sort(并行排序)",slug:"parallel-sort-并行排序",normalizedTitle:"parallel sort(并行排序)",charIndex:14538},{level:2,title:"Maps",slug:"maps",normalizedTitle:"maps",charIndex:14960},{level:2,title:"Date API(日期相关 API)",slug:"date-api-日期相关-api",normalizedTitle:"date api(日期相关 api)",charIndex:16285},{level:3,title:"Clock",slug:"clock",normalizedTitle:"clock",charIndex:16436},{level:3,title:"Timezones(时区)",slug:"timezones-时区",normalizedTitle:"timezones(时区)",charIndex:17361},{level:3,title:"LocalTime(本地时间)",slug:"localtime-本地时间",normalizedTitle:"localtime(本地时间)",charIndex:17814},{level:3,title:"LocalDate(本地日期)",slug:"localdate-本地日期",normalizedTitle:"localdate(本地日期)",charIndex:18656},{level:3,title:"LocalDateTime(本地日期时间)",slug:"localdatetime-本地日期时间",normalizedTitle:"localdatetime(本地日期时间)",charIndex:20959},{level:2,title:"Annotations(注解)",slug:"annotations-注解",normalizedTitle:"annotations(注解)",charIndex:22183},{level:2,title:"Where to go from here?",slug:"where-to-go-from-here",normalizedTitle:"where to go from here?",charIndex:23252}],headersStr:"接口的默认方法(Default Methods for Interfaces) Lambda 表达式(Lambda expressions) 函数式接口(Functional Interfaces) 方法和构造函数引用(Method and Constructor References) Lambda 表达式作用域(Lambda Scopes) 访问局部变量 访问字段和静态变量 访问默认接口方法 内置函数式接口(Built-in Functional Interfaces) Predicate Function Supplier Consumer Comparator Optional Streams(流) Filter(过滤) Sorted(排序) Map(映射) Match(匹配) Count(计数) Reduce(规约) Parallel Streams(并行流) Sequential Sort(串行排序) Parallel Sort(并行排序) Maps Date API(日期相关 API) Clock Timezones(时区) LocalTime(本地时间) LocalDate(本地日期) LocalDateTime(本地日期时间) Annotations(注解) Where to go from here?",content:'# 《Java8 指南》中文翻译\n\n随着 Java 8 的普及度越来越高，很多人都提到面试中关于 Java 8 也是非常常问的知识点。应各位要求和需要，我打算对这部分知识做一个总结。本来准备自己总结的，后面看到 GitHub 上有一个相关的仓库，地址： https://github.com/winterbe/java8-tutorial。这个仓库是英文的，我对其进行了翻译并添加和修改了部分内容，下面是正文。\n\n----------------------------------------\n\n欢迎阅读我对 Java 8 的介绍。本教程将逐步指导您完成所有新语言功能。 在简短的代码示例的基础上，您将学习如何使用默认接口方法，lambda 表达式，方法引用和可重复注释。 在本文的最后，您将熟悉最新的 API 更改，如流，函数式接口(Functional Interfaces)，Map 类的扩展和新的 Date API。 没有大段枯燥的文字，只有一堆注释的代码片段。\n\n\n# 接口的默认方法(Default Methods for Interfaces)\n\nJava 8 使我们能够通过使用 default 关键字向接口添加非抽象方法实现。 此功能也称为虚拟扩展方法。\n\n第一个例子：\n\ninterface Formula{\n\n    double calculate(int a);\n\n    default double sqrt(int a) {\n        return Math.sqrt(a);\n    }\n\n}\n\n\nFormula 接口中除了抽象方法计算接口公式还定义了默认方法 sqrt。 实现该接口的类只需要实现抽象方法 calculate。 默认方法sqrt 可以直接使用。当然你也可以直接通过接口创建对象，然后实现接口中的默认方法就可以了，我们通过代码演示一下这种方式。\n\npublic class Main {\n\n  public static void main(String[] args) {\n    // 通过匿名内部类方式访问接口\n    Formula formula = new Formula() {\n        @Override\n        public double calculate(int a) {\n            return sqrt(a * 100);\n        }\n    };\n\n    System.out.println(formula.calculate(100));     // 100.0\n    System.out.println(formula.sqrt(16));           // 4.0\n\n  }\n\n}\n\n\nformula 是作为匿名对象实现的。该代码非常容易理解，6 行代码实现了计算 sqrt(a * 100)。在下一节中，我们将会看到在 Java 8 中实现单个方法对象有一种更好更方便的方法。\n\n译者注： 不管是抽象类还是接口，都可以通过匿名内部类的方式访问。不能通过抽象类或者接口直接创建对象。对于上面通过匿名内部类方式访问接口，我们可以这样理解：一个内部类实现了接口里的抽象方法并且返回一个内部类对象，之后我们让接口的引用来指向这个对象。\n\n\n# Lambda 表达式(Lambda expressions)\n\n首先看看在老版本的 Java 中是如何排列字符串的：\n\nList<String> names = Arrays.asList("peter", "anna", "mike", "xenia");\n\nCollections.sort(names, new Comparator<String>() {\n    @Override\n    public int compare(String a, String b) {\n        return b.compareTo(a);\n    }\n});\n\n\n只需要给静态方法Collections.sort 传入一个 List 对象以及一个比较器来按指定顺序排列。通常做法都是创建一个匿名的比较器对象然后将其传递给 sort 方法。\n\n在 Java 8 中你就没必要使用这种传统的匿名对象的方式了，Java 8 提供了更简洁的语法，lambda 表达式：\n\nCollections.sort(names, (String a, String b) -> {\n    return b.compareTo(a);\n});\n\n\n可以看出，代码变得更短且更具有可读性，但是实际上还可以写得更短：\n\nCollections.sort(names, (String a, String b) -> b.compareTo(a));\n\n\n对于函数体只有一行代码的，你可以去掉大括号{}以及 return 关键字，但是你还可以写得更短点：\n\nnames.sort((a, b) -> b.compareTo(a));\n\n\nList 类本身就有一个 sort 方法。并且 Java 编译器可以自动推导出参数类型，所以你可以不用再写一次类型。接下来我们看看 lambda 表达式还有什么其他用法。\n\n\n# 函数式接口(Functional Interfaces)\n\n译者注： 原文对这部分解释不太清楚，故做了修改！\n\nJava 语言设计者们投入了大量精力来思考如何使现有的函数友好地支持 Lambda。最终采取的方法是：增加函数式接口的概念。“函数式接口”是指仅仅只包含一个抽象方法,但是可以有多个非抽象方法(也就是上面提到的默认方法)的接口。 像这样的接口，可以被隐式转换为 lambda 表达式。java.lang.Runnable 与 java.util.concurrent.Callable 是函数式接口最典型的两个例子。Java 8 增加了一种特殊的注解@FunctionalInterface,但是这个注解通常不是必须的(某些情况建议使用)，只要接口只包含一个抽象方法，虚拟机会自动判断该接口为函数式接口。一般建议在接口上使用@FunctionalInterface 注解进行声明，这样的话，编译器如果发现你标注了这个注解的接口有多于一个抽象方法的时候会报错的，如下图所示\n\n\n\n示例：\n\n@FunctionalInterface\npublic interface Converter<F, T> {\n  T convert(F from);\n}\n\n\n    // TODO 将数字字符串转换为整数类型\n    Converter<String, Integer> converter = (from) -> Integer.valueOf(from);\n    Integer converted = converter.convert("123");\n    System.out.println(converted.getClass()); //class java.lang.Integer\n\n\n译者注： 大部分函数式接口都不用我们自己写，Java8 都给我们实现好了，这些接口都在 java.util.function 包里。\n\n\n# 方法和构造函数引用(Method and Constructor References)\n\n前一节中的代码还可以通过静态方法引用来表示：\n\n    Converter<String, Integer> converter = Integer::valueOf;\n    Integer converted = converter.convert("123");\n    System.out.println(converted.getClass());   //class java.lang.Integer\n\n\nJava 8 允许您通过::关键字传递方法或构造函数的引用。 上面的示例显示了如何引用静态方法。 但我们也可以引用对象方法：\n\nclass Something {\n    String startsWith(String s) {\n        return String.valueOf(s.charAt(0));\n    }\n}\n\n\nSomething something = new Something();\nConverter<String, String> converter = something::startsWith;\nString converted = converter.convert("Java");\nSystem.out.println(converted);    // "J"\n\n\n接下来看看构造函数是如何使用::关键字来引用的，首先我们定义一个包含多个构造函数的简单类：\n\nclass Person {\n    String firstName;\n    String lastName;\n\n    Person() {}\n\n    Person(String firstName, String lastName) {\n        this.firstName = firstName;\n        this.lastName = lastName;\n    }\n}\n\n\n接下来我们指定一个用来创建 Person 对象的对象工厂接口：\n\ninterface PersonFactory<P extends Person> {\n    P create(String firstName, String lastName);\n}\n\n\n这里我们使用构造函数引用来将他们关联起来，而不是手动实现一个完整的工厂：\n\nPersonFactory<Person> personFactory = Person::new;\nPerson person = personFactory.create("Peter", "Parker");\n\n\n我们只需要使用 Person::new 来获取 Person 类构造函数的引用，Java 编译器会自动根据PersonFactory.create方法的参数类型来选择合适的构造函数。\n\n\n# Lambda 表达式作用域(Lambda Scopes)\n\n\n# 访问局部变量\n\n我们可以直接在 lambda 表达式中访问外部的局部变量：\n\nfinal int num = 1;\nConverter<Integer, String> stringConverter =\n        (from) -> String.valueOf(from + num);\n\nstringConverter.convert(2);     // 3\n\n\n但是和匿名对象不同的是，这里的变量 num 可以不用声明为 final，该代码同样正确：\n\nint num = 1;\nConverter<Integer, String> stringConverter =\n        (from) -> String.valueOf(from + num);\n\nstringConverter.convert(2);     // 3\n\n\n不过这里的 num 必须不可被后面的代码修改（即隐性的具有 final 的语义），例如下面的就无法编译：\n\nint num = 1;\nConverter<Integer, String> stringConverter =\n        (from) -> String.valueOf(from + num);\nnum = 3;//在lambda表达式中试图修改num同样是不允许的。\n\n\n\n# 访问字段和静态变量\n\n与局部变量相比，我们在 lambda 表达式中对实例字段和静态变量都有读写访问权限。 该行为和匿名对象是一致的。\n\nclass Lambda4 {\n    static int outerStaticNum;\n    int outerNum;\n\n    void testScopes() {\n        Converter<Integer, String> stringConverter1 = (from) -> {\n            outerNum = 23;\n            return String.valueOf(from);\n        };\n\n        Converter<Integer, String> stringConverter2 = (from) -> {\n            outerStaticNum = 72;\n            return String.valueOf(from);\n        };\n    }\n}\n\n\n\n# 访问默认接口方法\n\n还记得第一节中的 formula 示例吗？ Formula 接口定义了一个默认方法sqrt，可以从包含匿名对象的每个 formula 实例访问该方法。 这不适用于 lambda 表达式。\n\n无法从 lambda 表达式中访问默认方法,故以下代码无法编译：\n\nFormula formula = (a) -> sqrt(a * 100);\n\n\n\n# 内置函数式接口(Built-in Functional Interfaces)\n\nJDK 1.8 API 包含许多内置函数式接口。 其中一些接口在老版本的 Java 中是比较常见的比如：Comparator 或Runnable，这些接口都增加了@FunctionalInterface注解以便能用在 lambda 表达式上。\n\n但是 Java 8 API 同样还提供了很多全新的函数式接口来让你的编程工作更加方便，有一些接口是来自 Google Guava 库里的，即便你对这些很熟悉了，还是有必要看看这些是如何扩展到 lambda 上使用的。\n\n\n# Predicate\n\nPredicate 接口是只有一个参数的返回布尔类型值的 断言型 接口。该接口包含多种默认方法来将 Predicate 组合成其他复杂的逻辑（比如：与，或，非）：\n\n译者注： Predicate 接口源码如下\n\npackage java.util.function;\nimport java.util.Objects;\n\n@FunctionalInterface\npublic interface Predicate<T> {\n\n    // 该方法是接受一个传入类型,返回一个布尔值.此方法应用于判断.\n    boolean test(T t);\n\n    //and方法与关系型运算符"&&"相似，两边都成立才返回true\n    default Predicate<T> and(Predicate<? super T> other) {\n        Objects.requireNonNull(other);\n        return (t) -> test(t) && other.test(t);\n    }\n    // 与关系运算符"!"相似，对判断进行取反\n    default Predicate<T> negate() {\n        return (t) -> !test(t);\n    }\n    //or方法与关系型运算符"||"相似，两边只要有一个成立就返回true\n    default Predicate<T> or(Predicate<? super T> other) {\n        Objects.requireNonNull(other);\n        return (t) -> test(t) || other.test(t);\n    }\n   // 该方法接收一个Object对象,返回一个Predicate类型.此方法用于判断第一个test的方法与第二个test方法相同(equal).\n    static <T> Predicate<T> isEqual(Object targetRef) {\n        return (null == targetRef)\n                ? Objects::isNull\n                : object -> targetRef.equals(object);\n    }\n\n\n示例：\n\nPredicate<String> predicate = (s) -> s.length() > 0;\n\npredicate.test("foo");              // true\npredicate.negate().test("foo");     // false\n\nPredicate<Boolean> nonNull = Objects::nonNull;\nPredicate<Boolean> isNull = Objects::isNull;\n\nPredicate<String> isEmpty = String::isEmpty;\nPredicate<String> isNotEmpty = isEmpty.negate();\n\n\n\n# Function\n\nFunction 接口接受一个参数并生成结果。默认方法可用于将多个函数链接在一起（compose, andThen）：\n\n译者注： Function 接口源码如下\n\n\npackage java.util.function;\n\nimport java.util.Objects;\n\n@FunctionalInterface\npublic interface Function<T, R> {\n\n    //将Function对象应用到输入的参数上，然后返回计算结果。\n    R apply(T t);\n    //将两个Function整合，并返回一个能够执行两个Function对象功能的Function对象。\n    default <V> Function<V, R> compose(Function<? super V, ? extends T> before) {\n        Objects.requireNonNull(before);\n        return (V v) -> apply(before.apply(v));\n    }\n    //\n    default <V> Function<T, V> andThen(Function<? super R, ? extends V> after) {\n        Objects.requireNonNull(after);\n        return (T t) -> after.apply(apply(t));\n    }\n\n    static <T> Function<T, T> identity() {\n        return t -> t;\n    }\n}\n\n\nFunction<String, Integer> toInteger = Integer::valueOf;\nFunction<String, String> backToString = toInteger.andThen(String::valueOf);\nbackToString.apply("123");     // "123"\n\n\n\n# Supplier\n\nSupplier 接口产生给定泛型类型的结果。 与 Function 接口不同，Supplier 接口不接受参数。\n\nSupplier<Person> personSupplier = Person::new;\npersonSupplier.get();   // new Person\n\n\n\n# Consumer\n\nConsumer 接口表示要对单个输入参数执行的操作。\n\nConsumer<Person> greeter = (p) -> System.out.println("Hello, " + p.firstName);\ngreeter.accept(new Person("Luke", "Skywalker"));\n\n\n\n# Comparator\n\nComparator 是老 Java 中的经典接口， Java 8 在此之上添加了多种默认方法：\n\nComparator<Person> comparator = (p1, p2) -> p1.firstName.compareTo(p2.firstName);\n\nPerson p1 = new Person("John", "Doe");\nPerson p2 = new Person("Alice", "Wonderland");\n\ncomparator.compare(p1, p2);             // > 0\ncomparator.reversed().compare(p1, p2);  // < 0\n\n\n\n# Optional\n\nOptional 不是函数式接口，而是用于防止 NullPointerException 的漂亮工具。这是下一节的一个重要概念，让我们快速了解一下 Optional 的工作原理。\n\nOptional 是一个简单的容器，其值可能是 null 或者不是 null。在 Java 8 之前一般某个函数应该返回非空对象但是有时却什么也没有返回，而在 Java 8 中，你应该返回 Optional 而不是 null。\n\n译者注：示例中每个方法的作用已经添加。\n\n//of()：为非null的值创建一个Optional\nOptional<String> optional = Optional.of("bam");\n// isPresent()：如果值存在返回true，否则返回false\noptional.isPresent();           // true\n//get()：如果Optional有值则将其返回，否则抛出NoSuchElementException\noptional.get();                 // "bam"\n//orElse()：如果有值则将其返回，否则返回指定的其它值\noptional.orElse("fallback");    // "bam"\n//ifPresent()：如果Optional实例有值则为其调用consumer，否则不做处理\noptional.ifPresent((s) -> System.out.println(s.charAt(0)));     // "b"\n\n\n推荐阅读：[Java8]如何正确使用 Optional\n\n\n# Streams(流)\n\njava.util.Stream 表示能应用在一组元素上一次执行的操作序列。Stream 操作分为中间操作或者最终操作两种，最终操作返回一特定类型的计算结果，而中间操作返回 Stream 本身，这样你就可以将多个操作依次串起来。Stream 的创建需要指定一个数据源，比如java.util.Collection 的子类，List 或者 Set， Map 不支持。Stream 的操作可以串行执行或者并行执行。\n\n首先看看 Stream 是怎么用，首先创建实例代码需要用到的数据 List：\n\nList<String> stringList = new ArrayList<>();\nstringList.add("ddd2");\nstringList.add("aaa2");\nstringList.add("bbb1");\nstringList.add("aaa1");\nstringList.add("bbb3");\nstringList.add("ccc");\nstringList.add("bbb2");\nstringList.add("ddd1");\n\n\nJava 8 扩展了集合类，可以通过 Collection.stream() 或者 Collection.parallelStream() 来创建一个 Stream。下面几节将详细解释常用的 Stream 操作：\n\n\n# Filter(过滤)\n\n过滤通过一个 predicate 接口来过滤并只保留符合条件的元素，该操作属于中间操作，所以我们可以在过滤后的结果来应用其他 Stream 操作（比如 forEach）。forEach 需要一个函数来对过滤后的元素依次执行。forEach 是一个最终操作，所以我们不能在 forEach 之后来执行其他 Stream 操作。\n\n        // 测试 Filter(过滤)\n        stringList\n                .stream()\n                .filter((s) -> s.startsWith("a"))\n                .forEach(System.out::println);//aaa2 aaa1\n\n\nforEach 是为 Lambda 而设计的，保持了最紧凑的风格。而且 Lambda 表达式本身是可以重用的，非常方便。\n\n\n# Sorted(排序)\n\n排序是一个 中间操作，返回的是排序好后的 Stream。如果你不指定一个自定义的 Comparator 则会使用默认排序。\n\n        // 测试 Sort (排序)\n        stringList\n                .stream()\n                .sorted()\n                .filter((s) -> s.startsWith("a"))\n                .forEach(System.out::println);// aaa1 aaa2\n\n\n需要注意的是，排序只创建了一个排列好后的 Stream，而不会影响原有的数据源，排序之后原数据 stringList 是不会被修改的：\n\n    System.out.println(stringList);// ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1\n\n\n\n# Map(映射)\n\n中间操作 map 会将元素根据指定的 Function 接口来依次将元素转成另外的对象。\n\n下面的示例展示了将字符串转换为大写字符串。你也可以通过 map 来将对象转换成其他类型，map 返回的 Stream 类型是根据你 map 传递进去的函数的返回值决定的。\n\n        // 测试 Map 操作\n        stringList\n                .stream()\n                .map(String::toUpperCase)\n                .sorted((a, b) -> b.compareTo(a))\n                .forEach(System.out::println);// "DDD2", "DDD1", "CCC", "BBB3", "BBB2", "BBB1", "AAA2", "AAA1"\n\n\n\n# Match(匹配)\n\nStream 提供了多种匹配操作，允许检测指定的 Predicate 是否匹配整个 Stream。所有的匹配操作都是 最终操作 ，并返回一个 boolean 类型的值。\n\n        // 测试 Match (匹配)操作\n        boolean anyStartsWithA =\n                stringList\n                        .stream()\n                        .anyMatch((s) -> s.startsWith("a"));\n        System.out.println(anyStartsWithA);      // true\n\n        boolean allStartsWithA =\n                stringList\n                        .stream()\n                        .allMatch((s) -> s.startsWith("a"));\n\n        System.out.println(allStartsWithA);      // false\n\n        boolean noneStartsWithZ =\n                stringList\n                        .stream()\n                        .noneMatch((s) -> s.startsWith("z"));\n\n        System.out.println(noneStartsWithZ);      // true\n\n\n\n# Count(计数)\n\n计数是一个 最终操作，返回 Stream 中元素的个数，返回值类型是 long。\n\n      //测试 Count (计数)操作\n        long startsWithB =\n                stringList\n                        .stream()\n                        .filter((s) -> s.startsWith("b"))\n                        .count();\n        System.out.println(startsWithB);    // 3\n\n\n\n# Reduce(规约)\n\n这是一个 最终操作 ，允许通过指定的函数来将 stream 中的多个元素规约为一个元素，规约后的结果是通过 Optional 接口表示的：\n\n        //测试 Reduce (规约)操作\n        Optional<String> reduced =\n                stringList\n                        .stream()\n                        .sorted()\n                        .reduce((s1, s2) -> s1 + "#" + s2);\n\n        reduced.ifPresent(System.out::println);//aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2\n\n\n译者注： 这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。例如 Stream 的 sum 就相当于Integer sum = integers.reduce(0, (a, b) -> a+b);也有没有起始值的情况，这时会把 Stream 的前面两个元素组合起来，返回的是 Optional。\n\n// 字符串连接，concat = "ABCD"\nString concat = Stream.of("A", "B", "C", "D").reduce("", String::concat);\n// 求最小值，minValue = -3.0\ndouble minValue = Stream.of(-1.5, 1.0, -3.0, -2.0).reduce(Double.MAX_VALUE, Double::min);\n// 求和，sumValue = 10, 有起始值\nint sumValue = Stream.of(1, 2, 3, 4).reduce(0, Integer::sum);\n// 求和，sumValue = 10, 无起始值\nsumValue = Stream.of(1, 2, 3, 4).reduce(Integer::sum).get();\n// 过滤，字符串连接，concat = "ace"\nconcat = Stream.of("a", "B", "c", "D", "e", "F").\n filter(x -> x.compareTo("Z") > 0).\n reduce("", String::concat);\n\n\n上面代码例如第一个示例的 reduce()，第一个参数（空白字符）即为起始值，第二个参数（String::concat）为 BinaryOperator。这类有起始值的 reduce() 都返回具体的对象。而对于第四个示例没有起始值的 reduce()，由于可能没有足够的元素，返回的是 Optional，请留意这个区别。更多内容查看：IBM：Java 8 中的 Streams API 详解\n\n\n# Parallel Streams(并行流)\n\n前面提到过 Stream 有串行和并行两种，串行 Stream 上的操作是在一个线程中依次完成，而并行 Stream 则是在多个线程上同时执行。\n\n下面的例子展示了是如何通过并行 Stream 来提升性能：\n\n首先我们创建一个没有重复元素的大表：\n\nint max = 1000000;\nList<String> values = new ArrayList<>(max);\nfor (int i = 0; i < max; i++) {\n    UUID uuid = UUID.randomUUID();\n    values.add(uuid.toString());\n}\n\n\n我们分别用串行和并行两种方式对其进行排序，最后看看所用时间的对比。\n\n\n# Sequential Sort(串行排序)\n\n//串行排序\nlong t0 = System.nanoTime();\nlong count = values.stream().sorted().count();\nSystem.out.println(count);\n\nlong t1 = System.nanoTime();\n\nlong millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);\nSystem.out.println(String.format("sequential sort took: %d ms", millis));\n\n\n1000000\nsequential sort took: 709 ms//串行排序所用的时间\n\n\n\n# Parallel Sort(并行排序)\n\n//并行排序\nlong t0 = System.nanoTime();\n\nlong count = values.parallelStream().sorted().count();\nSystem.out.println(count);\n\nlong t1 = System.nanoTime();\n\nlong millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);\nSystem.out.println(String.format("parallel sort took: %d ms", millis));\n\n\n\n1000000\nparallel sort took: 475 ms//并行排序所用的时间\n\n\n上面两个代码几乎是一样的，但是并行版的快了 50% 左右，唯一需要做的改动就是将 stream() 改为parallelStream()。\n\n\n# Maps\n\n前面提到过，Map 类型不支持 streams，不过 Map 提供了一些新的有用的方法来处理一些日常任务。Map 接口本身没有可用的 stream()方法，但是你可以在键，值上创建专门的流或者通过 map.keySet().stream(),map.values().stream()和map.entrySet().stream()。\n\n此外,Maps 支持各种新的和有用的方法来执行常见任务。\n\nMap<Integer, String> map = new HashMap<>();\n\nfor (int i = 0; i < 10; i++) {\n    map.putIfAbsent(i, "val" + i);\n}\n\nmap.forEach((id, val) -> System.out.println(val));//val0 val1 val2 val3 val4 val5 val6 val7 val8 val9\n\n\nputIfAbsent 阻止我们在 null 检查时写入额外的代码;forEach接受一个 consumer 来对 map 中的每个元素操作。\n\n此示例显示如何使用函数在 map 上计算代码：\n\nmap.computeIfPresent(3, (num, val) -> val + num);\nmap.get(3);             // val33\n\nmap.computeIfPresent(9, (num, val) -> null);\nmap.containsKey(9);     // false\n\nmap.computeIfAbsent(23, num -> "val" + num);\nmap.containsKey(23);    // true\n\nmap.computeIfAbsent(3, num -> "bam");\nmap.get(3);             // val33\n\n\n接下来展示如何在 Map 里删除一个键值全都匹配的项：\n\nmap.remove(3, "val3");\nmap.get(3);             // val33\nmap.remove(3, "val33");\nmap.get(3);             // null\n\n\n另外一个有用的方法：\n\nmap.getOrDefault(42, "not found");  // not found\n\n\n对 Map 的元素做合并也变得很容易了：\n\nmap.merge(9, "val9", (value, newValue) -> value.concat(newValue));\nmap.get(9);             // val9\nmap.merge(9, "concat", (value, newValue) -> value.concat(newValue));\nmap.get(9);             // val9concat\n\n\nMerge 做的事情是如果键名不存在则插入，否则对原键对应的值做合并操作并重新插入到 map 中。\n\n\n# Date API(日期相关 API)\n\nJava 8 在 java.time 包下包含一个全新的日期和时间 API。新的 Date API 与 Joda-Time 库相似，但它们不一样。以下示例涵盖了此新 API 的最重要部分。译者对这部分内容参考相关书籍做了大部分修改。\n\n译者注(总结)：\n\n * Clock 类提供了访问当前日期和时间的方法，Clock 是时区敏感的，可以用来取代 System.currentTimeMillis() 来获取当前的微秒数。某一个特定的时间点也可以使用 Instant 类来表示，Instant 类也可以用来创建旧版本的java.util.Date 对象。\n\n * 在新 API 中时区使用 ZoneId 来表示。时区可以很方便的使用静态方法 of 来获取到。 抽象类ZoneId（在java.time包中）表示一个区域标识符。 它有一个名为getAvailableZoneIds的静态方法，它返回所有区域标识符。\n\n * jdk1.8 中新增了 LocalDate 与 LocalDateTime 等类来解决日期处理方法，同时引入了一个新的类 DateTimeFormatter 来解决日期格式化问题。可以使用 Instant 代替 Date，LocalDateTime 代替 Calendar，DateTimeFormatter 代替 SimpleDateFormat。\n\n\n# Clock\n\nClock 类提供了访问当前日期和时间的方法，Clock 是时区敏感的，可以用来取代 System.currentTimeMillis() 来获取当前的微秒数。某一个特定的时间点也可以使用 Instant 类来表示，Instant 类也可以用来创建旧版本的java.util.Date 对象。\n\nClock clock = Clock.systemDefaultZone();\nlong millis = clock.millis();\nSystem.out.println(millis);//1552379579043\nInstant instant = clock.instant();\nSystem.out.println(instant);\nDate legacyDate = Date.from(instant); //2019-03-12T08:46:42.588Z\nSystem.out.println(legacyDate);//Tue Mar 12 16:32:59 CST 2019\n\n\n\n# Timezones(时区)\n\n在新 API 中时区使用 ZoneId 来表示。时区可以很方便的使用静态方法 of 来获取到。 抽象类ZoneId（在java.time包中）表示一个区域标识符。 它有一个名为getAvailableZoneIds的静态方法，它返回所有区域标识符。\n\n//输出所有区域标识符\nSystem.out.println(ZoneId.getAvailableZoneIds());\n\nZoneId zone1 = ZoneId.of("Europe/Berlin");\nZoneId zone2 = ZoneId.of("Brazil/East");\nSystem.out.println(zone1.getRules());// ZoneRules[currentStandardOffset=+01:00]\nSystem.out.println(zone2.getRules());// ZoneRules[currentStandardOffset=-03:00]\n\n\n\n# LocalTime(本地时间)\n\nLocalTime 定义了一个没有时区信息的时间，例如 晚上 10 点或者 17:30:15。下面的例子使用前面代码创建的时区创建了两个本地时间。之后比较时间并以小时和分钟为单位计算两个时间的时间差：\n\nLocalTime now1 = LocalTime.now(zone1);\nLocalTime now2 = LocalTime.now(zone2);\nSystem.out.println(now1.isBefore(now2));  // false\n\nlong hoursBetween = ChronoUnit.HOURS.between(now1, now2);\nlong minutesBetween = ChronoUnit.MINUTES.between(now1, now2);\n\nSystem.out.println(hoursBetween);       // -3\nSystem.out.println(minutesBetween);     // -239\n\n\nLocalTime 提供了多种工厂方法来简化对象的创建，包括解析时间字符串.\n\nLocalTime late = LocalTime.of(23, 59, 59);\nSystem.out.println(late);       // 23:59:59\nDateTimeFormatter germanFormatter =\n    DateTimeFormatter\n        .ofLocalizedTime(FormatStyle.SHORT)\n        .withLocale(Locale.GERMAN);\n\nLocalTime leetTime = LocalTime.parse("13:37", germanFormatter);\nSystem.out.println(leetTime);   // 13:37\n\n\n\n# LocalDate(本地日期)\n\nLocalDate 表示了一个确切的日期，比如 2014-03-11。该对象值是不可变的，用起来和 LocalTime 基本一致。下面的例子展示了如何给 Date 对象加减天/月/年。另外要注意的是这些对象是不可变的，操作返回的总是一个新实例。\n\nLocalDate today = LocalDate.now();//获取现在的日期\nSystem.out.println("今天的日期: "+today);//2019-03-12\nLocalDate tomorrow = today.plus(1, ChronoUnit.DAYS);\nSystem.out.println("明天的日期: "+tomorrow);//2019-03-13\nLocalDate yesterday = tomorrow.minusDays(2);\nSystem.out.println("昨天的日期: "+yesterday);//2019-03-11\nLocalDate independenceDay = LocalDate.of(2019, Month.MARCH, 12);\nDayOfWeek dayOfWeek = independenceDay.getDayOfWeek();\nSystem.out.println("今天是周几:"+dayOfWeek);//TUESDAY\n\n\n从字符串解析一个 LocalDate 类型和解析 LocalTime 一样简单,下面是使用 DateTimeFormatter 解析字符串的例子：\n\n    String str1 = "2014==04==12 01时06分09秒";\n        // 根据需要解析的日期、时间字符串定义解析所用的格式器\n        DateTimeFormatter fomatter1 = DateTimeFormatter\n                .ofPattern("yyyy==MM==dd HH时mm分ss秒");\n\n        LocalDateTime dt1 = LocalDateTime.parse(str1, fomatter1);\n        System.out.println(dt1); // 输出 2014-04-12T01:06:09\n\n        String str2 = "2014$$$四月$$$13 20小时";\n        DateTimeFormatter fomatter2 = DateTimeFormatter\n                .ofPattern("yyy$$$MMM$$$dd HH小时");\n        LocalDateTime dt2 = LocalDateTime.parse(str2, fomatter2);\n        System.out.println(dt2); // 输出 2014-04-13T20:00\n\n\n\n再来看一个使用 DateTimeFormatter 格式化日期的示例\n\nLocalDateTime rightNow=LocalDateTime.now();\nString date=DateTimeFormatter.ISO_LOCAL_DATE_TIME.format(rightNow);\nSystem.out.println(date);//2019-03-12T16:26:48.29\nDateTimeFormatter formatter=DateTimeFormatter.ofPattern("YYYY-MM-dd HH:mm:ss");\nSystem.out.println(formatter.format(rightNow));//2019-03-12 16:26:48\n\n\n🐛 修正（参见：issue#1157）：使用 YYYY 显示年份时，会显示当前时间所在周的年份，在跨年周会有问题。一般情况下都使用 yyyy，来显示准确的年份。\n\n跨年导致日期显示错误示例：\n\nLocalDateTime rightNow = LocalDateTime.of(2020, 12, 31, 12, 0, 0);\nString date= DateTimeFormatter.ISO_LOCAL_DATE_TIME.format(rightNow);\n// 2020-12-31T12:00:00\nSystem.out.println(date);\nDateTimeFormatter formatterOfYYYY = DateTimeFormatter.ofPattern("YYYY-MM-dd HH:mm:ss");\n// 2021-12-31 12:00:00\nSystem.out.println(formatterOfYYYY.format(rightNow));\n\nDateTimeFormatter formatterOfYyyy = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");\n// 2020-12-31 12:00:00\nSystem.out.println(formatterOfYyyy.format(rightNow));\n\n\n从下图可以更清晰的看到具体的错误，并且 IDEA 已经智能地提示更倾向于使用 yyyy 而不是 YYYY 。\n\n\n\n\n# LocalDateTime(本地日期时间)\n\nLocalDateTime 同时表示了时间和日期，相当于前两节内容合并到一个对象上了。LocalDateTime 和 LocalTime 还有 LocalDate 一样，都是不可变的。LocalDateTime 提供了一些能访问具体字段的方法。\n\nLocalDateTime sylvester = LocalDateTime.of(2014, Month.DECEMBER, 31, 23, 59, 59);\n\nDayOfWeek dayOfWeek = sylvester.getDayOfWeek();\nSystem.out.println(dayOfWeek);      // WEDNESDAY\n\nMonth month = sylvester.getMonth();\nSystem.out.println(month);          // DECEMBER\n\nlong minuteOfDay = sylvester.getLong(ChronoField.MINUTE_OF_DAY);\nSystem.out.println(minuteOfDay);    // 1439\n\n\n只要附加上时区信息，就可以将其转换为一个时间点 Instant 对象，Instant 时间点对象可以很容易的转换为老式的java.util.Date。\n\nInstant instant = sylvester\n        .atZone(ZoneId.systemDefault())\n        .toInstant();\n\nDate legacyDate = Date.from(instant);\nSystem.out.println(legacyDate);     // Wed Dec 31 23:59:59 CET 2014\n\n\n格式化 LocalDateTime 和格式化时间和日期一样的，除了使用预定义好的格式外，我们也可以自己定义格式：\n\nDateTimeFormatter formatter =\n    DateTimeFormatter\n        .ofPattern("MMM dd, yyyy - HH:mm");\nLocalDateTime parsed = LocalDateTime.parse("Nov 03, 2014 - 07:13", formatter);\nString string = formatter.format(parsed);\nSystem.out.println(string);     // Nov 03, 2014 - 07:13\n\n\n和 java.text.NumberFormat 不一样的是新版的 DateTimeFormatter 是不可变的，所以它是线程安全的。 关于时间日期格式的详细信息在这里。\n\n\n# Annotations(注解)\n\n在 Java 8 中支持多重注解了，先看个例子来理解一下是什么意思。 首先定义一个包装类 Hints 注解用来放置一组具体的 Hint 注解：\n\n@Retention(RetentionPolicy.RUNTIME)\n@interface Hints {\n    Hint[] value();\n}\n@Repeatable(Hints.class)\n@interface Hint {\n    String value();\n}\n\n\nJava 8 允许我们把同一个类型的注解使用多次，只需要给该注解标注一下@Repeatable即可。\n\n例 1: 使用包装类当容器来存多个注解（老方法）\n\n@Hints({@Hint("hint1"), @Hint("hint2")})\nclass Person {}\n\n\n例 2：使用多重注解（新方法）\n\n@Hint("hint1")\n@Hint("hint2")\nclass Person {}\n\n\n第二个例子里 java 编译器会隐性的帮你定义好@Hints 注解，了解这一点有助于你用反射来获取这些信息：\n\nHint hint = Person.class.getAnnotation(Hint.class);\nSystem.out.println(hint);                   // null\nHints hints1 = Person.class.getAnnotation(Hints.class);\nSystem.out.println(hints1.value().length);  // 2\n\nHint[] hints2 = Person.class.getAnnotationsByType(Hint.class);\nSystem.out.println(hints2.length);          // 2\n\n\n即便我们没有在 Person类上定义 @Hints注解，我们还是可以通过 getAnnotation(Hints.class)来获取 @Hints注解，更加方便的方法是使用 getAnnotationsByType 可以直接获取到所有的@Hint注解。 另外 Java 8 的注解还增加到两种新的 target 上了：\n\n@Target({ElementType.TYPE_PARAMETER, ElementType.TYPE_USE})\n@interface MyAnnotation {}\n\n\n\n# Where to go from here?\n\n关于 Java 8 的新特性就写到这了，肯定还有更多的特性等待发掘。JDK 1.8 里还有很多很有用的东西，比如Arrays.parallelSort, StampedLock和CompletableFuture等等。',normalizedContent:'# 《java8 指南》中文翻译\n\n随着 java 8 的普及度越来越高，很多人都提到面试中关于 java 8 也是非常常问的知识点。应各位要求和需要，我打算对这部分知识做一个总结。本来准备自己总结的，后面看到 github 上有一个相关的仓库，地址： https://github.com/winterbe/java8-tutorial。这个仓库是英文的，我对其进行了翻译并添加和修改了部分内容，下面是正文。\n\n----------------------------------------\n\n欢迎阅读我对 java 8 的介绍。本教程将逐步指导您完成所有新语言功能。 在简短的代码示例的基础上，您将学习如何使用默认接口方法，lambda 表达式，方法引用和可重复注释。 在本文的最后，您将熟悉最新的 api 更改，如流，函数式接口(functional interfaces)，map 类的扩展和新的 date api。 没有大段枯燥的文字，只有一堆注释的代码片段。\n\n\n# 接口的默认方法(default methods for interfaces)\n\njava 8 使我们能够通过使用 default 关键字向接口添加非抽象方法实现。 此功能也称为虚拟扩展方法。\n\n第一个例子：\n\ninterface formula{\n\n    double calculate(int a);\n\n    default double sqrt(int a) {\n        return math.sqrt(a);\n    }\n\n}\n\n\nformula 接口中除了抽象方法计算接口公式还定义了默认方法 sqrt。 实现该接口的类只需要实现抽象方法 calculate。 默认方法sqrt 可以直接使用。当然你也可以直接通过接口创建对象，然后实现接口中的默认方法就可以了，我们通过代码演示一下这种方式。\n\npublic class main {\n\n  public static void main(string[] args) {\n    // 通过匿名内部类方式访问接口\n    formula formula = new formula() {\n        @override\n        public double calculate(int a) {\n            return sqrt(a * 100);\n        }\n    };\n\n    system.out.println(formula.calculate(100));     // 100.0\n    system.out.println(formula.sqrt(16));           // 4.0\n\n  }\n\n}\n\n\nformula 是作为匿名对象实现的。该代码非常容易理解，6 行代码实现了计算 sqrt(a * 100)。在下一节中，我们将会看到在 java 8 中实现单个方法对象有一种更好更方便的方法。\n\n译者注： 不管是抽象类还是接口，都可以通过匿名内部类的方式访问。不能通过抽象类或者接口直接创建对象。对于上面通过匿名内部类方式访问接口，我们可以这样理解：一个内部类实现了接口里的抽象方法并且返回一个内部类对象，之后我们让接口的引用来指向这个对象。\n\n\n# lambda 表达式(lambda expressions)\n\n首先看看在老版本的 java 中是如何排列字符串的：\n\nlist<string> names = arrays.aslist("peter", "anna", "mike", "xenia");\n\ncollections.sort(names, new comparator<string>() {\n    @override\n    public int compare(string a, string b) {\n        return b.compareto(a);\n    }\n});\n\n\n只需要给静态方法collections.sort 传入一个 list 对象以及一个比较器来按指定顺序排列。通常做法都是创建一个匿名的比较器对象然后将其传递给 sort 方法。\n\n在 java 8 中你就没必要使用这种传统的匿名对象的方式了，java 8 提供了更简洁的语法，lambda 表达式：\n\ncollections.sort(names, (string a, string b) -> {\n    return b.compareto(a);\n});\n\n\n可以看出，代码变得更短且更具有可读性，但是实际上还可以写得更短：\n\ncollections.sort(names, (string a, string b) -> b.compareto(a));\n\n\n对于函数体只有一行代码的，你可以去掉大括号{}以及 return 关键字，但是你还可以写得更短点：\n\nnames.sort((a, b) -> b.compareto(a));\n\n\nlist 类本身就有一个 sort 方法。并且 java 编译器可以自动推导出参数类型，所以你可以不用再写一次类型。接下来我们看看 lambda 表达式还有什么其他用法。\n\n\n# 函数式接口(functional interfaces)\n\n译者注： 原文对这部分解释不太清楚，故做了修改！\n\njava 语言设计者们投入了大量精力来思考如何使现有的函数友好地支持 lambda。最终采取的方法是：增加函数式接口的概念。“函数式接口”是指仅仅只包含一个抽象方法,但是可以有多个非抽象方法(也就是上面提到的默认方法)的接口。 像这样的接口，可以被隐式转换为 lambda 表达式。java.lang.runnable 与 java.util.concurrent.callable 是函数式接口最典型的两个例子。java 8 增加了一种特殊的注解@functionalinterface,但是这个注解通常不是必须的(某些情况建议使用)，只要接口只包含一个抽象方法，虚拟机会自动判断该接口为函数式接口。一般建议在接口上使用@functionalinterface 注解进行声明，这样的话，编译器如果发现你标注了这个注解的接口有多于一个抽象方法的时候会报错的，如下图所示\n\n\n\n示例：\n\n@functionalinterface\npublic interface converter<f, t> {\n  t convert(f from);\n}\n\n\n    // todo 将数字字符串转换为整数类型\n    converter<string, integer> converter = (from) -> integer.valueof(from);\n    integer converted = converter.convert("123");\n    system.out.println(converted.getclass()); //class java.lang.integer\n\n\n译者注： 大部分函数式接口都不用我们自己写，java8 都给我们实现好了，这些接口都在 java.util.function 包里。\n\n\n# 方法和构造函数引用(method and constructor references)\n\n前一节中的代码还可以通过静态方法引用来表示：\n\n    converter<string, integer> converter = integer::valueof;\n    integer converted = converter.convert("123");\n    system.out.println(converted.getclass());   //class java.lang.integer\n\n\njava 8 允许您通过::关键字传递方法或构造函数的引用。 上面的示例显示了如何引用静态方法。 但我们也可以引用对象方法：\n\nclass something {\n    string startswith(string s) {\n        return string.valueof(s.charat(0));\n    }\n}\n\n\nsomething something = new something();\nconverter<string, string> converter = something::startswith;\nstring converted = converter.convert("java");\nsystem.out.println(converted);    // "j"\n\n\n接下来看看构造函数是如何使用::关键字来引用的，首先我们定义一个包含多个构造函数的简单类：\n\nclass person {\n    string firstname;\n    string lastname;\n\n    person() {}\n\n    person(string firstname, string lastname) {\n        this.firstname = firstname;\n        this.lastname = lastname;\n    }\n}\n\n\n接下来我们指定一个用来创建 person 对象的对象工厂接口：\n\ninterface personfactory<p extends person> {\n    p create(string firstname, string lastname);\n}\n\n\n这里我们使用构造函数引用来将他们关联起来，而不是手动实现一个完整的工厂：\n\npersonfactory<person> personfactory = person::new;\nperson person = personfactory.create("peter", "parker");\n\n\n我们只需要使用 person::new 来获取 person 类构造函数的引用，java 编译器会自动根据personfactory.create方法的参数类型来选择合适的构造函数。\n\n\n# lambda 表达式作用域(lambda scopes)\n\n\n# 访问局部变量\n\n我们可以直接在 lambda 表达式中访问外部的局部变量：\n\nfinal int num = 1;\nconverter<integer, string> stringconverter =\n        (from) -> string.valueof(from + num);\n\nstringconverter.convert(2);     // 3\n\n\n但是和匿名对象不同的是，这里的变量 num 可以不用声明为 final，该代码同样正确：\n\nint num = 1;\nconverter<integer, string> stringconverter =\n        (from) -> string.valueof(from + num);\n\nstringconverter.convert(2);     // 3\n\n\n不过这里的 num 必须不可被后面的代码修改（即隐性的具有 final 的语义），例如下面的就无法编译：\n\nint num = 1;\nconverter<integer, string> stringconverter =\n        (from) -> string.valueof(from + num);\nnum = 3;//在lambda表达式中试图修改num同样是不允许的。\n\n\n\n# 访问字段和静态变量\n\n与局部变量相比，我们在 lambda 表达式中对实例字段和静态变量都有读写访问权限。 该行为和匿名对象是一致的。\n\nclass lambda4 {\n    static int outerstaticnum;\n    int outernum;\n\n    void testscopes() {\n        converter<integer, string> stringconverter1 = (from) -> {\n            outernum = 23;\n            return string.valueof(from);\n        };\n\n        converter<integer, string> stringconverter2 = (from) -> {\n            outerstaticnum = 72;\n            return string.valueof(from);\n        };\n    }\n}\n\n\n\n# 访问默认接口方法\n\n还记得第一节中的 formula 示例吗？ formula 接口定义了一个默认方法sqrt，可以从包含匿名对象的每个 formula 实例访问该方法。 这不适用于 lambda 表达式。\n\n无法从 lambda 表达式中访问默认方法,故以下代码无法编译：\n\nformula formula = (a) -> sqrt(a * 100);\n\n\n\n# 内置函数式接口(built-in functional interfaces)\n\njdk 1.8 api 包含许多内置函数式接口。 其中一些接口在老版本的 java 中是比较常见的比如：comparator 或runnable，这些接口都增加了@functionalinterface注解以便能用在 lambda 表达式上。\n\n但是 java 8 api 同样还提供了很多全新的函数式接口来让你的编程工作更加方便，有一些接口是来自 google guava 库里的，即便你对这些很熟悉了，还是有必要看看这些是如何扩展到 lambda 上使用的。\n\n\n# predicate\n\npredicate 接口是只有一个参数的返回布尔类型值的 断言型 接口。该接口包含多种默认方法来将 predicate 组合成其他复杂的逻辑（比如：与，或，非）：\n\n译者注： predicate 接口源码如下\n\npackage java.util.function;\nimport java.util.objects;\n\n@functionalinterface\npublic interface predicate<t> {\n\n    // 该方法是接受一个传入类型,返回一个布尔值.此方法应用于判断.\n    boolean test(t t);\n\n    //and方法与关系型运算符"&&"相似，两边都成立才返回true\n    default predicate<t> and(predicate<? super t> other) {\n        objects.requirenonnull(other);\n        return (t) -> test(t) && other.test(t);\n    }\n    // 与关系运算符"!"相似，对判断进行取反\n    default predicate<t> negate() {\n        return (t) -> !test(t);\n    }\n    //or方法与关系型运算符"||"相似，两边只要有一个成立就返回true\n    default predicate<t> or(predicate<? super t> other) {\n        objects.requirenonnull(other);\n        return (t) -> test(t) || other.test(t);\n    }\n   // 该方法接收一个object对象,返回一个predicate类型.此方法用于判断第一个test的方法与第二个test方法相同(equal).\n    static <t> predicate<t> isequal(object targetref) {\n        return (null == targetref)\n                ? objects::isnull\n                : object -> targetref.equals(object);\n    }\n\n\n示例：\n\npredicate<string> predicate = (s) -> s.length() > 0;\n\npredicate.test("foo");              // true\npredicate.negate().test("foo");     // false\n\npredicate<boolean> nonnull = objects::nonnull;\npredicate<boolean> isnull = objects::isnull;\n\npredicate<string> isempty = string::isempty;\npredicate<string> isnotempty = isempty.negate();\n\n\n\n# function\n\nfunction 接口接受一个参数并生成结果。默认方法可用于将多个函数链接在一起（compose, andthen）：\n\n译者注： function 接口源码如下\n\n\npackage java.util.function;\n\nimport java.util.objects;\n\n@functionalinterface\npublic interface function<t, r> {\n\n    //将function对象应用到输入的参数上，然后返回计算结果。\n    r apply(t t);\n    //将两个function整合，并返回一个能够执行两个function对象功能的function对象。\n    default <v> function<v, r> compose(function<? super v, ? extends t> before) {\n        objects.requirenonnull(before);\n        return (v v) -> apply(before.apply(v));\n    }\n    //\n    default <v> function<t, v> andthen(function<? super r, ? extends v> after) {\n        objects.requirenonnull(after);\n        return (t t) -> after.apply(apply(t));\n    }\n\n    static <t> function<t, t> identity() {\n        return t -> t;\n    }\n}\n\n\nfunction<string, integer> tointeger = integer::valueof;\nfunction<string, string> backtostring = tointeger.andthen(string::valueof);\nbacktostring.apply("123");     // "123"\n\n\n\n# supplier\n\nsupplier 接口产生给定泛型类型的结果。 与 function 接口不同，supplier 接口不接受参数。\n\nsupplier<person> personsupplier = person::new;\npersonsupplier.get();   // new person\n\n\n\n# consumer\n\nconsumer 接口表示要对单个输入参数执行的操作。\n\nconsumer<person> greeter = (p) -> system.out.println("hello, " + p.firstname);\ngreeter.accept(new person("luke", "skywalker"));\n\n\n\n# comparator\n\ncomparator 是老 java 中的经典接口， java 8 在此之上添加了多种默认方法：\n\ncomparator<person> comparator = (p1, p2) -> p1.firstname.compareto(p2.firstname);\n\nperson p1 = new person("john", "doe");\nperson p2 = new person("alice", "wonderland");\n\ncomparator.compare(p1, p2);             // > 0\ncomparator.reversed().compare(p1, p2);  // < 0\n\n\n\n# optional\n\noptional 不是函数式接口，而是用于防止 nullpointerexception 的漂亮工具。这是下一节的一个重要概念，让我们快速了解一下 optional 的工作原理。\n\noptional 是一个简单的容器，其值可能是 null 或者不是 null。在 java 8 之前一般某个函数应该返回非空对象但是有时却什么也没有返回，而在 java 8 中，你应该返回 optional 而不是 null。\n\n译者注：示例中每个方法的作用已经添加。\n\n//of()：为非null的值创建一个optional\noptional<string> optional = optional.of("bam");\n// ispresent()：如果值存在返回true，否则返回false\noptional.ispresent();           // true\n//get()：如果optional有值则将其返回，否则抛出nosuchelementexception\noptional.get();                 // "bam"\n//orelse()：如果有值则将其返回，否则返回指定的其它值\noptional.orelse("fallback");    // "bam"\n//ifpresent()：如果optional实例有值则为其调用consumer，否则不做处理\noptional.ifpresent((s) -> system.out.println(s.charat(0)));     // "b"\n\n\n推荐阅读：[java8]如何正确使用 optional\n\n\n# streams(流)\n\njava.util.stream 表示能应用在一组元素上一次执行的操作序列。stream 操作分为中间操作或者最终操作两种，最终操作返回一特定类型的计算结果，而中间操作返回 stream 本身，这样你就可以将多个操作依次串起来。stream 的创建需要指定一个数据源，比如java.util.collection 的子类，list 或者 set， map 不支持。stream 的操作可以串行执行或者并行执行。\n\n首先看看 stream 是怎么用，首先创建实例代码需要用到的数据 list：\n\nlist<string> stringlist = new arraylist<>();\nstringlist.add("ddd2");\nstringlist.add("aaa2");\nstringlist.add("bbb1");\nstringlist.add("aaa1");\nstringlist.add("bbb3");\nstringlist.add("ccc");\nstringlist.add("bbb2");\nstringlist.add("ddd1");\n\n\njava 8 扩展了集合类，可以通过 collection.stream() 或者 collection.parallelstream() 来创建一个 stream。下面几节将详细解释常用的 stream 操作：\n\n\n# filter(过滤)\n\n过滤通过一个 predicate 接口来过滤并只保留符合条件的元素，该操作属于中间操作，所以我们可以在过滤后的结果来应用其他 stream 操作（比如 foreach）。foreach 需要一个函数来对过滤后的元素依次执行。foreach 是一个最终操作，所以我们不能在 foreach 之后来执行其他 stream 操作。\n\n        // 测试 filter(过滤)\n        stringlist\n                .stream()\n                .filter((s) -> s.startswith("a"))\n                .foreach(system.out::println);//aaa2 aaa1\n\n\nforeach 是为 lambda 而设计的，保持了最紧凑的风格。而且 lambda 表达式本身是可以重用的，非常方便。\n\n\n# sorted(排序)\n\n排序是一个 中间操作，返回的是排序好后的 stream。如果你不指定一个自定义的 comparator 则会使用默认排序。\n\n        // 测试 sort (排序)\n        stringlist\n                .stream()\n                .sorted()\n                .filter((s) -> s.startswith("a"))\n                .foreach(system.out::println);// aaa1 aaa2\n\n\n需要注意的是，排序只创建了一个排列好后的 stream，而不会影响原有的数据源，排序之后原数据 stringlist 是不会被修改的：\n\n    system.out.println(stringlist);// ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1\n\n\n\n# map(映射)\n\n中间操作 map 会将元素根据指定的 function 接口来依次将元素转成另外的对象。\n\n下面的示例展示了将字符串转换为大写字符串。你也可以通过 map 来将对象转换成其他类型，map 返回的 stream 类型是根据你 map 传递进去的函数的返回值决定的。\n\n        // 测试 map 操作\n        stringlist\n                .stream()\n                .map(string::touppercase)\n                .sorted((a, b) -> b.compareto(a))\n                .foreach(system.out::println);// "ddd2", "ddd1", "ccc", "bbb3", "bbb2", "bbb1", "aaa2", "aaa1"\n\n\n\n# match(匹配)\n\nstream 提供了多种匹配操作，允许检测指定的 predicate 是否匹配整个 stream。所有的匹配操作都是 最终操作 ，并返回一个 boolean 类型的值。\n\n        // 测试 match (匹配)操作\n        boolean anystartswitha =\n                stringlist\n                        .stream()\n                        .anymatch((s) -> s.startswith("a"));\n        system.out.println(anystartswitha);      // true\n\n        boolean allstartswitha =\n                stringlist\n                        .stream()\n                        .allmatch((s) -> s.startswith("a"));\n\n        system.out.println(allstartswitha);      // false\n\n        boolean nonestartswithz =\n                stringlist\n                        .stream()\n                        .nonematch((s) -> s.startswith("z"));\n\n        system.out.println(nonestartswithz);      // true\n\n\n\n# count(计数)\n\n计数是一个 最终操作，返回 stream 中元素的个数，返回值类型是 long。\n\n      //测试 count (计数)操作\n        long startswithb =\n                stringlist\n                        .stream()\n                        .filter((s) -> s.startswith("b"))\n                        .count();\n        system.out.println(startswithb);    // 3\n\n\n\n# reduce(规约)\n\n这是一个 最终操作 ，允许通过指定的函数来将 stream 中的多个元素规约为一个元素，规约后的结果是通过 optional 接口表示的：\n\n        //测试 reduce (规约)操作\n        optional<string> reduced =\n                stringlist\n                        .stream()\n                        .sorted()\n                        .reduce((s1, s2) -> s1 + "#" + s2);\n\n        reduced.ifpresent(system.out::println);//aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2\n\n\n译者注： 这个方法的主要作用是把 stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（binaryoperator），和前面 stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。例如 stream 的 sum 就相当于integer sum = integers.reduce(0, (a, b) -> a+b);也有没有起始值的情况，这时会把 stream 的前面两个元素组合起来，返回的是 optional。\n\n// 字符串连接，concat = "abcd"\nstring concat = stream.of("a", "b", "c", "d").reduce("", string::concat);\n// 求最小值，minvalue = -3.0\ndouble minvalue = stream.of(-1.5, 1.0, -3.0, -2.0).reduce(double.max_value, double::min);\n// 求和，sumvalue = 10, 有起始值\nint sumvalue = stream.of(1, 2, 3, 4).reduce(0, integer::sum);\n// 求和，sumvalue = 10, 无起始值\nsumvalue = stream.of(1, 2, 3, 4).reduce(integer::sum).get();\n// 过滤，字符串连接，concat = "ace"\nconcat = stream.of("a", "b", "c", "d", "e", "f").\n filter(x -> x.compareto("z") > 0).\n reduce("", string::concat);\n\n\n上面代码例如第一个示例的 reduce()，第一个参数（空白字符）即为起始值，第二个参数（string::concat）为 binaryoperator。这类有起始值的 reduce() 都返回具体的对象。而对于第四个示例没有起始值的 reduce()，由于可能没有足够的元素，返回的是 optional，请留意这个区别。更多内容查看：ibm：java 8 中的 streams api 详解\n\n\n# parallel streams(并行流)\n\n前面提到过 stream 有串行和并行两种，串行 stream 上的操作是在一个线程中依次完成，而并行 stream 则是在多个线程上同时执行。\n\n下面的例子展示了是如何通过并行 stream 来提升性能：\n\n首先我们创建一个没有重复元素的大表：\n\nint max = 1000000;\nlist<string> values = new arraylist<>(max);\nfor (int i = 0; i < max; i++) {\n    uuid uuid = uuid.randomuuid();\n    values.add(uuid.tostring());\n}\n\n\n我们分别用串行和并行两种方式对其进行排序，最后看看所用时间的对比。\n\n\n# sequential sort(串行排序)\n\n//串行排序\nlong t0 = system.nanotime();\nlong count = values.stream().sorted().count();\nsystem.out.println(count);\n\nlong t1 = system.nanotime();\n\nlong millis = timeunit.nanoseconds.tomillis(t1 - t0);\nsystem.out.println(string.format("sequential sort took: %d ms", millis));\n\n\n1000000\nsequential sort took: 709 ms//串行排序所用的时间\n\n\n\n# parallel sort(并行排序)\n\n//并行排序\nlong t0 = system.nanotime();\n\nlong count = values.parallelstream().sorted().count();\nsystem.out.println(count);\n\nlong t1 = system.nanotime();\n\nlong millis = timeunit.nanoseconds.tomillis(t1 - t0);\nsystem.out.println(string.format("parallel sort took: %d ms", millis));\n\n\n\n1000000\nparallel sort took: 475 ms//并行排序所用的时间\n\n\n上面两个代码几乎是一样的，但是并行版的快了 50% 左右，唯一需要做的改动就是将 stream() 改为parallelstream()。\n\n\n# maps\n\n前面提到过，map 类型不支持 streams，不过 map 提供了一些新的有用的方法来处理一些日常任务。map 接口本身没有可用的 stream()方法，但是你可以在键，值上创建专门的流或者通过 map.keyset().stream(),map.values().stream()和map.entryset().stream()。\n\n此外,maps 支持各种新的和有用的方法来执行常见任务。\n\nmap<integer, string> map = new hashmap<>();\n\nfor (int i = 0; i < 10; i++) {\n    map.putifabsent(i, "val" + i);\n}\n\nmap.foreach((id, val) -> system.out.println(val));//val0 val1 val2 val3 val4 val5 val6 val7 val8 val9\n\n\nputifabsent 阻止我们在 null 检查时写入额外的代码;foreach接受一个 consumer 来对 map 中的每个元素操作。\n\n此示例显示如何使用函数在 map 上计算代码：\n\nmap.computeifpresent(3, (num, val) -> val + num);\nmap.get(3);             // val33\n\nmap.computeifpresent(9, (num, val) -> null);\nmap.containskey(9);     // false\n\nmap.computeifabsent(23, num -> "val" + num);\nmap.containskey(23);    // true\n\nmap.computeifabsent(3, num -> "bam");\nmap.get(3);             // val33\n\n\n接下来展示如何在 map 里删除一个键值全都匹配的项：\n\nmap.remove(3, "val3");\nmap.get(3);             // val33\nmap.remove(3, "val33");\nmap.get(3);             // null\n\n\n另外一个有用的方法：\n\nmap.getordefault(42, "not found");  // not found\n\n\n对 map 的元素做合并也变得很容易了：\n\nmap.merge(9, "val9", (value, newvalue) -> value.concat(newvalue));\nmap.get(9);             // val9\nmap.merge(9, "concat", (value, newvalue) -> value.concat(newvalue));\nmap.get(9);             // val9concat\n\n\nmerge 做的事情是如果键名不存在则插入，否则对原键对应的值做合并操作并重新插入到 map 中。\n\n\n# date api(日期相关 api)\n\njava 8 在 java.time 包下包含一个全新的日期和时间 api。新的 date api 与 joda-time 库相似，但它们不一样。以下示例涵盖了此新 api 的最重要部分。译者对这部分内容参考相关书籍做了大部分修改。\n\n译者注(总结)：\n\n * clock 类提供了访问当前日期和时间的方法，clock 是时区敏感的，可以用来取代 system.currenttimemillis() 来获取当前的微秒数。某一个特定的时间点也可以使用 instant 类来表示，instant 类也可以用来创建旧版本的java.util.date 对象。\n\n * 在新 api 中时区使用 zoneid 来表示。时区可以很方便的使用静态方法 of 来获取到。 抽象类zoneid（在java.time包中）表示一个区域标识符。 它有一个名为getavailablezoneids的静态方法，它返回所有区域标识符。\n\n * jdk1.8 中新增了 localdate 与 localdatetime 等类来解决日期处理方法，同时引入了一个新的类 datetimeformatter 来解决日期格式化问题。可以使用 instant 代替 date，localdatetime 代替 calendar，datetimeformatter 代替 simpledateformat。\n\n\n# clock\n\nclock 类提供了访问当前日期和时间的方法，clock 是时区敏感的，可以用来取代 system.currenttimemillis() 来获取当前的微秒数。某一个特定的时间点也可以使用 instant 类来表示，instant 类也可以用来创建旧版本的java.util.date 对象。\n\nclock clock = clock.systemdefaultzone();\nlong millis = clock.millis();\nsystem.out.println(millis);//1552379579043\ninstant instant = clock.instant();\nsystem.out.println(instant);\ndate legacydate = date.from(instant); //2019-03-12t08:46:42.588z\nsystem.out.println(legacydate);//tue mar 12 16:32:59 cst 2019\n\n\n\n# timezones(时区)\n\n在新 api 中时区使用 zoneid 来表示。时区可以很方便的使用静态方法 of 来获取到。 抽象类zoneid（在java.time包中）表示一个区域标识符。 它有一个名为getavailablezoneids的静态方法，它返回所有区域标识符。\n\n//输出所有区域标识符\nsystem.out.println(zoneid.getavailablezoneids());\n\nzoneid zone1 = zoneid.of("europe/berlin");\nzoneid zone2 = zoneid.of("brazil/east");\nsystem.out.println(zone1.getrules());// zonerules[currentstandardoffset=+01:00]\nsystem.out.println(zone2.getrules());// zonerules[currentstandardoffset=-03:00]\n\n\n\n# localtime(本地时间)\n\nlocaltime 定义了一个没有时区信息的时间，例如 晚上 10 点或者 17:30:15。下面的例子使用前面代码创建的时区创建了两个本地时间。之后比较时间并以小时和分钟为单位计算两个时间的时间差：\n\nlocaltime now1 = localtime.now(zone1);\nlocaltime now2 = localtime.now(zone2);\nsystem.out.println(now1.isbefore(now2));  // false\n\nlong hoursbetween = chronounit.hours.between(now1, now2);\nlong minutesbetween = chronounit.minutes.between(now1, now2);\n\nsystem.out.println(hoursbetween);       // -3\nsystem.out.println(minutesbetween);     // -239\n\n\nlocaltime 提供了多种工厂方法来简化对象的创建，包括解析时间字符串.\n\nlocaltime late = localtime.of(23, 59, 59);\nsystem.out.println(late);       // 23:59:59\ndatetimeformatter germanformatter =\n    datetimeformatter\n        .oflocalizedtime(formatstyle.short)\n        .withlocale(locale.german);\n\nlocaltime leettime = localtime.parse("13:37", germanformatter);\nsystem.out.println(leettime);   // 13:37\n\n\n\n# localdate(本地日期)\n\nlocaldate 表示了一个确切的日期，比如 2014-03-11。该对象值是不可变的，用起来和 localtime 基本一致。下面的例子展示了如何给 date 对象加减天/月/年。另外要注意的是这些对象是不可变的，操作返回的总是一个新实例。\n\nlocaldate today = localdate.now();//获取现在的日期\nsystem.out.println("今天的日期: "+today);//2019-03-12\nlocaldate tomorrow = today.plus(1, chronounit.days);\nsystem.out.println("明天的日期: "+tomorrow);//2019-03-13\nlocaldate yesterday = tomorrow.minusdays(2);\nsystem.out.println("昨天的日期: "+yesterday);//2019-03-11\nlocaldate independenceday = localdate.of(2019, month.march, 12);\ndayofweek dayofweek = independenceday.getdayofweek();\nsystem.out.println("今天是周几:"+dayofweek);//tuesday\n\n\n从字符串解析一个 localdate 类型和解析 localtime 一样简单,下面是使用 datetimeformatter 解析字符串的例子：\n\n    string str1 = "2014==04==12 01时06分09秒";\n        // 根据需要解析的日期、时间字符串定义解析所用的格式器\n        datetimeformatter fomatter1 = datetimeformatter\n                .ofpattern("yyyy==mm==dd hh时mm分ss秒");\n\n        localdatetime dt1 = localdatetime.parse(str1, fomatter1);\n        system.out.println(dt1); // 输出 2014-04-12t01:06:09\n\n        string str2 = "2014$$$四月$$$13 20小时";\n        datetimeformatter fomatter2 = datetimeformatter\n                .ofpattern("yyy$$$mmm$$$dd hh小时");\n        localdatetime dt2 = localdatetime.parse(str2, fomatter2);\n        system.out.println(dt2); // 输出 2014-04-13t20:00\n\n\n\n再来看一个使用 datetimeformatter 格式化日期的示例\n\nlocaldatetime rightnow=localdatetime.now();\nstring date=datetimeformatter.iso_local_date_time.format(rightnow);\nsystem.out.println(date);//2019-03-12t16:26:48.29\ndatetimeformatter formatter=datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss");\nsystem.out.println(formatter.format(rightnow));//2019-03-12 16:26:48\n\n\n🐛 修正（参见：issue#1157）：使用 yyyy 显示年份时，会显示当前时间所在周的年份，在跨年周会有问题。一般情况下都使用 yyyy，来显示准确的年份。\n\n跨年导致日期显示错误示例：\n\nlocaldatetime rightnow = localdatetime.of(2020, 12, 31, 12, 0, 0);\nstring date= datetimeformatter.iso_local_date_time.format(rightnow);\n// 2020-12-31t12:00:00\nsystem.out.println(date);\ndatetimeformatter formatterofyyyy = datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss");\n// 2021-12-31 12:00:00\nsystem.out.println(formatterofyyyy.format(rightnow));\n\ndatetimeformatter formatterofyyyy = datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss");\n// 2020-12-31 12:00:00\nsystem.out.println(formatterofyyyy.format(rightnow));\n\n\n从下图可以更清晰的看到具体的错误，并且 idea 已经智能地提示更倾向于使用 yyyy 而不是 yyyy 。\n\n\n\n\n# localdatetime(本地日期时间)\n\nlocaldatetime 同时表示了时间和日期，相当于前两节内容合并到一个对象上了。localdatetime 和 localtime 还有 localdate 一样，都是不可变的。localdatetime 提供了一些能访问具体字段的方法。\n\nlocaldatetime sylvester = localdatetime.of(2014, month.december, 31, 23, 59, 59);\n\ndayofweek dayofweek = sylvester.getdayofweek();\nsystem.out.println(dayofweek);      // wednesday\n\nmonth month = sylvester.getmonth();\nsystem.out.println(month);          // december\n\nlong minuteofday = sylvester.getlong(chronofield.minute_of_day);\nsystem.out.println(minuteofday);    // 1439\n\n\n只要附加上时区信息，就可以将其转换为一个时间点 instant 对象，instant 时间点对象可以很容易的转换为老式的java.util.date。\n\ninstant instant = sylvester\n        .atzone(zoneid.systemdefault())\n        .toinstant();\n\ndate legacydate = date.from(instant);\nsystem.out.println(legacydate);     // wed dec 31 23:59:59 cet 2014\n\n\n格式化 localdatetime 和格式化时间和日期一样的，除了使用预定义好的格式外，我们也可以自己定义格式：\n\ndatetimeformatter formatter =\n    datetimeformatter\n        .ofpattern("mmm dd, yyyy - hh:mm");\nlocaldatetime parsed = localdatetime.parse("nov 03, 2014 - 07:13", formatter);\nstring string = formatter.format(parsed);\nsystem.out.println(string);     // nov 03, 2014 - 07:13\n\n\n和 java.text.numberformat 不一样的是新版的 datetimeformatter 是不可变的，所以它是线程安全的。 关于时间日期格式的详细信息在这里。\n\n\n# annotations(注解)\n\n在 java 8 中支持多重注解了，先看个例子来理解一下是什么意思。 首先定义一个包装类 hints 注解用来放置一组具体的 hint 注解：\n\n@retention(retentionpolicy.runtime)\n@interface hints {\n    hint[] value();\n}\n@repeatable(hints.class)\n@interface hint {\n    string value();\n}\n\n\njava 8 允许我们把同一个类型的注解使用多次，只需要给该注解标注一下@repeatable即可。\n\n例 1: 使用包装类当容器来存多个注解（老方法）\n\n@hints({@hint("hint1"), @hint("hint2")})\nclass person {}\n\n\n例 2：使用多重注解（新方法）\n\n@hint("hint1")\n@hint("hint2")\nclass person {}\n\n\n第二个例子里 java 编译器会隐性的帮你定义好@hints 注解，了解这一点有助于你用反射来获取这些信息：\n\nhint hint = person.class.getannotation(hint.class);\nsystem.out.println(hint);                   // null\nhints hints1 = person.class.getannotation(hints.class);\nsystem.out.println(hints1.value().length);  // 2\n\nhint[] hints2 = person.class.getannotationsbytype(hint.class);\nsystem.out.println(hints2.length);          // 2\n\n\n即便我们没有在 person类上定义 @hints注解，我们还是可以通过 getannotation(hints.class)来获取 @hints注解，更加方便的方法是使用 getannotationsbytype 可以直接获取到所有的@hint注解。 另外 java 8 的注解还增加到两种新的 target 上了：\n\n@target({elementtype.type_parameter, elementtype.type_use})\n@interface myannotation {}\n\n\n\n# where to go from here?\n\n关于 java 8 的新特性就写到这了，肯定还有更多的特性等待发掘。jdk 1.8 里还有很多很有用的东西，比如arrays.parallelsort, stampedlock和completablefuture等等。',charsets:{cjk:!0}},{title:"Java 9 新特性概览",frontmatter:{title:"Java 9 新特性概览",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:05:56.000Z",permalink:"/pages/1091ad/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/03.java9.html",relativePath:"01.Java基础/05.版本新特性/03.java9.md",key:"v-2dd572b2",path:"/pages/1091ad/",headers:[{level:2,title:"JShell",slug:"jshell",normalizedTitle:"jshell",charIndex:360},{level:2,title:"模块化系统",slug:"模块化系统",normalizedTitle:"模块化系统",charIndex:288},{level:2,title:"G1 成为默认垃圾回收器",slug:"g1-成为默认垃圾回收器",normalizedTitle:"g1 成为默认垃圾回收器",charIndex:305},{level:2,title:"快速创建不可变集合",slug:"快速创建不可变集合",normalizedTitle:"快速创建不可变集合",charIndex:1863},{level:2,title:"String 存储结构优化",slug:"string-存储结构优化",normalizedTitle:"string 存储结构优化",charIndex:2125},{level:2,title:"接口私有方法",slug:"接口私有方法",normalizedTitle:"接口私有方法",charIndex:2406},{level:2,title:"try-with-resources 增强",slug:"try-with-resources-增强",normalizedTitle:"try-with-resources 增强",charIndex:2545},{level:2,title:"Stream & Optional 增强",slug:"stream-optional-增强",normalizedTitle:"stream &amp; optional 增强",charIndex:null},{level:2,title:"进程 API",slug:"进程-api",normalizedTitle:"进程 api",charIndex:5104},{level:2,title:"响应式流 （ Reactive Streams ）",slug:"响应式流-reactive-streams",normalizedTitle:"响应式流 （ reactive streams ）",charIndex:5393},{level:2,title:"变量句柄",slug:"变量句柄",normalizedTitle:"变量句柄",charIndex:330},{level:2,title:"其它",slug:"其它",normalizedTitle:"其它",charIndex:6024},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:1544}],headersStr:"JShell 模块化系统 G1 成为默认垃圾回收器 快速创建不可变集合 String 存储结构优化 接口私有方法 try-with-resources 增强 Stream & Optional 增强 进程 API 响应式流 （ Reactive Streams ） 变量句柄 其它 参考",content:'Java 9 发布于 2017 年 9 月 21 日 。作为 Java 8 之后 3 年半才发布的新版本，Java 9 带来了很多重大的变化其中最重要的改动是 Java 平台模块系统的引入，其他还有诸如集合、Stream 流……。\n\n你可以在 Archived OpenJDK General-Availability Releases 上下载自己需要的 JDK 版本！官方的新特性说明文档地址：https://openjdk.java.net/projects/jdk/ 。\n\n概览（精选了一部分）：\n\n * JEP 222: Java 命令行工具\n * JEP 261: 模块化系统\n * JEP 248：G1 成为默认垃圾回收器\n * JEP 193: 变量句柄\n * JEP 254：字符串存储结构优化\n\n\n# JShell\n\nJShell 是 Java 9 新增的一个实用工具。为 Java 提供了类似于 Python 的实时命令行交互工具。\n\n在 JShell 中可以直接输入表达式并查看其执行结果。\n\n\n\nJShell 为我们带来了哪些好处呢？\n\n 1. 降低了输出第一行 Java 版"Hello World！"的门槛，能够提高新手的学习热情。\n 2. 在处理简单的小逻辑，验证简单的小问题时，比 IDE 更有效率（并不是为了取代 IDE，对于复杂逻辑的验证，IDE 更合适，两者互补）。\n 3. ……\n\nJShell 的代码和普通的可编译代码，有什么不一样？\n\n 1. 一旦语句输入完成，JShell 立即就能返回执行的结果，而不再需要编辑器、编译器、解释器。\n 2. JShell 支持变量的重复声明，后面声明的会覆盖前面声明的。\n 3. JShell 支持独立的表达式比如普通的加法运算 1 + 1。\n 4. ……\n\n\n# 模块化系统\n\n模块系统是Jigsaw Project的一部分，把模块化开发实践引入到了 Java 平台中，可以让我们的代码可重用性更好！\n\n什么是模块系统？ 官方的定义是：\n\n> A uniquely named, reusable group of related packages, as well as resources (such as images and XML files) and a module descriptor。\n\n简单来说，你可以将一个模块看作是一组唯一命名、可重用的包、资源和模块描述文件（module-info.java）。\n\n任意一个 jar 文件，只要加上一个模块描述文件（module-info.java），就可以升级为一个模块。\n\n\n\n在引入了模块系统之后，JDK 被重新组织成 94 个模块。Java 应用可以通过新增的 jlink 工具 (Jlink 是随 Java 9 一起发布的新命令行工具。它允许开发人员为基于模块的 Java 应用程序创建自己的轻量级、定制的 JRE)，创建出只包含所依赖的 JDK 模块的自定义运行时镜像。这样可以极大的减少 Java 运行时环境的大小。\n\n我们可以通过 exports 关键词精准控制哪些类可以对外开放使用，哪些类只能内部使用。\n\nmodule my.module {\n    //exports 公开指定包的所有公共成员\n    exports com.my.package.name;\n}\n\nmodule my.module {\n     //exports…to 限制访问的成员范围\n    export com.my.package.name to com.specific.package;\n}\n\n\n想要深入了解 Java 9 的模块化，可以参考下面这几篇文章：\n\n * 《Project Jigsaw: Module System Quick-Start Guide》\n * 《Java 9 Modules: part 1》\n * Java 9 揭秘（2. 模块化系统）\n\n\n# G1 成为默认垃圾回收器\n\n在 Java 8 的时候，默认垃圾回收器是 Parallel Scavenge（新生代）+Parallel Old（老年代）。到了 Java 9, CMS 垃圾回收器被废弃了，G1（Garbage-First Garbage Collector） 成为了默认垃圾回收器。\n\nG1 还是在 Java 7 中被引入的，经过两个版本优异的表现成为成为默认垃圾回收器。\n\n\n# 快速创建不可变集合\n\n增加了List.of()、Set.of()、Map.of() 和 Map.ofEntries()等工厂方法来创建不可变集合（有点参考 Guava 的味道）：\n\nList.of("Java", "C++");\nSet.of("Java", "C++");\nMap.of("Java", 1, "C++", 2);\n\n\n使用 of() 创建的集合为不可变集合，不能进行添加、删除、替换、 排序等操作，不然会报 java.lang.UnsupportedOperationException 异常。\n\n\n# String 存储结构优化\n\nJava 8 及之前的版本，String 一直是用 char[] 存储。在 Java 9 之后，String 的实现改用 byte[] 数组存储字符串，节省了空间。\n\npublic final class String implements java.io.Serializable,Comparable<String>, CharSequence {\n    // @Stable 注解表示变量最多被修改一次，称为“稳定的”。\n    @Stable\n    private final byte[] value;\n}\n\n\n\n# 接口私有方法\n\nJava 9 允许在接口中使用私有方法。这样的话，接口的使用就更加灵活了，有点像是一个简化版的抽象类。\n\npublic interface MyInterface {\n    private void methodPrivate(){\n    }\n}\n\n\n\n# try-with-resources 增强\n\n在 Java 9 之前，我们只能在 try-with-resources 块中声明变量：\n\ntry (Scanner scanner = new Scanner(new File("testRead.txt"));\n    PrintWriter writer = new PrintWriter(new File("testWrite.txt"))) {\n    // omitted\n}\n\n\n在 Java 9 之后，在 try-with-resources 语句中可以使用 effectively-final 变量。\n\nfinal Scanner scanner = new Scanner(new File("testRead.txt"));\nPrintWriter writer = new PrintWriter(new File("testWrite.txt"))\ntry (scanner;writer) {\n    // omitted\n}\n\n\n什么是 effectively-final 变量？ 简单来说就是没有被 final 修饰但是值在初始化后从未更改的变量。\n\n正如上面的代码所演示的那样，即使 writer 变量没有被显示声明为 final，但它在第一次被赋值后就不会改变了，因此，它就是 effectively-final 变量。\n\n\n# Stream & Optional 增强\n\nStream 中增加了新的方法 ofNullable()、dropWhile()、takeWhile() 以及 iterate() 方法的重载方法。\n\nJava 9 中的 ofNullable() 方 法允许我们创建一个单元素的 Stream，可以包含一个非空元素，也可以创建一个空 Stream。 而在 Java 8 中则不可以创建空的 Stream 。\n\nStream<String> stringStream = Stream.ofNullable("Java");\nSystem.out.println(stringStream.count());// 1\nStream<String> nullStream = Stream.ofNullable(null);\nSystem.out.println(nullStream.count());//0\n\n\ntakeWhile() 方法可以从 Stream 中依次获取满足条件的元素，直到不满足条件为止结束获取。\n\nList<Integer> integerList = List.of(11, 33, 66, 8, 9, 13);\nintegerList.stream().takeWhile(x -> x < 50).forEach(System.out::println);// 11 33\n\n\ndropWhile() 方法的效果和 takeWhile() 相反。\n\nList<Integer> integerList2 = List.of(11, 33, 66, 8, 9, 13);\nintegerList2.stream().dropWhile(x -> x < 50).forEach(System.out::println);// 66 8 9 13\n\n\niterate() 方法的新重载方法提供了一个 Predicate 参数 (判断条件)来决定什么时候结束迭代\n\npublic static<T> Stream<T> iterate(final T seed, final UnaryOperator<T> f) {\n}\n// 新增加的重载方法\npublic static<T> Stream<T> iterate(T seed, Predicate<? super T> hasNext, UnaryOperator<T> next) {\n\n}\n\n\n两者的使用对比如下，新的 iterate() 重载方法更加灵活一些。\n\n// 使用原始 iterate() 方法输出数字 1~10\nStream.iterate(1, i -> i + 1).limit(10).forEach(System.out::println);\n// 使用新的 iterate() 重载方法输出数字 1~10\nStream.iterate(1, i -> i <= 10, i -> i + 1).forEach(System.out::println);\n\n\nOptional 类中新增了 ifPresentOrElse()、or() 和 stream() 等方法\n\nifPresentOrElse() 方法接受两个参数 Consumer 和 Runnable ，如果 Optional 不为空调用 Consumer 参数，为空则调用 Runnable 参数。\n\npublic void ifPresentOrElse(Consumer<? super T> action, Runnable emptyAction)\n\nOptional<Object> objectOptional = Optional.empty();\nobjectOptional.ifPresentOrElse(System.out::println, () -> System.out.println("Empty!!!"));// Empty!!!\n\n\nor() 方法接受一个 Supplier 参数 ，如果 Optional 为空则返回 Supplier 参数指定的 Optional 值。\n\npublic Optional<T> or(Supplier<? extends Optional<? extends T>> supplier)\n\nOptional<Object> objectOptional = Optional.empty();\nobjectOptional.or(() -> Optional.of("java")).ifPresent(System.out::println);//java\n\n\n\n# 进程 API\n\nJava 9 增加了 java.lang.ProcessHandle 接口来实现对原生进程进行管理，尤其适合于管理长时间运行的进程。\n\n// 获取当前正在运行的 JVM 的进程\nProcessHandle currentProcess = ProcessHandle.current();\n// 输出进程的 id\nSystem.out.println(currentProcess.pid());\n// 输出进程的信息\nSystem.out.println(currentProcess.info());\n\n\nProcessHandle 接口概览：\n\n\n\n\n# 响应式流 （ Reactive Streams ）\n\n在 Java 9 中的 java.util.concurrent.Flow 类中新增了反应式流规范的核心接口 。\n\nFlow 中包含了 Flow.Publisher、Flow.Subscriber、Flow.Subscription 和 Flow.Processor 等 4 个核心接口。Java 9 还提供了SubmissionPublisher 作为Flow.Publisher 的一个实现。\n\n关于 Java 9 响应式流更详细的解读，推荐你看 Java 9 揭秘（17. Reactive Streams ）- 林本托 这篇文章。\n\n\n# 变量句柄\n\n变量句柄是一个变量或一组变量的引用，包括静态域，非静态域，数组元素和堆外数据结构中的组成部分等。\n\n变量句柄的含义类似于已有的方法句柄 MethodHandle ，由 Java 类 java.lang.invoke.VarHandle 来表示，可以使用类 java.lang.invoke.MethodHandles.Lookup 中的静态工厂方法来创建 VarHandle 对象。\n\nVarHandle 的出现替代了 java.util.concurrent.atomic 和 sun.misc.Unsafe 的部分操作。并且提供了一系列标准的内存屏障操作，用于更加细粒度的控制内存排序。在安全性、可用性、性能上都要优于现有的 API。\n\n\n# 其它\n\n * 平台日志 API 改进：Java 9 允许为 JDK 和应用配置同样的日志实现。新增了 System.LoggerFinder 用来管理 JDK 使 用的日志记录器实现。JVM 在运行时只有一个系统范围的 LoggerFinder 实例。我们可以通过添加自己的 System.LoggerFinder 实现来让 JDK 和应用使用 SLF4J 等其他日志记录框架。\n * CompletableFuture类增强：新增了几个新的方法（completeAsync ，orTimeout 等）。\n * Nashorn 引擎的增强：Nashorn 是从 Java8 开始引入的 JavaScript 引擎，Java9 对 Nashorn 做了些增强，实现了一些 ES6 的新特性（Java 11 中已经被弃用）。\n * I/O 流的新特性：增加了新的方法来读取和复制 InputStream 中包含的数据。\n * 改进应用的安全性能：Java 9 新增了 4 个 SHA- 3 哈希算法，SHA3-224、SHA3-256、SHA3-384 和 SHA3-512。\n * 改进方法句柄（Method Handle）：方法句柄从 Java7 开始引入，Java9 在类java.lang.invoke.MethodHandles 中新增了更多的静态方法来创建不同类型的方法句柄。\n * ……\n\n\n# 参考\n\n * Java version history：https://en.wikipedia.org/wiki/Java_version_history\n * Release Notes for JDK 9 and JDK 9 Update Releases : https://www.oracle.com/java/technologies/javase/9-all-relnotes.html\n * 《深入剖析 Java 新特性》-极客时间 - JShell：怎么快速验证简单的小问题？\n * New Features in Java 9: https://www.baeldung.com/new-java-9\n * Java – Try with Resources：https://www.baeldung.com/java-try-with-resources',normalizedContent:'java 9 发布于 2017 年 9 月 21 日 。作为 java 8 之后 3 年半才发布的新版本，java 9 带来了很多重大的变化其中最重要的改动是 java 平台模块系统的引入，其他还有诸如集合、stream 流……。\n\n你可以在 archived openjdk general-availability releases 上下载自己需要的 jdk 版本！官方的新特性说明文档地址：https://openjdk.java.net/projects/jdk/ 。\n\n概览（精选了一部分）：\n\n * jep 222: java 命令行工具\n * jep 261: 模块化系统\n * jep 248：g1 成为默认垃圾回收器\n * jep 193: 变量句柄\n * jep 254：字符串存储结构优化\n\n\n# jshell\n\njshell 是 java 9 新增的一个实用工具。为 java 提供了类似于 python 的实时命令行交互工具。\n\n在 jshell 中可以直接输入表达式并查看其执行结果。\n\n\n\njshell 为我们带来了哪些好处呢？\n\n 1. 降低了输出第一行 java 版"hello world！"的门槛，能够提高新手的学习热情。\n 2. 在处理简单的小逻辑，验证简单的小问题时，比 ide 更有效率（并不是为了取代 ide，对于复杂逻辑的验证，ide 更合适，两者互补）。\n 3. ……\n\njshell 的代码和普通的可编译代码，有什么不一样？\n\n 1. 一旦语句输入完成，jshell 立即就能返回执行的结果，而不再需要编辑器、编译器、解释器。\n 2. jshell 支持变量的重复声明，后面声明的会覆盖前面声明的。\n 3. jshell 支持独立的表达式比如普通的加法运算 1 + 1。\n 4. ……\n\n\n# 模块化系统\n\n模块系统是jigsaw project的一部分，把模块化开发实践引入到了 java 平台中，可以让我们的代码可重用性更好！\n\n什么是模块系统？ 官方的定义是：\n\n> a uniquely named, reusable group of related packages, as well as resources (such as images and xml files) and a module descriptor。\n\n简单来说，你可以将一个模块看作是一组唯一命名、可重用的包、资源和模块描述文件（module-info.java）。\n\n任意一个 jar 文件，只要加上一个模块描述文件（module-info.java），就可以升级为一个模块。\n\n\n\n在引入了模块系统之后，jdk 被重新组织成 94 个模块。java 应用可以通过新增的 jlink 工具 (jlink 是随 java 9 一起发布的新命令行工具。它允许开发人员为基于模块的 java 应用程序创建自己的轻量级、定制的 jre)，创建出只包含所依赖的 jdk 模块的自定义运行时镜像。这样可以极大的减少 java 运行时环境的大小。\n\n我们可以通过 exports 关键词精准控制哪些类可以对外开放使用，哪些类只能内部使用。\n\nmodule my.module {\n    //exports 公开指定包的所有公共成员\n    exports com.my.package.name;\n}\n\nmodule my.module {\n     //exports…to 限制访问的成员范围\n    export com.my.package.name to com.specific.package;\n}\n\n\n想要深入了解 java 9 的模块化，可以参考下面这几篇文章：\n\n * 《project jigsaw: module system quick-start guide》\n * 《java 9 modules: part 1》\n * java 9 揭秘（2. 模块化系统）\n\n\n# g1 成为默认垃圾回收器\n\n在 java 8 的时候，默认垃圾回收器是 parallel scavenge（新生代）+parallel old（老年代）。到了 java 9, cms 垃圾回收器被废弃了，g1（garbage-first garbage collector） 成为了默认垃圾回收器。\n\ng1 还是在 java 7 中被引入的，经过两个版本优异的表现成为成为默认垃圾回收器。\n\n\n# 快速创建不可变集合\n\n增加了list.of()、set.of()、map.of() 和 map.ofentries()等工厂方法来创建不可变集合（有点参考 guava 的味道）：\n\nlist.of("java", "c++");\nset.of("java", "c++");\nmap.of("java", 1, "c++", 2);\n\n\n使用 of() 创建的集合为不可变集合，不能进行添加、删除、替换、 排序等操作，不然会报 java.lang.unsupportedoperationexception 异常。\n\n\n# string 存储结构优化\n\njava 8 及之前的版本，string 一直是用 char[] 存储。在 java 9 之后，string 的实现改用 byte[] 数组存储字符串，节省了空间。\n\npublic final class string implements java.io.serializable,comparable<string>, charsequence {\n    // @stable 注解表示变量最多被修改一次，称为“稳定的”。\n    @stable\n    private final byte[] value;\n}\n\n\n\n# 接口私有方法\n\njava 9 允许在接口中使用私有方法。这样的话，接口的使用就更加灵活了，有点像是一个简化版的抽象类。\n\npublic interface myinterface {\n    private void methodprivate(){\n    }\n}\n\n\n\n# try-with-resources 增强\n\n在 java 9 之前，我们只能在 try-with-resources 块中声明变量：\n\ntry (scanner scanner = new scanner(new file("testread.txt"));\n    printwriter writer = new printwriter(new file("testwrite.txt"))) {\n    // omitted\n}\n\n\n在 java 9 之后，在 try-with-resources 语句中可以使用 effectively-final 变量。\n\nfinal scanner scanner = new scanner(new file("testread.txt"));\nprintwriter writer = new printwriter(new file("testwrite.txt"))\ntry (scanner;writer) {\n    // omitted\n}\n\n\n什么是 effectively-final 变量？ 简单来说就是没有被 final 修饰但是值在初始化后从未更改的变量。\n\n正如上面的代码所演示的那样，即使 writer 变量没有被显示声明为 final，但它在第一次被赋值后就不会改变了，因此，它就是 effectively-final 变量。\n\n\n# stream & optional 增强\n\nstream 中增加了新的方法 ofnullable()、dropwhile()、takewhile() 以及 iterate() 方法的重载方法。\n\njava 9 中的 ofnullable() 方 法允许我们创建一个单元素的 stream，可以包含一个非空元素，也可以创建一个空 stream。 而在 java 8 中则不可以创建空的 stream 。\n\nstream<string> stringstream = stream.ofnullable("java");\nsystem.out.println(stringstream.count());// 1\nstream<string> nullstream = stream.ofnullable(null);\nsystem.out.println(nullstream.count());//0\n\n\ntakewhile() 方法可以从 stream 中依次获取满足条件的元素，直到不满足条件为止结束获取。\n\nlist<integer> integerlist = list.of(11, 33, 66, 8, 9, 13);\nintegerlist.stream().takewhile(x -> x < 50).foreach(system.out::println);// 11 33\n\n\ndropwhile() 方法的效果和 takewhile() 相反。\n\nlist<integer> integerlist2 = list.of(11, 33, 66, 8, 9, 13);\nintegerlist2.stream().dropwhile(x -> x < 50).foreach(system.out::println);// 66 8 9 13\n\n\niterate() 方法的新重载方法提供了一个 predicate 参数 (判断条件)来决定什么时候结束迭代\n\npublic static<t> stream<t> iterate(final t seed, final unaryoperator<t> f) {\n}\n// 新增加的重载方法\npublic static<t> stream<t> iterate(t seed, predicate<? super t> hasnext, unaryoperator<t> next) {\n\n}\n\n\n两者的使用对比如下，新的 iterate() 重载方法更加灵活一些。\n\n// 使用原始 iterate() 方法输出数字 1~10\nstream.iterate(1, i -> i + 1).limit(10).foreach(system.out::println);\n// 使用新的 iterate() 重载方法输出数字 1~10\nstream.iterate(1, i -> i <= 10, i -> i + 1).foreach(system.out::println);\n\n\noptional 类中新增了 ifpresentorelse()、or() 和 stream() 等方法\n\nifpresentorelse() 方法接受两个参数 consumer 和 runnable ，如果 optional 不为空调用 consumer 参数，为空则调用 runnable 参数。\n\npublic void ifpresentorelse(consumer<? super t> action, runnable emptyaction)\n\noptional<object> objectoptional = optional.empty();\nobjectoptional.ifpresentorelse(system.out::println, () -> system.out.println("empty!!!"));// empty!!!\n\n\nor() 方法接受一个 supplier 参数 ，如果 optional 为空则返回 supplier 参数指定的 optional 值。\n\npublic optional<t> or(supplier<? extends optional<? extends t>> supplier)\n\noptional<object> objectoptional = optional.empty();\nobjectoptional.or(() -> optional.of("java")).ifpresent(system.out::println);//java\n\n\n\n# 进程 api\n\njava 9 增加了 java.lang.processhandle 接口来实现对原生进程进行管理，尤其适合于管理长时间运行的进程。\n\n// 获取当前正在运行的 jvm 的进程\nprocesshandle currentprocess = processhandle.current();\n// 输出进程的 id\nsystem.out.println(currentprocess.pid());\n// 输出进程的信息\nsystem.out.println(currentprocess.info());\n\n\nprocesshandle 接口概览：\n\n\n\n\n# 响应式流 （ reactive streams ）\n\n在 java 9 中的 java.util.concurrent.flow 类中新增了反应式流规范的核心接口 。\n\nflow 中包含了 flow.publisher、flow.subscriber、flow.subscription 和 flow.processor 等 4 个核心接口。java 9 还提供了submissionpublisher 作为flow.publisher 的一个实现。\n\n关于 java 9 响应式流更详细的解读，推荐你看 java 9 揭秘（17. reactive streams ）- 林本托 这篇文章。\n\n\n# 变量句柄\n\n变量句柄是一个变量或一组变量的引用，包括静态域，非静态域，数组元素和堆外数据结构中的组成部分等。\n\n变量句柄的含义类似于已有的方法句柄 methodhandle ，由 java 类 java.lang.invoke.varhandle 来表示，可以使用类 java.lang.invoke.methodhandles.lookup 中的静态工厂方法来创建 varhandle 对象。\n\nvarhandle 的出现替代了 java.util.concurrent.atomic 和 sun.misc.unsafe 的部分操作。并且提供了一系列标准的内存屏障操作，用于更加细粒度的控制内存排序。在安全性、可用性、性能上都要优于现有的 api。\n\n\n# 其它\n\n * 平台日志 api 改进：java 9 允许为 jdk 和应用配置同样的日志实现。新增了 system.loggerfinder 用来管理 jdk 使 用的日志记录器实现。jvm 在运行时只有一个系统范围的 loggerfinder 实例。我们可以通过添加自己的 system.loggerfinder 实现来让 jdk 和应用使用 slf4j 等其他日志记录框架。\n * completablefuture类增强：新增了几个新的方法（completeasync ，ortimeout 等）。\n * nashorn 引擎的增强：nashorn 是从 java8 开始引入的 javascript 引擎，java9 对 nashorn 做了些增强，实现了一些 es6 的新特性（java 11 中已经被弃用）。\n * i/o 流的新特性：增加了新的方法来读取和复制 inputstream 中包含的数据。\n * 改进应用的安全性能：java 9 新增了 4 个 sha- 3 哈希算法，sha3-224、sha3-256、sha3-384 和 sha3-512。\n * 改进方法句柄（method handle）：方法句柄从 java7 开始引入，java9 在类java.lang.invoke.methodhandles 中新增了更多的静态方法来创建不同类型的方法句柄。\n * ……\n\n\n# 参考\n\n * java version history：https://en.wikipedia.org/wiki/java_version_history\n * release notes for jdk 9 and jdk 9 update releases : https://www.oracle.com/java/technologies/javase/9-all-relnotes.html\n * 《深入剖析 java 新特性》-极客时间 - jshell：怎么快速验证简单的小问题？\n * new features in java 9: https://www.baeldung.com/new-java-9\n * java – try with resources：https://www.baeldung.com/java-try-with-resources',charsets:{cjk:!0}},{title:"Java 10 新特性概览",frontmatter:{title:"Java 10 新特性概览",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:04:46.000Z",permalink:"/pages/e43406/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/04.java10.html",relativePath:"01.Java基础/05.版本新特性/04.java10.md",key:"v-31d26f3c",path:"/pages/e43406/",headers:[{level:2,title:"局部变量类型推断(var)",slug:"局部变量类型推断-var",normalizedTitle:"局部变量类型推断(var)",charIndex:242},{level:2,title:"垃圾回收器接口",slug:"垃圾回收器接口",normalizedTitle:"垃圾回收器接口",charIndex:140},{level:2,title:"G1 并行 Full GC",slug:"g1-并行-full-gc",normalizedTitle:"g1 并行 full gc",charIndex:159},{level:2,title:"集合增强",slug:"集合增强",normalizedTitle:"集合增强",charIndex:1326},{level:2,title:"Optional 增强",slug:"optional-增强",normalizedTitle:"optional 增强",charIndex:1804},{level:2,title:"应用程序类数据共享(扩展 CDS 功能)",slug:"应用程序类数据共享-扩展-cds-功能",normalizedTitle:"应用程序类数据共享(扩展 cds 功能)",charIndex:184},{level:2,title:"实验性的基于 Java 的 JIT 编译器",slug:"实验性的基于-java-的-jit-编译器",normalizedTitle:"实验性的基于 java 的 jit 编译器",charIndex:216},{level:2,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:60},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:3012}],headersStr:"局部变量类型推断(var) 垃圾回收器接口 G1 并行 Full GC 集合增强 Optional 增强 应用程序类数据共享(扩展 CDS 功能) 实验性的基于 Java 的 JIT 编译器 其他 参考",content:'Java 10 发布于 2018 年 3 月 20 日，最知名的特性应该是 var 关键字（局部变量类型推断）的引入了，其他还有垃圾收集器改善、GC 改进、性能提升、线程管控等一批新特性。\n\n概览（精选了一部分）：\n\n * JEP 286：局部变量类型推断\n * JEP 304：垃圾回收器接口\n * JEP 307：G1 并行 Full GC\n * JEP 310：应用程序类数据共享(扩展 CDS 功能)\n * JEP 317：实验性的基于 Java 的 JIT 编译器\n\n\n# 局部变量类型推断(var)\n\n由于太多 Java 开发者希望 Java 中引入局部变量推断，于是 Java 10 的时候它来了，也算是众望所归了！\n\nJava 10 提供了 var 关键字声明局部变量。\n\nvar id = 0;\nvar codefx = new URL("https://mp.weixin.qq.com/");\nvar list = new ArrayList<>();\nvar list = List.of(1, 2, 3);\nvar map = new HashMap<String, String>();\nvar p = Paths.of("src/test/java/Java9FeaturesTest.java");\nvar numbers = List.of("a", "b", "c");\nfor (var n : list)\n    System.out.print(n+ " ");\n\n\nvar 关键字只能用于带有构造器的局部变量和 for 循环中。\n\nvar count=null; //❌编译不通过，不能声明为 null\nvar r = () -> Math.random();//❌编译不通过,不能声明为 Lambda表达式\nvar array = {1,2,3};//❌编译不通过,不能声明数组\n\n\nvar 并不会改变 Java 是一门静态类型语言的事实，编译器负责推断出类型。\n\n另外，Scala 和 Kotlin 中已经有了 val 关键字 ( final var 组合关键字)。\n\n相关阅读：《Java 10 新特性之局部变量类型推断》。\n\n\n# 垃圾回收器接口\n\n在早期的 JDK 结构中，组成垃圾收集器 (GC) 实现的组件分散在代码库的各个部分。 Java 10 通过引入一套纯净的垃圾收集器接口来将不同垃圾收集器的源代码分隔开。\n\n\n# G1 并行 Full GC\n\n从 Java9 开始 G1 就了默认的垃圾回收器，G1 是以一种低延时的垃圾回收器来设计的，旨在避免进行 Full GC,但是 Java9 的 G1 的 FullGC 依然是使用单线程去完成标记清除算法,这可能会导致垃圾回收期在无法回收内存的时候触发 Full GC。\n\n为了最大限度地减少 Full GC 造成的应用停顿的影响，从 Java10 开始，G1 的 FullGC 改为并行的标记清除算法，同时会使用与年轻代回收和混合回收相同的并行工作线程数量，从而减少了 Full GC 的发生，以带来更好的性能提升、更大的吞吐量。\n\n\n# 集合增强\n\nList，Set，Map 提供了静态方法copyOf()返回入参集合的一个不可变拷贝。\n\nstatic <E> List<E> copyOf(Collection<? extends E> coll) {\n    return ImmutableCollections.listCopy(coll);\n}\n\n\n使用 copyOf() 创建的集合为不可变集合，不能进行添加、删除、替换、 排序等操作，不然会报 java.lang.UnsupportedOperationException 异常。 IDEA 也会有相应的提示。\n\n\n\n并且，java.util.stream.Collectors 中新增了静态方法，用于将流中的元素收集为不可变的集合。\n\nvar list = new ArrayList<>();\nlist.stream().collect(Collectors.toUnmodifiableList());\nlist.stream().collect(Collectors.toUnmodifiableSet());\n\n\n\n# Optional 增强\n\nOptional 新增了orElseThrow()方法来在没有值时抛出指定的异常。\n\nOptional.ofNullable(cache.getIfPresent(key))\n        .orElseThrow(() -> new PrestoException(NOT_FOUND, "Missing entry found for key: " + key));\n\n\n\n# 应用程序类数据共享(扩展 CDS 功能)\n\n在 Java 5 中就已经引入了类数据共享机制 (Class Data Sharing，简称 CDS)，允许将一组类预处理为共享归档文件，以便在运行时能够进行内存映射以减少 Java 程序的启动时间，当多个 Java 虚拟机（JVM）共享相同的归档文件时，还可以减少动态内存的占用量，同时减少多个虚拟机在同一个物理或虚拟的机器上运行时的资源占用。CDS 在当时还是 Oracle JDK 的商业特性。\n\nJava 10 在现有的 CDS 功能基础上再次拓展，以允许应用类放置在共享存档中。CDS 特性在原来的 bootstrap 类基础之上，扩展加入了应用类的 CDS 为 (Application Class-Data Sharing，AppCDS) 支持，大大加大了 CDS 的适用范围。其原理为：在启动时记录加载类的过程，写入到文本文件中，再次启动时直接读取此启动文本并加载。设想如果应用环境没有大的变化，启动速度就会得到提升。\n\n\n# 实验性的基于 Java 的 JIT 编译器\n\nGraal 是一个基于 Java 语言编写的 JIT 编译器，是 JDK 9 中引入的实验性 Ahead-of-Time (AOT) 编译器的基础。\n\nOracle 的 HotSpot VM 便附带两个用 C++ 实现的 JIT compiler：C1 及 C2。在 Java 10 (Linux/x64, macOS/x64) 中，默认情况下 HotSpot 仍使用 C2，但通过向 java 命令添加 -XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler 参数便可将 C2 替换成 Graal。\n\n相关阅读：深入浅出 Java 10 的实验性 JIT 编译器 Graal - 郑雨迪\n\n\n# 其他\n\n * 线程-局部管控：Java 10 中线程管控引入 JVM 安全点的概念，将允许在不运行全局 JVM 安全点的情况下实现线程回调，由线程本身或者 JVM 线程来执行，同时保持线程处于阻塞状态，这种方式使得停止单个线程变成可能，而不是只能启用或停止所有线程\n * 备用存储装置上的堆分配：Java 10 中将使得 JVM 能够使用适用于不同类型的存储机制的堆，在可选内存设备上进行堆内存分配\n * ……\n\n\n# 参考\n\n * Java 10 Features and Enhancements : https://howtodoinjava.com/java10/java10-features/\n\n * Guide to Java10 : https://www.baeldung.com/java-10-overview\n\n * 4 Class Data Sharing : https://docs.oracle.com/javase/10/vm/class-data-sharing.htm#JSJVM-GUID-7EAA3411-8CF0-4D19-BD05-DF5E1780AA91',normalizedContent:'java 10 发布于 2018 年 3 月 20 日，最知名的特性应该是 var 关键字（局部变量类型推断）的引入了，其他还有垃圾收集器改善、gc 改进、性能提升、线程管控等一批新特性。\n\n概览（精选了一部分）：\n\n * jep 286：局部变量类型推断\n * jep 304：垃圾回收器接口\n * jep 307：g1 并行 full gc\n * jep 310：应用程序类数据共享(扩展 cds 功能)\n * jep 317：实验性的基于 java 的 jit 编译器\n\n\n# 局部变量类型推断(var)\n\n由于太多 java 开发者希望 java 中引入局部变量推断，于是 java 10 的时候它来了，也算是众望所归了！\n\njava 10 提供了 var 关键字声明局部变量。\n\nvar id = 0;\nvar codefx = new url("https://mp.weixin.qq.com/");\nvar list = new arraylist<>();\nvar list = list.of(1, 2, 3);\nvar map = new hashmap<string, string>();\nvar p = paths.of("src/test/java/java9featurestest.java");\nvar numbers = list.of("a", "b", "c");\nfor (var n : list)\n    system.out.print(n+ " ");\n\n\nvar 关键字只能用于带有构造器的局部变量和 for 循环中。\n\nvar count=null; //❌编译不通过，不能声明为 null\nvar r = () -> math.random();//❌编译不通过,不能声明为 lambda表达式\nvar array = {1,2,3};//❌编译不通过,不能声明数组\n\n\nvar 并不会改变 java 是一门静态类型语言的事实，编译器负责推断出类型。\n\n另外，scala 和 kotlin 中已经有了 val 关键字 ( final var 组合关键字)。\n\n相关阅读：《java 10 新特性之局部变量类型推断》。\n\n\n# 垃圾回收器接口\n\n在早期的 jdk 结构中，组成垃圾收集器 (gc) 实现的组件分散在代码库的各个部分。 java 10 通过引入一套纯净的垃圾收集器接口来将不同垃圾收集器的源代码分隔开。\n\n\n# g1 并行 full gc\n\n从 java9 开始 g1 就了默认的垃圾回收器，g1 是以一种低延时的垃圾回收器来设计的，旨在避免进行 full gc,但是 java9 的 g1 的 fullgc 依然是使用单线程去完成标记清除算法,这可能会导致垃圾回收期在无法回收内存的时候触发 full gc。\n\n为了最大限度地减少 full gc 造成的应用停顿的影响，从 java10 开始，g1 的 fullgc 改为并行的标记清除算法，同时会使用与年轻代回收和混合回收相同的并行工作线程数量，从而减少了 full gc 的发生，以带来更好的性能提升、更大的吞吐量。\n\n\n# 集合增强\n\nlist，set，map 提供了静态方法copyof()返回入参集合的一个不可变拷贝。\n\nstatic <e> list<e> copyof(collection<? extends e> coll) {\n    return immutablecollections.listcopy(coll);\n}\n\n\n使用 copyof() 创建的集合为不可变集合，不能进行添加、删除、替换、 排序等操作，不然会报 java.lang.unsupportedoperationexception 异常。 idea 也会有相应的提示。\n\n\n\n并且，java.util.stream.collectors 中新增了静态方法，用于将流中的元素收集为不可变的集合。\n\nvar list = new arraylist<>();\nlist.stream().collect(collectors.tounmodifiablelist());\nlist.stream().collect(collectors.tounmodifiableset());\n\n\n\n# optional 增强\n\noptional 新增了orelsethrow()方法来在没有值时抛出指定的异常。\n\noptional.ofnullable(cache.getifpresent(key))\n        .orelsethrow(() -> new prestoexception(not_found, "missing entry found for key: " + key));\n\n\n\n# 应用程序类数据共享(扩展 cds 功能)\n\n在 java 5 中就已经引入了类数据共享机制 (class data sharing，简称 cds)，允许将一组类预处理为共享归档文件，以便在运行时能够进行内存映射以减少 java 程序的启动时间，当多个 java 虚拟机（jvm）共享相同的归档文件时，还可以减少动态内存的占用量，同时减少多个虚拟机在同一个物理或虚拟的机器上运行时的资源占用。cds 在当时还是 oracle jdk 的商业特性。\n\njava 10 在现有的 cds 功能基础上再次拓展，以允许应用类放置在共享存档中。cds 特性在原来的 bootstrap 类基础之上，扩展加入了应用类的 cds 为 (application class-data sharing，appcds) 支持，大大加大了 cds 的适用范围。其原理为：在启动时记录加载类的过程，写入到文本文件中，再次启动时直接读取此启动文本并加载。设想如果应用环境没有大的变化，启动速度就会得到提升。\n\n\n# 实验性的基于 java 的 jit 编译器\n\ngraal 是一个基于 java 语言编写的 jit 编译器，是 jdk 9 中引入的实验性 ahead-of-time (aot) 编译器的基础。\n\noracle 的 hotspot vm 便附带两个用 c++ 实现的 jit compiler：c1 及 c2。在 java 10 (linux/x64, macos/x64) 中，默认情况下 hotspot 仍使用 c2，但通过向 java 命令添加 -xx:+unlockexperimentalvmoptions -xx:+usejvmcicompiler 参数便可将 c2 替换成 graal。\n\n相关阅读：深入浅出 java 10 的实验性 jit 编译器 graal - 郑雨迪\n\n\n# 其他\n\n * 线程-局部管控：java 10 中线程管控引入 jvm 安全点的概念，将允许在不运行全局 jvm 安全点的情况下实现线程回调，由线程本身或者 jvm 线程来执行，同时保持线程处于阻塞状态，这种方式使得停止单个线程变成可能，而不是只能启用或停止所有线程\n * 备用存储装置上的堆分配：java 10 中将使得 jvm 能够使用适用于不同类型的存储机制的堆，在可选内存设备上进行堆内存分配\n * ……\n\n\n# 参考\n\n * java 10 features and enhancements : https://howtodoinjava.com/java10/java10-features/\n\n * guide to java10 : https://www.baeldung.com/java-10-overview\n\n * 4 class data sharing : https://docs.oracle.com/javase/10/vm/class-data-sharing.htm#jsjvm-guid-7eaa3411-8cf0-4d19-bd05-df5e1780aa91',charsets:{cjk:!0}},{title:"Java 11 新特性概览",frontmatter:{title:"Java 11 新特性概览",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:04:53.000Z",permalink:"/pages/f37c60/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/05.java11.html",relativePath:"01.Java基础/05.版本新特性/05.java11.md",key:"v-4ad5cd7c",path:"/pages/f37c60/",headers:[{level:2,title:"HTTP Client 标准化",slug:"http-client-标准化",normalizedTitle:"http client 标准化",charIndex:277},{level:2,title:"String 增强",slug:"string-增强",normalizedTitle:"string 增强",charIndex:1060},{level:2,title:"Optional 增强",slug:"optional-增强",normalizedTitle:"optional 增强",charIndex:1434},{level:2,title:"ZGC(可伸缩低延迟垃圾收集器)",slug:"zgc-可伸缩低延迟垃圾收集器",normalizedTitle:"zgc(可伸缩低延迟垃圾收集器)",charIndex:304},{level:2,title:"Lambda 参数的局部变量语法",slug:"lambda-参数的局部变量语法",normalizedTitle:"lambda 参数的局部变量语法",charIndex:332},{level:2,title:"启动单文件源代码程序",slug:"启动单文件源代码程序",normalizedTitle:"启动单文件源代码程序",charIndex:360},{level:2,title:"其他新特性",slug:"其他新特性",normalizedTitle:"其他新特性",charIndex:2573},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:3016}],headersStr:"HTTP Client 标准化 String 增强 Optional 增强 ZGC(可伸缩低延迟垃圾收集器) Lambda 参数的局部变量语法 启动单文件源代码程序 其他新特性 参考",content:'Java 11 于 2018 年 9 月 25 日正式发布，这是很重要的一个版本！Java 11 和 2017 年 9 月份发布的 Java 9 以及 2018 年 3 月份发布的 Java 10 相比，其最大的区别就是：在长期支持(Long-Term-Support)方面，Oracle 表示会对 Java 11 提供大力支持，这一支持将会持续至 2026 年 9 月。这是据 Java 8 以后支持的首个长期版本。\n\n下面这张图是 Oracle 官方给出的 Oracle JDK 支持的时间线。\n\n\n\n概览（精选了一部分）：\n\n * JEP 321：HTTP Client 标准化\n * JEP 333：ZGC(可伸缩低延迟垃圾收集器)\n * JEP 323：Lambda 参数的局部变量语法\n * JEP 330：启动单文件源代码程序\n\n\n# HTTP Client 标准化\n\nJava 11 对 Java 9 中引入并在 Java 10 中进行了更新的 Http Client API 进行了标准化，在前两个版本中进行孵化的同时，Http Client 几乎被完全重写，并且现在完全支持异步非阻塞。\n\n并且，Java 11 中，Http Client 的包名由 jdk.incubator.http 改为java.net.http，该 API 通过 CompleteableFuture 提供非阻塞请求和响应语义。使用起来也很简单，如下：\n\nvar request = HttpRequest.newBuilder()\n    .uri(URI.create("https://javastack.cn"))\n    .GET()\n    .build();\nvar client = HttpClient.newHttpClient();\n\n// 同步\nHttpResponse<String> response = client.send(request, HttpResponse.BodyHandlers.ofString());\nSystem.out.println(response.body());\n\n// 异步\nclient.sendAsync(request, HttpResponse.BodyHandlers.ofString())\n    .thenApply(HttpResponse::body)\n    .thenAccept(System.out::println);\n\n\n\n# String 增强\n\nJava 11 增加了一系列的字符串处理方法：\n\n//判断字符串是否为空\n" ".isBlank();//true\n//去除字符串首尾空格\n" Java ".strip();// "Java"\n//去除字符串首部空格\n" Java ".stripLeading();   // "Java "\n//去除字符串尾部空格\n" Java ".stripTrailing();  // " Java"\n//重复字符串多少次\n"Java".repeat(3);             // "JavaJavaJava"\n//返回由行终止符分隔的字符串集合。\n"A\\nB\\nC".lines().count();    // 3\n"A\\nB\\nC".lines().collect(Collectors.toList());\n\n\n\n# Optional 增强\n\n新增了isEmpty()方法来判断指定的 Optional 对象是否为空。\n\nvar op = Optional.empty();\nSystem.out.println(op.isEmpty());//判断指定的 Optional 对象是否为空\n\n\n\n# ZGC(可伸缩低延迟垃圾收集器)\n\nZGC 即 Z Garbage Collector，是一个可伸缩的、低延迟的垃圾收集器。\n\nZGC 主要为了满足如下目标进行设计：\n\n * GC 停顿时间不超过 10ms\n * 即能处理几百 MB 的小堆，也能处理几个 TB 的大堆\n * 应用吞吐能力不会下降超过 15%（与 G1 回收算法相比）\n * 方便在此基础上引入新的 GC 特性和利用 colored 针以及 Load barriers 优化奠定基础\n * 当前只支持 Linux/x64 位平台\n\nZGC 目前 处在实验阶段，只支持 Linux/x64 平台。\n\n与 CMS 中的 ParNew 和 G1 类似，ZGC 也采用标记-复制算法，不过 ZGC 对该算法做了重大改进。\n\n在 ZGC 中出现 Stop The World 的情况会更少！\n\n详情可以看：《新一代垃圾回收器 ZGC 的探索与实践》\n\n\n# Lambda 参数的局部变量语法\n\n从 Java 10 开始，便引入了局部变量类型推断这一关键特性。类型推断允许使用关键字 var 作为局部变量的类型而不是实际类型，编译器根据分配给变量的值推断出类型。\n\nJava 10 中对 var 关键字存在几个限制\n\n * 只能用于局部变量上\n * 声明时必须初始化\n * 不能用作方法参数\n * 不能在 Lambda 表达式中使用\n\nJava11 开始允许开发者在 Lambda 表达式中使用 var 进行参数声明。\n\n// 下面两者是等价的\nConsumer<String> consumer = (var i) -> System.out.println(i);\nConsumer<String> consumer = (String i) -> System.out.println(i);\n\n\n\n# 启动单文件源代码程序\n\n这意味着我们可以运行单一文件的 Java 源代码。此功能允许使用 Java 解释器直接执行 Java 源代码。源代码在内存中编译，然后由解释器执行，不需要在磁盘上生成 .class 文件了。唯一的约束在于所有相关的类必须定义在同一个 Java 文件中。\n\n对于 Java 初学者并希望尝试简单程序的人特别有用，并且能和 jshell 一起使用。一定能程度上增强了使用 Java 来写脚本程序的能力。\n\n\n# 其他新特性\n\n * 新的垃圾回收器 Epsilon：一个完全消极的 GC 实现，分配有限的内存资源，最大限度的降低内存占用和内存吞吐延迟时间\n * 低开销的 Heap Profiling：Java 11 中提供一种低开销的 Java 堆分配采样方法，能够得到堆分配的 Java 对象信息，并且能够通过 JVMTI 访问堆信息\n * TLS1.3 协议：Java 11 中包含了传输层安全性（TLS）1.3 规范（RFC 8446）的实现，替换了之前版本中包含的 TLS，包括 TLS 1.2，同时还改进了其他 TLS 功能，例如 OCSP 装订扩展（RFC 6066，RFC 6961），以及会话散列和扩展主密钥扩展（RFC 7627），在安全性和性能方面也做了很多提升\n * 飞行记录器(Java Flight Recorder)：飞行记录器之前是商业版 JDK 的一项分析工具，但在 Java 11 中，其代码被包含到公开代码库中，这样所有人都能使用该功能了。\n * ……\n\n\n# 参考\n\n * JDK 11 Release Notes：https://www.oracle.com/java/technologies/javase/11-relnote-issues.html\n * Java 11 – Features and Comparison：https://www.geeksforgeeks.org/java-11-features-and-comparison/',normalizedContent:'java 11 于 2018 年 9 月 25 日正式发布，这是很重要的一个版本！java 11 和 2017 年 9 月份发布的 java 9 以及 2018 年 3 月份发布的 java 10 相比，其最大的区别就是：在长期支持(long-term-support)方面，oracle 表示会对 java 11 提供大力支持，这一支持将会持续至 2026 年 9 月。这是据 java 8 以后支持的首个长期版本。\n\n下面这张图是 oracle 官方给出的 oracle jdk 支持的时间线。\n\n\n\n概览（精选了一部分）：\n\n * jep 321：http client 标准化\n * jep 333：zgc(可伸缩低延迟垃圾收集器)\n * jep 323：lambda 参数的局部变量语法\n * jep 330：启动单文件源代码程序\n\n\n# http client 标准化\n\njava 11 对 java 9 中引入并在 java 10 中进行了更新的 http client api 进行了标准化，在前两个版本中进行孵化的同时，http client 几乎被完全重写，并且现在完全支持异步非阻塞。\n\n并且，java 11 中，http client 的包名由 jdk.incubator.http 改为java.net.http，该 api 通过 completeablefuture 提供非阻塞请求和响应语义。使用起来也很简单，如下：\n\nvar request = httprequest.newbuilder()\n    .uri(uri.create("https://javastack.cn"))\n    .get()\n    .build();\nvar client = httpclient.newhttpclient();\n\n// 同步\nhttpresponse<string> response = client.send(request, httpresponse.bodyhandlers.ofstring());\nsystem.out.println(response.body());\n\n// 异步\nclient.sendasync(request, httpresponse.bodyhandlers.ofstring())\n    .thenapply(httpresponse::body)\n    .thenaccept(system.out::println);\n\n\n\n# string 增强\n\njava 11 增加了一系列的字符串处理方法：\n\n//判断字符串是否为空\n" ".isblank();//true\n//去除字符串首尾空格\n" java ".strip();// "java"\n//去除字符串首部空格\n" java ".stripleading();   // "java "\n//去除字符串尾部空格\n" java ".striptrailing();  // " java"\n//重复字符串多少次\n"java".repeat(3);             // "javajavajava"\n//返回由行终止符分隔的字符串集合。\n"a\\nb\\nc".lines().count();    // 3\n"a\\nb\\nc".lines().collect(collectors.tolist());\n\n\n\n# optional 增强\n\n新增了isempty()方法来判断指定的 optional 对象是否为空。\n\nvar op = optional.empty();\nsystem.out.println(op.isempty());//判断指定的 optional 对象是否为空\n\n\n\n# zgc(可伸缩低延迟垃圾收集器)\n\nzgc 即 z garbage collector，是一个可伸缩的、低延迟的垃圾收集器。\n\nzgc 主要为了满足如下目标进行设计：\n\n * gc 停顿时间不超过 10ms\n * 即能处理几百 mb 的小堆，也能处理几个 tb 的大堆\n * 应用吞吐能力不会下降超过 15%（与 g1 回收算法相比）\n * 方便在此基础上引入新的 gc 特性和利用 colored 针以及 load barriers 优化奠定基础\n * 当前只支持 linux/x64 位平台\n\nzgc 目前 处在实验阶段，只支持 linux/x64 平台。\n\n与 cms 中的 parnew 和 g1 类似，zgc 也采用标记-复制算法，不过 zgc 对该算法做了重大改进。\n\n在 zgc 中出现 stop the world 的情况会更少！\n\n详情可以看：《新一代垃圾回收器 zgc 的探索与实践》\n\n\n# lambda 参数的局部变量语法\n\n从 java 10 开始，便引入了局部变量类型推断这一关键特性。类型推断允许使用关键字 var 作为局部变量的类型而不是实际类型，编译器根据分配给变量的值推断出类型。\n\njava 10 中对 var 关键字存在几个限制\n\n * 只能用于局部变量上\n * 声明时必须初始化\n * 不能用作方法参数\n * 不能在 lambda 表达式中使用\n\njava11 开始允许开发者在 lambda 表达式中使用 var 进行参数声明。\n\n// 下面两者是等价的\nconsumer<string> consumer = (var i) -> system.out.println(i);\nconsumer<string> consumer = (string i) -> system.out.println(i);\n\n\n\n# 启动单文件源代码程序\n\n这意味着我们可以运行单一文件的 java 源代码。此功能允许使用 java 解释器直接执行 java 源代码。源代码在内存中编译，然后由解释器执行，不需要在磁盘上生成 .class 文件了。唯一的约束在于所有相关的类必须定义在同一个 java 文件中。\n\n对于 java 初学者并希望尝试简单程序的人特别有用，并且能和 jshell 一起使用。一定能程度上增强了使用 java 来写脚本程序的能力。\n\n\n# 其他新特性\n\n * 新的垃圾回收器 epsilon：一个完全消极的 gc 实现，分配有限的内存资源，最大限度的降低内存占用和内存吞吐延迟时间\n * 低开销的 heap profiling：java 11 中提供一种低开销的 java 堆分配采样方法，能够得到堆分配的 java 对象信息，并且能够通过 jvmti 访问堆信息\n * tls1.3 协议：java 11 中包含了传输层安全性（tls）1.3 规范（rfc 8446）的实现，替换了之前版本中包含的 tls，包括 tls 1.2，同时还改进了其他 tls 功能，例如 ocsp 装订扩展（rfc 6066，rfc 6961），以及会话散列和扩展主密钥扩展（rfc 7627），在安全性和性能方面也做了很多提升\n * 飞行记录器(java flight recorder)：飞行记录器之前是商业版 jdk 的一项分析工具，但在 java 11 中，其代码被包含到公开代码库中，这样所有人都能使用该功能了。\n * ……\n\n\n# 参考\n\n * jdk 11 release notes：https://www.oracle.com/java/technologies/javase/11-relnote-issues.html\n * java 11 – features and comparison：https://www.geeksforgeeks.org/java-11-features-and-comparison/',charsets:{cjk:!0}},{title:"Java 12  & 13 新特性概览",frontmatter:{title:"Java 12  & 13 新特性概览",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:04:59.000Z",permalink:"/pages/79a5f6/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/06.java12-13.html",relativePath:"01.Java基础/05.版本新特性/06.java12-13.md",key:"v-676002b2",path:"/pages/79a5f6/",headers:[{level:2,title:"Java12",slug:"java12",normalizedTitle:"java12",charIndex:2},{level:3,title:"String 增强",slug:"string-增强",normalizedTitle:"string 增强",charIndex:13},{level:3,title:"Files 增强（文件比较）",slug:"files-增强-文件比较",normalizedTitle:"files 增强（文件比较）",charIndex:363},{level:3,title:"数字格式化工具类",slug:"数字格式化工具类",normalizedTitle:"数字格式化工具类",charIndex:1163},{level:3,title:"Shenandoah GC",slug:"shenandoah-gc",normalizedTitle:"shenandoah gc",charIndex:1377},{level:3,title:"G1 收集器优化",slug:"g1-收集器优化",normalizedTitle:"g1 收集器优化",charIndex:1554},{level:3,title:"预览新特性",slug:"预览新特性",normalizedTitle:"预览新特性",charIndex:1785},{level:4,title:"增强 Switch",slug:"增强-switch",normalizedTitle:"增强 switch",charIndex:1845},{level:4,title:"instanceof 模式匹配",slug:"instanceof-模式匹配",normalizedTitle:"instanceof 模式匹配",charIndex:2235},{level:2,title:"Java13",slug:"java13",normalizedTitle:"java13",charIndex:2544},{level:3,title:"增强 ZGC(释放未使用内存)",slug:"增强-zgc-释放未使用内存",normalizedTitle:"增强 zgc(释放未使用内存)",charIndex:2555},{level:3,title:"SocketAPI 重构",slug:"socketapi-重构",normalizedTitle:"socketapi 重构",charIndex:2801},{level:3,title:"FileSystems",slug:"filesystems",normalizedTitle:"filesystems",charIndex:3124},{level:3,title:"动态 CDS 存档",slug:"动态-cds-存档",normalizedTitle:"动态 cds 存档",charIndex:3311},{level:3,title:"预览新特性",slug:"预览新特性-2",normalizedTitle:"预览新特性",charIndex:1785},{level:4,title:"文本块",slug:"文本块",normalizedTitle:"文本块",charIndex:3636},{level:4,title:"增强 Switch(引入 yield 关键字到 Switch 中)",slug:"增强-switch-引入-yield-关键字到-switch-中",normalizedTitle:"增强 switch(引入 yield 关键字到 switch 中)",charIndex:4924},{level:2,title:"补充",slug:"补充",normalizedTitle:"补充",charIndex:5410},{level:3,title:"关于预览特性",slug:"关于预览特性",normalizedTitle:"关于预览特性",charIndex:5417},{level:3,title:"JVM 虚拟机优化",slug:"jvm-虚拟机优化",normalizedTitle:"jvm 虚拟机优化",charIndex:6063},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:6247}],headersStr:"Java12 String 增强 Files 增强（文件比较） 数字格式化工具类 Shenandoah GC G1 收集器优化 预览新特性 增强 Switch instanceof 模式匹配 Java13 增强 ZGC(释放未使用内存) SocketAPI 重构 FileSystems 动态 CDS 存档 预览新特性 文本块 增强 Switch(引入 yield 关键字到 Switch 中) 补充 关于预览特性 JVM 虚拟机优化 参考",content:'# Java12\n\n\n# String 增强\n\nJava 12 增加了两个的字符串处理方法，如以下所示。\n\nindent() 方法可以实现字符串缩进。\n\nString text = "Java";\n// 缩进 4 格\ntext = text.indent(4);\nSystem.out.println(text);\ntext = text.indent(-10);\nSystem.out.println(text);\n\n\n输出：\n\n     Java\nJava\n\n\ntransform() 方法可以用来转变指定字符串。\n\nString result = "foo".transform(input -> input + " bar");\nSystem.out.println(result); // foo bar\n\n\n\n# Files 增强（文件比较）\n\nJava 12 添加了以下方法来比较两个文件：\n\npublic static long mismatch(Path path, Path path2) throws IOException\n\n\nmismatch() 方法用于比较两个文件，并返回第一个不匹配字符的位置，如果文件相同则返回 -1L。\n\n代码示例（两个文件内容相同的情况）：\n\nPath filePath1 = Files.createTempFile("file1", ".txt");\nPath filePath2 = Files.createTempFile("file2", ".txt");\nFiles.writeString(filePath1, "Java 12 Article");\nFiles.writeString(filePath2, "Java 12 Article");\n\nlong mismatch = Files.mismatch(filePath1, filePath2);\nassertEquals(-1, mismatch);\n\n\n代码示例（两个文件内容不相同的情况）：\n\nPath filePath3 = Files.createTempFile("file3", ".txt");\nPath filePath4 = Files.createTempFile("file4", ".txt");\nFiles.writeString(filePath3, "Java 12 Article");\nFiles.writeString(filePath4, "Java 12 Tutorial");\n\nlong mismatch = Files.mismatch(filePath3, filePath4);\nassertEquals(8, mismatch);\n\n\n\n# 数字格式化工具类\n\nNumberFormat 新增了对复杂的数字进行格式化的支持\n\nNumberFormat fmt = NumberFormat.getCompactNumberInstance(Locale.US, NumberFormat.Style.SHORT);\nString result = fmt.format(1000);\nSystem.out.println(result);\n\n\n输出:\n\n1K\n\n\n\n# Shenandoah GC\n\nRedhat 主导开发的 Pauseless GC 实现，主要目标是 99.9% 的暂停小于 10ms，暂停与堆大小无关等\n\n和 Java11 开源的 ZGC 相比（需要升级到 JDK11 才能使用），Shenandoah GC 有稳定的 JDK8u 版本，在 Java8 占据主要市场份额的今天有更大的可落地性。\n\n\n# G1 收集器优化\n\nJava12 为默认的垃圾收集器 G1 带来了两项更新:\n\n * 可中止的混合收集集合：JEP344 的实现，为了达到用户提供的停顿时间目标，JEP 344 通过把要被回收的区域集（混合收集集合）拆分为强制和可选部分，使 G1 垃圾回收器能中止垃圾回收过程。 G1 可以中止可选部分的回收以达到停顿时间目标\n * 及时返回未使用的已分配内存：JEP346 的实现，增强 G1 GC，以便在空闲时自动将 Java 堆内存返回给操作系统\n\n\n# 预览新特性\n\n作为预览特性加入，需要在javac编译和java运行时增加参数--enable-preview 。\n\n# 增强 Switch\n\n传统的 switch 语法存在容易漏写 break 的问题，而且从代码整洁性层面来看，多个 break 本质也是一种重复。\n\nJava12 增强了 switch 表达式，使用类似 lambda 语法条件匹配成功后的执行块，不需要多写 break 。\n\nswitch (day) {\n    case MONDAY, FRIDAY, SUNDAY -> System.out.println(6);\n    case TUESDAY                -> System.out.println(7);\n    case THURSDAY, SATURDAY     -> System.out.println(8);\n    case WEDNESDAY              -> System.out.println(9);\n}\n\n\n# instanceof 模式匹配\n\ninstanceof 主要在类型强转前探测对象的具体类型。\n\n之前的版本中，我们需要显示地对对象进行类型转换。\n\nObject obj = "我是字符串";\nif(obj instanceof String){\n   String str = (String) obj;\n  System.out.println(str);\n}\n\n\n新版的 instanceof 可以在判断是否属于具体的类型同时完成转换。\n\nObject obj = "我是字符串";\nif(obj instanceof String str){\n  System.out.println(str);\n}\n\n\n\n# Java13\n\n\n# 增强 ZGC(释放未使用内存)\n\n在 Java 11 中实验性引入的 ZGC 在实际的使用中存在未能主动将未使用的内存释放给操作系统的问题。\n\nZGC 堆由一组称为 ZPages 的堆区域组成。在 GC 周期中清空 ZPages 区域时，它们将被释放并返回到页面缓存 ZPageCache 中，此缓存中的 ZPages 按最近最少使用（LRU）的顺序，并按照大小进行组织。\n\n在 Java 13 中，ZGC 将向操作系统返回被标识为长时间未使用的页面，这样它们将可以被其他进程重用。\n\n\n# SocketAPI 重构\n\nJava Socket API 终于迎来了重大更新！\n\nJava 13 将 Socket API 的底层进行了重写， NioSocketImpl 是对 PlainSocketImpl 的直接替代，它使用 java.util.concurrent 包下的锁而不是同步方法。如果要使用旧实现，请使用 -Djdk.net.usePlainSocketImpl=true。\n\n并且，在 Java 13 中是默认使用新的 Socket 实现。\n\npublic final class NioSocketImpl extends SocketImpl implements PlatformSocketImpl {\n}\n\n\n\n# FileSystems\n\nFileSystems 类中添加了以下三种新方法，以便更容易地使用将文件内容视为文件系统的文件系统提供程序：\n\n * newFileSystem(Path)\n * newFileSystem(Path, Map<String, ?>)\n * newFileSystem(Path, Map<String, ?>, ClassLoader)\n\n\n# 动态 CDS 存档\n\nJava 13 中对 Java 10 中引入的应用程序类数据共享(AppCDS)进行了进一步的简化、改进和扩展，即：允许在 Java 应用程序执行结束时动态进行类归档，具体能够被归档的类包括所有已被加载，但不属于默认基层 CDS 的应用程序类和引用类库中的类。\n\n这提高了应用程序类数据共享（AppCDS）的可用性。无需用户进行试运行来为每个应用程序创建类列表。\n\njava -XX:ArchiveClassesAtExit=my_app_cds.jsa -cp my_app.jar\njava -XX:SharedArchiveFile=my_app_cds.jsa -cp my_app.jar\n\n\n\n# 预览新特性\n\n# 文本块\n\n解决 Java 定义多行字符串时只能通过换行转义或者换行连接符来变通支持的问题，引入三重双引号来定义多行文本。\n\nJava 13 支持两个 """ 符号中间的任何内容都会被解释为字符串的一部分，包括换行符。\n\n未支持文本块之前的 HTML 写法：\n\nString json ="{\\n" +\n              "   \\"name\\":\\"mkyong\\",\\n" +\n              "   \\"age\\":38\\n" +\n              "}\\n";\n\n\n支持文本块之后的 HTML 写法：\n\n String json = """\n                {\n                    "name":"mkyong",\n                    "age":38\n                }\n                """;\n\n\n未支持文本块之前的 SQL 写法：\n\nString query = "SELECT `EMP_ID`, `LAST_NAME` FROM `EMPLOYEE_TB`\\n" +\n               "WHERE `CITY` = \'INDIANAPOLIS\'\\n" +\n               "ORDER BY `EMP_ID`, `LAST_NAME`;\\n";\n\n\n支持文本块之后的 SQL 写法：\n\nString query = """\n               SELECT `EMP_ID`, `LAST_NAME` FROM `EMPLOYEE_TB`\n               WHERE `CITY` = \'INDIANAPOLIS\'\n               ORDER BY `EMP_ID`, `LAST_NAME`;\n               """;\n\n\n另外，String 类新增加了 3 个新的方法来操作文本块：\n\n * formatted(Object... args)：它类似于 String 的format()方法。添加它是为了支持文本块的格式设置。\n * stripIndent()：用于去除文本块中每一行开头和结尾的空格。\n * translateEscapes()：转义序列如 “\\\\t” 转换为 “\\t”\n\n由于文本块是一项预览功能，可以在未来版本中删除，因此这些新方法被标记为弃用。\n\n@Deprecated(forRemoval=true, since="13")\npublic String stripIndent() {\n}\n@Deprecated(forRemoval=true, since="13")\npublic String formatted(Object... args) {\n\n}\n@Deprecated(forRemoval=true, since="13")\npublic String translateEscapes() {\n}\n\n\n# 增强 Switch(引入 yield 关键字到 Switch 中)\n\nSwitch 表达式中就多了一个关键字用于跳出 Switch 块的关键字 yield，主要用于返回一个值\n\nyield和 return 的区别在于：return 会直接跳出当前循环或者方法，而 yield 只会跳出当前 Switch 块，同时在使用 yield 时，需要有 default 条件\n\n private static String descLanguage(String name) {\n        return switch (name) {\n            case "Java": yield "object-oriented, platform independent and secured";\n            case "Ruby": yield "a programmer\'s best friend";\n            default: yield name +" is a good language";\n        };\n }\n\n\n\n# 补充\n\n\n# 关于预览特性\n\n先贴一段 oracle 官网原文：This is a preview feature, which is a feature whose design, specification, and implementation are complete, but is not permanent, which means that the feature may exist in a different form or not at all in future JDK releases. To compile and run code that contains preview features, you must specify additional command-line options.\n\n这是一个预览功能，该功能的设计，规格和实现是完整的，但不是永久性的，这意味着该功能可能以其他形式存在或在将来的 JDK 版本中根本不存在。 要编译和运行包含预览功能的代码，必须指定其他命令行选项。\n\n就以switch的增强为例子，从 Java12 中推出，到 Java13 中将继续增强，直到 Java14 才正式转正进入 JDK 可以放心使用，不用考虑后续 JDK 版本对其的改动或修改\n\n一方面可以看出 JDK 作为标准平台在增加新特性的严谨态度，另一方面个人认为是对于预览特性应该采取审慎使用的态度。特性的设计和实现容易，但是其实际价值依然需要在使用中去验证\n\n\n# JVM 虚拟机优化\n\n每次 Java 版本的发布都伴随着对 JVM 虚拟机的优化，包括对现有垃圾回收算法的改进，引入新的垃圾回收算法，移除老旧的不再适用于今天的垃圾回收算法等\n\n整体优化的方向是高效，低时延的垃圾回收表现\n\n对于日常的应用开发者可能比较关注新的语法特性，但是从一个公司角度来说，在考虑是否升级 Java 平台时更加考虑的是JVM 运行时的提升\n\n\n# 参考\n\n * JDK Project Overview：https://openjdk.java.net/projects/jdk/\n * Oracle Java12 ReleaseNote：https://www.oracle.com/java/technologies/javase/12all-relnotes.htm\n * What is new in Java 12：https://mkyong.com/java/what-is-new-in-java-12/\n * Oracle Java13 ReleaseNote https://www.oracle.com/technetwork/java/javase/13all-relnotes-5461743.html#NewFeature\n * New Java13 Features https://www.baeldung.com/java-13-new-features\n * Java13 新特性概述 https://www.ibm.com/developerworks/cn/java/the-new-features-of-Java-13/index.html',normalizedContent:'# java12\n\n\n# string 增强\n\njava 12 增加了两个的字符串处理方法，如以下所示。\n\nindent() 方法可以实现字符串缩进。\n\nstring text = "java";\n// 缩进 4 格\ntext = text.indent(4);\nsystem.out.println(text);\ntext = text.indent(-10);\nsystem.out.println(text);\n\n\n输出：\n\n     java\njava\n\n\ntransform() 方法可以用来转变指定字符串。\n\nstring result = "foo".transform(input -> input + " bar");\nsystem.out.println(result); // foo bar\n\n\n\n# files 增强（文件比较）\n\njava 12 添加了以下方法来比较两个文件：\n\npublic static long mismatch(path path, path path2) throws ioexception\n\n\nmismatch() 方法用于比较两个文件，并返回第一个不匹配字符的位置，如果文件相同则返回 -1l。\n\n代码示例（两个文件内容相同的情况）：\n\npath filepath1 = files.createtempfile("file1", ".txt");\npath filepath2 = files.createtempfile("file2", ".txt");\nfiles.writestring(filepath1, "java 12 article");\nfiles.writestring(filepath2, "java 12 article");\n\nlong mismatch = files.mismatch(filepath1, filepath2);\nassertequals(-1, mismatch);\n\n\n代码示例（两个文件内容不相同的情况）：\n\npath filepath3 = files.createtempfile("file3", ".txt");\npath filepath4 = files.createtempfile("file4", ".txt");\nfiles.writestring(filepath3, "java 12 article");\nfiles.writestring(filepath4, "java 12 tutorial");\n\nlong mismatch = files.mismatch(filepath3, filepath4);\nassertequals(8, mismatch);\n\n\n\n# 数字格式化工具类\n\nnumberformat 新增了对复杂的数字进行格式化的支持\n\nnumberformat fmt = numberformat.getcompactnumberinstance(locale.us, numberformat.style.short);\nstring result = fmt.format(1000);\nsystem.out.println(result);\n\n\n输出:\n\n1k\n\n\n\n# shenandoah gc\n\nredhat 主导开发的 pauseless gc 实现，主要目标是 99.9% 的暂停小于 10ms，暂停与堆大小无关等\n\n和 java11 开源的 zgc 相比（需要升级到 jdk11 才能使用），shenandoah gc 有稳定的 jdk8u 版本，在 java8 占据主要市场份额的今天有更大的可落地性。\n\n\n# g1 收集器优化\n\njava12 为默认的垃圾收集器 g1 带来了两项更新:\n\n * 可中止的混合收集集合：jep344 的实现，为了达到用户提供的停顿时间目标，jep 344 通过把要被回收的区域集（混合收集集合）拆分为强制和可选部分，使 g1 垃圾回收器能中止垃圾回收过程。 g1 可以中止可选部分的回收以达到停顿时间目标\n * 及时返回未使用的已分配内存：jep346 的实现，增强 g1 gc，以便在空闲时自动将 java 堆内存返回给操作系统\n\n\n# 预览新特性\n\n作为预览特性加入，需要在javac编译和java运行时增加参数--enable-preview 。\n\n# 增强 switch\n\n传统的 switch 语法存在容易漏写 break 的问题，而且从代码整洁性层面来看，多个 break 本质也是一种重复。\n\njava12 增强了 switch 表达式，使用类似 lambda 语法条件匹配成功后的执行块，不需要多写 break 。\n\nswitch (day) {\n    case monday, friday, sunday -> system.out.println(6);\n    case tuesday                -> system.out.println(7);\n    case thursday, saturday     -> system.out.println(8);\n    case wednesday              -> system.out.println(9);\n}\n\n\n# instanceof 模式匹配\n\ninstanceof 主要在类型强转前探测对象的具体类型。\n\n之前的版本中，我们需要显示地对对象进行类型转换。\n\nobject obj = "我是字符串";\nif(obj instanceof string){\n   string str = (string) obj;\n  system.out.println(str);\n}\n\n\n新版的 instanceof 可以在判断是否属于具体的类型同时完成转换。\n\nobject obj = "我是字符串";\nif(obj instanceof string str){\n  system.out.println(str);\n}\n\n\n\n# java13\n\n\n# 增强 zgc(释放未使用内存)\n\n在 java 11 中实验性引入的 zgc 在实际的使用中存在未能主动将未使用的内存释放给操作系统的问题。\n\nzgc 堆由一组称为 zpages 的堆区域组成。在 gc 周期中清空 zpages 区域时，它们将被释放并返回到页面缓存 zpagecache 中，此缓存中的 zpages 按最近最少使用（lru）的顺序，并按照大小进行组织。\n\n在 java 13 中，zgc 将向操作系统返回被标识为长时间未使用的页面，这样它们将可以被其他进程重用。\n\n\n# socketapi 重构\n\njava socket api 终于迎来了重大更新！\n\njava 13 将 socket api 的底层进行了重写， niosocketimpl 是对 plainsocketimpl 的直接替代，它使用 java.util.concurrent 包下的锁而不是同步方法。如果要使用旧实现，请使用 -djdk.net.useplainsocketimpl=true。\n\n并且，在 java 13 中是默认使用新的 socket 实现。\n\npublic final class niosocketimpl extends socketimpl implements platformsocketimpl {\n}\n\n\n\n# filesystems\n\nfilesystems 类中添加了以下三种新方法，以便更容易地使用将文件内容视为文件系统的文件系统提供程序：\n\n * newfilesystem(path)\n * newfilesystem(path, map<string, ?>)\n * newfilesystem(path, map<string, ?>, classloader)\n\n\n# 动态 cds 存档\n\njava 13 中对 java 10 中引入的应用程序类数据共享(appcds)进行了进一步的简化、改进和扩展，即：允许在 java 应用程序执行结束时动态进行类归档，具体能够被归档的类包括所有已被加载，但不属于默认基层 cds 的应用程序类和引用类库中的类。\n\n这提高了应用程序类数据共享（appcds）的可用性。无需用户进行试运行来为每个应用程序创建类列表。\n\njava -xx:archiveclassesatexit=my_app_cds.jsa -cp my_app.jar\njava -xx:sharedarchivefile=my_app_cds.jsa -cp my_app.jar\n\n\n\n# 预览新特性\n\n# 文本块\n\n解决 java 定义多行字符串时只能通过换行转义或者换行连接符来变通支持的问题，引入三重双引号来定义多行文本。\n\njava 13 支持两个 """ 符号中间的任何内容都会被解释为字符串的一部分，包括换行符。\n\n未支持文本块之前的 html 写法：\n\nstring json ="{\\n" +\n              "   \\"name\\":\\"mkyong\\",\\n" +\n              "   \\"age\\":38\\n" +\n              "}\\n";\n\n\n支持文本块之后的 html 写法：\n\n string json = """\n                {\n                    "name":"mkyong",\n                    "age":38\n                }\n                """;\n\n\n未支持文本块之前的 sql 写法：\n\nstring query = "select `emp_id`, `last_name` from `employee_tb`\\n" +\n               "where `city` = \'indianapolis\'\\n" +\n               "order by `emp_id`, `last_name`;\\n";\n\n\n支持文本块之后的 sql 写法：\n\nstring query = """\n               select `emp_id`, `last_name` from `employee_tb`\n               where `city` = \'indianapolis\'\n               order by `emp_id`, `last_name`;\n               """;\n\n\n另外，string 类新增加了 3 个新的方法来操作文本块：\n\n * formatted(object... args)：它类似于 string 的format()方法。添加它是为了支持文本块的格式设置。\n * stripindent()：用于去除文本块中每一行开头和结尾的空格。\n * translateescapes()：转义序列如 “\\\\t” 转换为 “\\t”\n\n由于文本块是一项预览功能，可以在未来版本中删除，因此这些新方法被标记为弃用。\n\n@deprecated(forremoval=true, since="13")\npublic string stripindent() {\n}\n@deprecated(forremoval=true, since="13")\npublic string formatted(object... args) {\n\n}\n@deprecated(forremoval=true, since="13")\npublic string translateescapes() {\n}\n\n\n# 增强 switch(引入 yield 关键字到 switch 中)\n\nswitch 表达式中就多了一个关键字用于跳出 switch 块的关键字 yield，主要用于返回一个值\n\nyield和 return 的区别在于：return 会直接跳出当前循环或者方法，而 yield 只会跳出当前 switch 块，同时在使用 yield 时，需要有 default 条件\n\n private static string desclanguage(string name) {\n        return switch (name) {\n            case "java": yield "object-oriented, platform independent and secured";\n            case "ruby": yield "a programmer\'s best friend";\n            default: yield name +" is a good language";\n        };\n }\n\n\n\n# 补充\n\n\n# 关于预览特性\n\n先贴一段 oracle 官网原文：this is a preview feature, which is a feature whose design, specification, and implementation are complete, but is not permanent, which means that the feature may exist in a different form or not at all in future jdk releases. to compile and run code that contains preview features, you must specify additional command-line options.\n\n这是一个预览功能，该功能的设计，规格和实现是完整的，但不是永久性的，这意味着该功能可能以其他形式存在或在将来的 jdk 版本中根本不存在。 要编译和运行包含预览功能的代码，必须指定其他命令行选项。\n\n就以switch的增强为例子，从 java12 中推出，到 java13 中将继续增强，直到 java14 才正式转正进入 jdk 可以放心使用，不用考虑后续 jdk 版本对其的改动或修改\n\n一方面可以看出 jdk 作为标准平台在增加新特性的严谨态度，另一方面个人认为是对于预览特性应该采取审慎使用的态度。特性的设计和实现容易，但是其实际价值依然需要在使用中去验证\n\n\n# jvm 虚拟机优化\n\n每次 java 版本的发布都伴随着对 jvm 虚拟机的优化，包括对现有垃圾回收算法的改进，引入新的垃圾回收算法，移除老旧的不再适用于今天的垃圾回收算法等\n\n整体优化的方向是高效，低时延的垃圾回收表现\n\n对于日常的应用开发者可能比较关注新的语法特性，但是从一个公司角度来说，在考虑是否升级 java 平台时更加考虑的是jvm 运行时的提升\n\n\n# 参考\n\n * jdk project overview：https://openjdk.java.net/projects/jdk/\n * oracle java12 releasenote：https://www.oracle.com/java/technologies/javase/12all-relnotes.htm\n * what is new in java 12：https://mkyong.com/java/what-is-new-in-java-12/\n * oracle java13 releasenote https://www.oracle.com/technetwork/java/javase/13all-relnotes-5461743.html#newfeature\n * new java13 features https://www.baeldung.com/java-13-new-features\n * java13 新特性概述 https://www.ibm.com/developerworks/cn/java/the-new-features-of-java-13/index.html',charsets:{cjk:!0}},{title:"Java 14  & 15 新特性概览",frontmatter:{title:"Java 14  & 15 新特性概览",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:05:05.000Z",permalink:"/pages/683a03/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/07.java14-15.html",relativePath:"01.Java基础/05.版本新特性/07.java14-15.md",key:"v-f4d1815c",path:"/pages/683a03/",headers:[{level:2,title:"Java14",slug:"java14",normalizedTitle:"java14",charIndex:2},{level:3,title:"空指针异常精准提示",slug:"空指针异常精准提示",normalizedTitle:"空指针异常精准提示",charIndex:13},{level:3,title:"switch 的增强(转正)",slug:"switch-的增强-转正",normalizedTitle:"switch 的增强(转正)",charIndex:462},{level:3,title:"预览新特性",slug:"预览新特性",normalizedTitle:"预览新特性",charIndex:997},{level:4,title:"record 关键字",slug:"record-关键字",normalizedTitle:"record 关键字",charIndex:1006},{level:4,title:"文本块",slug:"文本块",normalizedTitle:"文本块",charIndex:1793},{level:4,title:"instanceof 增强",slug:"instanceof-增强",normalizedTitle:"instanceof 增强",charIndex:2129},{level:3,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:2174},{level:2,title:"Java15",slug:"java15",normalizedTitle:"java15",charIndex:2438},{level:3,title:"CharSequence",slug:"charsequence",normalizedTitle:"charsequence",charIndex:2449},{level:3,title:"TreeMap",slug:"treemap",normalizedTitle:"treemap",charIndex:2628},{level:3,title:"ZGC(转正)",slug:"zgc-转正",normalizedTitle:"zgc(转正)",charIndex:2746},{level:3,title:"EdDSA(数字签名算法)",slug:"eddsa-数字签名算法",normalizedTitle:"eddsa(数字签名算法)",charIndex:2943},{level:3,title:"文本块(转正)",slug:"文本块-转正",normalizedTitle:"文本块(转正)",charIndex:3582},{level:3,title:"隐藏类(Hidden Classes)",slug:"隐藏类-hidden-classes",normalizedTitle:"隐藏类(hidden classes)",charIndex:3620},{level:3,title:"预览新特性",slug:"预览新特性-2",normalizedTitle:"预览新特性",charIndex:997},{level:4,title:"密封类",slug:"密封类",normalizedTitle:"密封类",charIndex:3718},{level:4,title:"instanceof 模式匹配",slug:"instanceof-模式匹配",normalizedTitle:"instanceof 模式匹配",charIndex:4247},{level:3,title:"其他",slug:"其他-2",normalizedTitle:"其他",charIndex:2174}],headersStr:"Java14 空指针异常精准提示 switch 的增强(转正) 预览新特性 record 关键字 文本块 instanceof 增强 其他 Java15 CharSequence TreeMap ZGC(转正) EdDSA(数字签名算法) 文本块(转正) 隐藏类(Hidden Classes) 预览新特性 密封类 instanceof 模式匹配 其他",content:'# Java14\n\n\n# 空指针异常精准提示\n\n通过 JVM 参数中添加-XX:+ShowCodeDetailsInExceptionMessages，可以在空指针异常中获取更为详细的调用信息，更快的定位和解决问题。\n\na.b.c.i = 99; // 假设这段代码会发生空指针\n\n\nJava 14 之前：\n\nException in thread "main" java.lang.NullPointerException\n    at NullPointerExample.main(NullPointerExample.java:5)\n\n\nJava 14 之后：\n\n // 增加参数后提示的异常中很明确的告知了哪里为空导致\nException in thread "main" java.lang.NullPointerException:\n        Cannot read field \'c\' because \'a.b\' is null.\n    at Prog.main(Prog.java:5)\n\n\n\n# switch 的增强(转正)\n\nJava12 引入的 switch（预览特性）在 Java14 变为正式版本，不需要增加参数来启用，直接在 JDK14 中就能使用。\n\nJava12 为 switch 表达式引入了类似 lambda 语法条件匹配成功后的执行块，不需要多写 break ，Java13 提供了 yield 来在 block 中返回值。\n\nString result = switch (day) {\n            case "M", "W", "F" -> "MWF";\n            case "T", "TH", "S" -> "TTS";\n            default -> {\n                if(day.isEmpty())\n                    yield "Please insert a valid day.";\n                else\n                    yield "Looks like a Sunday.";\n            }\n\n        };\nSystem.out.println(result);\n\n\n\n# 预览新特性\n\n# record 关键字\n\nrecord 关键字可以简化 数据类（一个 Java 类一旦实例化就不能再修改）的定义方式，使用 record 代替 class 定义的类，只需要声明属性，就可以在获得属性的访问方法，以及 toString()，hashCode(), equals()方法。\n\n类似于使用 class 定义类，同时使用了 lombok 插件，并打上了@Getter,@ToString,@EqualsAndHashCode注解。\n\n/**\n * 这个类具有两个特征\n * 1. 所有成员属性都是final\n * 2. 全部方法由构造方法，和两个成员属性访问器组成（共三个）\n * 那么这种类就很适合使用record来声明\n */\nfinal class Rectangle implements Shape {\n    final double length;\n    final double width;\n\n    public Rectangle(double length, double width) {\n        this.length = length;\n        this.width = width;\n    }\n\n    double length() { return length; }\n    double width() { return width; }\n}\n/**\n * 1. 使用record声明的类会自动拥有上面类中的三个方法\n * 2. 在这基础上还附赠了equals()，hashCode()方法以及toString()方法\n * 3. toString方法中包括所有成员属性的字符串表示形式及其名称\n */\nrecord Rectangle(float length, float width) { }\n\n\n# 文本块\n\nJava14 中，文本块依然是预览特性，不过，其引入了两个新的转义字符：\n\n * \\ : 表示行尾，不引入换行符\n * \\s：表示单个空格\n\nString str = "凡心所向，素履所往，生如逆旅，一苇以航。";\n\nString str2 = """\n        凡心所向，素履所往， \\\n        生如逆旅，一苇以航。""";\nSystem.out.println(str2);// 凡心所向，素履所往， 生如逆旅，一苇以航。\nString text = """\n        java\n        c++\\sphp\n        """;\nSystem.out.println(text);\n//输出：\njava\nc++ php\n\n\n# instanceof 增强\n\n依然是预览特性 ，Java 12 新特性中介绍过。\n\n\n# 其他\n\n * 从 Java11 引入的 ZGC 作为继 G1 过后的下一代 GC 算法，从支持 Linux 平台到 Java14 开始支持 MacOS 和 Windows（个人感觉是终于可以在日常开发工具中先体验下 ZGC 的效果了，虽然其实 G1 也够用）\n * 移除了 CMS(Concurrent Mark Sweep) 垃圾收集器（功成而退）\n * 新增了 jpackage 工具，标配将应用打成 jar 包外，还支持不同平台的特性包，比如 linux 下的deb和rpm，window 平台下的msi和exe\n\n\n# Java15\n\n\n# CharSequence\n\nCharSequence 接口添加了一个默认方法 isEmpty() 来判断字符序列为空，如果是则返回 true。\n\npublic interface CharSequence {\n  default boolean isEmpty() {\n      return this.length() == 0;\n  }\n}\n\n\n\n# TreeMap\n\nTreeMap 新引入了下面这些方法：\n\n * putIfAbsent()\n * computeIfAbsent()\n * computeIfPresent()\n * compute()\n * merge()\n\n\n# ZGC(转正)\n\nJava11 的时候 ，ZGC 还在试验阶段。\n\n当时，ZGC 的出现让众多 Java 开发者看到了垃圾回收器的另外一种可能，因此备受关注。\n\n经过多个版本的迭代，不断的完善和修复问题，ZGC 在 Java 15 已经可以正式使用了！\n\n不过，默认的垃圾回收器依然是 G1。你可以通过下面的参数启动 ZGC：\n\njava -XX:+UseZGC className\n\n\n\n# EdDSA(数字签名算法)\n\n新加入了一个安全性和性能都更强的基于 Edwards-Curve Digital Signature Algorithm （EdDSA）实现的数字签名算法。\n\n虽然其性能优于现有的 ECDSA 实现，不过，它并不会完全取代 JDK 中现有的椭圆曲线数字签名算法( ECDSA)。\n\nKeyPairGenerator kpg = KeyPairGenerator.getInstance("Ed25519");\nKeyPair kp = kpg.generateKeyPair();\n\nbyte[] msg = "test_string".getBytes(StandardCharsets.UTF_8);\n\nSignature sig = Signature.getInstance("Ed25519");\nsig.initSign(kp.getPrivate());\nsig.update(msg);\nbyte[] s = sig.sign();\n\nString encodedString = Base64.getEncoder().encodeToString(s);\nSystem.out.println(encodedString);\n\n\n输出：\n\n0Hc0lxxASZNvS52WsvnncJOH/mlFhnA8Tc6D/k5DtAX5BSsNVjtPF4R4+yMWXVjrvB2mxVXmChIbki6goFBgAg==\n\n\n\n# 文本块(转正)\n\n在 Java 15 ，文本块是正式的功能特性了。\n\n\n# 隐藏类(Hidden Classes)\n\n隐藏类是为框架（frameworks）所设计的，隐藏类不能直接被其他类的字节码使用，只能在运行时生成类并通过反射间接使用它们。\n\n\n# 预览新特性\n\n# 密封类\n\n密封类（Sealed Classes） 是 Java 15 中的一个预览新特性。\n\n没有密封类之前，在 Java 中如果想让一个类不能被继承和修改，我们可以使用final 关键字对类进行修饰。不过，这种方式不太灵活，直接把一个类的继承和修改渠道给堵死了。\n\n密封类可以对继承或者实现它们的类进行限制，这样这个类就只能被指定的类继承。\n\n// 抽象类 Person 只允许 Employee 和 Manager 继承。\npublic abstract sealed class Person\n    permits Employee, Manager {\n\n    //...\n}\n\n\n另外，任何扩展密封类的类本身都必须声明为 sealed、non-sealed 或 final。\n\npublic final class Employee extends Person {\n}\n\npublic non-sealed class Manager extends Person {\n}\n\n\n\n\n如果允许扩展的子类和封闭类在同一个源代码文件里，封闭类可以不使用 permits 语句，Java 编译器将检索源文件，在编译期为封闭类添加上许可的子类。\n\n# instanceof 模式匹配\n\nJava 15 并没有对此特性进行调整，继续预览特性，主要用于接受更多的使用反馈。\n\n在未来的 Java 版本中，Java 的目标是继续完善 instanceof 模式匹配新特性。\n\n\n# 其他\n\n * Nashorn JavaScript 引擎彻底移除：Nashorn 从 Java8 开始引入的 JavaScript 引擎，Java9 对 Nashorn 做了些增强，实现了一些 ES6 的新特性。在 Java 11 中就已经被弃用，到了 Java 15 就彻底被删除了。\n * DatagramSocket API 重构\n * 禁用和废弃偏向锁（Biased Locking）：偏向锁的引入增加了 JVM 的复杂性大于其带来的性能提升。不过，你仍然可以使用 -XX:+UseBiasedLocking 启用偏向锁定，但它会提示这是一个已弃用的 API。\n * ……',normalizedContent:'# java14\n\n\n# 空指针异常精准提示\n\n通过 jvm 参数中添加-xx:+showcodedetailsinexceptionmessages，可以在空指针异常中获取更为详细的调用信息，更快的定位和解决问题。\n\na.b.c.i = 99; // 假设这段代码会发生空指针\n\n\njava 14 之前：\n\nexception in thread "main" java.lang.nullpointerexception\n    at nullpointerexample.main(nullpointerexample.java:5)\n\n\njava 14 之后：\n\n // 增加参数后提示的异常中很明确的告知了哪里为空导致\nexception in thread "main" java.lang.nullpointerexception:\n        cannot read field \'c\' because \'a.b\' is null.\n    at prog.main(prog.java:5)\n\n\n\n# switch 的增强(转正)\n\njava12 引入的 switch（预览特性）在 java14 变为正式版本，不需要增加参数来启用，直接在 jdk14 中就能使用。\n\njava12 为 switch 表达式引入了类似 lambda 语法条件匹配成功后的执行块，不需要多写 break ，java13 提供了 yield 来在 block 中返回值。\n\nstring result = switch (day) {\n            case "m", "w", "f" -> "mwf";\n            case "t", "th", "s" -> "tts";\n            default -> {\n                if(day.isempty())\n                    yield "please insert a valid day.";\n                else\n                    yield "looks like a sunday.";\n            }\n\n        };\nsystem.out.println(result);\n\n\n\n# 预览新特性\n\n# record 关键字\n\nrecord 关键字可以简化 数据类（一个 java 类一旦实例化就不能再修改）的定义方式，使用 record 代替 class 定义的类，只需要声明属性，就可以在获得属性的访问方法，以及 tostring()，hashcode(), equals()方法。\n\n类似于使用 class 定义类，同时使用了 lombok 插件，并打上了@getter,@tostring,@equalsandhashcode注解。\n\n/**\n * 这个类具有两个特征\n * 1. 所有成员属性都是final\n * 2. 全部方法由构造方法，和两个成员属性访问器组成（共三个）\n * 那么这种类就很适合使用record来声明\n */\nfinal class rectangle implements shape {\n    final double length;\n    final double width;\n\n    public rectangle(double length, double width) {\n        this.length = length;\n        this.width = width;\n    }\n\n    double length() { return length; }\n    double width() { return width; }\n}\n/**\n * 1. 使用record声明的类会自动拥有上面类中的三个方法\n * 2. 在这基础上还附赠了equals()，hashcode()方法以及tostring()方法\n * 3. tostring方法中包括所有成员属性的字符串表示形式及其名称\n */\nrecord rectangle(float length, float width) { }\n\n\n# 文本块\n\njava14 中，文本块依然是预览特性，不过，其引入了两个新的转义字符：\n\n * \\ : 表示行尾，不引入换行符\n * \\s：表示单个空格\n\nstring str = "凡心所向，素履所往，生如逆旅，一苇以航。";\n\nstring str2 = """\n        凡心所向，素履所往， \\\n        生如逆旅，一苇以航。""";\nsystem.out.println(str2);// 凡心所向，素履所往， 生如逆旅，一苇以航。\nstring text = """\n        java\n        c++\\sphp\n        """;\nsystem.out.println(text);\n//输出：\njava\nc++ php\n\n\n# instanceof 增强\n\n依然是预览特性 ，java 12 新特性中介绍过。\n\n\n# 其他\n\n * 从 java11 引入的 zgc 作为继 g1 过后的下一代 gc 算法，从支持 linux 平台到 java14 开始支持 macos 和 windows（个人感觉是终于可以在日常开发工具中先体验下 zgc 的效果了，虽然其实 g1 也够用）\n * 移除了 cms(concurrent mark sweep) 垃圾收集器（功成而退）\n * 新增了 jpackage 工具，标配将应用打成 jar 包外，还支持不同平台的特性包，比如 linux 下的deb和rpm，window 平台下的msi和exe\n\n\n# java15\n\n\n# charsequence\n\ncharsequence 接口添加了一个默认方法 isempty() 来判断字符序列为空，如果是则返回 true。\n\npublic interface charsequence {\n  default boolean isempty() {\n      return this.length() == 0;\n  }\n}\n\n\n\n# treemap\n\ntreemap 新引入了下面这些方法：\n\n * putifabsent()\n * computeifabsent()\n * computeifpresent()\n * compute()\n * merge()\n\n\n# zgc(转正)\n\njava11 的时候 ，zgc 还在试验阶段。\n\n当时，zgc 的出现让众多 java 开发者看到了垃圾回收器的另外一种可能，因此备受关注。\n\n经过多个版本的迭代，不断的完善和修复问题，zgc 在 java 15 已经可以正式使用了！\n\n不过，默认的垃圾回收器依然是 g1。你可以通过下面的参数启动 zgc：\n\njava -xx:+usezgc classname\n\n\n\n# eddsa(数字签名算法)\n\n新加入了一个安全性和性能都更强的基于 edwards-curve digital signature algorithm （eddsa）实现的数字签名算法。\n\n虽然其性能优于现有的 ecdsa 实现，不过，它并不会完全取代 jdk 中现有的椭圆曲线数字签名算法( ecdsa)。\n\nkeypairgenerator kpg = keypairgenerator.getinstance("ed25519");\nkeypair kp = kpg.generatekeypair();\n\nbyte[] msg = "test_string".getbytes(standardcharsets.utf_8);\n\nsignature sig = signature.getinstance("ed25519");\nsig.initsign(kp.getprivate());\nsig.update(msg);\nbyte[] s = sig.sign();\n\nstring encodedstring = base64.getencoder().encodetostring(s);\nsystem.out.println(encodedstring);\n\n\n输出：\n\n0hc0lxxasznvs52wsvnncjoh/mlfhna8tc6d/k5dtax5bssnvjtpf4r4+ymwxvjrvb2mxvxmchibki6gofbgag==\n\n\n\n# 文本块(转正)\n\n在 java 15 ，文本块是正式的功能特性了。\n\n\n# 隐藏类(hidden classes)\n\n隐藏类是为框架（frameworks）所设计的，隐藏类不能直接被其他类的字节码使用，只能在运行时生成类并通过反射间接使用它们。\n\n\n# 预览新特性\n\n# 密封类\n\n密封类（sealed classes） 是 java 15 中的一个预览新特性。\n\n没有密封类之前，在 java 中如果想让一个类不能被继承和修改，我们可以使用final 关键字对类进行修饰。不过，这种方式不太灵活，直接把一个类的继承和修改渠道给堵死了。\n\n密封类可以对继承或者实现它们的类进行限制，这样这个类就只能被指定的类继承。\n\n// 抽象类 person 只允许 employee 和 manager 继承。\npublic abstract sealed class person\n    permits employee, manager {\n\n    //...\n}\n\n\n另外，任何扩展密封类的类本身都必须声明为 sealed、non-sealed 或 final。\n\npublic final class employee extends person {\n}\n\npublic non-sealed class manager extends person {\n}\n\n\n\n\n如果允许扩展的子类和封闭类在同一个源代码文件里，封闭类可以不使用 permits 语句，java 编译器将检索源文件，在编译期为封闭类添加上许可的子类。\n\n# instanceof 模式匹配\n\njava 15 并没有对此特性进行调整，继续预览特性，主要用于接受更多的使用反馈。\n\n在未来的 java 版本中，java 的目标是继续完善 instanceof 模式匹配新特性。\n\n\n# 其他\n\n * nashorn javascript 引擎彻底移除：nashorn 从 java8 开始引入的 javascript 引擎，java9 对 nashorn 做了些增强，实现了一些 es6 的新特性。在 java 11 中就已经被弃用，到了 java 15 就彻底被删除了。\n * datagramsocket api 重构\n * 禁用和废弃偏向锁（biased locking）：偏向锁的引入增加了 jvm 的复杂性大于其带来的性能提升。不过，你仍然可以使用 -xx:+usebiasedlocking 启用偏向锁定，但它会提示这是一个已弃用的 api。\n * ……',charsets:{cjk:!0}},{title:"Java 16 新特性概览",frontmatter:{title:"Java 16 新特性概览",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:05:13.000Z",permalink:"/pages/fa2c73/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/08.java16.html",relativePath:"01.Java基础/05.版本新特性/08.java16.md",key:"v-38ca00b8",path:"/pages/fa2c73/",headers:[{level:2,title:"JEP 338:向量 API(第一次孵化)",slug:"jep-338-向量-api-第一次孵化",normalizedTitle:"jep 338:向量 api(第一次孵化)",charIndex:75},{level:2,title:"JEP 347:启用 C++ 14 语言特性",slug:"jep-347-启用-c-14-语言特性",normalizedTitle:"jep 347:启用 c++ 14 语言特性",charIndex:508},{level:2,title:"JEP 376:ZGC 并发线程堆栈处理",slug:"jep-376-zgc-并发线程堆栈处理",normalizedTitle:"jep 376:zgc 并发线程堆栈处理",charIndex:679},{level:2,title:"JEP 387:弹性元空间",slug:"jep-387-弹性元空间",normalizedTitle:"jep 387:弹性元空间",charIndex:799},{level:2,title:"JEP 390:对基于值的类发出警告",slug:"jep-390-对基于值的类发出警告",normalizedTitle:"jep 390:对基于值的类发出警告",charIndex:972},{level:2,title:"JEP 392:打包工具",slug:"jep-392-打包工具",normalizedTitle:"jep 392:打包工具",charIndex:2253},{level:2,title:"JEP 393:外部内存访问 API(第三次孵化)",slug:"jep-393-外部内存访问-api-第三次孵化",normalizedTitle:"jep 393:外部内存访问 api(第三次孵化)",charIndex:2689},{level:2,title:"JEP 394:instanceof 模式匹配(转正)",slug:"jep-394-instanceof-模式匹配-转正",normalizedTitle:"jep 394:instanceof 模式匹配(转正)",charIndex:3029},{level:2,title:"JEP 395:记录类型(转正)",slug:"jep-395-记录类型-转正",normalizedTitle:"jep 395:记录类型(转正)",charIndex:3489},{level:2,title:"JEP 396:默认强封装 JDK 内部元素",slug:"jep-396-默认强封装-jdk-内部元素",normalizedTitle:"jep 396:默认强封装 jdk 内部元素",charIndex:4073},{level:2,title:"JEP 397:密封类(预览)",slug:"jep-397-密封类-预览",normalizedTitle:"jep 397:密封类(预览)",charIndex:4391},{level:2,title:"其他优化与改进",slug:"其他优化与改进",normalizedTitle:"其他优化与改进",charIndex:4554},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:5776}],headersStr:"JEP 338:向量 API(第一次孵化) JEP 347:启用 C++ 14 语言特性 JEP 376:ZGC 并发线程堆栈处理 JEP 387:弹性元空间 JEP 390:对基于值的类发出警告 JEP 392:打包工具 JEP 393:外部内存访问 API(第三次孵化) JEP 394:instanceof 模式匹配(转正) JEP 395:记录类型(转正) JEP 396:默认强封装 JDK 内部元素 JEP 397:密封类(预览) 其他优化与改进 参考文献",content:"Java 16 在 2021 年 3 月 16 日正式发布，非长期支持（LTS）版本。\n\n相关阅读：OpenJDK Java 16 文档 。\n\n\n# JEP 338:向量 API(第一次孵化)\n\n向量（Vector） API 最初由 JEP 338 提出，并作为孵化 API集成到 Java 16 中。第二轮孵化由 JEP 414 提出并集成到 Java 17 中，第三轮孵化由 JEP 417 提出并集成到 Java 18 中，第四轮由 JEP 426 提出并集成到了 Java 19 中。\n\n该孵化器 API 提供了一个 API 的初始迭代以表达一些向量计算，这些计算在运行时可靠地编译为支持的 CPU 架构上的最佳向量硬件指令，从而获得优于同等标量计算的性能，充分利用单指令多数据（SIMD）技术（大多数现代 CPU 上都可以使用的一种指令）。尽管 HotSpot 支持自动向量化，但是可转换的标量操作集有限且易受代码更改的影响。该 API 将使开发人员能够轻松地用 Java 编写可移植的高性能向量算法。\n\n在 Java 18 新特性概览 中，我有详细介绍到向量 API，这里就不再做额外的介绍了。\n\n\n# JEP 347:启用 C++ 14 语言特性\n\nJava 16 允许在 JDK 的 C++ 源代码中使用 C++14 语言特性，并提供在 HotSpot 代码中可以使用哪些特性的具体指导。\n\n在 Java 15 中，JDK 中 C++ 代码使用的语言特性仅限于 C++98/03 语言标准。它要求更新各种平台编译器的最低可接受版本。\n\n\n# JEP 376:ZGC 并发线程堆栈处理\n\nJava16 将 ZGC 线程栈处理从安全点转移到一个并发阶段，甚至在大堆上也允许在毫秒内暂停 GC 安全点。消除 ZGC 垃圾收集器中最后一个延迟源可以极大地提高应用程序的性能和效率。\n\n\n# JEP 387:弹性元空间\n\n自从引入了 Metaspace 以来，根据反馈，Metaspace 经常占用过多的堆外内存，从而导致内存浪费。弹性元空间这个特性可将未使用的 HotSpot 类元数据（即元空间，metaspace）内存更快速地返回到操作系统，从而减少元空间的占用空间。\n\n并且，这个提案还简化了元空间的代码以降低维护成本。\n\n\n# JEP 390:对基于值的类发出警告\n\n> 以下介绍摘自：实操 | 剖析 Java16 新语法特性，原文写的很不错，推荐阅读。\n\n早在 Java9 版本时，Java 的设计者们就对 @Deprecated 注解进行了一次升级，增加了 since 和 forRemoval 等 2 个新元素。其中，since 元素用于指定标记了 @Deprecated 注解的 API 被弃用时的版本，而 forRemoval 则进一步明确了 API 标记 @Deprecated 注解时的语义，如果forRemoval=true时，则表示该 API 在未来版本中肯定会被删除，开发人员应该使用新的 API 进行替代，不再容易产生歧义（Java9 之前，标记 @Deprecated 注解的 API，语义上存在多种可能性，比如：存在使用风险、可能在未来存在兼容性错误、可能在未来版本中被删除，以及应该使用更好的替代方案等）。\n\n仔细观察原始类型的包装类（比如：java.lang.Integer、java.lang.Double），不难发现，其构造函数上都已经标记有@Deprecated(since=\"9\", forRemoval = true)注解，这就意味着其构造函数在将来会被删除，不应该在程序中继续使用诸如new Integer();这样的编码方式（建议使用Integer a = 10;或者Integer.valueOf()函数），如果继续使用，编译期将会产生'Integer(int)' is deprecated and marked for removal 告警。并且，值得注意的是，这些包装类型已经被指定为同 java.util.Optional 和 java.time.LocalDateTime 一样的值类型。\n\n其次，如果继续在 synchronized 同步块中使用值类型，将会在编译期和运行期产生警告，甚至是异常。在此大家需要注意，就算编译期和运行期没有产生警告和异常，也不建议在 synchronized 同步块中使用值类型，举个自增的例子。示例 1-5：\n\npublic void inc(Integer count) {\n    for (int i = 0; i < 10; i++) {\n        new Thread(() -> {\n            synchronized (count) {\n                count++;\n            }\n        }).start();\n    }\n}\n\n\n当执行上述程序示例时，最终的输出结果一定会与你的期望产生差异，这是许多新人经常犯错的一个点，因为在并发环境下，Integer 对象根本无法通过 synchronized 来保证线程安全，这是因为每次的count++操作，所产生的 hashcode 均不同，简而言之，每次加锁都锁在了不同的对象上。因此，如果希望在实际的开发过程中保证其原子性，应该使用 AtomicInteger。\n\n\n# JEP 392:打包工具\n\n在 Java 14 中，JEP 343 引入了打包工具，命令是 jpackage。在 Java 15 中，继续孵化，现在在 Java 16 中，终于成为了正式功能。\n\n这个打包工具允许打包自包含的 Java 应用程序。它支持原生打包格式，为最终用户提供自然的安装体验，这些格式包括 Windows 上的 msi 和 exe、macOS 上的 pkg 和 dmg，还有 Linux 上的 deb 和 rpm。它还允许在打包时指定启动时参数，并且可以从命令行直接调用，也可以通过 ToolProvider API 以编程方式调用。注意 jpackage 模块名称从 jdk.incubator.jpackage 更改为 jdk.jpackage。这将改善最终用户在安装应用程序时的体验，并简化了“应用商店”模型的部署。\n\n关于这个打包工具的实际使用，可以看这个视频 Playing with Java 16 jpackage（需要梯子）。\n\n\n# JEP 393:外部内存访问 API(第三次孵化)\n\n引入外部内存访问 API 以允许 Java 程序安全有效地访问 Java 堆之外的外部内存。\n\nJava 14(JEP 370) 的时候，第一次孵化外部内存访问 API，Java 15 中进行了第二次复活（JEP 383），在 Java 16 中进行了第三次孵化。\n\n引入外部内存访问 API 的目的如下：\n\n * 通用：单个 API 应该能够对各种外部内存（如本机内存、持久内存、堆内存等）进行操作。\n * 安全：无论操作何种内存，API 都不应该破坏 JVM 的安全性。\n * 控制：可以自由的选择如何释放内存（显式、隐式等）。\n * 可用：如果需要访问外部内存，API 应该是 sun.misc.Unsafe.\n\n\n# JEP 394:instanceof 模式匹配(转正)\n\nJDK 版本       更新类型                JEP       更新内容\nJava SE 14   preview             JEP 305   首次引入 instanceof 模式匹配。\nJava SE 15   Second Preview      JEP 375   相比较上个版本无变化，继续收集更多反馈。\nJava SE 16   Permanent Release   JEP 394   模式变量不再隐式为 final。\n\n从 Java 16 开始，你可以对 instanceof 中的变量值进行修改。\n\n// Old code\nif (o instanceof String) {\n    String s = (String)o;\n    ... use s ...\n}\n\n// New code\nif (o instanceof String s) {\n    ... use s ...\n}\n\n\n\n# JEP 395:记录类型(转正)\n\n记录类型变更历史：\n\nJDK 版本       更新类型                JEP       更新内容\nJava SE 14   Preview             JEP 359   引入 record 关键字，record 提供一种紧凑的语法来定义类中的不可变数据。\nJava SE 15   Second Preview      JEP 384   支持在局部方法和接口中使用 record。\nJava SE 16   Permanent Release   JEP 395   非静态内部类可以定义非常量的静态成员。\n\n从 Java SE 16 开始，非静态内部类可以定义非常量的静态成员。\n\npublic class Outer {\n  class Inner {\n    static int age;\n  }\n}\n\n\n> 在 JDK 16 之前，如果写上面这种代码，IDE 会提示你静态字段 age 不能在非静态的内部类中定义，除非它用一个常量表达式初始化。（The field age cannot be declared static in a non-static inner type, unless initialized with a constant expression）\n\n\n# JEP 396:默认强封装 JDK 内部元素\n\n此特性会默认强封装 JDK 的所有内部元素，但关键内部 API（例如 sun.misc.Unsafe）除外。默认情况下，使用早期版本成功编译的访问 JDK 内部 API 的代码可能不再起作用。鼓励开发人员从使用内部元素迁移到使用标准 API 的方法上，以便他们及其用户都可以无缝升级到将来的 Java 版本。强封装由 JDK 9 的启动器选项–illegal-access 控制，到 JDK 15 默认改为 warning，从 JDK 16 开始默认为 deny。（目前）仍然可以使用单个命令行选项放宽对所有软件包的封装，将来只有使用–add-opens 打开特定的软件包才行。\n\n\n# JEP 397:密封类(预览)\n\n密封类由 JEP 360 提出预览，集成到了 Java 15 中。在 JDK 16 中， 密封类得到了改进（更加严格的引用检查和密封类的继承关系），由 JEP 397 提出了再次预览。\n\n在 Java 14 & 15 新特性概览 中，我有详细介绍到密封类，这里就不再做额外的介绍了。\n\n\n# 其他优化与改进\n\n * JEP 380:Unix-Domain 套接字通道：Unix-domain 套接字一直是大多数 Unix 平台的一个特性，现在在 Windows 10 和 Windows Server 2019 也提供了支持。此特性为 java.nio.channels 包的套接字通道和服务器套接字通道 API 添加了 Unix-domain（AF_UNIX）套接字支持。它扩展了继承的通道机制以支持 Unix-domain 套接字通道和服务器套接字通道。Unix-domain 套接字用于同一主机上的进程间通信（IPC）。它们在很大程度上类似于 TCP/IP，区别在于套接字是通过文件系统路径名而不是 Internet 协议（IP）地址和端口号寻址的。对于本地进程间通信，Unix-domain 套接字比 TCP/IP 环回连接更安全、更有效\n * JEP 389:外部链接器 API(孵化)： 该孵化器 API 提供了静态类型、纯 Java 访问原生代码的特性，该 API 将大大简化绑定原生库的原本复杂且容易出错的过程。Java 1.1 就已通过 Java 原生接口（JNI）支持了原生方法调用，但并不好用。Java 开发人员应该能够为特定任务绑定特定的原生库。它还提供了外来函数支持，而无需任何中间的 JNI 粘合代码。\n * JEP 357:从 Mercurial 迁移到 Git：在此之前，OpenJDK 源代码是使用版本管理工具 Mercurial 进行管理，现在迁移到了 Git。\n * JEP 369:迁移到 GitHub：和 JEP 357 从 Mercurial 迁移到 Git 的改变一致，在把版本管理迁移到 Git 之后，选择了在 GitHub 上托管 OpenJDK 社区的 Git 仓库。不过只对 JDK 11 以及更高版本 JDK 进行了迁移。\n * JEP 386:移植 Alpine Linux：Alpine Linux 是一个独立的、非商业的 Linux 发行版，它十分的小，一个容器需要不超过 8MB 的空间，最小安装到磁盘只需要大约 130MB 存储空间，并且十分的简单，同时兼顾了安全性。此提案将 JDK 移植到了 Apline Linux，由于 Apline Linux 是基于 musl lib 的轻量级 Linux 发行版，因此其他 x64 和 AArch64 架构上使用 musl lib 的 Linux 发行版也适用。\n * JEP 388:Windows/AArch64 移植：这些 JEP 的重点不是移植工作本身，而是将它们集成到 JDK 主线存储库中；JEP 386 将 JDK 移植到 Alpine Linux 和其他使用 musl 作为 x64 上主要 C 库的发行版上。此外，JEP 388 将 JDK 移植到 Windows AArch64（ARM64）。\n\n\n# 参考文献\n\n * Java Language Changes\n * Consolidated JDK 16 Release Notes\n * Java 16 正式发布，新特性一一解析\n * 实操 | 剖析 Java16 新语法特性（写的很赞）",normalizedContent:"java 16 在 2021 年 3 月 16 日正式发布，非长期支持（lts）版本。\n\n相关阅读：openjdk java 16 文档 。\n\n\n# jep 338:向量 api(第一次孵化)\n\n向量（vector） api 最初由 jep 338 提出，并作为孵化 api集成到 java 16 中。第二轮孵化由 jep 414 提出并集成到 java 17 中，第三轮孵化由 jep 417 提出并集成到 java 18 中，第四轮由 jep 426 提出并集成到了 java 19 中。\n\n该孵化器 api 提供了一个 api 的初始迭代以表达一些向量计算，这些计算在运行时可靠地编译为支持的 cpu 架构上的最佳向量硬件指令，从而获得优于同等标量计算的性能，充分利用单指令多数据（simd）技术（大多数现代 cpu 上都可以使用的一种指令）。尽管 hotspot 支持自动向量化，但是可转换的标量操作集有限且易受代码更改的影响。该 api 将使开发人员能够轻松地用 java 编写可移植的高性能向量算法。\n\n在 java 18 新特性概览 中，我有详细介绍到向量 api，这里就不再做额外的介绍了。\n\n\n# jep 347:启用 c++ 14 语言特性\n\njava 16 允许在 jdk 的 c++ 源代码中使用 c++14 语言特性，并提供在 hotspot 代码中可以使用哪些特性的具体指导。\n\n在 java 15 中，jdk 中 c++ 代码使用的语言特性仅限于 c++98/03 语言标准。它要求更新各种平台编译器的最低可接受版本。\n\n\n# jep 376:zgc 并发线程堆栈处理\n\njava16 将 zgc 线程栈处理从安全点转移到一个并发阶段，甚至在大堆上也允许在毫秒内暂停 gc 安全点。消除 zgc 垃圾收集器中最后一个延迟源可以极大地提高应用程序的性能和效率。\n\n\n# jep 387:弹性元空间\n\n自从引入了 metaspace 以来，根据反馈，metaspace 经常占用过多的堆外内存，从而导致内存浪费。弹性元空间这个特性可将未使用的 hotspot 类元数据（即元空间，metaspace）内存更快速地返回到操作系统，从而减少元空间的占用空间。\n\n并且，这个提案还简化了元空间的代码以降低维护成本。\n\n\n# jep 390:对基于值的类发出警告\n\n> 以下介绍摘自：实操 | 剖析 java16 新语法特性，原文写的很不错，推荐阅读。\n\n早在 java9 版本时，java 的设计者们就对 @deprecated 注解进行了一次升级，增加了 since 和 forremoval 等 2 个新元素。其中，since 元素用于指定标记了 @deprecated 注解的 api 被弃用时的版本，而 forremoval 则进一步明确了 api 标记 @deprecated 注解时的语义，如果forremoval=true时，则表示该 api 在未来版本中肯定会被删除，开发人员应该使用新的 api 进行替代，不再容易产生歧义（java9 之前，标记 @deprecated 注解的 api，语义上存在多种可能性，比如：存在使用风险、可能在未来存在兼容性错误、可能在未来版本中被删除，以及应该使用更好的替代方案等）。\n\n仔细观察原始类型的包装类（比如：java.lang.integer、java.lang.double），不难发现，其构造函数上都已经标记有@deprecated(since=\"9\", forremoval = true)注解，这就意味着其构造函数在将来会被删除，不应该在程序中继续使用诸如new integer();这样的编码方式（建议使用integer a = 10;或者integer.valueof()函数），如果继续使用，编译期将会产生'integer(int)' is deprecated and marked for removal 告警。并且，值得注意的是，这些包装类型已经被指定为同 java.util.optional 和 java.time.localdatetime 一样的值类型。\n\n其次，如果继续在 synchronized 同步块中使用值类型，将会在编译期和运行期产生警告，甚至是异常。在此大家需要注意，就算编译期和运行期没有产生警告和异常，也不建议在 synchronized 同步块中使用值类型，举个自增的例子。示例 1-5：\n\npublic void inc(integer count) {\n    for (int i = 0; i < 10; i++) {\n        new thread(() -> {\n            synchronized (count) {\n                count++;\n            }\n        }).start();\n    }\n}\n\n\n当执行上述程序示例时，最终的输出结果一定会与你的期望产生差异，这是许多新人经常犯错的一个点，因为在并发环境下，integer 对象根本无法通过 synchronized 来保证线程安全，这是因为每次的count++操作，所产生的 hashcode 均不同，简而言之，每次加锁都锁在了不同的对象上。因此，如果希望在实际的开发过程中保证其原子性，应该使用 atomicinteger。\n\n\n# jep 392:打包工具\n\n在 java 14 中，jep 343 引入了打包工具，命令是 jpackage。在 java 15 中，继续孵化，现在在 java 16 中，终于成为了正式功能。\n\n这个打包工具允许打包自包含的 java 应用程序。它支持原生打包格式，为最终用户提供自然的安装体验，这些格式包括 windows 上的 msi 和 exe、macos 上的 pkg 和 dmg，还有 linux 上的 deb 和 rpm。它还允许在打包时指定启动时参数，并且可以从命令行直接调用，也可以通过 toolprovider api 以编程方式调用。注意 jpackage 模块名称从 jdk.incubator.jpackage 更改为 jdk.jpackage。这将改善最终用户在安装应用程序时的体验，并简化了“应用商店”模型的部署。\n\n关于这个打包工具的实际使用，可以看这个视频 playing with java 16 jpackage（需要梯子）。\n\n\n# jep 393:外部内存访问 api(第三次孵化)\n\n引入外部内存访问 api 以允许 java 程序安全有效地访问 java 堆之外的外部内存。\n\njava 14(jep 370) 的时候，第一次孵化外部内存访问 api，java 15 中进行了第二次复活（jep 383），在 java 16 中进行了第三次孵化。\n\n引入外部内存访问 api 的目的如下：\n\n * 通用：单个 api 应该能够对各种外部内存（如本机内存、持久内存、堆内存等）进行操作。\n * 安全：无论操作何种内存，api 都不应该破坏 jvm 的安全性。\n * 控制：可以自由的选择如何释放内存（显式、隐式等）。\n * 可用：如果需要访问外部内存，api 应该是 sun.misc.unsafe.\n\n\n# jep 394:instanceof 模式匹配(转正)\n\njdk 版本       更新类型                jep       更新内容\njava se 14   preview             jep 305   首次引入 instanceof 模式匹配。\njava se 15   second preview      jep 375   相比较上个版本无变化，继续收集更多反馈。\njava se 16   permanent release   jep 394   模式变量不再隐式为 final。\n\n从 java 16 开始，你可以对 instanceof 中的变量值进行修改。\n\n// old code\nif (o instanceof string) {\n    string s = (string)o;\n    ... use s ...\n}\n\n// new code\nif (o instanceof string s) {\n    ... use s ...\n}\n\n\n\n# jep 395:记录类型(转正)\n\n记录类型变更历史：\n\njdk 版本       更新类型                jep       更新内容\njava se 14   preview             jep 359   引入 record 关键字，record 提供一种紧凑的语法来定义类中的不可变数据。\njava se 15   second preview      jep 384   支持在局部方法和接口中使用 record。\njava se 16   permanent release   jep 395   非静态内部类可以定义非常量的静态成员。\n\n从 java se 16 开始，非静态内部类可以定义非常量的静态成员。\n\npublic class outer {\n  class inner {\n    static int age;\n  }\n}\n\n\n> 在 jdk 16 之前，如果写上面这种代码，ide 会提示你静态字段 age 不能在非静态的内部类中定义，除非它用一个常量表达式初始化。（the field age cannot be declared static in a non-static inner type, unless initialized with a constant expression）\n\n\n# jep 396:默认强封装 jdk 内部元素\n\n此特性会默认强封装 jdk 的所有内部元素，但关键内部 api（例如 sun.misc.unsafe）除外。默认情况下，使用早期版本成功编译的访问 jdk 内部 api 的代码可能不再起作用。鼓励开发人员从使用内部元素迁移到使用标准 api 的方法上，以便他们及其用户都可以无缝升级到将来的 java 版本。强封装由 jdk 9 的启动器选项–illegal-access 控制，到 jdk 15 默认改为 warning，从 jdk 16 开始默认为 deny。（目前）仍然可以使用单个命令行选项放宽对所有软件包的封装，将来只有使用–add-opens 打开特定的软件包才行。\n\n\n# jep 397:密封类(预览)\n\n密封类由 jep 360 提出预览，集成到了 java 15 中。在 jdk 16 中， 密封类得到了改进（更加严格的引用检查和密封类的继承关系），由 jep 397 提出了再次预览。\n\n在 java 14 & 15 新特性概览 中，我有详细介绍到密封类，这里就不再做额外的介绍了。\n\n\n# 其他优化与改进\n\n * jep 380:unix-domain 套接字通道：unix-domain 套接字一直是大多数 unix 平台的一个特性，现在在 windows 10 和 windows server 2019 也提供了支持。此特性为 java.nio.channels 包的套接字通道和服务器套接字通道 api 添加了 unix-domain（af_unix）套接字支持。它扩展了继承的通道机制以支持 unix-domain 套接字通道和服务器套接字通道。unix-domain 套接字用于同一主机上的进程间通信（ipc）。它们在很大程度上类似于 tcp/ip，区别在于套接字是通过文件系统路径名而不是 internet 协议（ip）地址和端口号寻址的。对于本地进程间通信，unix-domain 套接字比 tcp/ip 环回连接更安全、更有效\n * jep 389:外部链接器 api(孵化)： 该孵化器 api 提供了静态类型、纯 java 访问原生代码的特性，该 api 将大大简化绑定原生库的原本复杂且容易出错的过程。java 1.1 就已通过 java 原生接口（jni）支持了原生方法调用，但并不好用。java 开发人员应该能够为特定任务绑定特定的原生库。它还提供了外来函数支持，而无需任何中间的 jni 粘合代码。\n * jep 357:从 mercurial 迁移到 git：在此之前，openjdk 源代码是使用版本管理工具 mercurial 进行管理，现在迁移到了 git。\n * jep 369:迁移到 github：和 jep 357 从 mercurial 迁移到 git 的改变一致，在把版本管理迁移到 git 之后，选择了在 github 上托管 openjdk 社区的 git 仓库。不过只对 jdk 11 以及更高版本 jdk 进行了迁移。\n * jep 386:移植 alpine linux：alpine linux 是一个独立的、非商业的 linux 发行版，它十分的小，一个容器需要不超过 8mb 的空间，最小安装到磁盘只需要大约 130mb 存储空间，并且十分的简单，同时兼顾了安全性。此提案将 jdk 移植到了 apline linux，由于 apline linux 是基于 musl lib 的轻量级 linux 发行版，因此其他 x64 和 aarch64 架构上使用 musl lib 的 linux 发行版也适用。\n * jep 388:windows/aarch64 移植：这些 jep 的重点不是移植工作本身，而是将它们集成到 jdk 主线存储库中；jep 386 将 jdk 移植到 alpine linux 和其他使用 musl 作为 x64 上主要 c 库的发行版上。此外，jep 388 将 jdk 移植到 windows aarch64（arm64）。\n\n\n# 参考文献\n\n * java language changes\n * consolidated jdk 16 release notes\n * java 16 正式发布，新特性一一解析\n * 实操 | 剖析 java16 新语法特性（写的很赞）",charsets:{cjk:!0}},{title:"Java 17 新特性概览（重要）",frontmatter:{title:"Java 17 新特性概览（重要）",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:05:19.000Z",permalink:"/pages/245aa2/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/09.java17.html",relativePath:"01.Java基础/05.版本新特性/09.java17.md",key:"v-51cd5ef8",path:"/pages/245aa2/",headers:[{level:2,title:"JEP 356:增强的伪随机数生成器",slug:"jep-356-增强的伪随机数生成器",normalizedTitle:"jep 356:增强的伪随机数生成器",charIndex:1140},{level:2,title:"JEP 398:弃用 Applet API 以进行删除",slug:"jep-398-弃用-applet-api-以进行删除",normalizedTitle:"jep 398:弃用 applet api 以进行删除",charIndex:1744},{level:2,title:"JEP 406:switch 的类型匹配（预览）",slug:"jep-406-switch-的类型匹配-预览",normalizedTitle:"jep 406:switch 的类型匹配（预览）",charIndex:1884},{level:2,title:"JEP 407:删除远程方法调用激活机制",slug:"jep-407-删除远程方法调用激活机制",normalizedTitle:"jep 407:删除远程方法调用激活机制",charIndex:3494},{level:2,title:"JEP 409:密封类（转正）",slug:"jep-409-密封类-转正",normalizedTitle:"jep 409:密封类（转正）",charIndex:3573},{level:2,title:"JEP 410:删除实验性的 AOT 和 JIT 编译器",slug:"jep-410-删除实验性的-aot-和-jit-编译器",normalizedTitle:"jep 410:删除实验性的 aot 和 jit 编译器",charIndex:3736},{level:2,title:"JEP 411:弃用安全管理器以进行删除",slug:"jep-411-弃用安全管理器以进行删除",normalizedTitle:"jep 411:弃用安全管理器以进行删除",charIndex:3966},{level:2,title:"JEP 412:外部函数和内存 API（孵化）",slug:"jep-412-外部函数和内存-api-孵化",normalizedTitle:"jep 412:外部函数和内存 api（孵化）",charIndex:4140},{level:2,title:"JEP 414:向量 API（第二次孵化）",slug:"jep-414-向量-api-第二次孵化",normalizedTitle:"jep 414:向量 api（第二次孵化）",charIndex:4469}],headersStr:"JEP 356:增强的伪随机数生成器 JEP 398:弃用 Applet API 以进行删除 JEP 406:switch 的类型匹配（预览） JEP 407:删除远程方法调用激活机制 JEP 409:密封类（转正） JEP 410:删除实验性的 AOT 和 JIT 编译器 JEP 411:弃用安全管理器以进行删除 JEP 412:外部函数和内存 API（孵化） JEP 414:向量 API（第二次孵化）",content:'Java 17 在 2021 年 9 月 14 日正式发布，是一个长期支持（LTS）版本。\n\n下面这张图是 Oracle 官方给出的 Oracle JDK 支持的时间线。可以看得到，Java\n\n17 最多可以支持到 2029 年 9 月份。\n\n\n\nJava 17 将是继 Java 8 以来最重要的长期支持（LTS）版本，是 Java 社区八年努力的成果。Spring 6.x 和 Spring Boot 3.x 最低支持的就是 Java 17。\n\n这次更新共带来 14 个新特性：\n\n * JEP 306:Restore Always-Strict Floating-Point Semantics（恢复始终严格的浮点语义）\n * JEP 356:Enhanced Pseudo-Random Number Generators（增强的伪随机数生成器）\n * JEP 382:New macOS Rendering Pipeline（新的 macOS 渲染管道）\n * JEP 391:macOS/AArch64 Port（支持 macOS AArch64）\n * JEP 398:Deprecate the Applet API for Removal（删除已弃用的 Applet API）\n * JEP 403:Strongly Encapsulate JDK Internals（更强大的封装 JDK 内部元素）\n * JEP 406:Pattern Matching for switch (switch 的类型匹配)（预览）\n * JEP 407:Remove RMI Activation（删除远程方法调用激活机制）\n * JEP 409:Sealed Classes（密封类）（转正）\n * JEP 410:Remove the Experimental AOT and JIT Compiler（删除实验性的 AOT 和 JIT 编译器）\n * JEP 411:Deprecate the Security Manager for Removal（弃用安全管理器以进行删除）\n * JEP 412:Foreign Function & Memory API (外部函数和内存 API)（孵化）\n * JEP 414:Vector（向量） API（第二次孵化）\n * JEP 415:Context-Specific Deserialization Filters\n\n这里只对 356、398、413、406、407、409、410、411、412、414 这几个我觉得比较重要的新特性进行详细介绍。\n\n相关阅读：OpenJDK Java 17 文档 。\n\n\n# JEP 356:增强的伪随机数生成器\n\nJDK 17 之前，我们可以借助 Random、ThreadLocalRandom和SplittableRandom来生成随机数。不过，这 3 个类都各有缺陷，且缺少常见的伪随机算法支持。\n\nJava 17 为伪随机数生成器 （pseudorandom number generator，PRNG，又称为确定性随机位生成器）增加了新的接口类型和实现，使得开发者更容易在应用程序中互换使用各种 PRNG 算法。\n\n> PRNG 用来生成接近于绝对随机数序列的数字序列。一般来说，PRNG 会依赖于一个初始值，也称为种子，来生成对应的伪随机数序列。只要种子确定了，PRNG 所生成的随机数就是完全确定的，因此其生成的随机数序列并不是真正随机的。\n\n使用示例：\n\nRandomGeneratorFactory<RandomGenerator> l128X256MixRandom = RandomGeneratorFactory.of("L128X256MixRandom");\n// 使用时间戳作为随机数种子\nRandomGenerator randomGenerator = l128X256MixRandom.create(System.currentTimeMillis());\n// 生成随机数\nrandomGenerator.nextInt(10);\n\n\n\n# JEP 398:弃用 Applet API 以进行删除\n\nApplet API 用于编写在 Web 浏览器端运行的 Java 小程序，很多年前就已经被淘汰了，已经没有理由使用了。\n\nApplet API 在 Java 9 时被标记弃用（JEP 289），但不是为了删除。\n\n\n# JEP 406:switch 的类型匹配（预览）\n\n正如 instanceof 一样， switch 也紧跟着增加了类型匹配自动转换功能。\n\ninstanceof 代码示例：\n\n// Old code\nif (o instanceof String) {\n    String s = (String)o;\n    ... use s ...\n}\n\n// New code\nif (o instanceof String s) {\n    ... use s ...\n}\n\n\nswitch 代码示例：\n\n// Old code\nstatic String formatter(Object o) {\n    String formatted = "unknown";\n    if (o instanceof Integer i) {\n        formatted = String.format("int %d", i);\n    } else if (o instanceof Long l) {\n        formatted = String.format("long %d", l);\n    } else if (o instanceof Double d) {\n        formatted = String.format("double %f", d);\n    } else if (o instanceof String s) {\n        formatted = String.format("String %s", s);\n    }\n    return formatted;\n}\n\n// New code\nstatic String formatterPatternSwitch(Object o) {\n    return switch (o) {\n        case Integer i -> String.format("int %d", i);\n        case Long l    -> String.format("long %d", l);\n        case Double d  -> String.format("double %f", d);\n        case String s  -> String.format("String %s", s);\n        default        -> o.toString();\n    };\n}\n\n\n\n对于 null 值的判断也进行了优化。\n\n// Old code\nstatic void testFooBar(String s) {\n    if (s == null) {\n        System.out.println("oops!");\n        return;\n    }\n    switch (s) {\n        case "Foo", "Bar" -> System.out.println("Great");\n        default           -> System.out.println("Ok");\n    }\n}\n\n// New code\nstatic void testFooBar(String s) {\n    switch (s) {\n        case null         -> System.out.println("Oops");\n        case "Foo", "Bar" -> System.out.println("Great");\n        default           -> System.out.println("Ok");\n    }\n}\n\n\n\n# JEP 407:删除远程方法调用激活机制\n\n删除远程方法调用 (RMI) 激活机制，同时保留 RMI 的其余部分。RMI 激活机制已过时且不再使用。\n\n\n# JEP 409:密封类（转正）\n\n密封类由 JEP 360 提出预览，集成到了 Java 15 中。在 JDK 16 中， 密封类得到了改进（更加严格的引用检查和密封类的继承关系），由 JEP 397 提出了再次预览。\n\n在 Java 14 & 15 新特性概览 中，我有详细介绍到密封类，这里就不再做额外的介绍了。\n\n\n# JEP 410:删除实验性的 AOT 和 JIT 编译器\n\n在 Java 9 的 JEP 295 ,引入了实验性的提前 (AOT) 编译器，在启动虚拟机之前将 Java 类编译为本机代码。\n\nJava 17，删除实验性的提前 (AOT) 和即时 (JIT) 编译器，因为该编译器自推出以来很少使用，维护它所需的工作量很大。保留实验性的 Java 级 JVM 编译器接口 (JVMCI)，以便开发人员可以继续使用外部构建的编译器版本进行 JIT 编译。\n\n\n# JEP 411:弃用安全管理器以进行删除\n\n弃用安全管理器以便在将来的版本中删除。\n\n安全管理器可追溯到 Java 1.0，多年来，它一直不是保护客户端 Java 代码的主要方法，也很少用于保护服务器端代码。为了推动 Java 向前发展，Java 17 弃用安全管理器，以便与旧版 Applet API ( JEP 398 ) 一起移除。\n\n\n# JEP 412:外部函数和内存 API（孵化）\n\nJava 程序可以通过该 API 与 Java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 JVM 之外的代码）和安全地访问外部内存（即不受 JVM 管理的内存），该 API 使 Java 程序能够调用本机库并处理本机数据，而不会像 JNI 那样危险和脆弱。\n\n外部函数和内存 API 在 Java 17 中进行了第一轮孵化，由 JEP 412 提出。第二轮孵化由JEP 419 提出并集成到了 Java 18 中，预览由 JEP 424 提出并集成到了 Java 19 中。\n\n在 Java 19 新特性概览 中，我有详细介绍到外部函数和内存 API，这里就不再做额外的介绍了。\n\n\n# JEP 414:向量 API（第二次孵化）\n\n向量（Vector） API 最初由 JEP 338 提出，并作为孵化 API集成到 Java 16 中。第二轮孵化由 JEP 414 提出并集成到 Java 17 中，第三轮孵化由 JEP 417 提出并集成到 Java 18 中，第四轮由 JEP 426 提出并集成到了 Java 19 中。\n\n该孵化器 API 提供了一个 API 的初始迭代以表达一些向量计算，这些计算在运行时可靠地编译为支持的 CPU 架构上的最佳向量硬件指令，从而获得优于同等标量计算的性能，充分利用单指令多数据（SIMD）技术（大多数现代 CPU 上都可以使用的一种指令）。尽管 HotSpot 支持自动向量化，但是可转换的标量操作集有限且易受代码更改的影响。该 API 将使开发人员能够轻松地用 Java 编写可移植的高性能向量算法。\n\n在 Java 18 新特性概览 中，我有详细介绍到向量 API，这里就不再做额外的介绍了。',normalizedContent:'java 17 在 2021 年 9 月 14 日正式发布，是一个长期支持（lts）版本。\n\n下面这张图是 oracle 官方给出的 oracle jdk 支持的时间线。可以看得到，java\n\n17 最多可以支持到 2029 年 9 月份。\n\n\n\njava 17 将是继 java 8 以来最重要的长期支持（lts）版本，是 java 社区八年努力的成果。spring 6.x 和 spring boot 3.x 最低支持的就是 java 17。\n\n这次更新共带来 14 个新特性：\n\n * jep 306:restore always-strict floating-point semantics（恢复始终严格的浮点语义）\n * jep 356:enhanced pseudo-random number generators（增强的伪随机数生成器）\n * jep 382:new macos rendering pipeline（新的 macos 渲染管道）\n * jep 391:macos/aarch64 port（支持 macos aarch64）\n * jep 398:deprecate the applet api for removal（删除已弃用的 applet api）\n * jep 403:strongly encapsulate jdk internals（更强大的封装 jdk 内部元素）\n * jep 406:pattern matching for switch (switch 的类型匹配)（预览）\n * jep 407:remove rmi activation（删除远程方法调用激活机制）\n * jep 409:sealed classes（密封类）（转正）\n * jep 410:remove the experimental aot and jit compiler（删除实验性的 aot 和 jit 编译器）\n * jep 411:deprecate the security manager for removal（弃用安全管理器以进行删除）\n * jep 412:foreign function & memory api (外部函数和内存 api)（孵化）\n * jep 414:vector（向量） api（第二次孵化）\n * jep 415:context-specific deserialization filters\n\n这里只对 356、398、413、406、407、409、410、411、412、414 这几个我觉得比较重要的新特性进行详细介绍。\n\n相关阅读：openjdk java 17 文档 。\n\n\n# jep 356:增强的伪随机数生成器\n\njdk 17 之前，我们可以借助 random、threadlocalrandom和splittablerandom来生成随机数。不过，这 3 个类都各有缺陷，且缺少常见的伪随机算法支持。\n\njava 17 为伪随机数生成器 （pseudorandom number generator，prng，又称为确定性随机位生成器）增加了新的接口类型和实现，使得开发者更容易在应用程序中互换使用各种 prng 算法。\n\n> prng 用来生成接近于绝对随机数序列的数字序列。一般来说，prng 会依赖于一个初始值，也称为种子，来生成对应的伪随机数序列。只要种子确定了，prng 所生成的随机数就是完全确定的，因此其生成的随机数序列并不是真正随机的。\n\n使用示例：\n\nrandomgeneratorfactory<randomgenerator> l128x256mixrandom = randomgeneratorfactory.of("l128x256mixrandom");\n// 使用时间戳作为随机数种子\nrandomgenerator randomgenerator = l128x256mixrandom.create(system.currenttimemillis());\n// 生成随机数\nrandomgenerator.nextint(10);\n\n\n\n# jep 398:弃用 applet api 以进行删除\n\napplet api 用于编写在 web 浏览器端运行的 java 小程序，很多年前就已经被淘汰了，已经没有理由使用了。\n\napplet api 在 java 9 时被标记弃用（jep 289），但不是为了删除。\n\n\n# jep 406:switch 的类型匹配（预览）\n\n正如 instanceof 一样， switch 也紧跟着增加了类型匹配自动转换功能。\n\ninstanceof 代码示例：\n\n// old code\nif (o instanceof string) {\n    string s = (string)o;\n    ... use s ...\n}\n\n// new code\nif (o instanceof string s) {\n    ... use s ...\n}\n\n\nswitch 代码示例：\n\n// old code\nstatic string formatter(object o) {\n    string formatted = "unknown";\n    if (o instanceof integer i) {\n        formatted = string.format("int %d", i);\n    } else if (o instanceof long l) {\n        formatted = string.format("long %d", l);\n    } else if (o instanceof double d) {\n        formatted = string.format("double %f", d);\n    } else if (o instanceof string s) {\n        formatted = string.format("string %s", s);\n    }\n    return formatted;\n}\n\n// new code\nstatic string formatterpatternswitch(object o) {\n    return switch (o) {\n        case integer i -> string.format("int %d", i);\n        case long l    -> string.format("long %d", l);\n        case double d  -> string.format("double %f", d);\n        case string s  -> string.format("string %s", s);\n        default        -> o.tostring();\n    };\n}\n\n\n\n对于 null 值的判断也进行了优化。\n\n// old code\nstatic void testfoobar(string s) {\n    if (s == null) {\n        system.out.println("oops!");\n        return;\n    }\n    switch (s) {\n        case "foo", "bar" -> system.out.println("great");\n        default           -> system.out.println("ok");\n    }\n}\n\n// new code\nstatic void testfoobar(string s) {\n    switch (s) {\n        case null         -> system.out.println("oops");\n        case "foo", "bar" -> system.out.println("great");\n        default           -> system.out.println("ok");\n    }\n}\n\n\n\n# jep 407:删除远程方法调用激活机制\n\n删除远程方法调用 (rmi) 激活机制，同时保留 rmi 的其余部分。rmi 激活机制已过时且不再使用。\n\n\n# jep 409:密封类（转正）\n\n密封类由 jep 360 提出预览，集成到了 java 15 中。在 jdk 16 中， 密封类得到了改进（更加严格的引用检查和密封类的继承关系），由 jep 397 提出了再次预览。\n\n在 java 14 & 15 新特性概览 中，我有详细介绍到密封类，这里就不再做额外的介绍了。\n\n\n# jep 410:删除实验性的 aot 和 jit 编译器\n\n在 java 9 的 jep 295 ,引入了实验性的提前 (aot) 编译器，在启动虚拟机之前将 java 类编译为本机代码。\n\njava 17，删除实验性的提前 (aot) 和即时 (jit) 编译器，因为该编译器自推出以来很少使用，维护它所需的工作量很大。保留实验性的 java 级 jvm 编译器接口 (jvmci)，以便开发人员可以继续使用外部构建的编译器版本进行 jit 编译。\n\n\n# jep 411:弃用安全管理器以进行删除\n\n弃用安全管理器以便在将来的版本中删除。\n\n安全管理器可追溯到 java 1.0，多年来，它一直不是保护客户端 java 代码的主要方法，也很少用于保护服务器端代码。为了推动 java 向前发展，java 17 弃用安全管理器，以便与旧版 applet api ( jep 398 ) 一起移除。\n\n\n# jep 412:外部函数和内存 api（孵化）\n\njava 程序可以通过该 api 与 java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 jvm 之外的代码）和安全地访问外部内存（即不受 jvm 管理的内存），该 api 使 java 程序能够调用本机库并处理本机数据，而不会像 jni 那样危险和脆弱。\n\n外部函数和内存 api 在 java 17 中进行了第一轮孵化，由 jep 412 提出。第二轮孵化由jep 419 提出并集成到了 java 18 中，预览由 jep 424 提出并集成到了 java 19 中。\n\n在 java 19 新特性概览 中，我有详细介绍到外部函数和内存 api，这里就不再做额外的介绍了。\n\n\n# jep 414:向量 api（第二次孵化）\n\n向量（vector） api 最初由 jep 338 提出，并作为孵化 api集成到 java 16 中。第二轮孵化由 jep 414 提出并集成到 java 17 中，第三轮孵化由 jep 417 提出并集成到 java 18 中，第四轮由 jep 426 提出并集成到了 java 19 中。\n\n该孵化器 api 提供了一个 api 的初始迭代以表达一些向量计算，这些计算在运行时可靠地编译为支持的 cpu 架构上的最佳向量硬件指令，从而获得优于同等标量计算的性能，充分利用单指令多数据（simd）技术（大多数现代 cpu 上都可以使用的一种指令）。尽管 hotspot 支持自动向量化，但是可转换的标量操作集有限且易受代码更改的影响。该 api 将使开发人员能够轻松地用 java 编写可移植的高性能向量算法。\n\n在 java 18 新特性概览 中，我有详细介绍到向量 api，这里就不再做额外的介绍了。',charsets:{cjk:!0}},{title:"Java 18 新特性概览",frontmatter:{title:"Java 18 新特性概览",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:05:23.000Z",permalink:"/pages/ce76de/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/10.java18.html",relativePath:"01.Java基础/05.版本新特性/10.java18.md",key:"v-497d7762",path:"/pages/ce76de/",headers:[{level:2,title:"JEP 400:默认字符集为 UTF-8",slug:"jep-400-默认字符集为-utf-8",normalizedTitle:"jep 400:默认字符集为 utf-8",charIndex:770},{level:2,title:"JEP 408:简易的 Web 服务器",slug:"jep-408-简易的-web-服务器",normalizedTitle:"jep 408:简易的 web 服务器",charIndex:961},{level:2,title:"JEP 413:优化 Java API 文档中的代码片段",slug:"jep-413-优化-java-api-文档中的代码片段",normalizedTitle:"jep 413:优化 java api 文档中的代码片段",charIndex:1246},{level:2,title:"JEP 416:使用方法句柄重新实现反射核心",slug:"jep-416-使用方法句柄重新实现反射核心",normalizedTitle:"jep 416:使用方法句柄重新实现反射核心",charIndex:1673},{level:2,title:"JEP 417: 向量 API（第三次孵化）",slug:"jep-417-向量-api-第三次孵化",normalizedTitle:"jep 417: 向量 api（第三次孵化）",charIndex:1850},{level:2,title:"JEP 418:互联网地址解析 SPI",slug:"jep-418-互联网地址解析-spi",normalizedTitle:"jep 418:互联网地址解析 spi",charIndex:3006},{level:2,title:"JEP 419:Foreign Function & Memory API（第二次孵化）",slug:"jep-419-foreign-function-memory-api-第二次孵化",normalizedTitle:"jep 419:foreign function &amp; memory api（第二次孵化）",charIndex:null}],headersStr:"JEP 400:默认字符集为 UTF-8 JEP 408:简易的 Web 服务器 JEP 413:优化 Java API 文档中的代码片段 JEP 416:使用方法句柄重新实现反射核心 JEP 417: 向量 API（第三次孵化） JEP 418:互联网地址解析 SPI JEP 419:Foreign Function & Memory API（第二次孵化）",content:'Java 18 在 2022 年 3 月 22 日正式发布，非长期支持版本。\n\nJava 18 带来了 9 个新特性：\n\n * JEP 400:UTF-8 by Default（默认字符集为 UTF-8）\n * JEP 408:Simple Web Server（简易的 Web 服务器）\n * JEP 413:Code Snippets in Java API Documentation（Java API 文档中的代码片段）\n * JEP 416:Reimplement Core Reflection with Method Handles（使用方法句柄重新实现反射核心）\n * JEP 417:Vector（向量） API（第三次孵化）\n * JEP 418:Internet-Address Resolution（互联网地址解析）SPI\n * JEP 419:Foreign Function & Memory API（外部函数和内存 API）（第二次孵化）\n * JEP 420:Pattern Matching for switch（switch 模式匹配）（第二次预览）\n * JEP 421:Deprecate Finalization for Removal\n\nJava 17 中包含 14 个特性，Java 16 中包含 17 个特性，Java 15 中包含 14 个特性，Java 14 中包含 16 个特性。相比于前面发布的版本来说，Java 18 的新特性少了很多。\n\n这里只对 400、408、413、416、417、418、419 这几个我觉得比较重要的新特性进行详细介绍。\n\n相关阅读：\n\n * OpenJDK Java 18 文档\n * IntelliJ IDEA | Java 18 功能支持\n\n\n# JEP 400:默认字符集为 UTF-8\n\nJDK 终于将 UTF-8 设置为默认字符集。\n\n在 Java 17 及更早版本中，默认字符集是在 Java 虚拟机运行时才确定的，取决于不同的操作系统、区域设置等因素，因此存在潜在的风险。就比如说你在 Mac 上运行正常的一段打印文字到控制台的 Java 程序到了 Windows 上就会出现乱码，如果你不手动更改字符集的话。\n\n\n# JEP 408:简易的 Web 服务器\n\nJava 18 之后，你可以使用 jwebserver 命令启动一个简易的静态 Web 服务器。\n\n$ jwebserver\nBinding to loopback by default. For all interfaces use "-b 0.0.0.0" or "-b ::".\nServing /cwd and subdirectories on 127.0.0.1 port 8000\nURL: http://127.0.0.1:8000/\n\n\n这个服务器不支持 CGI 和 Servlet，只限于静态文件。\n\n\n# JEP 413:优化 Java API 文档中的代码片段\n\n在 Java 18 之前，如果我们想要在 Javadoc 中引入代码片段可以使用 <pre>{@code ...}</pre> 。\n\n<pre>{@code\n    lines of source code\n}</pre>\n\n\n<pre>{@code ...}</pre> 这种方式生成的效果比较一般。\n\n在 Java 18 之后，可以通过 @snippet 标签来做这件事情。\n\n/**\n * The following code shows how to use {@code Optional.isPresent}:\n * {@snippet :\n * if (v.isPresent()) {\n *     System.out.println("v: " + v.get());\n * }\n * }\n */\n\n\n@snippet 这种方式生成的效果更好且使用起来更方便一些。\n\n\n# JEP 416:使用方法句柄重新实现反射核心\n\nJava 18 改进了 java.lang.reflect.Method、Constructor 的实现逻辑，使之性能更好，速度更快。这项改动不会改动相关 API ，这意味着开发中不需要改动反射相关代码，就可以体验到性能更好反射。\n\nOpenJDK 官方给出了新老实现的反射性能基准测试结果。\n\n\n\n\n# JEP 417: 向量 API（第三次孵化）\n\n向量（Vector） API 最初由 JEP 338 提出，并作为孵化 API集成到 Java 16 中。第二轮孵化由 JEP 414 提出并集成到 Java 17 中，第三轮孵化由 JEP 417 提出并集成到 Java 18 中，第四轮由 JEP 426 提出并集成到了 Java 19 中。\n\n向量计算由对向量的一系列操作组成。向量 API 用来表达向量计算，该计算可以在运行时可靠地编译为支持的 CPU 架构上的最佳向量指令，从而实现优于等效标量计算的性能。\n\n向量 API 的目标是为用户提供简洁易用且与平台无关的表达范围广泛的向量计算。\n\n这是对数组元素的简单标量计算：\n\nvoid scalarComputation(float[] a, float[] b, float[] c) {\n   for (int i = 0; i < a.length; i++) {\n        c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f;\n   }\n}\n\n\n这是使用 Vector API 进行的等效向量计算：\n\nstatic final VectorSpecies<Float> SPECIES = FloatVector.SPECIES_PREFERRED;\n\nvoid vectorComputation(float[] a, float[] b, float[] c) {\n    int i = 0;\n    int upperBound = SPECIES.loopBound(a.length);\n    for (; i < upperBound; i += SPECIES.length()) {\n        // FloatVector va, vb, vc;\n        var va = FloatVector.fromArray(SPECIES, a, i);\n        var vb = FloatVector.fromArray(SPECIES, b, i);\n        var vc = va.mul(va)\n                   .add(vb.mul(vb))\n                   .neg();\n        vc.intoArray(c, i);\n    }\n    for (; i < a.length; i++) {\n        c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f;\n    }\n}\n\n\n\n在 JDK 18 中，向量 API 的性能得到了进一步的优化。\n\n\n# JEP 418:互联网地址解析 SPI\n\nJava 18 定义了一个全新的 SPI（service-provider interface），用于主要名称和地址的解析，以便 java.net.InetAddress 可以使用平台之外的第三方解析器。\n\n\n# JEP 419:Foreign Function & Memory API（第二次孵化）\n\nJava 程序可以通过该 API 与 Java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 JVM 之外的代码）和安全地访问外部内存（即不受 JVM 管理的内存），该 API 使 Java 程序能够调用本机库并处理本机数据，而不会像 JNI 那样危险和脆弱。\n\n外部函数和内存 API 在 Java 17 中进行了第一轮孵化，由 JEP 412 提出。第二轮孵化由JEP 419 提出并集成到了 Java 18 中，预览由 JEP 424 提出并集成到了 Java 19 中。\n\n在 Java 19 新特性概览 中，我有详细介绍到外部函数和内存 API，这里就不再做额外的介绍了。',normalizedContent:'java 18 在 2022 年 3 月 22 日正式发布，非长期支持版本。\n\njava 18 带来了 9 个新特性：\n\n * jep 400:utf-8 by default（默认字符集为 utf-8）\n * jep 408:simple web server（简易的 web 服务器）\n * jep 413:code snippets in java api documentation（java api 文档中的代码片段）\n * jep 416:reimplement core reflection with method handles（使用方法句柄重新实现反射核心）\n * jep 417:vector（向量） api（第三次孵化）\n * jep 418:internet-address resolution（互联网地址解析）spi\n * jep 419:foreign function & memory api（外部函数和内存 api）（第二次孵化）\n * jep 420:pattern matching for switch（switch 模式匹配）（第二次预览）\n * jep 421:deprecate finalization for removal\n\njava 17 中包含 14 个特性，java 16 中包含 17 个特性，java 15 中包含 14 个特性，java 14 中包含 16 个特性。相比于前面发布的版本来说，java 18 的新特性少了很多。\n\n这里只对 400、408、413、416、417、418、419 这几个我觉得比较重要的新特性进行详细介绍。\n\n相关阅读：\n\n * openjdk java 18 文档\n * intellij idea | java 18 功能支持\n\n\n# jep 400:默认字符集为 utf-8\n\njdk 终于将 utf-8 设置为默认字符集。\n\n在 java 17 及更早版本中，默认字符集是在 java 虚拟机运行时才确定的，取决于不同的操作系统、区域设置等因素，因此存在潜在的风险。就比如说你在 mac 上运行正常的一段打印文字到控制台的 java 程序到了 windows 上就会出现乱码，如果你不手动更改字符集的话。\n\n\n# jep 408:简易的 web 服务器\n\njava 18 之后，你可以使用 jwebserver 命令启动一个简易的静态 web 服务器。\n\n$ jwebserver\nbinding to loopback by default. for all interfaces use "-b 0.0.0.0" or "-b ::".\nserving /cwd and subdirectories on 127.0.0.1 port 8000\nurl: http://127.0.0.1:8000/\n\n\n这个服务器不支持 cgi 和 servlet，只限于静态文件。\n\n\n# jep 413:优化 java api 文档中的代码片段\n\n在 java 18 之前，如果我们想要在 javadoc 中引入代码片段可以使用 <pre>{@code ...}</pre> 。\n\n<pre>{@code\n    lines of source code\n}</pre>\n\n\n<pre>{@code ...}</pre> 这种方式生成的效果比较一般。\n\n在 java 18 之后，可以通过 @snippet 标签来做这件事情。\n\n/**\n * the following code shows how to use {@code optional.ispresent}:\n * {@snippet :\n * if (v.ispresent()) {\n *     system.out.println("v: " + v.get());\n * }\n * }\n */\n\n\n@snippet 这种方式生成的效果更好且使用起来更方便一些。\n\n\n# jep 416:使用方法句柄重新实现反射核心\n\njava 18 改进了 java.lang.reflect.method、constructor 的实现逻辑，使之性能更好，速度更快。这项改动不会改动相关 api ，这意味着开发中不需要改动反射相关代码，就可以体验到性能更好反射。\n\nopenjdk 官方给出了新老实现的反射性能基准测试结果。\n\n\n\n\n# jep 417: 向量 api（第三次孵化）\n\n向量（vector） api 最初由 jep 338 提出，并作为孵化 api集成到 java 16 中。第二轮孵化由 jep 414 提出并集成到 java 17 中，第三轮孵化由 jep 417 提出并集成到 java 18 中，第四轮由 jep 426 提出并集成到了 java 19 中。\n\n向量计算由对向量的一系列操作组成。向量 api 用来表达向量计算，该计算可以在运行时可靠地编译为支持的 cpu 架构上的最佳向量指令，从而实现优于等效标量计算的性能。\n\n向量 api 的目标是为用户提供简洁易用且与平台无关的表达范围广泛的向量计算。\n\n这是对数组元素的简单标量计算：\n\nvoid scalarcomputation(float[] a, float[] b, float[] c) {\n   for (int i = 0; i < a.length; i++) {\n        c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f;\n   }\n}\n\n\n这是使用 vector api 进行的等效向量计算：\n\nstatic final vectorspecies<float> species = floatvector.species_preferred;\n\nvoid vectorcomputation(float[] a, float[] b, float[] c) {\n    int i = 0;\n    int upperbound = species.loopbound(a.length);\n    for (; i < upperbound; i += species.length()) {\n        // floatvector va, vb, vc;\n        var va = floatvector.fromarray(species, a, i);\n        var vb = floatvector.fromarray(species, b, i);\n        var vc = va.mul(va)\n                   .add(vb.mul(vb))\n                   .neg();\n        vc.intoarray(c, i);\n    }\n    for (; i < a.length; i++) {\n        c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f;\n    }\n}\n\n\n\n在 jdk 18 中，向量 api 的性能得到了进一步的优化。\n\n\n# jep 418:互联网地址解析 spi\n\njava 18 定义了一个全新的 spi（service-provider interface），用于主要名称和地址的解析，以便 java.net.inetaddress 可以使用平台之外的第三方解析器。\n\n\n# jep 419:foreign function & memory api（第二次孵化）\n\njava 程序可以通过该 api 与 java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 jvm 之外的代码）和安全地访问外部内存（即不受 jvm 管理的内存），该 api 使 java 程序能够调用本机库并处理本机数据，而不会像 jni 那样危险和脆弱。\n\n外部函数和内存 api 在 java 17 中进行了第一轮孵化，由 jep 412 提出。第二轮孵化由jep 419 提出并集成到了 java 18 中，预览由 jep 424 提出并集成到了 java 19 中。\n\n在 java 19 新特性概览 中，我有详细介绍到外部函数和内存 api，这里就不再做额外的介绍了。',charsets:{cjk:!0}},{title:"Java 19 新特性概览",frontmatter:{title:"Java 19 新特性概览",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:05:28.000Z",permalink:"/pages/42d550/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/11.java19.html",relativePath:"01.Java基础/05.版本新特性/11.java19.md",key:"v-6280d5a2",path:"/pages/42d550/",headers:[{level:2,title:"JEP 424: 外部函数和内存 API（预览）",slug:"jep-424-外部函数和内存-api-预览",normalizedTitle:"jep 424: 外部函数和内存 api（预览）",charIndex:464},{level:2,title:"JEP 425: 虚拟线程（预览）",slug:"jep-425-虚拟线程-预览",normalizedTitle:"jep 425: 虚拟线程（预览）",charIndex:2592},{level:2,title:"JEP 426: 向量 API（第四次孵化）",slug:"jep-426-向量-api-第四次孵化",normalizedTitle:"jep 426: 向量 api（第四次孵化）",charIndex:3044},{level:2,title:"JEP 428: 结构化并发(孵化)",slug:"jep-428-结构化并发-孵化",normalizedTitle:"jep 428: 结构化并发(孵化)",charIndex:3268}],headersStr:"JEP 424: 外部函数和内存 API（预览） JEP 425: 虚拟线程（预览） JEP 426: 向量 API（第四次孵化） JEP 428: 结构化并发(孵化)",content:'JDK 19 定于 2022 年 9 月 20 日正式发布以供生产使用，非长期支持版本。不过，JDK 19 中有一些比较重要的新特性值得关注。\n\nJDK 19 只有 7 个新特性：\n\n * JEP 405: Record Patterns（记录模式）（预览）\n * JEP 422: Linux/RISC-V Port\n * JEP 424: Foreign Function & Memory API（外部函数和内存 API）（预览）\n * JEP 425: Virtual Threads（虚拟线程）（预览）\n * JEP 426: Vector（向量）API（第四次孵化）\n * JEP 427: Pattern Matching for switch（switch 模式匹配）\n * JEP 428: Structured Concurrency（结构化并发）（孵化）\n\n这里只对 424、425、426、428 这 4 个我觉得比较重要的新特性进行详细介绍。\n\n相关阅读：OpenJDK Java 19 文档\n\n\n# JEP 424: 外部函数和内存 API（预览）\n\nJava 程序可以通过该 API 与 Java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 JVM 之外的代码）和安全地访问外部内存（即不受 JVM 管理的内存），该 API 使 Java 程序能够调用本机库并处理本机数据，而不会像 JNI 那样危险和脆弱。\n\n外部函数和内存 API 在 Java 17 中进行了第一轮孵化，由 JEP 412 提出。第二轮孵化由JEP 419 提出并集成到了 Java 18 中，预览由 JEP 424 提出并集成到了 Java 19 中。\n\n在没有外部函数和内存 API 之前：\n\n * Java 通过 sun.misc.Unsafe 提供一些执行低级别、不安全操作的方法（如直接访问系统内存资源、自主管理内存资源等），Unsafe 类让 Java 语言拥有了类似 C 语言指针一样操作内存空间的能力的同时，也增加了 Java 语言的不安全性，不正确使用 Unsafe 类会使得程序出错的概率变大。\n * Java 1.1 就已通过 Java 原生接口（JNI）支持了原生方法调用，但并不好用。JNI 实现起来过于复杂，步骤繁琐（具体的步骤可以参考这篇文章：Guide to JNI (Java Native Interface) ），不受 JVM 的语言安全机制控制，影响 Java 语言的跨平台特性。并且，JNI 的性能也不行，因为 JNI 方法调用不能从许多常见的 JIT 优化(如内联)中受益。虽然JNA、JNR和JavaCPP等框架对 JNI 进行了改进，但效果还是不太理想。\n\n引入外部函数和内存 API 就是为了解决 Java 访问外部函数和外部内存存在的一些痛点。\n\nForeign Function & Memory API (FFM API) 定义了类和接口：\n\n * 分配外部内存：MemorySegment、、MemoryAddress和SegmentAllocator）；\n * 操作和访问结构化的外部内存：MemoryLayout, VarHandle；\n * 控制外部内存的分配和释放：MemorySession；\n * 调用外部函数：Linker、FunctionDescriptor和SymbolLookup。\n\n下面是 FFM API 使用示例，这段代码获取了 C 库函数的 radixsort 方法句柄，然后使用它对 Java 数组中的四个字符串进行排序。\n\n// 1. 在C库路径上查找外部函数\nLinker linker = Linker.nativeLinker();\nSymbolLookup stdlib = linker.defaultLookup();\nMethodHandle radixSort = linker.downcallHandle(\n                             stdlib.lookup("radixsort"), ...);\n// 2. 分配堆上内存以存储四个字符串\nString[] javaStrings   = { "mouse", "cat", "dog", "car" };\n// 3. 分配堆外内存以存储四个指针\nSegmentAllocator allocator = implicitAllocator();\nMemorySegment offHeap  = allocator.allocateArray(ValueLayout.ADDRESS, javaStrings.length);\n// 4. 将字符串从堆上复制到堆外\nfor (int i = 0; i < javaStrings.length; i++) {\n    // 在堆外分配一个字符串，然后存储指向它的指针\n    MemorySegment cString = allocator.allocateUtf8String(javaStrings[i]);\n    offHeap.setAtIndex(ValueLayout.ADDRESS, i, cString);\n}\n// 5. 通过调用外部函数对堆外数据进行排序\nradixSort.invoke(offHeap, javaStrings.length, MemoryAddress.NULL, \'\\0\');\n// 6. 将(重新排序的)字符串从堆外复制到堆上\nfor (int i = 0; i < javaStrings.length; i++) {\n    MemoryAddress cStringPtr = offHeap.getAtIndex(ValueLayout.ADDRESS, i);\n    javaStrings[i] = cStringPtr.getUtf8String(0);\n}\nassert Arrays.equals(javaStrings, new String[] {"car", "cat", "dog", "mouse"});  // true\n\n\n\n# JEP 425: 虚拟线程（预览）\n\n虚拟线程（Virtual Thread-）是 JDK 而不是 OS 实现的轻量级线程(Lightweight Process，LWP），许多虚拟线程共享同一个操作系统线程，虚拟线程的数量可以远大于操作系统线程的数量。\n\n虚拟线程在其他多线程语言中已经被证实是十分有用的，比如 Go 中的 Goroutine、Erlang 中的进程。\n\n虚拟线程避免了上下文切换的额外耗费，兼顾了多线程的优点，简化了高并发程序的复杂，可以有效减少编写、维护和观察高吞吐量并发应用程序的工作量。\n\n知乎有一个关于 Java 19 虚拟线程的讨论，感兴趣的可以去看看：https://www.zhihu.com/question/536743167 。\n\nJava 虚拟线程的详细解读和原理可以看下面这两篇文章：\n\n * 虚拟线程原理及性能分析｜得物技术\n * Java19 正式 GA！看虚拟线程如何大幅提高系统吞吐量\n * 虚拟线程 - VirtualThread 源码透视\n\n\n# JEP 426: 向量 API（第四次孵化）\n\n向量（Vector） API 最初由 JEP 338 提出，并作为孵化 API集成到 Java 16 中。第二轮孵化由 JEP 414 提出并集成到 Java 17 中，第三轮孵化由 JEP 417 提出并集成到 Java 18 中，第四轮由 JEP 426 提出并集成到了 Java 19 中。\n\n在 Java 18 新特性概览 中，我有详细介绍到向量 API，这里就不再做额外的介绍了。\n\n\n# JEP 428: 结构化并发(孵化)\n\nJDK 19 引入了结构化并发，一种多线程编程方法，目的是为了通过结构化并发 API 来简化多线程编程，并不是为了取代java.util.concurrent，目前处于孵化器阶段。\n\n结构化并发将不同线程中运行的多个任务视为单个工作单元，从而简化错误处理、提高可靠性并增强可观察性。也就是说，结构化并发保留了单线程代码的可读性、可维护性和可观察性。\n\n结构化并发的基本 API 是StructuredTaskScope。StructuredTaskScope 支持将任务拆分为多个并发子任务，在它们自己的线程中执行，并且子任务必须在主任务继续之前完成。\n\nStructuredTaskScope 的基本用法如下：\n\n    try (var scope = new StructuredTaskScope<Object>()) {\n        // 使用fork方法派生线程来执行子任务\n        Future<Integer> future1 = scope.fork(task1);\n        Future<String> future2 = scope.fork(task2);\n        // 等待线程完成\n        scope.join();\n        // 结果的处理可能包括处理或重新抛出异常\n        ... process results/exceptions ...\n    } // close\n\n\n结构化并发非常适合虚拟线程，虚拟线程是 JDK 实现的轻量级线程。许多虚拟线程共享同一个操作系统线程，从而允许非常多的虚拟线程。',normalizedContent:'jdk 19 定于 2022 年 9 月 20 日正式发布以供生产使用，非长期支持版本。不过，jdk 19 中有一些比较重要的新特性值得关注。\n\njdk 19 只有 7 个新特性：\n\n * jep 405: record patterns（记录模式）（预览）\n * jep 422: linux/risc-v port\n * jep 424: foreign function & memory api（外部函数和内存 api）（预览）\n * jep 425: virtual threads（虚拟线程）（预览）\n * jep 426: vector（向量）api（第四次孵化）\n * jep 427: pattern matching for switch（switch 模式匹配）\n * jep 428: structured concurrency（结构化并发）（孵化）\n\n这里只对 424、425、426、428 这 4 个我觉得比较重要的新特性进行详细介绍。\n\n相关阅读：openjdk java 19 文档\n\n\n# jep 424: 外部函数和内存 api（预览）\n\njava 程序可以通过该 api 与 java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 jvm 之外的代码）和安全地访问外部内存（即不受 jvm 管理的内存），该 api 使 java 程序能够调用本机库并处理本机数据，而不会像 jni 那样危险和脆弱。\n\n外部函数和内存 api 在 java 17 中进行了第一轮孵化，由 jep 412 提出。第二轮孵化由jep 419 提出并集成到了 java 18 中，预览由 jep 424 提出并集成到了 java 19 中。\n\n在没有外部函数和内存 api 之前：\n\n * java 通过 sun.misc.unsafe 提供一些执行低级别、不安全操作的方法（如直接访问系统内存资源、自主管理内存资源等），unsafe 类让 java 语言拥有了类似 c 语言指针一样操作内存空间的能力的同时，也增加了 java 语言的不安全性，不正确使用 unsafe 类会使得程序出错的概率变大。\n * java 1.1 就已通过 java 原生接口（jni）支持了原生方法调用，但并不好用。jni 实现起来过于复杂，步骤繁琐（具体的步骤可以参考这篇文章：guide to jni (java native interface) ），不受 jvm 的语言安全机制控制，影响 java 语言的跨平台特性。并且，jni 的性能也不行，因为 jni 方法调用不能从许多常见的 jit 优化(如内联)中受益。虽然jna、jnr和javacpp等框架对 jni 进行了改进，但效果还是不太理想。\n\n引入外部函数和内存 api 就是为了解决 java 访问外部函数和外部内存存在的一些痛点。\n\nforeign function & memory api (ffm api) 定义了类和接口：\n\n * 分配外部内存：memorysegment、、memoryaddress和segmentallocator）；\n * 操作和访问结构化的外部内存：memorylayout, varhandle；\n * 控制外部内存的分配和释放：memorysession；\n * 调用外部函数：linker、functiondescriptor和symbollookup。\n\n下面是 ffm api 使用示例，这段代码获取了 c 库函数的 radixsort 方法句柄，然后使用它对 java 数组中的四个字符串进行排序。\n\n// 1. 在c库路径上查找外部函数\nlinker linker = linker.nativelinker();\nsymbollookup stdlib = linker.defaultlookup();\nmethodhandle radixsort = linker.downcallhandle(\n                             stdlib.lookup("radixsort"), ...);\n// 2. 分配堆上内存以存储四个字符串\nstring[] javastrings   = { "mouse", "cat", "dog", "car" };\n// 3. 分配堆外内存以存储四个指针\nsegmentallocator allocator = implicitallocator();\nmemorysegment offheap  = allocator.allocatearray(valuelayout.address, javastrings.length);\n// 4. 将字符串从堆上复制到堆外\nfor (int i = 0; i < javastrings.length; i++) {\n    // 在堆外分配一个字符串，然后存储指向它的指针\n    memorysegment cstring = allocator.allocateutf8string(javastrings[i]);\n    offheap.setatindex(valuelayout.address, i, cstring);\n}\n// 5. 通过调用外部函数对堆外数据进行排序\nradixsort.invoke(offheap, javastrings.length, memoryaddress.null, \'\\0\');\n// 6. 将(重新排序的)字符串从堆外复制到堆上\nfor (int i = 0; i < javastrings.length; i++) {\n    memoryaddress cstringptr = offheap.getatindex(valuelayout.address, i);\n    javastrings[i] = cstringptr.getutf8string(0);\n}\nassert arrays.equals(javastrings, new string[] {"car", "cat", "dog", "mouse"});  // true\n\n\n\n# jep 425: 虚拟线程（预览）\n\n虚拟线程（virtual thread-）是 jdk 而不是 os 实现的轻量级线程(lightweight process，lwp），许多虚拟线程共享同一个操作系统线程，虚拟线程的数量可以远大于操作系统线程的数量。\n\n虚拟线程在其他多线程语言中已经被证实是十分有用的，比如 go 中的 goroutine、erlang 中的进程。\n\n虚拟线程避免了上下文切换的额外耗费，兼顾了多线程的优点，简化了高并发程序的复杂，可以有效减少编写、维护和观察高吞吐量并发应用程序的工作量。\n\n知乎有一个关于 java 19 虚拟线程的讨论，感兴趣的可以去看看：https://www.zhihu.com/question/536743167 。\n\njava 虚拟线程的详细解读和原理可以看下面这两篇文章：\n\n * 虚拟线程原理及性能分析｜得物技术\n * java19 正式 ga！看虚拟线程如何大幅提高系统吞吐量\n * 虚拟线程 - virtualthread 源码透视\n\n\n# jep 426: 向量 api（第四次孵化）\n\n向量（vector） api 最初由 jep 338 提出，并作为孵化 api集成到 java 16 中。第二轮孵化由 jep 414 提出并集成到 java 17 中，第三轮孵化由 jep 417 提出并集成到 java 18 中，第四轮由 jep 426 提出并集成到了 java 19 中。\n\n在 java 18 新特性概览 中，我有详细介绍到向量 api，这里就不再做额外的介绍了。\n\n\n# jep 428: 结构化并发(孵化)\n\njdk 19 引入了结构化并发，一种多线程编程方法，目的是为了通过结构化并发 api 来简化多线程编程，并不是为了取代java.util.concurrent，目前处于孵化器阶段。\n\n结构化并发将不同线程中运行的多个任务视为单个工作单元，从而简化错误处理、提高可靠性并增强可观察性。也就是说，结构化并发保留了单线程代码的可读性、可维护性和可观察性。\n\n结构化并发的基本 api 是structuredtaskscope。structuredtaskscope 支持将任务拆分为多个并发子任务，在它们自己的线程中执行，并且子任务必须在主任务继续之前完成。\n\nstructuredtaskscope 的基本用法如下：\n\n    try (var scope = new structuredtaskscope<object>()) {\n        // 使用fork方法派生线程来执行子任务\n        future<integer> future1 = scope.fork(task1);\n        future<string> future2 = scope.fork(task2);\n        // 等待线程完成\n        scope.join();\n        // 结果的处理可能包括处理或重新抛出异常\n        ... process results/exceptions ...\n    } // close\n\n\n结构化并发非常适合虚拟线程，虚拟线程是 jdk 实现的轻量级线程。许多虚拟线程共享同一个操作系统线程，从而允许非常多的虚拟线程。',charsets:{cjk:!0}},{title:"Java 20 新特性概览",frontmatter:{title:"Java 20 新特性概览",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:05:34.000Z",permalink:"/pages/d5208b/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/12.java20.html",relativePath:"01.Java基础/05.版本新特性/12.java20.md",key:"v-abc39610",path:"/pages/d5208b/",headers:[{level:2,title:"JEP 429：作用域值（第一次孵化）",slug:"jep-429-作用域值-第一次孵化",normalizedTitle:"jep 429：作用域值（第一次孵化）",charIndex:391},{level:2,title:"JEP 432：记录模式（第二次预览）",slug:"jep-432-记录模式-第二次预览",normalizedTitle:"jep 432：记录模式（第二次预览）",charIndex:808},{level:2,title:"JEP 433：switch 模式匹配（第四次预览）",slug:"jep-433-switch-模式匹配-第四次预览",normalizedTitle:"jep 433：switch 模式匹配（第四次预览）",charIndex:184},{level:2,title:"JEP 434: 外部函数和内存 API（第二次预览）",slug:"jep-434-外部函数和内存-api-第二次预览",normalizedTitle:"jep 434: 外部函数和内存 api（第二次预览）",charIndex:4128},{level:2,title:"JEP 436: 虚拟线程（第二次预览）",slug:"jep-436-虚拟线程-第二次预览",normalizedTitle:"jep 436: 虚拟线程（第二次预览）",charIndex:4613},{level:2,title:"JEP 437: 结构化并发(第二次孵化)",slug:"jep-437-结构化并发-第二次孵化",normalizedTitle:"jep 437: 结构化并发(第二次孵化)",charIndex:6517},{level:2,title:"JEP 432：向量 API（第五次孵化）",slug:"jep-432-向量-api-第五次孵化",normalizedTitle:"jep 432：向量 api（第五次孵化）",charIndex:7328}],headersStr:"JEP 429：作用域值（第一次孵化） JEP 432：记录模式（第二次预览） JEP 433：switch 模式匹配（第四次预览） JEP 434: 外部函数和内存 API（第二次预览） JEP 436: 虚拟线程（第二次预览） JEP 437: 结构化并发(第二次孵化) JEP 432：向量 API（第五次孵化）",content:'JDK 20 于 2023 年 3 月 21 日发布，非长期支持版本。\n\n根据开发计划，下一个 LTS 版本就是将于 2023 年 9 月发布的 JDK 21。\n\n\n\nJDK 20 只有 7 个新特性：\n\n * JEP 429：Scoped Values（作用域值）（第一次孵化）\n * JEP 432：Record Patterns（记录模式）（第二次预览）\n * JEP 433：switch 模式匹配（第四次预览）\n * JEP 434: Foreign Function & Memory API（外部函数和内存 API）（第二次预览）\n * JEP 436: Virtual Threads（虚拟线程）（第二次预览）\n * JEP 437:Structured Concurrency（结构化并发）(第二次孵化)\n * JEP 432:向量 API（第五次孵化）\n\n\n# JEP 429：作用域值（第一次孵化）\n\n作用域值（Scoped Values）它可以在线程内和线程间共享不可变的数据，优于线程局部变量，尤其是在使用大量虚拟线程时。\n\nfinal static ScopedValue<...> V = new ScopedValue<>();\n\n// In some method\nScopedValue.where(V, <value>)\n           .run(() -> { ... V.get() ... call methods ... });\n\n// In a method called directly or indirectly from the lambda expression\n... V.get() ...\n\n\n作用域值允许在大型程序中的组件之间安全有效地共享数据，而无需求助于方法参数。\n\n关于作用域值的详细介绍，推荐阅读作用域值常见问题解答这篇文章。\n\n\n# JEP 432：记录模式（第二次预览）\n\n记录模式（Record Patterns） 可对 record 的值进行解构，也就是更方便地从记录类（Record Class）中提取数据。并且，还可以嵌套记录模式和类型模式结合使用，以实现强大的、声明性的和可组合的数据导航和处理形式。\n\n记录模式不能单独使用，而是要与 instanceof 或 switch 模式匹配一同使用。\n\n先以 instanceof 为例简单演示一下。\n\n简单定义一个记录类：\n\nrecord Shape(String type, long unit){}\n\n\n没有记录模式之前：\n\nShape circle = new Shape("Circle", 10);\nif (circle instanceof Shape shape) {\n\n  System.out.println("Area of " + shape.type() + " is : " + Math.PI * Math.pow(shape.unit(), 2));\n}\n\n\n有了记录模式之后：\n\nShape circle = new Shape("Circle", 10);\nif (circle instanceof Shape(String type, long unit)) {\n  System.out.println("Area of " + type + " is : " + Math.PI * Math.pow(unit, 2));\n}\n\n\n再看看记录模式与 switch 的配合使用。\n\n定义一些类：\n\ninterface Shape {}\nrecord Circle(double radius) implements Shape { }\nrecord Square(double side) implements Shape { }\nrecord Rectangle(double length, double width) implements Shape { }\n\n\n没有记录模式之前：\n\nShape shape = new Circle(10);\nswitch (shape) {\n    case Circle c:\n        System.out.println("The shape is Circle with area: " + Math.PI * c.radius() * c.radius());\n        break;\n\n    case Square s:\n        System.out.println("The shape is Square with area: " + s.side() * s.side());\n        break;\n\n    case Rectangle r:\n        System.out.println("The shape is Rectangle with area: + " + r.length() * r.width());\n        break;\n\n    default:\n        System.out.println("Unknown Shape");\n        break;\n}\n\n\n有了记录模式之后：\n\nShape shape = new Circle(10);\nswitch(shape) {\n\n  case Circle(double radius):\n    System.out.println("The shape is Circle with area: " + Math.PI * radius * radius);\n    break;\n\n  case Square(double side):\n    System.out.println("The shape is Square with area: " + side * side);\n    break;\n\n  case Rectangle(double length, double width):\n    System.out.println("The shape is Rectangle with area: + " + length * width);\n    break;\n\n  default:\n    System.out.println("Unknown Shape");\n    break;\n}\n\n\n记录模式可以避免不必要的转换，使得代码更建简洁易读。而且，用了记录模式后不必再担心 null 或者 NullPointerException，代码更安全可靠。\n\n记录模式在 Java 19 进行了第一次预览， 由 JEP 405 提出。JDK 20 中是第二次预览，由 JEP 432 提出。这次的改进包括：\n\n * 添加对通用记录模式类型参数推断的支持，\n * 添加对记录模式的支持以出现在增强语句的标题中for\n * 删除对命名记录模式的支持。\n\n注意：不要把记录模式和 JDK16 正式引入的记录类搞混了。\n\n\n# JEP 433：switch 模式匹配（第四次预览）\n\n正如 instanceof 一样， switch 也紧跟着增加了类型匹配自动转换功能。\n\ninstanceof 代码示例：\n\n// Old code\nif (o instanceof String) {\n    String s = (String)o;\n    ... use s ...\n}\n\n// New code\nif (o instanceof String s) {\n    ... use s ...\n}\n\n\nswitch 代码示例：\n\n// Old code\nstatic String formatter(Object o) {\n    String formatted = "unknown";\n    if (o instanceof Integer i) {\n        formatted = String.format("int %d", i);\n    } else if (o instanceof Long l) {\n        formatted = String.format("long %d", l);\n    } else if (o instanceof Double d) {\n        formatted = String.format("double %f", d);\n    } else if (o instanceof String s) {\n        formatted = String.format("String %s", s);\n    }\n    return formatted;\n}\n\n// New code\nstatic String formatterPatternSwitch(Object o) {\n    return switch (o) {\n        case Integer i -> String.format("int %d", i);\n        case Long l    -> String.format("long %d", l);\n        case Double d  -> String.format("double %f", d);\n        case String s  -> String.format("String %s", s);\n        default        -> o.toString();\n    };\n}\n\n\nswitch 模式匹配分别在 Java17、Java18、Java19 中进行了预览，Java20 是第四次预览了。每一次的预览基本都会有一些小改进，这里就不细提了。\n\n\n# JEP 434: 外部函数和内存 API（第二次预览）\n\nJava 程序可以通过该 API 与 Java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 JVM 之外的代码）和安全地访问外部内存（即不受 JVM 管理的内存），该 API 使 Java 程序能够调用本机库并处理本机数据，而不会像 JNI 那样危险和脆弱。\n\n外部函数和内存 API 在 Java 17 中进行了第一轮孵化，由 JEP 412 提出。Java 18 中进行了第二次孵化，由JEP 419 提出。Java 19 中是第一次预览，由 JEP 424 提出。\n\nJDK 20 中是第二次预览，由 JEP 434 提出，这次的改进包括：\n\n * MemorySegment 和 MemoryAddress 抽象的统一\n * 增强的 MemoryLayout 层次结构\n * MemorySession拆分为Arena和SegmentScope，以促进跨维护边界的段共享。\n\n在 Java 19 新特性概览 中，我有详细介绍到外部函数和内存 API，这里就不再做额外的介绍了。\n\n\n# JEP 436: 虚拟线程（第二次预览）\n\n虚拟线程（Virtual Thread）是 JDK 而不是 OS 实现的轻量级线程(Lightweight Process，LWP），由 JVM 调度。许多虚拟线程共享同一个操作系统线程，虚拟线程的数量可以远大于操作系统线程的数量。\n\n在引入虚拟线程之前，java.lang.Thread 包已经支持所谓的平台线程，也就是没有虚拟线程之前，我们一直使用的线程。JVM 调度程序通过平台线程（载体线程）来管理虚拟线程，一个平台线程可以在不同的时间执行不同的虚拟线程（多个虚拟线程挂载在一个平台线程上），当虚拟线程被阻塞或等待时，平台线程可以切换到执行另一个虚拟线程。\n\n虚拟线程、平台线程和系统内核线程的关系图如下所示（图源：How to Use Java 19 Virtual Threads）：\n\n\n\n关于平台线程和系统内核线程的对应关系多提一点：在 Windows 和 Linux 等主流操作系统中，Java 线程采用的是一对一的线程模型，也就是一个平台线程对应一个系统内核线程。Solaris 系统是一个特例，HotSpot VM 在 Solaris 上支持多对多和一对一。具体可以参考 R 大的回答: JVM 中的线程模型是用户级的么？。\n\n相比较于平台线程来说，虚拟线程是廉价且轻量级的，使用完后立即被销毁，因此它们不需要被重用或池化，每个任务可以有自己专属的虚拟线程来运行。虚拟线程暂停和恢复来实现线程之间的切换，避免了上下文切换的额外耗费，兼顾了多线程的优点，简化了高并发程序的复杂，可以有效减少编写、维护和观察高吞吐量并发应用程序的工作量。\n\n虚拟线程在其他多线程语言中已经被证实是十分有用的，比如 Go 中的 Goroutine、Erlang 中的进程。\n\n知乎有一个关于 Java 19 虚拟线程的讨论，感兴趣的可以去看看：https://www.zhihu.com/question/536743167 。\n\nJava 虚拟线程的详细解读和原理可以看下面这几篇文章：\n\n * 虚拟线程极简入门\n * Java19 正式 GA！看虚拟线程如何大幅提高系统吞吐量\n * 虚拟线程 - VirtualThread 源码透视\n\n虚拟线程在 Java 19 中进行了第一次预览，由JEP 425提出。JDK 20 中是第二次预览，做了一些细微变化，这里就不细提了。\n\n最后，我们来看一下四种创建虚拟线程的方法：\n\n// 1、通过 Thread.ofVirtual() 创建\nRunnable fn = () -> {\n  // your code here\n};\n\nThread thread = Thread.ofVirtual(fn)\n                      .start();\n\n// 2、通过 Thread.startVirtualThread() 、创建\nThread thread = Thread.startVirtualThread(() -> {\n  // your code here\n});\n\n// 3、通过 Executors.newVirtualThreadPerTaskExecutor() 创建\nvar executorService = Executors.newVirtualThreadPerTaskExecutor();\n\nexecutorService.submit(() -> {\n  // your code here\n});\n\nclass CustomThread implements Runnable {\n  @Override\n  public void run() {\n    System.out.println("CustomThread run");\n  }\n}\n\n//4、通过 ThreadFactory 创建\nCustomThread customThread = new CustomThread();\n// 获取线程工厂类\nThreadFactory factory = Thread.ofVirtual().factory();\n// 创建虚拟线程\nThread thread = factory.newThread(customThread);\n// 启动线程\nthread.start();\n\n\n通过上述列举的 4 种创建虚拟线程的方式可以看出，官方为了降低虚拟线程的门槛，尽力复用原有的 Thread 线程类，这样可以平滑的过渡到虚拟线程的使用。\n\n\n# JEP 437: 结构化并发(第二次孵化)\n\nJava 19 引入了结构化并发，一种多线程编程方法，目的是为了通过结构化并发 API 来简化多线程编程，并不是为了取代java.util.concurrent，目前处于孵化器阶段。\n\n结构化并发将不同线程中运行的多个任务视为单个工作单元，从而简化错误处理、提高可靠性并增强可观察性。也就是说，结构化并发保留了单线程代码的可读性、可维护性和可观察性。\n\n结构化并发的基本 API 是StructuredTaskScope。StructuredTaskScope 支持将任务拆分为多个并发子任务，在它们自己的线程中执行，并且子任务必须在主任务继续之前完成。\n\nStructuredTaskScope 的基本用法如下：\n\n    try (var scope = new StructuredTaskScope<Object>()) {\n        // 使用fork方法派生线程来执行子任务\n        Future<Integer> future1 = scope.fork(task1);\n        Future<String> future2 = scope.fork(task2);\n        // 等待线程完成\n        scope.join();\n        // 结果的处理可能包括处理或重新抛出异常\n        ... process results/exceptions ...\n    } // close\n\n\n结构化并发非常适合虚拟线程，虚拟线程是 JDK 实现的轻量级线程。许多虚拟线程共享同一个操作系统线程，从而允许非常多的虚拟线程。\n\nJDK 20 中对结构化并发唯一变化是更新为支持在任务范围内创建的线程StructuredTaskScope继承范围值 这简化了跨线程共享不可变数据，详见JEP 429。\n\n\n# JEP 432：向量 API（第五次孵化）\n\n向量计算由对向量的一系列操作组成。向量 API 用来表达向量计算，该计算可以在运行时可靠地编译为支持的 CPU 架构上的最佳向量指令，从而实现优于等效标量计算的性能。\n\n向量 API 的目标是为用户提供简洁易用且与平台无关的表达范围广泛的向量计算。\n\n向量（Vector） API 最初由 JEP 338 提出，并作为孵化 API集成到 Java 16 中。第二轮孵化由 JEP 414 提出并集成到 Java 17 中，第三轮孵化由 JEP 417 提出并集成到 Java 18 中，第四轮由 JEP 426 提出并集成到了 Java 19 中。\n\nJava20 的这次孵化基本没有改变向量 API ，只是进行了一些错误修复和性能增强，详见 JEP 438。',normalizedContent:'jdk 20 于 2023 年 3 月 21 日发布，非长期支持版本。\n\n根据开发计划，下一个 lts 版本就是将于 2023 年 9 月发布的 jdk 21。\n\n\n\njdk 20 只有 7 个新特性：\n\n * jep 429：scoped values（作用域值）（第一次孵化）\n * jep 432：record patterns（记录模式）（第二次预览）\n * jep 433：switch 模式匹配（第四次预览）\n * jep 434: foreign function & memory api（外部函数和内存 api）（第二次预览）\n * jep 436: virtual threads（虚拟线程）（第二次预览）\n * jep 437:structured concurrency（结构化并发）(第二次孵化)\n * jep 432:向量 api（第五次孵化）\n\n\n# jep 429：作用域值（第一次孵化）\n\n作用域值（scoped values）它可以在线程内和线程间共享不可变的数据，优于线程局部变量，尤其是在使用大量虚拟线程时。\n\nfinal static scopedvalue<...> v = new scopedvalue<>();\n\n// in some method\nscopedvalue.where(v, <value>)\n           .run(() -> { ... v.get() ... call methods ... });\n\n// in a method called directly or indirectly from the lambda expression\n... v.get() ...\n\n\n作用域值允许在大型程序中的组件之间安全有效地共享数据，而无需求助于方法参数。\n\n关于作用域值的详细介绍，推荐阅读作用域值常见问题解答这篇文章。\n\n\n# jep 432：记录模式（第二次预览）\n\n记录模式（record patterns） 可对 record 的值进行解构，也就是更方便地从记录类（record class）中提取数据。并且，还可以嵌套记录模式和类型模式结合使用，以实现强大的、声明性的和可组合的数据导航和处理形式。\n\n记录模式不能单独使用，而是要与 instanceof 或 switch 模式匹配一同使用。\n\n先以 instanceof 为例简单演示一下。\n\n简单定义一个记录类：\n\nrecord shape(string type, long unit){}\n\n\n没有记录模式之前：\n\nshape circle = new shape("circle", 10);\nif (circle instanceof shape shape) {\n\n  system.out.println("area of " + shape.type() + " is : " + math.pi * math.pow(shape.unit(), 2));\n}\n\n\n有了记录模式之后：\n\nshape circle = new shape("circle", 10);\nif (circle instanceof shape(string type, long unit)) {\n  system.out.println("area of " + type + " is : " + math.pi * math.pow(unit, 2));\n}\n\n\n再看看记录模式与 switch 的配合使用。\n\n定义一些类：\n\ninterface shape {}\nrecord circle(double radius) implements shape { }\nrecord square(double side) implements shape { }\nrecord rectangle(double length, double width) implements shape { }\n\n\n没有记录模式之前：\n\nshape shape = new circle(10);\nswitch (shape) {\n    case circle c:\n        system.out.println("the shape is circle with area: " + math.pi * c.radius() * c.radius());\n        break;\n\n    case square s:\n        system.out.println("the shape is square with area: " + s.side() * s.side());\n        break;\n\n    case rectangle r:\n        system.out.println("the shape is rectangle with area: + " + r.length() * r.width());\n        break;\n\n    default:\n        system.out.println("unknown shape");\n        break;\n}\n\n\n有了记录模式之后：\n\nshape shape = new circle(10);\nswitch(shape) {\n\n  case circle(double radius):\n    system.out.println("the shape is circle with area: " + math.pi * radius * radius);\n    break;\n\n  case square(double side):\n    system.out.println("the shape is square with area: " + side * side);\n    break;\n\n  case rectangle(double length, double width):\n    system.out.println("the shape is rectangle with area: + " + length * width);\n    break;\n\n  default:\n    system.out.println("unknown shape");\n    break;\n}\n\n\n记录模式可以避免不必要的转换，使得代码更建简洁易读。而且，用了记录模式后不必再担心 null 或者 nullpointerexception，代码更安全可靠。\n\n记录模式在 java 19 进行了第一次预览， 由 jep 405 提出。jdk 20 中是第二次预览，由 jep 432 提出。这次的改进包括：\n\n * 添加对通用记录模式类型参数推断的支持，\n * 添加对记录模式的支持以出现在增强语句的标题中for\n * 删除对命名记录模式的支持。\n\n注意：不要把记录模式和 jdk16 正式引入的记录类搞混了。\n\n\n# jep 433：switch 模式匹配（第四次预览）\n\n正如 instanceof 一样， switch 也紧跟着增加了类型匹配自动转换功能。\n\ninstanceof 代码示例：\n\n// old code\nif (o instanceof string) {\n    string s = (string)o;\n    ... use s ...\n}\n\n// new code\nif (o instanceof string s) {\n    ... use s ...\n}\n\n\nswitch 代码示例：\n\n// old code\nstatic string formatter(object o) {\n    string formatted = "unknown";\n    if (o instanceof integer i) {\n        formatted = string.format("int %d", i);\n    } else if (o instanceof long l) {\n        formatted = string.format("long %d", l);\n    } else if (o instanceof double d) {\n        formatted = string.format("double %f", d);\n    } else if (o instanceof string s) {\n        formatted = string.format("string %s", s);\n    }\n    return formatted;\n}\n\n// new code\nstatic string formatterpatternswitch(object o) {\n    return switch (o) {\n        case integer i -> string.format("int %d", i);\n        case long l    -> string.format("long %d", l);\n        case double d  -> string.format("double %f", d);\n        case string s  -> string.format("string %s", s);\n        default        -> o.tostring();\n    };\n}\n\n\nswitch 模式匹配分别在 java17、java18、java19 中进行了预览，java20 是第四次预览了。每一次的预览基本都会有一些小改进，这里就不细提了。\n\n\n# jep 434: 外部函数和内存 api（第二次预览）\n\njava 程序可以通过该 api 与 java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 jvm 之外的代码）和安全地访问外部内存（即不受 jvm 管理的内存），该 api 使 java 程序能够调用本机库并处理本机数据，而不会像 jni 那样危险和脆弱。\n\n外部函数和内存 api 在 java 17 中进行了第一轮孵化，由 jep 412 提出。java 18 中进行了第二次孵化，由jep 419 提出。java 19 中是第一次预览，由 jep 424 提出。\n\njdk 20 中是第二次预览，由 jep 434 提出，这次的改进包括：\n\n * memorysegment 和 memoryaddress 抽象的统一\n * 增强的 memorylayout 层次结构\n * memorysession拆分为arena和segmentscope，以促进跨维护边界的段共享。\n\n在 java 19 新特性概览 中，我有详细介绍到外部函数和内存 api，这里就不再做额外的介绍了。\n\n\n# jep 436: 虚拟线程（第二次预览）\n\n虚拟线程（virtual thread）是 jdk 而不是 os 实现的轻量级线程(lightweight process，lwp），由 jvm 调度。许多虚拟线程共享同一个操作系统线程，虚拟线程的数量可以远大于操作系统线程的数量。\n\n在引入虚拟线程之前，java.lang.thread 包已经支持所谓的平台线程，也就是没有虚拟线程之前，我们一直使用的线程。jvm 调度程序通过平台线程（载体线程）来管理虚拟线程，一个平台线程可以在不同的时间执行不同的虚拟线程（多个虚拟线程挂载在一个平台线程上），当虚拟线程被阻塞或等待时，平台线程可以切换到执行另一个虚拟线程。\n\n虚拟线程、平台线程和系统内核线程的关系图如下所示（图源：how to use java 19 virtual threads）：\n\n\n\n关于平台线程和系统内核线程的对应关系多提一点：在 windows 和 linux 等主流操作系统中，java 线程采用的是一对一的线程模型，也就是一个平台线程对应一个系统内核线程。solaris 系统是一个特例，hotspot vm 在 solaris 上支持多对多和一对一。具体可以参考 r 大的回答: jvm 中的线程模型是用户级的么？。\n\n相比较于平台线程来说，虚拟线程是廉价且轻量级的，使用完后立即被销毁，因此它们不需要被重用或池化，每个任务可以有自己专属的虚拟线程来运行。虚拟线程暂停和恢复来实现线程之间的切换，避免了上下文切换的额外耗费，兼顾了多线程的优点，简化了高并发程序的复杂，可以有效减少编写、维护和观察高吞吐量并发应用程序的工作量。\n\n虚拟线程在其他多线程语言中已经被证实是十分有用的，比如 go 中的 goroutine、erlang 中的进程。\n\n知乎有一个关于 java 19 虚拟线程的讨论，感兴趣的可以去看看：https://www.zhihu.com/question/536743167 。\n\njava 虚拟线程的详细解读和原理可以看下面这几篇文章：\n\n * 虚拟线程极简入门\n * java19 正式 ga！看虚拟线程如何大幅提高系统吞吐量\n * 虚拟线程 - virtualthread 源码透视\n\n虚拟线程在 java 19 中进行了第一次预览，由jep 425提出。jdk 20 中是第二次预览，做了一些细微变化，这里就不细提了。\n\n最后，我们来看一下四种创建虚拟线程的方法：\n\n// 1、通过 thread.ofvirtual() 创建\nrunnable fn = () -> {\n  // your code here\n};\n\nthread thread = thread.ofvirtual(fn)\n                      .start();\n\n// 2、通过 thread.startvirtualthread() 、创建\nthread thread = thread.startvirtualthread(() -> {\n  // your code here\n});\n\n// 3、通过 executors.newvirtualthreadpertaskexecutor() 创建\nvar executorservice = executors.newvirtualthreadpertaskexecutor();\n\nexecutorservice.submit(() -> {\n  // your code here\n});\n\nclass customthread implements runnable {\n  @override\n  public void run() {\n    system.out.println("customthread run");\n  }\n}\n\n//4、通过 threadfactory 创建\ncustomthread customthread = new customthread();\n// 获取线程工厂类\nthreadfactory factory = thread.ofvirtual().factory();\n// 创建虚拟线程\nthread thread = factory.newthread(customthread);\n// 启动线程\nthread.start();\n\n\n通过上述列举的 4 种创建虚拟线程的方式可以看出，官方为了降低虚拟线程的门槛，尽力复用原有的 thread 线程类，这样可以平滑的过渡到虚拟线程的使用。\n\n\n# jep 437: 结构化并发(第二次孵化)\n\njava 19 引入了结构化并发，一种多线程编程方法，目的是为了通过结构化并发 api 来简化多线程编程，并不是为了取代java.util.concurrent，目前处于孵化器阶段。\n\n结构化并发将不同线程中运行的多个任务视为单个工作单元，从而简化错误处理、提高可靠性并增强可观察性。也就是说，结构化并发保留了单线程代码的可读性、可维护性和可观察性。\n\n结构化并发的基本 api 是structuredtaskscope。structuredtaskscope 支持将任务拆分为多个并发子任务，在它们自己的线程中执行，并且子任务必须在主任务继续之前完成。\n\nstructuredtaskscope 的基本用法如下：\n\n    try (var scope = new structuredtaskscope<object>()) {\n        // 使用fork方法派生线程来执行子任务\n        future<integer> future1 = scope.fork(task1);\n        future<string> future2 = scope.fork(task2);\n        // 等待线程完成\n        scope.join();\n        // 结果的处理可能包括处理或重新抛出异常\n        ... process results/exceptions ...\n    } // close\n\n\n结构化并发非常适合虚拟线程，虚拟线程是 jdk 实现的轻量级线程。许多虚拟线程共享同一个操作系统线程，从而允许非常多的虚拟线程。\n\njdk 20 中对结构化并发唯一变化是更新为支持在任务范围内创建的线程structuredtaskscope继承范围值 这简化了跨线程共享不可变数据，详见jep 429。\n\n\n# jep 432：向量 api（第五次孵化）\n\n向量计算由对向量的一系列操作组成。向量 api 用来表达向量计算，该计算可以在运行时可靠地编译为支持的 cpu 架构上的最佳向量指令，从而实现优于等效标量计算的性能。\n\n向量 api 的目标是为用户提供简洁易用且与平台无关的表达范围广泛的向量计算。\n\n向量（vector） api 最初由 jep 338 提出，并作为孵化 api集成到 java 16 中。第二轮孵化由 jep 414 提出并集成到 java 17 中，第三轮孵化由 jep 417 提出并集成到 java 18 中，第四轮由 jep 426 提出并集成到了 java 19 中。\n\njava20 的这次孵化基本没有改变向量 api ，只是进行了一些错误修复和性能增强，详见 jep 438。',charsets:{cjk:!0}},{title:"Java 21 新特性概览(重要)",frontmatter:{title:"Java 21 新特性概览(重要)",category:"Java",tag:["Java新特性"],date:"2024-08-21T23:05:40.000Z",permalink:"/pages/54087b/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/05.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/13.java21.html",relativePath:"01.Java基础/05.版本新特性/13.java21.md",key:"v-79bcd990",path:"/pages/54087b/",headers:[{level:2,title:"JEP 430：字符串模板（预览）",slug:"jep-430-字符串模板-预览",normalizedTitle:"jep 430：字符串模板（预览）",charIndex:595},{level:2,title:"JEP431：序列化集合",slug:"jep431-序列化集合",normalizedTitle:"jep431：序列化集合",charIndex:2624},{level:2,title:"JEP 439：分代 ZGC",slug:"jep-439-分代-zgc",normalizedTitle:"jep 439：分代 zgc",charIndex:5627},{level:2,title:"JEP 440：记录模式",slug:"jep-440-记录模式",normalizedTitle:"jep 440：记录模式",charIndex:6291},{level:2,title:"JEP 441：switch 的模式匹配",slug:"jep-441-switch-的模式匹配",normalizedTitle:"jep 441：switch 的模式匹配",charIndex:6430},{level:2,title:"JEP 442: 外部函数和内存 API（第三次预览）",slug:"jep-442-外部函数和内存-api-第三次预览",normalizedTitle:"jep 442: 外部函数和内存 api（第三次预览）",charIndex:6908},{level:2,title:"JEP 443：未命名模式和变量（预览）",slug:"jep-443-未命名模式和变量-预览",normalizedTitle:"jep 443：未命名模式和变量（预览）",charIndex:7294},{level:2,title:"JEP 444：虚拟线程",slug:"jep-444-虚拟线程",normalizedTitle:"jep 444：虚拟线程",charIndex:7984},{level:2,title:"JEP 445：未命名类和实例 main 方法 （预览）",slug:"jep-445-未命名类和实例-main-方法-预览",normalizedTitle:"jep 445：未命名类和实例 main 方法 （预览）",charIndex:8132},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:8591}],headersStr:"JEP 430：字符串模板（预览） JEP431：序列化集合 JEP 439：分代 ZGC JEP 440：记录模式 JEP 441：switch 的模式匹配 JEP 442: 外部函数和内存 API（第三次预览） JEP 443：未命名模式和变量（预览） JEP 444：虚拟线程 JEP 445：未命名类和实例 main 方法 （预览） 参考",content:'JDK 21 于 2023 年 9 月 19 日 发布，这是一个非常重要的版本，里程碑式。\n\nJDK21 是 LTS（长期支持版），至此为止，目前有 JDK8、JDK11、JDK17 和 JDK21 这四个长期支持版了。\n\nJDK 21 共有 15 个新特性，这篇文章会挑选其中较为重要的一些新特性进行详细介绍：\n\n * JEP 430：String Templates（字符串模板）（预览）\n\n * JEP 431：Sequenced Collections（序列化集合）\n\n * JEP 439：Generational ZGC（分代 ZGC）\n\n * JEP 440：Record Patterns（记录模式）\n\n * JEP 441：Pattern Matching for switch（switch 的模式匹配）\n\n * JEP 442：Foreign Function & Memory API（外部函数和内存 API）（第三次预览）\n\n * JEP 443：Unnamed Patterns and Variables（未命名模式和变量（预览）\n\n * JEP 444：Virtual Threads（虚拟线程）\n\n * JEP 445：Unnamed Classes and Instance Main Methods（未命名类和实例 main 方法 ）（预览）\n\n\n# JEP 430：字符串模板（预览）\n\nString Templates(字符串模板) 目前仍然是 JDK 21 中的一个预览功能。\n\nString Templates 提供了一种更简洁、更直观的方式来动态构建字符串。通过使用占位符${}，我们可以将变量的值直接嵌入到字符串中，而不需要手动处理。在运行时，Java 编译器会将这些占位符替换为实际的变量值。并且，表达式支持局部变量、静态/非静态字段甚至方法、计算结果等特性。\n\n实际上，String Templates（字符串模板）再大多数编程语言中都存在:\n\n"Greetings {{ name }}!";  //Angular\n`Greetings ${ name }!`;    //Typescript\n$"Greetings { name }!"    //Visual basic\nf"Greetings { name }!"    //Python\n\n\nJava 在没有 String Templates 之前，我们通常使用字符串拼接或格式化方法来构建字符串：\n\n//concatenation\nmessage = "Greetings " + name + "!";\n\n//String.format()\nmessage = String.format("Greetings %s!", name);  //concatenation\n\n//MessageFormat\nmessage = new MessageFormat("Greetings {0}!").format(name);\n\n//StringBuilder\nmessage = new StringBuilder().append("Greetings ").append(name).append("!").toString();\n\n\n这些方法或多或少都存在一些缺点，比如难以阅读、冗长、复杂。\n\nJava 使用 String Templates 进行字符串拼接，可以直接在字符串中嵌入表达式，而无需进行额外的处理：\n\nString message = STR."Greetings \\{name}!";\n\n\n在上面的模板表达式中：\n\n * STR 是模板处理器。\n * \\{name}为表达式，运行时，这些表达式将被相应的变量值替换。\n\nJava 目前支持三种模板处理器：\n\n * STR：自动执行字符串插值，即将模板中的每个嵌入式表达式替换为其值（转换为字符串）。\n * FMT：和 STR 类似，但是它还可以接受格式说明符，这些格式说明符出现在嵌入式表达式的左边，用来控制输出的样式。\n * RAW：不会像 STR 和 FMT 模板处理器那样自动处理字符串模板，而是返回一个 StringTemplate 对象，这个对象包含了模板中的文本和表达式的信息。\n\nString name = "Lokesh";\n\n//STR\nString message = STR."Greetings \\{name}.";\n\n//FMT\nString message = STR."Greetings %-12s\\{name}.";\n\n//RAW\nStringTemplate st = RAW."Greetings \\{name}.";\nString message = STR.process(st);\n\n\n除了 JDK 自带的三种模板处理器外，你还可以实现 StringTemplate.Processor 接口来创建自己的模板处理器，只需要继承 StringTemplate.Processor接口，然后实现 process 方法即可。\n\n我们可以使用局部变量、静态/非静态字段甚至方法作为嵌入表达式：\n\n//variable\nmessage = STR."Greetings \\{name}!";\n\n//method\nmessage = STR."Greetings \\{getName()}!";\n\n//field\nmessage = STR."Greetings \\{this.name}!";\n\n\n还可以在表达式中执行计算并打印结果：\n\nint x = 10, y = 20;\nString s = STR."\\{x} + \\{y} = \\{x + y}";  //"10 + 20 = 30"\n\n\n为了提高可读性，我们可以将嵌入的表达式分成多行:\n\nString time = STR."The current time is \\{\n    //sample comment - current time in HH:mm:ss\n    DateTimeFormatter\n      .ofPattern("HH:mm:ss")\n      .format(LocalTime.now())\n  }.";\n\n\n\n# JEP431：序列化集合\n\nJDK 21 引入了一种新的集合类型：Sequenced Collections（序列化集合，也叫有序集合），这是一种具有确定出现顺序（encounter order）的集合（无论我们遍历这样的集合多少次，元素的出现顺序始终是固定的）。序列化集合提供了处理集合的第一个和最后一个元素以及反向视图（与原始集合相反的顺序）的简单方法。\n\nSequenced Collections 包括以下三个接口：\n\n * SequencedCollection\n * SequencedSet\n * SequencedMap\n\nSequencedCollection 接口继承了 Collection接口， 提供了在集合两端访问、添加或删除元素以及获取集合的反向视图的方法。\n\ninterface SequencedCollection<E> extends Collection<E> {\n\n  // New Method\n\n  SequencedCollection<E> reversed();\n\n  // Promoted methods from Deque<E>\n\n  void addFirst(E);\n  void addLast(E);\n\n  E getFirst();\n  E getLast();\n\n  E removeFirst();\n  E removeLast();\n}\n\n\nList 和 Deque 接口实现了SequencedCollection 接口。\n\n这里以 ArrayList 为例，演示一下实际使用效果：\n\nArrayList<Integer> arrayList = new ArrayList<>();\n\narrayList.add(1);   // List contains: [1]\n\narrayList.addFirst(0);  // List contains: [0, 1]\narrayList.addLast(2);   // List contains: [0, 1, 2]\n\nInteger firstElement = arrayList.getFirst();  // 0\nInteger lastElement = arrayList.getLast();  // 2\n\nList<Integer> reversed = arrayList.reversed();\nSystem.out.println(reversed); // Prints [2, 1, 0]\n\n\nSequencedSet接口直接继承了 SequencedCollection 接口并重写了 reversed() 方法。\n\ninterface SequencedSet<E> extends SequencedCollection<E>, Set<E> {\n\n    SequencedSet<E> reversed();\n}\n\n\nSortedSet 和 LinkedHashSet 实现了SequencedSet接口。\n\n这里以 LinkedHashSet 为例，演示一下实际使用效果：\n\nLinkedHashSet<Integer> linkedHashSet = new LinkedHashSet<>(List.of(1, 2, 3));\n\nInteger firstElement = linkedHashSet.getFirst();   // 1\nInteger lastElement = linkedHashSet.getLast();    // 3\n\nlinkedHashSet.addFirst(0);  //List contains: [0, 1, 2, 3]\nlinkedHashSet.addLast(4);   //List contains: [0, 1, 2, 3, 4]\n\nSystem.out.println(linkedHashSet.reversed());   //Prints [5, 3, 2, 1, 0]\n\n\nSequencedMap 接口继承了 Map接口， 提供了在集合两端访问、添加或删除键值对、获取包含 key 的 SequencedSet、包含 value 的 SequencedCollection、包含 entry（键值对） 的 SequencedSet以及获取集合的反向视图的方法。\n\ninterface SequencedMap<K,V> extends Map<K,V> {\n\n  // New Methods\n\n  SequencedMap<K,V> reversed();\n\n  SequencedSet<K> sequencedKeySet();\n  SequencedCollection<V> sequencedValues();\n  SequencedSet<Entry<K,V>> sequencedEntrySet();\n\n  V putFirst(K, V);\n  V putLast(K, V);\n\n\n  // Promoted Methods from NavigableMap<K, V>\n\n  Entry<K, V> firstEntry();\n  Entry<K, V> lastEntry();\n\n  Entry<K, V> pollFirstEntry();\n  Entry<K, V> pollLastEntry();\n}\n\n\nSortedMap 和LinkedHashMap 实现了SequencedMap 接口。\n\n这里以 LinkedHashMap 为例，演示一下实际使用效果：\n\nLinkedHashMap<Integer, String> map = new LinkedHashMap<>();\n\nmap.put(1, "One");\nmap.put(2, "Two");\nmap.put(3, "Three");\n\nmap.firstEntry();   //1=One\nmap.lastEntry();    //3=Three\n\nSystem.out.println(map);  //{1=One, 2=Two, 3=Three}\n\nMap.Entry<Integer, String> first = map.pollFirstEntry();   //1=One\nMap.Entry<Integer, String> last = map.pollLastEntry();    //3=Three\n\nSystem.out.println(map);  //{2=Two}\n\nmap.putFirst(1, "One");     //{1=One, 2=Two}\nmap.putLast(3, "Three");    //{1=One, 2=Two, 3=Three}\n\nSystem.out.println(map);  //{1=One, 2=Two, 3=Three}\nSystem.out.println(map.reversed());   //{3=Three, 2=Two, 1=One}\n\n\n\n# JEP 439：分代 ZGC\n\nJDK21 中对 ZGC 进行了功能扩展，增加了分代 GC 功能。不过，默认是关闭的，需要通过配置打开：\n\n// 启用分代ZGC\njava -XX:+UseZGC -XX:+ZGenerational ...\n\n\n在未来的版本中，官方会把 ZGenerational 设为默认值，即默认打开 ZGC 的分代 GC。在更晚的版本中，非分代 ZGC 就被移除。\n\n> In a future release we intend to make Generational ZGC the default, at which point -XX:-ZGenerational will select non-generational ZGC. In an even later release we intend to remove non-generational ZGC, at which point the ZGenerational option will become obsolete.\n> \n> 在将来的版本中，我们打算将 Generational ZGC 作为默认选项，此时-XX:-ZGenerational 将选择非分代 ZGC。在更晚的版本中，我们打算移除非分代 ZGC，此时 ZGenerational 选项将变得过时。\n\n分代 ZGC 可以显著减少垃圾回收过程中的停顿时间，并提高应用程序的响应性能。这对于大型 Java 应用程序和高并发场景下的性能优化非常有价值。\n\n\n# JEP 440：记录模式\n\n记录模式在 Java 19 进行了第一次预览， 由 JEP 405 提出。JDK 20 中是第二次预览，由 JEP 432 提出。最终，记录模式在 JDK21 顺利转正。\n\nJava 20 新特性概览已经详细介绍过记录模式，这里就不重复了。\n\n\n# JEP 441：switch 的模式匹配\n\n增强 Java 中的 switch 表达式和语句，允许在 case 标签中使用模式。当模式匹配时，执行 case 标签对应的代码。\n\n在下面的代码中，switch 表达式使用了类型模式来进行匹配。\n\nstatic String formatterPatternSwitch(Object obj) {\n    return switch (obj) {\n        case Integer i -> String.format("int %d", i);\n        case Long l    -> String.format("long %d", l);\n        case Double d  -> String.format("double %f", d);\n        case String s  -> String.format("String %s", s);\n        default        -> obj.toString();\n    };\n}\n\n\n\n# JEP 442: 外部函数和内存 API（第三次预览）\n\nJava 程序可以通过该 API 与 Java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 JVM 之外的代码）和安全地访问外部内存（即不受 JVM 管理的内存），该 API 使 Java 程序能够调用本机库并处理本机数据，而不会像 JNI 那样危险和脆弱。\n\n外部函数和内存 API 在 Java 17 中进行了第一轮孵化，由 JEP 412 提出。Java 18 中进行了第二次孵化，由JEP 419 提出。Java 19 中是第一次预览，由 JEP 424 提出。JDK 20 中是第二次预览，由 JEP 434 提出。JDK 21 中是第三次预览，由 JEP 442 提出。\n\n在 Java 19 新特性概览 中，我有详细介绍到外部函数和内存 API，这里就不再做额外的介绍了。\n\n\n# JEP 443：未命名模式和变量（预览）\n\n未命名模式和变量使得我们可以使用下划线 _ 表示未命名的变量以及模式匹配时不使用的组件，旨在提高代码的可读性和可维护性。\n\n未命名变量的典型场景是 try-with-resources 语句、 catch 子句中的异常变量和for循环。当变量不需要使用的时候就可以使用下划线 _代替，这样清晰标识未被使用的变量。\n\ntry (var _ = ScopedContext.acquire()) {\n  // No use of acquired resource\n}\ntry { ... }\ncatch (Exception _) { ... }\ncatch (Throwable _) { ... }\n\nfor (int i = 0, _ = runOnce(); i < arr.length; i++) {\n  ...\n}\n\n\n未命名模式是一个无条件的模式，并不绑定任何值。未命名模式变量出现在类型模式中。\n\nif (r instanceof ColoredPoint(_, Color c)) { ... c ... }\n\nswitch (b) {\n    case Box(RedBall _), Box(BlueBall _) -> processBox(b);\n    case Box(GreenBall _)                -> stopProcessing();\n    case Box(_)                          -> pickAnotherBox();\n}\n\n\n\n# JEP 444：虚拟线程\n\n虚拟线程是一项重量级的更新，一定一定要重视！\n\n虚拟线程在 Java 19 中进行了第一次预览，由JEP 425提出。JDK 20 中是第二次预览。最终，虚拟线程在 JDK21 顺利转正。\n\nJava 20 新特性概览已经详细介绍过虚拟线程，这里就不重复了。\n\n\n# JEP 445：未命名类和实例 main 方法 （预览）\n\n这个特性主要简化了 main 方法的的声明。对于 Java 初学者来说，这个 main 方法的声明引入了太多的 Java 语法概念，不利于初学者快速上手。\n\n没有使用该特性之前定义一个 main 方法：\n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        System.out.println("Hello, World!");\n    }\n}\n\n\n使用该新特性之后定义一个 main 方法：\n\nclass HelloWorld {\n    void main() {\n        System.out.println("Hello, World!");\n    }\n}\n\n\n进一步精简(未命名的类允许我们不定义类名)：\n\nvoid main() {\n   System.out.println("Hello, World!");\n}\n\n\n\n# 参考\n\n * Java 21 String Templates：https://howtodoinjava.com/java/java-string-templates/\n * Java 21 Sequenced Collections：https://howtodoinjava.com/java/sequenced-collections/',normalizedContent:'jdk 21 于 2023 年 9 月 19 日 发布，这是一个非常重要的版本，里程碑式。\n\njdk21 是 lts（长期支持版），至此为止，目前有 jdk8、jdk11、jdk17 和 jdk21 这四个长期支持版了。\n\njdk 21 共有 15 个新特性，这篇文章会挑选其中较为重要的一些新特性进行详细介绍：\n\n * jep 430：string templates（字符串模板）（预览）\n\n * jep 431：sequenced collections（序列化集合）\n\n * jep 439：generational zgc（分代 zgc）\n\n * jep 440：record patterns（记录模式）\n\n * jep 441：pattern matching for switch（switch 的模式匹配）\n\n * jep 442：foreign function & memory api（外部函数和内存 api）（第三次预览）\n\n * jep 443：unnamed patterns and variables（未命名模式和变量（预览）\n\n * jep 444：virtual threads（虚拟线程）\n\n * jep 445：unnamed classes and instance main methods（未命名类和实例 main 方法 ）（预览）\n\n\n# jep 430：字符串模板（预览）\n\nstring templates(字符串模板) 目前仍然是 jdk 21 中的一个预览功能。\n\nstring templates 提供了一种更简洁、更直观的方式来动态构建字符串。通过使用占位符${}，我们可以将变量的值直接嵌入到字符串中，而不需要手动处理。在运行时，java 编译器会将这些占位符替换为实际的变量值。并且，表达式支持局部变量、静态/非静态字段甚至方法、计算结果等特性。\n\n实际上，string templates（字符串模板）再大多数编程语言中都存在:\n\n"greetings {{ name }}!";  //angular\n`greetings ${ name }!`;    //typescript\n$"greetings { name }!"    //visual basic\nf"greetings { name }!"    //python\n\n\njava 在没有 string templates 之前，我们通常使用字符串拼接或格式化方法来构建字符串：\n\n//concatenation\nmessage = "greetings " + name + "!";\n\n//string.format()\nmessage = string.format("greetings %s!", name);  //concatenation\n\n//messageformat\nmessage = new messageformat("greetings {0}!").format(name);\n\n//stringbuilder\nmessage = new stringbuilder().append("greetings ").append(name).append("!").tostring();\n\n\n这些方法或多或少都存在一些缺点，比如难以阅读、冗长、复杂。\n\njava 使用 string templates 进行字符串拼接，可以直接在字符串中嵌入表达式，而无需进行额外的处理：\n\nstring message = str."greetings \\{name}!";\n\n\n在上面的模板表达式中：\n\n * str 是模板处理器。\n * \\{name}为表达式，运行时，这些表达式将被相应的变量值替换。\n\njava 目前支持三种模板处理器：\n\n * str：自动执行字符串插值，即将模板中的每个嵌入式表达式替换为其值（转换为字符串）。\n * fmt：和 str 类似，但是它还可以接受格式说明符，这些格式说明符出现在嵌入式表达式的左边，用来控制输出的样式。\n * raw：不会像 str 和 fmt 模板处理器那样自动处理字符串模板，而是返回一个 stringtemplate 对象，这个对象包含了模板中的文本和表达式的信息。\n\nstring name = "lokesh";\n\n//str\nstring message = str."greetings \\{name}.";\n\n//fmt\nstring message = str."greetings %-12s\\{name}.";\n\n//raw\nstringtemplate st = raw."greetings \\{name}.";\nstring message = str.process(st);\n\n\n除了 jdk 自带的三种模板处理器外，你还可以实现 stringtemplate.processor 接口来创建自己的模板处理器，只需要继承 stringtemplate.processor接口，然后实现 process 方法即可。\n\n我们可以使用局部变量、静态/非静态字段甚至方法作为嵌入表达式：\n\n//variable\nmessage = str."greetings \\{name}!";\n\n//method\nmessage = str."greetings \\{getname()}!";\n\n//field\nmessage = str."greetings \\{this.name}!";\n\n\n还可以在表达式中执行计算并打印结果：\n\nint x = 10, y = 20;\nstring s = str."\\{x} + \\{y} = \\{x + y}";  //"10 + 20 = 30"\n\n\n为了提高可读性，我们可以将嵌入的表达式分成多行:\n\nstring time = str."the current time is \\{\n    //sample comment - current time in hh:mm:ss\n    datetimeformatter\n      .ofpattern("hh:mm:ss")\n      .format(localtime.now())\n  }.";\n\n\n\n# jep431：序列化集合\n\njdk 21 引入了一种新的集合类型：sequenced collections（序列化集合，也叫有序集合），这是一种具有确定出现顺序（encounter order）的集合（无论我们遍历这样的集合多少次，元素的出现顺序始终是固定的）。序列化集合提供了处理集合的第一个和最后一个元素以及反向视图（与原始集合相反的顺序）的简单方法。\n\nsequenced collections 包括以下三个接口：\n\n * sequencedcollection\n * sequencedset\n * sequencedmap\n\nsequencedcollection 接口继承了 collection接口， 提供了在集合两端访问、添加或删除元素以及获取集合的反向视图的方法。\n\ninterface sequencedcollection<e> extends collection<e> {\n\n  // new method\n\n  sequencedcollection<e> reversed();\n\n  // promoted methods from deque<e>\n\n  void addfirst(e);\n  void addlast(e);\n\n  e getfirst();\n  e getlast();\n\n  e removefirst();\n  e removelast();\n}\n\n\nlist 和 deque 接口实现了sequencedcollection 接口。\n\n这里以 arraylist 为例，演示一下实际使用效果：\n\narraylist<integer> arraylist = new arraylist<>();\n\narraylist.add(1);   // list contains: [1]\n\narraylist.addfirst(0);  // list contains: [0, 1]\narraylist.addlast(2);   // list contains: [0, 1, 2]\n\ninteger firstelement = arraylist.getfirst();  // 0\ninteger lastelement = arraylist.getlast();  // 2\n\nlist<integer> reversed = arraylist.reversed();\nsystem.out.println(reversed); // prints [2, 1, 0]\n\n\nsequencedset接口直接继承了 sequencedcollection 接口并重写了 reversed() 方法。\n\ninterface sequencedset<e> extends sequencedcollection<e>, set<e> {\n\n    sequencedset<e> reversed();\n}\n\n\nsortedset 和 linkedhashset 实现了sequencedset接口。\n\n这里以 linkedhashset 为例，演示一下实际使用效果：\n\nlinkedhashset<integer> linkedhashset = new linkedhashset<>(list.of(1, 2, 3));\n\ninteger firstelement = linkedhashset.getfirst();   // 1\ninteger lastelement = linkedhashset.getlast();    // 3\n\nlinkedhashset.addfirst(0);  //list contains: [0, 1, 2, 3]\nlinkedhashset.addlast(4);   //list contains: [0, 1, 2, 3, 4]\n\nsystem.out.println(linkedhashset.reversed());   //prints [5, 3, 2, 1, 0]\n\n\nsequencedmap 接口继承了 map接口， 提供了在集合两端访问、添加或删除键值对、获取包含 key 的 sequencedset、包含 value 的 sequencedcollection、包含 entry（键值对） 的 sequencedset以及获取集合的反向视图的方法。\n\ninterface sequencedmap<k,v> extends map<k,v> {\n\n  // new methods\n\n  sequencedmap<k,v> reversed();\n\n  sequencedset<k> sequencedkeyset();\n  sequencedcollection<v> sequencedvalues();\n  sequencedset<entry<k,v>> sequencedentryset();\n\n  v putfirst(k, v);\n  v putlast(k, v);\n\n\n  // promoted methods from navigablemap<k, v>\n\n  entry<k, v> firstentry();\n  entry<k, v> lastentry();\n\n  entry<k, v> pollfirstentry();\n  entry<k, v> polllastentry();\n}\n\n\nsortedmap 和linkedhashmap 实现了sequencedmap 接口。\n\n这里以 linkedhashmap 为例，演示一下实际使用效果：\n\nlinkedhashmap<integer, string> map = new linkedhashmap<>();\n\nmap.put(1, "one");\nmap.put(2, "two");\nmap.put(3, "three");\n\nmap.firstentry();   //1=one\nmap.lastentry();    //3=three\n\nsystem.out.println(map);  //{1=one, 2=two, 3=three}\n\nmap.entry<integer, string> first = map.pollfirstentry();   //1=one\nmap.entry<integer, string> last = map.polllastentry();    //3=three\n\nsystem.out.println(map);  //{2=two}\n\nmap.putfirst(1, "one");     //{1=one, 2=two}\nmap.putlast(3, "three");    //{1=one, 2=two, 3=three}\n\nsystem.out.println(map);  //{1=one, 2=two, 3=three}\nsystem.out.println(map.reversed());   //{3=three, 2=two, 1=one}\n\n\n\n# jep 439：分代 zgc\n\njdk21 中对 zgc 进行了功能扩展，增加了分代 gc 功能。不过，默认是关闭的，需要通过配置打开：\n\n// 启用分代zgc\njava -xx:+usezgc -xx:+zgenerational ...\n\n\n在未来的版本中，官方会把 zgenerational 设为默认值，即默认打开 zgc 的分代 gc。在更晚的版本中，非分代 zgc 就被移除。\n\n> in a future release we intend to make generational zgc the default, at which point -xx:-zgenerational will select non-generational zgc. in an even later release we intend to remove non-generational zgc, at which point the zgenerational option will become obsolete.\n> \n> 在将来的版本中，我们打算将 generational zgc 作为默认选项，此时-xx:-zgenerational 将选择非分代 zgc。在更晚的版本中，我们打算移除非分代 zgc，此时 zgenerational 选项将变得过时。\n\n分代 zgc 可以显著减少垃圾回收过程中的停顿时间，并提高应用程序的响应性能。这对于大型 java 应用程序和高并发场景下的性能优化非常有价值。\n\n\n# jep 440：记录模式\n\n记录模式在 java 19 进行了第一次预览， 由 jep 405 提出。jdk 20 中是第二次预览，由 jep 432 提出。最终，记录模式在 jdk21 顺利转正。\n\njava 20 新特性概览已经详细介绍过记录模式，这里就不重复了。\n\n\n# jep 441：switch 的模式匹配\n\n增强 java 中的 switch 表达式和语句，允许在 case 标签中使用模式。当模式匹配时，执行 case 标签对应的代码。\n\n在下面的代码中，switch 表达式使用了类型模式来进行匹配。\n\nstatic string formatterpatternswitch(object obj) {\n    return switch (obj) {\n        case integer i -> string.format("int %d", i);\n        case long l    -> string.format("long %d", l);\n        case double d  -> string.format("double %f", d);\n        case string s  -> string.format("string %s", s);\n        default        -> obj.tostring();\n    };\n}\n\n\n\n# jep 442: 外部函数和内存 api（第三次预览）\n\njava 程序可以通过该 api 与 java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 jvm 之外的代码）和安全地访问外部内存（即不受 jvm 管理的内存），该 api 使 java 程序能够调用本机库并处理本机数据，而不会像 jni 那样危险和脆弱。\n\n外部函数和内存 api 在 java 17 中进行了第一轮孵化，由 jep 412 提出。java 18 中进行了第二次孵化，由jep 419 提出。java 19 中是第一次预览，由 jep 424 提出。jdk 20 中是第二次预览，由 jep 434 提出。jdk 21 中是第三次预览，由 jep 442 提出。\n\n在 java 19 新特性概览 中，我有详细介绍到外部函数和内存 api，这里就不再做额外的介绍了。\n\n\n# jep 443：未命名模式和变量（预览）\n\n未命名模式和变量使得我们可以使用下划线 _ 表示未命名的变量以及模式匹配时不使用的组件，旨在提高代码的可读性和可维护性。\n\n未命名变量的典型场景是 try-with-resources 语句、 catch 子句中的异常变量和for循环。当变量不需要使用的时候就可以使用下划线 _代替，这样清晰标识未被使用的变量。\n\ntry (var _ = scopedcontext.acquire()) {\n  // no use of acquired resource\n}\ntry { ... }\ncatch (exception _) { ... }\ncatch (throwable _) { ... }\n\nfor (int i = 0, _ = runonce(); i < arr.length; i++) {\n  ...\n}\n\n\n未命名模式是一个无条件的模式，并不绑定任何值。未命名模式变量出现在类型模式中。\n\nif (r instanceof coloredpoint(_, color c)) { ... c ... }\n\nswitch (b) {\n    case box(redball _), box(blueball _) -> processbox(b);\n    case box(greenball _)                -> stopprocessing();\n    case box(_)                          -> pickanotherbox();\n}\n\n\n\n# jep 444：虚拟线程\n\n虚拟线程是一项重量级的更新，一定一定要重视！\n\n虚拟线程在 java 19 中进行了第一次预览，由jep 425提出。jdk 20 中是第二次预览。最终，虚拟线程在 jdk21 顺利转正。\n\njava 20 新特性概览已经详细介绍过虚拟线程，这里就不重复了。\n\n\n# jep 445：未命名类和实例 main 方法 （预览）\n\n这个特性主要简化了 main 方法的的声明。对于 java 初学者来说，这个 main 方法的声明引入了太多的 java 语法概念，不利于初学者快速上手。\n\n没有使用该特性之前定义一个 main 方法：\n\npublic class helloworld {\n    public static void main(string[] args) {\n        system.out.println("hello, world!");\n    }\n}\n\n\n使用该新特性之后定义一个 main 方法：\n\nclass helloworld {\n    void main() {\n        system.out.println("hello, world!");\n    }\n}\n\n\n进一步精简(未命名的类允许我们不定义类名)：\n\nvoid main() {\n   system.out.println("hello, world!");\n}\n\n\n\n# 参考\n\n * java 21 string templates：https://howtodoinjava.com/java/java-string-templates/\n * java 21 sequenced collections：https://howtodoinjava.com/java/sequenced-collections/',charsets:{cjk:!0}},{title:"Spring源码",frontmatter:{title:"Spring源码",date:"2024-08-23T07:01:06.000Z",permalink:"/pages/be9ac8/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/06.SpringBoot/01.Spring%E6%BA%90%E7%A0%81.html",relativePath:"01.Java基础/06.SpringBoot/01.Spring源码.md",key:"v-1ccb3574",path:"/pages/be9ac8/",headersStr:null,content:" * 源码学习\n\n * 在线md\n\n * 面试算法\n\n * 设计模式\n\n * 语言排行榜\n\n * 博客学习1\n\n * 博客学习2\n\n * maven仓库",normalizedContent:" * 源码学习\n\n * 在线md\n\n * 面试算法\n\n * 设计模式\n\n * 语言排行榜\n\n * 博客学习1\n\n * 博客学习2\n\n * maven仓库",charsets:{cjk:!0}},{title:"权限模型",frontmatter:{title:"权限模型",date:"2024-08-26T17:38:32.000Z",permalink:"/pages/5b4265/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/06.SpringBoot/02.%E6%9D%83%E9%99%90%E6%A8%A1%E5%9E%8B.html",relativePath:"01.Java基础/06.SpringBoot/02.权限模型.md",key:"v-4bad8eff",path:"/pages/5b4265/",headers:[{level:3,title:"RBAC: Role-Based Access Control",slug:"rbac-role-based-access-control",normalizedTitle:"rbac: role-based access control",charIndex:100},{level:3,title:"ABAC: Role-Based Access Control",slug:"abac-role-based-access-control",normalizedTitle:"abac: role-based access control",charIndex:166}],headersStr:"RBAC: Role-Based Access Control ABAC: Role-Based Access Control",content:"权限模型\n\n 1. 目标: 校验用户,能不能进行某个操作!\n 2. 诉求:\n\n * 灵活配置权限\n * 多种级别权限:菜单、按钮、URL\n\n 3. 常见权限模型一共有两种,RBAC、ABAC\n\n\n# RBAC: Role-Based Access Control\n\n基于角色的访问控制, 只看角色即可 特点: 简单、可复用\n\n\n# ABAC: Role-Based Access Control\n\n基于属性的访问控制,一个操作是否被允许要基于四个信息,共同动态计算决定的\n\n特点:",normalizedContent:"权限模型\n\n 1. 目标: 校验用户,能不能进行某个操作!\n 2. 诉求:\n\n * 灵活配置权限\n * 多种级别权限:菜单、按钮、url\n\n 3. 常见权限模型一共有两种,rbac、abac\n\n\n# rbac: role-based access control\n\n基于角色的访问控制, 只看角色即可 特点: 简单、可复用\n\n\n# abac: role-based access control\n\n基于属性的访问控制,一个操作是否被允许要基于四个信息,共同动态计算决定的\n\n特点:",charsets:{cjk:!0}},{title:"Cookie-Session-Token-JWT",frontmatter:{title:"Cookie-Session-Token-JWT",date:"2024-09-13T23:07:28.000Z",permalink:"/pages/c6bced/"},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/06.SpringBoot/03.Cookie-Session-Token-JWT.html",relativePath:"01.Java基础/06.SpringBoot/03.Cookie-Session-Token-JWT.md",key:"v-6ef6bf36",path:"/pages/c6bced/",headers:[{level:2,title:"Acesss Token",slug:"acesss-token",normalizedTitle:"acesss token",charIndex:3268},{level:2,title:"Refresh Token",slug:"refresh-token",normalizedTitle:"refresh token",charIndex:3896},{level:2,title:"生成 JWT",slug:"生成-jwt",normalizedTitle:"生成 jwt",charIndex:5316},{level:2,title:"JWT 的原理",slug:"jwt-的原理",normalizedTitle:"jwt 的原理",charIndex:5357},{level:2,title:"JWT 的使用方式",slug:"jwt-的使用方式",normalizedTitle:"jwt 的使用方式",charIndex:5793},{level:3,title:"方式一",slug:"方式一",normalizedTitle:"方式一",charIndex:5864},{level:3,title:"方式二",slug:"方式二",normalizedTitle:"方式二",charIndex:6331},{level:3,title:"方式三",slug:"方式三",normalizedTitle:"方式三",charIndex:6374},{level:2,title:"项目中使用 JWT",slug:"项目中使用-jwt",normalizedTitle:"项目中使用 jwt",charIndex:6435},{level:2,title:"使用 cookie 时需要考虑的问题",slug:"使用-cookie-时需要考虑的问题",normalizedTitle:"使用 cookie 时需要考虑的问题",charIndex:7627},{level:2,title:"使用 session 时需要考虑的问题",slug:"使用-session-时需要考虑的问题",normalizedTitle:"使用 session 时需要考虑的问题",charIndex:7930},{level:2,title:"使用 token 时需要考虑的问题",slug:"使用-token-时需要考虑的问题",normalizedTitle:"使用 token 时需要考虑的问题",charIndex:8448},{level:2,title:"使用 JWT 时需要考虑的问题",slug:"使用-jwt-时需要考虑的问题",normalizedTitle:"使用 jwt 时需要考虑的问题",charIndex:8673},{level:2,title:"使用加密算法时需要考虑的问题",slug:"使用加密算法时需要考虑的问题",normalizedTitle:"使用加密算法时需要考虑的问题",charIndex:9274},{level:2,title:"分布式架构下 session 共享方案",slug:"分布式架构下-session-共享方案",normalizedTitle:"分布式架构下 session 共享方案",charIndex:9609},{level:3,title:"1\\. session 复制",slug:"_1-session-复制",normalizedTitle:"1. session 复制",charIndex:9633},{level:3,title:"2\\. 粘性 session /IP 绑定策略",slug:"_2-粘性-session-ip-绑定策略",normalizedTitle:"2. 粘性 session /ip 绑定策略",charIndex:9841},{level:3,title:"3\\. session 共享（常用）",slug:"_3-session-共享-常用",normalizedTitle:"3. session 共享（常用）",charIndex:10230},{level:3,title:"4\\. session 持久化",slug:"_4-session-持久化",normalizedTitle:"4. session 持久化",charIndex:10552},{level:2,title:"只要关闭浏览器 ，session 真的就消失了？",slug:"只要关闭浏览器-session-真的就消失了",normalizedTitle:"只要关闭浏览器 ，session 真的就消失了？",charIndex:10697}],headersStr:"Acesss Token Refresh Token 生成 JWT JWT 的原理 JWT 的使用方式 方式一 方式二 方式三 项目中使用 JWT 使用 cookie 时需要考虑的问题 使用 session 时需要考虑的问题 使用 token 时需要考虑的问题 使用 JWT 时需要考虑的问题 使用加密算法时需要考虑的问题 分布式架构下 session 共享方案 1\\. session 复制 2\\. 粘性 session /IP 绑定策略 3\\. session 共享（常用） 4\\. session 持久化 只要关闭浏览器 ，session 真的就消失了？",content:"# 还分不清 Cookie、Session、Token、JWT？\n\n摘要: 原创出处 juejin.im/post/5e055d9ef265da33997a42cc 「秋天不落叶」欢迎转载，保留摘要，谢谢！\n\n * 什么是认证（Authentication）\n * 什么是授权（Authorization）\n * 什么是凭证（Credentials）\n * 什么是 Cookie\n * 什么是 Session\n * Cookie 和 Session 的区别\n * 什么是 Token（令牌）\n * Token 和 Session 的区别\n * 什么是 JWT\n * Token 和 JWT 的区别\n * 常见的前后端鉴权方式\n * 常见的加密算法\n * 常见问题\n\n----------------------------------------\n\n\n# 什么是认证（Authentication）\n\n * 通俗地讲就是验证当前用户的身份，证明“你是你自己”（比如：你每天上下班打卡，都需要通过指纹打卡，当你的指纹和系统里录入的指纹相匹配时，就打卡成功）\n * 互联网中的认证：\n   * 用户名密码登录\n   * 邮箱发送登录链接\n   * 手机号接收验证码\n   * 只要你能收到邮箱/验证码，就默认你是账号的主人\n\n\n# 什么是授权（Authorization）\n\n * 用户授予第三方应用访问该用户某些资源的权限\n   * 你在安装手机应用的时候，APP 会询问是否允许授予权限（访问相册、地理位置等权限）\n   * 你在访问微信小程序时，当登录时，小程序会询问是否允许授予权限（获取昵称、头像、地区、性别等个人信息）\n * 实现授权的方式有：cookie、session、token、OAuth\n\n\n# 什么是凭证（Credentials）\n\n * 实现认证和授权的前提\n   \n   是需要一种\n   \n   媒介（证书）\n   \n   来标记访问者的身份\n   \n   * 在战国时期，商鞅变法，发明了照身帖。照身帖由官府发放，是一块打磨光滑细密的竹板，上面刻有持有人的头像和籍贯信息。国人必须持有，如若没有就被认为是黑户，或者间谍之类的。\n   * 在现实生活中，每个人都会有一张专属的居民身份证，是用于证明持有人身份的一种法定证件。通过身份证，我们可以办理手机卡/银行卡/个人贷款/交通出行等等，这就是认证的凭证。\n   * 在互联网应用中，一般网站（如掘金）会有两种模式，游客模式和登录模式。游客模式下，可以正常浏览网站上面的文章，一旦想要点赞/收藏/分享文章，就需要登录或者注册账号。当用户登录成功后，服务器会给该用户使用的浏览器颁发一个令牌（token），这个令牌用来表明你的身份，每次浏览器发送请求时会带上这个令牌，就可以使用游客模式下无法使用的功能。\n\n\n# 什么是 Cookie\n\n * HTTP 是无状态的协议（对于事务处理没有记忆能力，每次客户端和服务端会话完成时，服务端不会保存任何会话信息）：每个请求都是完全独立的，服务端无法确认当前访问者的身份信息，无法分辨上一次的请求发送者和这一次的发送者是不是同一个人。所以服务器与浏览器为了进行会话跟踪（知道是谁在访问我），就必须主动的去维护一个状态，这个状态用于告知服务端前后两个请求是否来自同一浏览器。而这个状态需要通过 cookie 或者 session 去实现。\n * cookie 存储在客户端： cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。\n * cookie 是不可跨域的： 每个 cookie 都会绑定单一的域名，无法在别的域名下获取使用，一级域名和二级域名之间是允许共享使用的（靠的是 domain）。\n\ncookie 重要的属性\n\n属性\n\n说明\n\nname=value\n\n键值对，设置 Cookie 的名称及相对应的值，都必须是字符串类型 - 如果值为 Unicode 字符，需要为字符编码。 - 如果值为二进制数据，则需要使用 BASE64 编码。\n\ndomain\n\n指定 cookie 所属域名，默认是当前域名\n\npath\n\n指定 cookie 在哪个路径（路由）下生效，默认是 '/'。 如果设置为 /abc，则只有 /abc 下的路由可以访问到该 cookie，如：/abc/read。\n\nmaxAge\n\ncookie 失效的时间，单位秒。如果为整数，则该 cookie 在 maxAge 秒后失效。如果为负数，该 cookie 为临时 cookie ，关闭浏览器即失效，浏览器也不会以任何形式保存该 cookie 。如果为 0，表示删除该 cookie 。默认为 -1。 - 比 expires 好用。\n\nexpires\n\n过期时间，在设置的某个时间点后该 cookie 就会失效。 一般浏览器的 cookie 都是默认储存的，当关闭浏览器结束这个会话的时候，这个 cookie 也就会被删除\n\nsecure\n\n该 cookie 是否仅被使用安全协议传输。安全协议有 HTTPS，SSL等，在网络上传输数据之前先将数据加密。默认为false。 当 secure 值为 true 时，cookie 在 HTTP 中是无效，在 HTTPS 中才有效。\n\nhttpOnly\n\n如果给某个 cookie 设置了 httpOnly 属性，则无法通过 JS 脚本 读取到该 cookie 的信息，但还是能通过 Application 中手动修改 cookie，所以只是在一定程度上可以防止 XSS 攻击，不是绝对的安全\n\n\n# 什么是 Session\n\n * session 是另一种记录服务器和客户端会话状态的机制\n * session 是基于 cookie 实现的，session 存储在服务器端，sessionId 会被存储到客户端的cookie 中\n\n\n\n * session 认证流程：\n   * 用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session\n   * 请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器\n   * 浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名\n   * 当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。\n\n根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。\n\n\n# Cookie 和 Session 的区别\n\n * 安全性： Session 比 Cookie 安全，Session 是存储在服务器端的，Cookie 是存储在客户端的。\n * 存取值的类型不同：Cookie 只支持存字符串数据，想要设置其他类型的数据，需要将其转换成字符串，Session 可以存任意数据类型。\n * 有效期不同： Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭（默认情况下）或者 Session 超时都会失效。\n * 存储大小不同： 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie，但是当访问量过多，会占用过多的服务器资源。\n\n\n# 什么是 Token（令牌）\n\n\n# Acesss Token\n\n * 访问资源接口（API）时所需要的资源凭证\n * 简单 token 的组成： uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign（签名，token 的前几位以哈希算法压缩成的一定长度的十六进制字符串）\n * 特点：\n   * 服务端无状态化、可扩展性好\n   * 支持移动端设备\n   * 安全\n   * 支持跨程序调用\n * token 的身份验证流程：\n\n\n\n 1. 客户端使用用户名跟密码请求登录\n 2. 服务端收到请求，去验证用户名与密码\n 3. 验证成功后，服务端会签发一个 token 并把这个 token 发送给客户端\n 4. 客户端收到 token 以后，会把它存储起来，比如放在 cookie 里或者 localStorage 里\n 5. 客户端每次向服务端请求资源的时候需要带着服务端签发的 token\n 6. 服务端收到请求，然后去验证客户端请求里面带着的 token ，如果验证成功，就向客户端返回请求的数据\n\n * 每一次请求都需要携带 token，需要把 token 放到 HTTP 的 Header 里\n * 基于 token 的用户认证是一种服务端无状态的认证方式，服务端不用存放 token 数据。用解析 token 的计算时间换取 session 的存储空间，从而减轻服务器的压力，减少频繁的查询数据库\n * token 完全由应用管理，所以它可以避开同源策略\n\n\n# Refresh Token\n\n * 另外一种 token——refresh token\n * refresh token 是专用于刷新 access token 的 token。如果没有 refresh token，也可以刷新 access token，但每次刷新都要用户输入登录用户名与密码，会很麻烦。有了 refresh token，可以减少这个麻烦，客户端直接用 refresh token 去更新 access token，无需用户进行额外的操作。\n\n\n\n * Access Token 的有效期比较短，当 Acesss Token 由于过期而失效时，使用 Refresh Token 就可以获取到新的 Token，如果 Refresh Token 也失效了，用户就只能重新登录了。\n * Refresh Token 及过期时间是存储在服务器的数据库中，只有在申请新的 Acesss Token 时才会验证，不会对业务接口响应时间造成影响，也不需要向 Session 一样一直保持在内存中以应对大量的请求。\n\n\n# Token 和 Session 的区别\n\n * Session 是一种记录服务器和客户端会话状态的机制，使服务端有状态化，可以记录会话信息。而 Token 是令牌，访问资源接口（API）时所需要的资源凭证。Token 使服务端无状态化，不会存储会话信息。\n * Session 和 Token 并不矛盾，作为身份认证 Token 安全性比 Session 好，因为每一个请求都有签名还能防止监听以及重放攻击，而 Session 就必须依赖链路层来保障通讯安全了。如果你需要实现有状态的会话，仍然可以增加 Session 来在服务器端保存一些状态。\n * 所谓 Session 认证只是简单的把 User 信息存储到 Session 里，因为 SessionID 的不可预测性，暂且认为是安全的。而 Token ，如果指的是 OAuth Token 或类似的机制的话，提供的是 认证 和 授权 ，认证是针对用户，授权是针对 App 。其目的是让某 App 有权利访问某用户的信息。这里的 Token 是唯一的。不可以转移到其它 App上，也不可以转到其它用户上。Session 只提供一种简单的认证，即只要有此 SessionID ，即认为有此 User 的全部权利。是需要严格保密的，这个数据应该只保存在站方，不应该共享给其它网站或者第三方 App。所以简单来说：如果你的用户数据可能需要和第三方共享，或者允许第三方调用 API 接口，用 Token 。如果永远只是自己的网站，自己的 App，用什么就无所谓了。\n\n\n# 什么是 JWT\n\n * JSON Web Token（简称 JWT）是目前最流行的跨域认证解决方案。\n * 是一种认证授权机制。\n * JWT 是为了在网络应用环境间传递声明而执行的一种基于 JSON 的开放标准（RFC 7519）。JWT 的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源。比如用在用户登录上。\n * 可以使用 HMAC 算法或者是 RSA 的公/私秘钥对 JWT 进行签名。因为数字签名的存在，这些传递的信息是可信的。\n * 阮一峰老师的 JSON Web Token 入门教程 讲的非常通俗易懂，这里就不再班门弄斧了\n\n\n# 生成 JWT\n\njwt.io/ www.jsonwebtoken.io/\n\n\n# JWT 的原理\n\n\n\n * JWT 认证流程：\n   * 用户输入用户名/密码登录，服务端认证成功后，会返回给客户端一个 JWT\n   * 客户端将 token 保存到本地（通常使用 localstorage，也可以使用 cookie）\n   * 当用户希望访问一个受保护的路由或者资源的时候，需要请求头的 Authorization 字段中使用Bearer 模式添加 JWT，其内容看起来是下面这样\n\nAuthorization: Bearer\n\n * 服务端的保护路由将会检查请求头 Authorization 中的 JWT 信息，如果合法，则允许用户的行为\n * 因为 JWT 是自包含的（内部包含了一些会话信息），因此减少了需要查询数据库的需要\n * 因为 JWT 并不使用 Cookie 的，所以你可以使用任何域名提供你的 API 服务而不需要担心跨域资源共享问题（CORS）\n * 因为用户的状态不再存储在服务端的内存中，所以这是一种无状态的认证机制\n\n\n# JWT 的使用方式\n\n * 客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。\n\n\n# 方式一\n\n * 当用户希望访问一个受保护的路由或者资源的时候，可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求头信息的 Authorization 字段里，使用 Bearer 模式添加 JWT。\n   \n   GET /calendar/v1/events\n   Host: api.example.com\n   Authorization: Bearer\n   \n   * 用户的状态不会存储在服务端的内存中，这是一种 无状态的认证机制\n   * 服务端的保护路由将会检查请求头 Authorization 中的 JWT 信息，如果合法，则允许用户的行为。\n   * 由于 JWT 是自包含的，因此减少了需要查询数据库的需要\n   * JWT 的这些特性使得我们可以完全依赖其无状态的特性提供数据 API 服务，甚至是创建一个下载流服务。\n   * 因为 JWT 并不使用 Cookie ，所以你可以使用任何域名提供你的 API 服务而不需要担心跨域资源共享问题（CORS）\n\n\n# 方式二\n\n * 跨域的时候，可以把 JWT 放在 POST 请求的数据体里。\n\n\n# 方式三\n\n * 通过 URL 传输\n\nhttp://www.example.com/user?token=xxx\n\n\n# 项目中使用 JWT\n\n项目地址\n\n\n# Token 和 JWT 的区别\n\n相同：\n\n * 都是访问资源的令牌\n * 都可以记录用户的信息\n * 都是使服务端无状态化\n * 都是只有验证成功后，客户端才能访问服务端上受保护的资源\n\n区别：\n\n * Token：服务端验证客户端发送过来的 Token 时，还需要查询数据库获取用户信息，然后验证 Token 是否有效。\n * JWT： 将 Token 和 Payload 加密后存储于客户端，服务端只需要使用密钥解密进行校验（校验也是 JWT 自己实现的）即可，不需要查询或者减少查询数据库，因为 JWT 自包含了用户信息和加密的数据。\n\n\n# 常见的前后端鉴权方式\n\n 1. Session-Cookie\n 2. Token 验证（包括 JWT，SSO）\n 3. OAuth2.0（开放授权）\n\n\n# 常见的加密算法\n\n\n\n * 哈希算法(Hash Algorithm)又称散列算法、散列函数、哈希函数，是一种从任何一种数据中创建小的数字“指纹”的方法。哈希算法将数据重新打乱混合，重新创建一个哈希值。\n * 哈希算法主要用来保障数据真实性(即完整性)，即发信人将原始消息和哈希值一起发送，收信人通过相同的哈希函数来校验原始数据是否真实。\n * 哈希算法通常有以下几个特点：\n   * 正像快速：原始数据可以快速计算出哈希值\n   * 逆向困难：通过哈希值基本不可能推导出原始数据\n   * 输入敏感：原始数据只要有一点变动，得到的哈希值差别很大\n   * 冲突避免：很难找到不同的原始数据得到相同的哈希值，宇宙中原子数大约在 10 的 60 次方到 80 次方之间，所以 2 的 256 次方有足够的空间容纳所有的可能，算法好的情况下冲突碰撞的概率很低：\n     * 2 的 128 次方为 340282366920938463463374607431768211456，也就是 10 的 39 次方级别\n     * 2 的 160 次方为 1.4615016373309029182036848327163e+48，也就是 10 的 48 次方级别\n     * 2 的 256 次方为 1.1579208923731619542357098500869 × 10 的 77 次方，也就是 10 的 77 次方\n\n注意：\n\n 1. 以上不能保证数据被恶意篡改，原始数据和哈希值都可能被恶意篡改，要保证不被篡改，可以使用RSA 公钥私钥方案，再配合哈希值。\n 2. 哈希算法主要用来防止计算机传输过程中的错误，早期计算机通过前 7 位数据第 8 位奇偶校验码来保障（12.5% 的浪费效率低），对于一段数据或文件，通过哈希算法生成 128bit 或者 256bit 的哈希值，如果校验有问题就要求重传。\n\n\n# 常见问题\n\n\n# 使用 cookie 时需要考虑的问题\n\n * 因为存储在客户端，容易被客户端篡改，使用前需要验证合法性\n * 不要存储敏感数据，比如用户密码，账户余额\n * 使用 httpOnly 在一定程度上提高安全性\n * 尽量减少 cookie 的体积，能存储的数据量不能超过 4kb\n * 设置正确的 domain 和 path，减少数据传输\n * cookie 无法跨域\n * 一个浏览器针对一个网站最多存 20 个Cookie，浏览器一般只允许存放 300 个Cookie\n * 移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token\n\n\n# 使用 session 时需要考虑的问题\n\n * 将 session 存储在服务器里面，当用户同时在线量比较多时，这些 session 会占据较多的内存，需要在服务端定期的去清理过期的 session\n * 当网站采用集群部署的时候，会遇到多台 web 服务器之间如何做 session 共享的问题。因为 session 是由单个服务器创建的，但是处理用户请求的服务器不一定是那个创建 session 的服务器，那么该服务器就无法拿到之前已经放入到 session 中的登录凭证之类的信息了。\n * 当多个应用要共享 session 时，除了以上问题，还会遇到跨域问题，因为不同的应用可能部署的主机不一样，需要在各个应用做好 cookie 跨域的处理。\n * sessionId 是存储在 cookie 中的，假如浏览器禁止 cookie 或不支持 cookie 怎么办？ 一般会把 sessionId 跟在 url 参数后面即重写 url，所以 session 不一定非得需要靠 cookie 实现\n * 移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token\n\n\n# 使用 token 时需要考虑的问题\n\n * 如果你认为用数据库来存储 token 会导致查询时间太长，可以选择放在内存当中。比如 redis 很适合你对 token 查询的需求。\n * token 完全由应用管理，所以它可以避开同源策略\n * token 可以避免 CSRF 攻击(因为不需要 cookie 了)\n * 移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token\n\n\n# 使用 JWT 时需要考虑的问题\n\n * 因为 JWT 并不依赖 Cookie 的，所以你可以使用任何域名提供你的 API 服务而不需要担心跨域资源共享问题（CORS）\n * JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。\n * JWT 不加密的情况下，不能将秘密数据写入 JWT。\n * JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。\n * JWT 最大的优势是服务器不再需要存储 Session，使得服务器认证鉴权业务可以方便扩展。但这也是 JWT 最大的缺点：由于服务器不需要存储 Session 状态，因此使用过程中无法废弃某个 Token 或者更改 Token 的权限。也就是说一旦 JWT 签发了，到期之前就会始终有效，除非服务器部署额外的逻辑。\n * JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。\n * JWT 适合一次性的命令认证，颁发一个有效期极短的 JWT，即使暴露了危险也很小，由于每次操作都会生成新的 JWT，因此也没必要保存 JWT，真正实现无状态。\n * 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。\n\n\n# 使用加密算法时需要考虑的问题\n\n * 绝不要以明文存储密码\n * 永远使用 哈希算法 来处理密码，绝不要使用 Base64 或其他编码方式来存储密码，这和以明文存储密码是一样的，使用哈希，而不要使用编码。编码以及加密，都是双向的过程，而密码是保密的，应该只被它的所有者知道， 这个过程必须是单向的。哈希正是用于做这个的，从来没有解哈希这种说法， 但是编码就存在解码，加密就存在解密。\n * 绝不要使用弱哈希或已被破解的哈希算法，像 MD5 或 SHA1 ，只使用强密码哈希算法。\n * 绝不要以明文形式显示或发送密码，即使是对密码的所有者也应该这样。如果你需要 “忘记密码” 的功能，可以随机生成一个新的 一次性的（这点很重要）密码，然后把这个密码发送给用户。\n\n\n# 分布式架构下 session 共享方案\n\n\n# 1. session 复制\n\n * 任何一个服务器上的 session 发生改变（增删改），该节点会把这个 session 的所有内容序列化，然后广播给所有其它节点，不管其他服务器需不需要 session ，以此来保证 session 同步\n\n优点： 可容错，各个服务器间 session 能够实时响应。 缺点： 会对网络负荷造成一定压力，如果 session 量大的话可能会造成网络堵塞，拖慢服务器性能。\n\n\n# 2. 粘性 session /IP 绑定策略\n\n * 采用 Ngnix 中的 ip_hash 机制，将某个 ip的所有请求都定向到同一台服务器上，即将用户与服务器绑定。 用户第一次请求时，负载均衡器将用户的请求转发到了 A 服务器上，如果负载均衡器设置了粘性 session 的话，那么用户以后的每次请求都会转发到 A 服务器上，相当于把用户和 A 服务器粘到了一块，这就是粘性 session 机制。\n\n优点： 简单，不需要对 session 做任何处理。 缺点： 缺乏容错性，如果当前访问的服务器发生故障，用户被转移到第二个服务器上时，他的 session 信息都将失效。 适用场景： 发生故障对客户产生的影响较小；服务器发生故障是低概率事件 。 实现方式： 以 Nginx 为例，在 upstream 模块配置 ip_hash 属性即可实现粘性 session。\n\n\n# 3. session 共享（常用）\n\n * 使用分布式缓存方案比如 Memcached 、Redis 来缓存 session，但是要求 Memcached 或 Redis 必须是集群\n * 把 session 放到 Redis 中存储，虽然架构上变得复杂，并且需要多访问一次 Redis ，但是这种方案带来的好处也是很大的：\n   * 实现了 session 共享；\n   * 可以水平扩展（增加 Redis 服务器）；\n   * 服务器重启 session 不丢失（不过也要注意 session 在 Redis 中的刷新/失效机制）；\n   * 不仅可以跨服务器 session 共享，甚至可以跨平台（例如网页端和 APP 端）\n\n\n\n\n# 4. session 持久化\n\n * 将 session 存储到数据库中，保证 session 的持久化\n\n优点： 服务器出现问题，session 不会丢失 缺点： 如果网站的访问量很大，把 session 存储到数据库中，会对数据库造成很大压力，还需要增加额外的开销维护数据库。\n\n\n# 只要关闭浏览器 ，session 真的就消失了？\n\n不对。对 session 来说，除非程序通知服务器删除一个 session，否则服务器会一直保留，程序一般都是在用户做 log off 的时候发个指令去删除 session。 然而浏览器从来不会主动在关闭之前通知服务器它将要关闭，因此服务器根本不会有机会知道浏览器已经关闭，之所以会有这种错觉，是大部分 session 机制都使用会话 cookie 来保存 session id，而关闭浏览器后这个 session id 就消失了，再次连接服务器时也就无法找到原来的 session。如果服务器设置的 cookie 被保存在硬盘上，或者使用某种手段改写浏览器发出的 HTTP 请求头，把原来的 session id 发送给服务器，则再次打开浏览器仍然能够打开原来的 session。 恰恰是由于关闭浏览器不会导致 session 被删除，迫使服务器为 session 设置了一个失效时间，当距离客户端上一次使用 session 的时间超过这个失效时间时，服务器就认为客户端已经停止了活动，才会把 session 删除以节省存储空间。\n\n\n# 项目地址\n\n在项目中使用 JWT\n\n\n# 后语\n\n * 本文只是基于自己的理解讲了理论知识，因为对后端/算法知识不是很熟，如有谬误，还请告知，万分感谢\n * 如果本文对你有所帮助，还请点个赞~~",normalizedContent:"# 还分不清 cookie、session、token、jwt？\n\n摘要: 原创出处 juejin.im/post/5e055d9ef265da33997a42cc 「秋天不落叶」欢迎转载，保留摘要，谢谢！\n\n * 什么是认证（authentication）\n * 什么是授权（authorization）\n * 什么是凭证（credentials）\n * 什么是 cookie\n * 什么是 session\n * cookie 和 session 的区别\n * 什么是 token（令牌）\n * token 和 session 的区别\n * 什么是 jwt\n * token 和 jwt 的区别\n * 常见的前后端鉴权方式\n * 常见的加密算法\n * 常见问题\n\n----------------------------------------\n\n\n# 什么是认证（authentication）\n\n * 通俗地讲就是验证当前用户的身份，证明“你是你自己”（比如：你每天上下班打卡，都需要通过指纹打卡，当你的指纹和系统里录入的指纹相匹配时，就打卡成功）\n * 互联网中的认证：\n   * 用户名密码登录\n   * 邮箱发送登录链接\n   * 手机号接收验证码\n   * 只要你能收到邮箱/验证码，就默认你是账号的主人\n\n\n# 什么是授权（authorization）\n\n * 用户授予第三方应用访问该用户某些资源的权限\n   * 你在安装手机应用的时候，app 会询问是否允许授予权限（访问相册、地理位置等权限）\n   * 你在访问微信小程序时，当登录时，小程序会询问是否允许授予权限（获取昵称、头像、地区、性别等个人信息）\n * 实现授权的方式有：cookie、session、token、oauth\n\n\n# 什么是凭证（credentials）\n\n * 实现认证和授权的前提\n   \n   是需要一种\n   \n   媒介（证书）\n   \n   来标记访问者的身份\n   \n   * 在战国时期，商鞅变法，发明了照身帖。照身帖由官府发放，是一块打磨光滑细密的竹板，上面刻有持有人的头像和籍贯信息。国人必须持有，如若没有就被认为是黑户，或者间谍之类的。\n   * 在现实生活中，每个人都会有一张专属的居民身份证，是用于证明持有人身份的一种法定证件。通过身份证，我们可以办理手机卡/银行卡/个人贷款/交通出行等等，这就是认证的凭证。\n   * 在互联网应用中，一般网站（如掘金）会有两种模式，游客模式和登录模式。游客模式下，可以正常浏览网站上面的文章，一旦想要点赞/收藏/分享文章，就需要登录或者注册账号。当用户登录成功后，服务器会给该用户使用的浏览器颁发一个令牌（token），这个令牌用来表明你的身份，每次浏览器发送请求时会带上这个令牌，就可以使用游客模式下无法使用的功能。\n\n\n# 什么是 cookie\n\n * http 是无状态的协议（对于事务处理没有记忆能力，每次客户端和服务端会话完成时，服务端不会保存任何会话信息）：每个请求都是完全独立的，服务端无法确认当前访问者的身份信息，无法分辨上一次的请求发送者和这一次的发送者是不是同一个人。所以服务器与浏览器为了进行会话跟踪（知道是谁在访问我），就必须主动的去维护一个状态，这个状态用于告知服务端前后两个请求是否来自同一浏览器。而这个状态需要通过 cookie 或者 session 去实现。\n * cookie 存储在客户端： cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。\n * cookie 是不可跨域的： 每个 cookie 都会绑定单一的域名，无法在别的域名下获取使用，一级域名和二级域名之间是允许共享使用的（靠的是 domain）。\n\ncookie 重要的属性\n\n属性\n\n说明\n\nname=value\n\n键值对，设置 cookie 的名称及相对应的值，都必须是字符串类型 - 如果值为 unicode 字符，需要为字符编码。 - 如果值为二进制数据，则需要使用 base64 编码。\n\ndomain\n\n指定 cookie 所属域名，默认是当前域名\n\npath\n\n指定 cookie 在哪个路径（路由）下生效，默认是 '/'。 如果设置为 /abc，则只有 /abc 下的路由可以访问到该 cookie，如：/abc/read。\n\nmaxage\n\ncookie 失效的时间，单位秒。如果为整数，则该 cookie 在 maxage 秒后失效。如果为负数，该 cookie 为临时 cookie ，关闭浏览器即失效，浏览器也不会以任何形式保存该 cookie 。如果为 0，表示删除该 cookie 。默认为 -1。 - 比 expires 好用。\n\nexpires\n\n过期时间，在设置的某个时间点后该 cookie 就会失效。 一般浏览器的 cookie 都是默认储存的，当关闭浏览器结束这个会话的时候，这个 cookie 也就会被删除\n\nsecure\n\n该 cookie 是否仅被使用安全协议传输。安全协议有 https，ssl等，在网络上传输数据之前先将数据加密。默认为false。 当 secure 值为 true 时，cookie 在 http 中是无效，在 https 中才有效。\n\nhttponly\n\n如果给某个 cookie 设置了 httponly 属性，则无法通过 js 脚本 读取到该 cookie 的信息，但还是能通过 application 中手动修改 cookie，所以只是在一定程度上可以防止 xss 攻击，不是绝对的安全\n\n\n# 什么是 session\n\n * session 是另一种记录服务器和客户端会话状态的机制\n * session 是基于 cookie 实现的，session 存储在服务器端，sessionid 会被存储到客户端的cookie 中\n\n\n\n * session 认证流程：\n   * 用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 session\n   * 请求返回时将此 session 的唯一标识信息 sessionid 返回给浏览器\n   * 浏览器接收到服务器返回的 sessionid 信息后，会将此信息存入到 cookie 中，同时 cookie 记录此 sessionid 属于哪个域名\n   * 当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 cookie 信息，如果存在自动将 cookie 信息也发送给服务端，服务端会从 cookie 中获取 sessionid，再根据 sessionid 查找对应的 session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 session 证明用户已经登录可执行后面操作。\n\n根据以上流程可知，sessionid 是连接 cookie 和 session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。\n\n\n# cookie 和 session 的区别\n\n * 安全性： session 比 cookie 安全，session 是存储在服务器端的，cookie 是存储在客户端的。\n * 存取值的类型不同：cookie 只支持存字符串数据，想要设置其他类型的数据，需要将其转换成字符串，session 可以存任意数据类型。\n * 有效期不同： cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，session 一般失效时间较短，客户端关闭（默认情况下）或者 session 超时都会失效。\n * 存储大小不同： 单个 cookie 保存的数据不能超过 4k，session 可存储数据远高于 cookie，但是当访问量过多，会占用过多的服务器资源。\n\n\n# 什么是 token（令牌）\n\n\n# acesss token\n\n * 访问资源接口（api）时所需要的资源凭证\n * 简单 token 的组成： uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign（签名，token 的前几位以哈希算法压缩成的一定长度的十六进制字符串）\n * 特点：\n   * 服务端无状态化、可扩展性好\n   * 支持移动端设备\n   * 安全\n   * 支持跨程序调用\n * token 的身份验证流程：\n\n\n\n 1. 客户端使用用户名跟密码请求登录\n 2. 服务端收到请求，去验证用户名与密码\n 3. 验证成功后，服务端会签发一个 token 并把这个 token 发送给客户端\n 4. 客户端收到 token 以后，会把它存储起来，比如放在 cookie 里或者 localstorage 里\n 5. 客户端每次向服务端请求资源的时候需要带着服务端签发的 token\n 6. 服务端收到请求，然后去验证客户端请求里面带着的 token ，如果验证成功，就向客户端返回请求的数据\n\n * 每一次请求都需要携带 token，需要把 token 放到 http 的 header 里\n * 基于 token 的用户认证是一种服务端无状态的认证方式，服务端不用存放 token 数据。用解析 token 的计算时间换取 session 的存储空间，从而减轻服务器的压力，减少频繁的查询数据库\n * token 完全由应用管理，所以它可以避开同源策略\n\n\n# refresh token\n\n * 另外一种 token——refresh token\n * refresh token 是专用于刷新 access token 的 token。如果没有 refresh token，也可以刷新 access token，但每次刷新都要用户输入登录用户名与密码，会很麻烦。有了 refresh token，可以减少这个麻烦，客户端直接用 refresh token 去更新 access token，无需用户进行额外的操作。\n\n\n\n * access token 的有效期比较短，当 acesss token 由于过期而失效时，使用 refresh token 就可以获取到新的 token，如果 refresh token 也失效了，用户就只能重新登录了。\n * refresh token 及过期时间是存储在服务器的数据库中，只有在申请新的 acesss token 时才会验证，不会对业务接口响应时间造成影响，也不需要向 session 一样一直保持在内存中以应对大量的请求。\n\n\n# token 和 session 的区别\n\n * session 是一种记录服务器和客户端会话状态的机制，使服务端有状态化，可以记录会话信息。而 token 是令牌，访问资源接口（api）时所需要的资源凭证。token 使服务端无状态化，不会存储会话信息。\n * session 和 token 并不矛盾，作为身份认证 token 安全性比 session 好，因为每一个请求都有签名还能防止监听以及重放攻击，而 session 就必须依赖链路层来保障通讯安全了。如果你需要实现有状态的会话，仍然可以增加 session 来在服务器端保存一些状态。\n * 所谓 session 认证只是简单的把 user 信息存储到 session 里，因为 sessionid 的不可预测性，暂且认为是安全的。而 token ，如果指的是 oauth token 或类似的机制的话，提供的是 认证 和 授权 ，认证是针对用户，授权是针对 app 。其目的是让某 app 有权利访问某用户的信息。这里的 token 是唯一的。不可以转移到其它 app上，也不可以转到其它用户上。session 只提供一种简单的认证，即只要有此 sessionid ，即认为有此 user 的全部权利。是需要严格保密的，这个数据应该只保存在站方，不应该共享给其它网站或者第三方 app。所以简单来说：如果你的用户数据可能需要和第三方共享，或者允许第三方调用 api 接口，用 token 。如果永远只是自己的网站，自己的 app，用什么就无所谓了。\n\n\n# 什么是 jwt\n\n * json web token（简称 jwt）是目前最流行的跨域认证解决方案。\n * 是一种认证授权机制。\n * jwt 是为了在网络应用环境间传递声明而执行的一种基于 json 的开放标准（rfc 7519）。jwt 的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源。比如用在用户登录上。\n * 可以使用 hmac 算法或者是 rsa 的公/私秘钥对 jwt 进行签名。因为数字签名的存在，这些传递的信息是可信的。\n * 阮一峰老师的 json web token 入门教程 讲的非常通俗易懂，这里就不再班门弄斧了\n\n\n# 生成 jwt\n\njwt.io/ www.jsonwebtoken.io/\n\n\n# jwt 的原理\n\n\n\n * jwt 认证流程：\n   * 用户输入用户名/密码登录，服务端认证成功后，会返回给客户端一个 jwt\n   * 客户端将 token 保存到本地（通常使用 localstorage，也可以使用 cookie）\n   * 当用户希望访问一个受保护的路由或者资源的时候，需要请求头的 authorization 字段中使用bearer 模式添加 jwt，其内容看起来是下面这样\n\nauthorization: bearer\n\n * 服务端的保护路由将会检查请求头 authorization 中的 jwt 信息，如果合法，则允许用户的行为\n * 因为 jwt 是自包含的（内部包含了一些会话信息），因此减少了需要查询数据库的需要\n * 因为 jwt 并不使用 cookie 的，所以你可以使用任何域名提供你的 api 服务而不需要担心跨域资源共享问题（cors）\n * 因为用户的状态不再存储在服务端的内存中，所以这是一种无状态的认证机制\n\n\n# jwt 的使用方式\n\n * 客户端收到服务器返回的 jwt，可以储存在 cookie 里面，也可以储存在 localstorage。\n\n\n# 方式一\n\n * 当用户希望访问一个受保护的路由或者资源的时候，可以把它放在 cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 http 请求头信息的 authorization 字段里，使用 bearer 模式添加 jwt。\n   \n   get /calendar/v1/events\n   host: api.example.com\n   authorization: bearer\n   \n   * 用户的状态不会存储在服务端的内存中，这是一种 无状态的认证机制\n   * 服务端的保护路由将会检查请求头 authorization 中的 jwt 信息，如果合法，则允许用户的行为。\n   * 由于 jwt 是自包含的，因此减少了需要查询数据库的需要\n   * jwt 的这些特性使得我们可以完全依赖其无状态的特性提供数据 api 服务，甚至是创建一个下载流服务。\n   * 因为 jwt 并不使用 cookie ，所以你可以使用任何域名提供你的 api 服务而不需要担心跨域资源共享问题（cors）\n\n\n# 方式二\n\n * 跨域的时候，可以把 jwt 放在 post 请求的数据体里。\n\n\n# 方式三\n\n * 通过 url 传输\n\nhttp://www.example.com/user?token=xxx\n\n\n# 项目中使用 jwt\n\n项目地址\n\n\n# token 和 jwt 的区别\n\n相同：\n\n * 都是访问资源的令牌\n * 都可以记录用户的信息\n * 都是使服务端无状态化\n * 都是只有验证成功后，客户端才能访问服务端上受保护的资源\n\n区别：\n\n * token：服务端验证客户端发送过来的 token 时，还需要查询数据库获取用户信息，然后验证 token 是否有效。\n * jwt： 将 token 和 payload 加密后存储于客户端，服务端只需要使用密钥解密进行校验（校验也是 jwt 自己实现的）即可，不需要查询或者减少查询数据库，因为 jwt 自包含了用户信息和加密的数据。\n\n\n# 常见的前后端鉴权方式\n\n 1. session-cookie\n 2. token 验证（包括 jwt，sso）\n 3. oauth2.0（开放授权）\n\n\n# 常见的加密算法\n\n\n\n * 哈希算法(hash algorithm)又称散列算法、散列函数、哈希函数，是一种从任何一种数据中创建小的数字“指纹”的方法。哈希算法将数据重新打乱混合，重新创建一个哈希值。\n * 哈希算法主要用来保障数据真实性(即完整性)，即发信人将原始消息和哈希值一起发送，收信人通过相同的哈希函数来校验原始数据是否真实。\n * 哈希算法通常有以下几个特点：\n   * 正像快速：原始数据可以快速计算出哈希值\n   * 逆向困难：通过哈希值基本不可能推导出原始数据\n   * 输入敏感：原始数据只要有一点变动，得到的哈希值差别很大\n   * 冲突避免：很难找到不同的原始数据得到相同的哈希值，宇宙中原子数大约在 10 的 60 次方到 80 次方之间，所以 2 的 256 次方有足够的空间容纳所有的可能，算法好的情况下冲突碰撞的概率很低：\n     * 2 的 128 次方为 340282366920938463463374607431768211456，也就是 10 的 39 次方级别\n     * 2 的 160 次方为 1.4615016373309029182036848327163e+48，也就是 10 的 48 次方级别\n     * 2 的 256 次方为 1.1579208923731619542357098500869 × 10 的 77 次方，也就是 10 的 77 次方\n\n注意：\n\n 1. 以上不能保证数据被恶意篡改，原始数据和哈希值都可能被恶意篡改，要保证不被篡改，可以使用rsa 公钥私钥方案，再配合哈希值。\n 2. 哈希算法主要用来防止计算机传输过程中的错误，早期计算机通过前 7 位数据第 8 位奇偶校验码来保障（12.5% 的浪费效率低），对于一段数据或文件，通过哈希算法生成 128bit 或者 256bit 的哈希值，如果校验有问题就要求重传。\n\n\n# 常见问题\n\n\n# 使用 cookie 时需要考虑的问题\n\n * 因为存储在客户端，容易被客户端篡改，使用前需要验证合法性\n * 不要存储敏感数据，比如用户密码，账户余额\n * 使用 httponly 在一定程度上提高安全性\n * 尽量减少 cookie 的体积，能存储的数据量不能超过 4kb\n * 设置正确的 domain 和 path，减少数据传输\n * cookie 无法跨域\n * 一个浏览器针对一个网站最多存 20 个cookie，浏览器一般只允许存放 300 个cookie\n * 移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token\n\n\n# 使用 session 时需要考虑的问题\n\n * 将 session 存储在服务器里面，当用户同时在线量比较多时，这些 session 会占据较多的内存，需要在服务端定期的去清理过期的 session\n * 当网站采用集群部署的时候，会遇到多台 web 服务器之间如何做 session 共享的问题。因为 session 是由单个服务器创建的，但是处理用户请求的服务器不一定是那个创建 session 的服务器，那么该服务器就无法拿到之前已经放入到 session 中的登录凭证之类的信息了。\n * 当多个应用要共享 session 时，除了以上问题，还会遇到跨域问题，因为不同的应用可能部署的主机不一样，需要在各个应用做好 cookie 跨域的处理。\n * sessionid 是存储在 cookie 中的，假如浏览器禁止 cookie 或不支持 cookie 怎么办？ 一般会把 sessionid 跟在 url 参数后面即重写 url，所以 session 不一定非得需要靠 cookie 实现\n * 移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token\n\n\n# 使用 token 时需要考虑的问题\n\n * 如果你认为用数据库来存储 token 会导致查询时间太长，可以选择放在内存当中。比如 redis 很适合你对 token 查询的需求。\n * token 完全由应用管理，所以它可以避开同源策略\n * token 可以避免 csrf 攻击(因为不需要 cookie 了)\n * 移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token\n\n\n# 使用 jwt 时需要考虑的问题\n\n * 因为 jwt 并不依赖 cookie 的，所以你可以使用任何域名提供你的 api 服务而不需要担心跨域资源共享问题（cors）\n * jwt 默认是不加密，但也是可以加密的。生成原始 token 以后，可以用密钥再加密一次。\n * jwt 不加密的情况下，不能将秘密数据写入 jwt。\n * jwt 不仅可以用于认证，也可以用于交换信息。有效使用 jwt，可以降低服务器查询数据库的次数。\n * jwt 最大的优势是服务器不再需要存储 session，使得服务器认证鉴权业务可以方便扩展。但这也是 jwt 最大的缺点：由于服务器不需要存储 session 状态，因此使用过程中无法废弃某个 token 或者更改 token 的权限。也就是说一旦 jwt 签发了，到期之前就会始终有效，除非服务器部署额外的逻辑。\n * jwt 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，jwt的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。\n * jwt 适合一次性的命令认证，颁发一个有效期极短的 jwt，即使暴露了危险也很小，由于每次操作都会生成新的 jwt，因此也没必要保存 jwt，真正实现无状态。\n * 为了减少盗用，jwt 不应该使用 http 协议明码传输，要使用 https 协议传输。\n\n\n# 使用加密算法时需要考虑的问题\n\n * 绝不要以明文存储密码\n * 永远使用 哈希算法 来处理密码，绝不要使用 base64 或其他编码方式来存储密码，这和以明文存储密码是一样的，使用哈希，而不要使用编码。编码以及加密，都是双向的过程，而密码是保密的，应该只被它的所有者知道， 这个过程必须是单向的。哈希正是用于做这个的，从来没有解哈希这种说法， 但是编码就存在解码，加密就存在解密。\n * 绝不要使用弱哈希或已被破解的哈希算法，像 md5 或 sha1 ，只使用强密码哈希算法。\n * 绝不要以明文形式显示或发送密码，即使是对密码的所有者也应该这样。如果你需要 “忘记密码” 的功能，可以随机生成一个新的 一次性的（这点很重要）密码，然后把这个密码发送给用户。\n\n\n# 分布式架构下 session 共享方案\n\n\n# 1. session 复制\n\n * 任何一个服务器上的 session 发生改变（增删改），该节点会把这个 session 的所有内容序列化，然后广播给所有其它节点，不管其他服务器需不需要 session ，以此来保证 session 同步\n\n优点： 可容错，各个服务器间 session 能够实时响应。 缺点： 会对网络负荷造成一定压力，如果 session 量大的话可能会造成网络堵塞，拖慢服务器性能。\n\n\n# 2. 粘性 session /ip 绑定策略\n\n * 采用 ngnix 中的 ip_hash 机制，将某个 ip的所有请求都定向到同一台服务器上，即将用户与服务器绑定。 用户第一次请求时，负载均衡器将用户的请求转发到了 a 服务器上，如果负载均衡器设置了粘性 session 的话，那么用户以后的每次请求都会转发到 a 服务器上，相当于把用户和 a 服务器粘到了一块，这就是粘性 session 机制。\n\n优点： 简单，不需要对 session 做任何处理。 缺点： 缺乏容错性，如果当前访问的服务器发生故障，用户被转移到第二个服务器上时，他的 session 信息都将失效。 适用场景： 发生故障对客户产生的影响较小；服务器发生故障是低概率事件 。 实现方式： 以 nginx 为例，在 upstream 模块配置 ip_hash 属性即可实现粘性 session。\n\n\n# 3. session 共享（常用）\n\n * 使用分布式缓存方案比如 memcached 、redis 来缓存 session，但是要求 memcached 或 redis 必须是集群\n * 把 session 放到 redis 中存储，虽然架构上变得复杂，并且需要多访问一次 redis ，但是这种方案带来的好处也是很大的：\n   * 实现了 session 共享；\n   * 可以水平扩展（增加 redis 服务器）；\n   * 服务器重启 session 不丢失（不过也要注意 session 在 redis 中的刷新/失效机制）；\n   * 不仅可以跨服务器 session 共享，甚至可以跨平台（例如网页端和 app 端）\n\n\n\n\n# 4. session 持久化\n\n * 将 session 存储到数据库中，保证 session 的持久化\n\n优点： 服务器出现问题，session 不会丢失 缺点： 如果网站的访问量很大，把 session 存储到数据库中，会对数据库造成很大压力，还需要增加额外的开销维护数据库。\n\n\n# 只要关闭浏览器 ，session 真的就消失了？\n\n不对。对 session 来说，除非程序通知服务器删除一个 session，否则服务器会一直保留，程序一般都是在用户做 log off 的时候发个指令去删除 session。 然而浏览器从来不会主动在关闭之前通知服务器它将要关闭，因此服务器根本不会有机会知道浏览器已经关闭，之所以会有这种错觉，是大部分 session 机制都使用会话 cookie 来保存 session id，而关闭浏览器后这个 session id 就消失了，再次连接服务器时也就无法找到原来的 session。如果服务器设置的 cookie 被保存在硬盘上，或者使用某种手段改写浏览器发出的 http 请求头，把原来的 session id 发送给服务器，则再次打开浏览器仍然能够打开原来的 session。 恰恰是由于关闭浏览器不会导致 session 被删除，迫使服务器为 session 设置了一个失效时间，当距离客户端上一次使用 session 的时间超过这个失效时间时，服务器就认为客户端已经停止了活动，才会把 session 删除以节省存储空间。\n\n\n# 项目地址\n\n在项目中使用 jwt\n\n\n# 后语\n\n * 本文只是基于自己的理解讲了理论知识，因为对后端/算法知识不是很熟，如有谬误，还请告知，万分感谢\n * 如果本文对你有所帮助，还请点个赞~~",charsets:{cjk:!0}},{title:"监督学习-吴恩达coursera",frontmatter:{title:"监督学习-吴恩达coursera",date:"2024-08-21T17:12:36.000Z",permalink:"/pages/3c4623/"},regularPath:"/03.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/01.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BEcoursera.html",relativePath:"03.人工智能/01.监督学习-吴恩达coursera.md",key:"v-c290b01e",path:"/pages/3c4623/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"吴恩达：机器学习的六个核心算法",frontmatter:{title:"吴恩达：机器学习的六个核心算法",date:"2024-08-13T16:19:12.000Z",permalink:"/pages/cb2190/"},regularPath:"/03.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/02.%E5%90%B4%E6%81%A9%E8%BE%BE%EF%BC%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%85%AD%E4%B8%AA%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95.html",relativePath:"03.人工智能/02.吴恩达：机器学习的六个核心算法.md",key:"v-e70761c4",path:"/pages/cb2190/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"总览",frontmatter:{title:"总览",date:"2023-09-06T15:03:26.000Z",permalink:"/pages/8448ab/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/01.%E6%80%BB%E8%A7%88.html",relativePath:"04.知识地图/02.源码脑图/01.总览.md",key:"v-660b1f27",path:"/pages/8448ab/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/09/06, 16:05:49",lastUpdatedTimestamp:1693987549e3},{title:"Program入口",frontmatter:{title:"Program入口",date:"2023-09-06T15:29:54.000Z",permalink:"/pages/372b2d/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/02.Program%E5%85%A5%E5%8F%A3.html",relativePath:"04.知识地图/02.源码脑图/02.Program入口.md",key:"v-80aef426",path:"/pages/372b2d/",headersStr:null,content:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/02-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%20%EF%BC%88Program%EF%BC%89.xmind\n\n",normalizedContent:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/02-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%20%ef%bc%88program%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"知识地图",frontmatter:{title:"知识地图",article:!1,date:"2023-04-15T17:04:40.000Z",permalink:"/pages/f8be69/"},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/01.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/01.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE.html",relativePath:"04.知识地图/01.知识地图/01.知识地图.md",key:"v-639a0f7a",path:"/pages/f8be69/",headersStr:null,content:"来源\n\nhttps://roadmap.sh/aspnet-core\n\n",normalizedContent:"来源\n\nhttps://roadmap.sh/aspnet-core\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:05:49",lastUpdatedTimestamp:1693987549e3},{title:"WebApplication主机",frontmatter:{title:"WebApplication主机",date:"2023-09-06T15:29:54.000Z",permalink:"/pages/cb2fbc/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/03.WebApplication%E4%B8%BB%E6%9C%BA.html",relativePath:"04.知识地图/02.源码脑图/03.WebApplication主机.md",key:"v-03a6f1e0",path:"/pages/cb2fbc/",headersStr:null,content:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/03-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%20%EF%BC%88WebApplication%EF%BC%89.xmind\n\n",normalizedContent:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/03-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%20%ef%bc%88webapplication%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"Host主机",frontmatter:{title:"Host主机",date:"2023-09-06T15:29:54.000Z",permalink:"/pages/78c443/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/04.Host%E4%B8%BB%E6%9C%BA.html",relativePath:"04.知识地图/02.源码脑图/04.Host主机.md",key:"v-4e919d70",path:"/pages/78c443/",headersStr:null,content:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/04-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%20%EF%BC%88Host%EF%BC%89.xmind\n\n",normalizedContent:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/04-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%20%ef%bc%88host%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"WebHost主机",frontmatter:{title:"WebHost主机",date:"2023-09-06T15:29:54.000Z",permalink:"/pages/840f86/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/05.WebHost%E4%B8%BB%E6%9C%BA.html",relativePath:"04.知识地图/02.源码脑图/05.WebHost主机.md",key:"v-4f7e5a56",path:"/pages/840f86/",headersStr:null,content:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/05-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%20%EF%BC%88WebHost%EF%BC%89.xmind\n\n",normalizedContent:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/05-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%20%ef%bc%88webhost%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"依赖注入",frontmatter:{title:"依赖注入",date:"2023-09-06T15:29:53.000Z",permalink:"/pages/0d115d/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/06.%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5.html",relativePath:"04.知识地图/02.源码脑图/06.依赖注入.md",key:"v-f7980a44",path:"/pages/0d115d/",headersStr:null,content:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/06-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%EF%BC%89.xmind\n\n",normalizedContent:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/06-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88%e4%be%9d%e8%b5%96%e6%b3%a8%e5%85%a5%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"Autofac",frontmatter:{title:"Autofac",date:"2023-09-06T15:33:02.000Z",permalink:"/pages/e2d1de/",article:!1},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/07.Autofac.html",relativePath:"04.知识地图/02.源码脑图/07.Autofac.md",key:"v-039b7178",path:"/pages/e2d1de/",headersStr:null,content:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/07-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88Autofac%EF%BC%89.xmind\n\n",normalizedContent:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/07-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88autofac%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/06, 16:25:53",lastUpdatedTimestamp:1693988753e3},{title:"Middleware中间件",frontmatter:{title:"Middleware中间件",date:"2023-09-06T15:33:02.000Z",article:!1,permalink:"/pages/899977/"},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/08.Middleware%E4%B8%AD%E9%97%B4%E4%BB%B6.html",relativePath:"04.知识地图/02.源码脑图/08.Middleware中间件.md",key:"v-5459eecd",path:"/pages/899977/",headersStr:null,content:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/08-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88Middleware%EF%BC%89.xmind\n\n",normalizedContent:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/08-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88middleware%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"RateLimiter限制速率",frontmatter:{title:"RateLimiter限制速率",date:"2023-09-06T15:33:02.000Z",article:!1,permalink:"/pages/5991be/"},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/09.RateLimiter%E9%99%90%E5%88%B6%E9%80%9F%E7%8E%87.html",relativePath:"04.知识地图/02.源码脑图/09.RateLimiter限制速率.md",key:"v-27c64bc0",path:"/pages/5991be/",headersStr:null,content:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/09-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88%E9%99%90%E5%88%B6%E9%80%9F%E7%8E%87%E4%B8%AD%E9%97%B4%E4%BB%B6%EF%BC%89.xmind\n\n",normalizedContent:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/09-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88%e9%99%90%e5%88%b6%e9%80%9f%e7%8e%87%e4%b8%ad%e9%97%b4%e4%bb%b6%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"响应缓存、请求解压缩",frontmatter:{title:"响应缓存、请求解压缩",date:"2023-09-06T15:33:02.000Z",article:!1,permalink:"/pages/bacc57/"},regularPath:"/04.%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/02.%E6%BA%90%E7%A0%81%E8%84%91%E5%9B%BE/10.%E5%93%8D%E5%BA%94%E7%BC%93%E5%AD%98%E8%AF%B7%E6%B1%82%E8%A7%A3%E5%8E%8B%E7%BC%A9.html",relativePath:"04.知识地图/02.源码脑图/10.响应缓存请求解压缩.md",key:"v-cd219960",path:"/pages/bacc57/",headersStr:null,content:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/10-.NET8%20%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%EF%BC%88%E5%93%8D%E5%BA%94%E7%BC%93%E5%AD%98%26%E8%AF%B7%E6%B1%82%E8%A7%A3%E5%8E%8B%E7%BC%A9%EF%BC%89.xmind\n\n",normalizedContent:"开源地址\n\nhttps://github.com/786744873/easy-dotnet/blob/main/files/xmind/10-.net8%20%e6%a0%b8%e5%bf%83%e6%ba%90%e7%a0%81%ef%bc%88%e5%93%8d%e5%ba%94%e7%bc%93%e5%ad%98%26%e8%af%b7%e6%b1%82%e8%a7%a3%e5%8e%8b%e7%bc%a9%ef%bc%89.xmind\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"开源简介",frontmatter:{title:"开源简介",article:!1,date:"2023-04-15T17:04:41.000Z",permalink:"/pages/e50dff/"},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/01.%E5%BC%80%E6%BA%90%E7%AE%80%E4%BB%8B.html",relativePath:"05.工具&部署/01.Docker/01.开源简介.md",key:"v-0b12933a",path:"/pages/e50dff/",headers:[{level:2,title:"脚本列表",slug:"脚本列表",normalizedTitle:"脚本列表",charIndex:2}],headersStr:"脚本列表",content:"# 脚本列表\n\n * [x] Adminer：MySQL 管理客户端\n * [x] Apache：APISIX 云原生 API 网关\n * [x] Apollo：配置中心\n * [ ] Atlassian：项目管理\n * [x] Cassandra：开源分布式NoSQL数据库\n * [x] Cerebro：ElasticSearch可视化工具\n * [x] Clickhouse：OLAP开源列式数据库\n * [x] Consul：服务注册与发现中心\n * [x] Easymock：模拟测试辅助工具\n * [x] Elasticseasrch：分布式搜索和分析引擎\n * [x] Emqx：云原生 MQTT 消息服务器\n * [x] FastDFS：轻量级分布式文件系统\n * [x] Flink：分布式流数据流引擎\n * [x] Gitlab：项目管理和代码托管\n * [x] Jenkins：持续集成工具\n * [x] Jrebel：IDEA热部署插件\n * [x] MariaDB：关系型数据库系统(RDBS)\n * [x] MySQL：关系型数据库系统(RDBS)\n * [x] Percona：关系型数据库系统(RDBS)\n * [x] PhpMyAdmin：Web端MySQL 数据库的管理软件\n * [x] PostgreSQL：关系型数据库管理系统（ORDBMS）\n * [x] Redis：高性能的key-value数据库",normalizedContent:"# 脚本列表\n\n * [x] adminer：mysql 管理客户端\n * [x] apache：apisix 云原生 api 网关\n * [x] apollo：配置中心\n * [ ] atlassian：项目管理\n * [x] cassandra：开源分布式nosql数据库\n * [x] cerebro：elasticsearch可视化工具\n * [x] clickhouse：olap开源列式数据库\n * [x] consul：服务注册与发现中心\n * [x] easymock：模拟测试辅助工具\n * [x] elasticseasrch：分布式搜索和分析引擎\n * [x] emqx：云原生 mqtt 消息服务器\n * [x] fastdfs：轻量级分布式文件系统\n * [x] flink：分布式流数据流引擎\n * [x] gitlab：项目管理和代码托管\n * [x] jenkins：持续集成工具\n * [x] jrebel：idea热部署插件\n * [x] mariadb：关系型数据库系统(rdbs)\n * [x] mysql：关系型数据库系统(rdbs)\n * [x] percona：关系型数据库系统(rdbs)\n * [x] phpmyadmin：web端mysql 数据库的管理软件\n * [x] postgresql：关系型数据库管理系统（ordbms）\n * [x] redis：高性能的key-value数据库",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"吴恩达机器学习视频",frontmatter:{title:"吴恩达机器学习视频",date:"2024-08-11T15:47:44.000Z",permalink:"/pages/f1d3fb/"},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/02.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BEcoursera.html",relativePath:"05.工具&部署/01.Docker/02.监督学习-吴恩达coursera.md",key:"v-7b9db9b6",path:"/pages/f1d3fb/",headers:[{level:3,title:"引言(Introduction)",slug:"引言-introduction",normalizedTitle:"引言(introduction)",charIndex:10},{level:4,title:"1.1 欢迎",slug:"_1-1-欢迎",normalizedTitle:"1.1 欢迎",charIndex:63},{level:5,title:"1.2 机器学习是什么？",slug:"_1-2-机器学习是什么",normalizedTitle:"1.2 机器学习是什么？",charIndex:73},{level:5,title:"1.3 监督学习",slug:"_1-3-监督学习",normalizedTitle:"1.3 监督学习",charIndex:772},{level:2,title:"Jupyter 示例",slug:"jupyter-示例",normalizedTitle:"jupyter 示例",charIndex:1605},{level:4,title:"数据集 usahousingprice.csv",slug:"数据集-usa-housing-price-csv",normalizedTitle:"数据集 usahousingprice.csv",charIndex:null},{level:5,title:"1.4 无监督学习",slug:"_1-4-无监督学习",normalizedTitle:"1.4 无监督学习",charIndex:1650},{level:4,title:"二、单变量线性回归(Linear Regression with One Variable)",slug:"二、单变量线性回归-linear-regression-with-one-variable",normalizedTitle:"二、单变量线性回归(linear regression with one variable)",charIndex:2336},{level:5,title:"2.1 模型表示",slug:"_2-1-模型表示",normalizedTitle:"2.1 模型表示",charIndex:2386},{level:5,title:"2.2 代价函数",slug:"_2-2-代价函数",normalizedTitle:"2.2 代价函数",charIndex:2398},{level:5,title:"2.3 代价函数的直观理解I",slug:"_2-3-代价函数的直观理解i",normalizedTitle:"2.3 代价函数的直观理解i",charIndex:2412},{level:5,title:"2.4 代价函数的直观理解II",slug:"_2-4-代价函数的直观理解ii",normalizedTitle:"2.4 代价函数的直观理解ii",charIndex:2430},{level:5,title:"2.5 梯度下降",slug:"_2-5-梯度下降",normalizedTitle:"2.5 梯度下降",charIndex:2449},{level:5,title:"2.6 梯度下降的直观理解",slug:"_2-6-梯度下降的直观理解",normalizedTitle:"2.6 梯度下降的直观理解",charIndex:2461},{level:5,title:"2.7 梯度下降的线性回归",slug:"_2-7-梯度下降的线性回归",normalizedTitle:"2.7 梯度下降的线性回归",charIndex:2478},{level:5,title:"2.8 接下来的内容",slug:"_2-8-接下来的内容",normalizedTitle:"2.8 接下来的内容",charIndex:2495},{level:5,title:"三、线性代数回顾(Linear Algebra Review)",slug:"三、线性代数回顾-linear-algebra-review",normalizedTitle:"三、线性代数回顾(linear algebra review)",charIndex:2509},{level:5,title:"3.1 矩阵和向量",slug:"_3-1-矩阵和向量",normalizedTitle:"3.1 矩阵和向量",charIndex:2544},{level:5,title:"3.2 加法和标量乘法",slug:"_3-2-加法和标量乘法",normalizedTitle:"3.2 加法和标量乘法",charIndex:2557},{level:5,title:"3.3 矩阵向量乘法",slug:"_3-3-矩阵向量乘法",normalizedTitle:"3.3 矩阵向量乘法",charIndex:2572},{level:5,title:"3.4 矩阵乘法",slug:"_3-4-矩阵乘法",normalizedTitle:"3.4 矩阵乘法",charIndex:2586},{level:5,title:"3.5 矩阵乘法的性质",slug:"_3-5-矩阵乘法的性质",normalizedTitle:"3.5 矩阵乘法的性质",charIndex:2598},{level:5,title:"3.6 逆、转置",slug:"_3-6-逆、转置",normalizedTitle:"3.6 逆、转置",charIndex:2613}],headersStr:"引言(Introduction) 1.1 欢迎 1.2 机器学习是什么？ 1.3 监督学习 Jupyter 示例 数据集 usahousingprice.csv 1.4 无监督学习 二、单变量线性回归(Linear Regression with One Variable) 2.1 模型表示 2.2 代价函数 2.3 代价函数的直观理解I 2.4 代价函数的直观理解II 2.5 梯度下降 2.6 梯度下降的直观理解 2.7 梯度下降的线性回归 2.8 接下来的内容 三、线性代数回顾(Linear Algebra Review) 3.1 矩阵和向量 3.2 加法和标量乘法 3.3 矩阵向量乘法 3.4 矩阵乘法 3.5 矩阵乘法的性质 3.6 逆、转置",content:"# 第一周\n\n\n# 引言(Introduction)\n\n> 第一个视频主要讲了什么是机器学习，机器学习能做些什么事情。\n\n# 1.1 欢迎\n\n# 1.2 机器学习是什么？\n\n * 第一个机器学习的定义来自于Arthur Samuel。他定义机器学习为，在进行特定编程的情况下，给予计算机学习能力的领域。Samuel的定义可以回溯到50年代，他编写了一个西洋棋程序。这程序神奇之处在于，编程者自己并不是个下棋高手。但因为他太菜了，于是就通过编程，让西洋棋程序自己跟自己下了上万盘棋。通过观察哪种布局（棋盘位置）会赢，哪种布局会输，久而久之，这西洋棋程序明白了什么是好的布局，什么样是坏的布局。\n * 另一个年代近一点的定义，由Tom Mitchell提出，来自卡内基梅隆大学，Tom定义的机器学习是，一个好的学习问题定义如下，他说，一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P，当且仅当，有了经验E后，经过P评判，程序在处理T时的性能有所提升。我认为经验E 就是程序上万次的自我练习的经验而任务T 就是下棋。性能度量值P呢，就是它在与一些新的对手比赛时，赢得比赛的概率。\n\n> 本课中，我希望教你有关各种不同类型的学习算法。目前存在几种不同类型的学习算法。主要的两种类型被我们称之为监督学习和无监督学习。监督学习这个想法是指，我们将教计算机如何去完成任务，而在无监督学习中，我们打算让它自己进行学习。我会具体介绍这两种学习算法。此外你将听到诸如，强化学习和推荐系统等各种术语。这些都是机器学习算法的一员，以后我们都将介绍到，但学习算法最常用两个类型就是监督学习、无监督学习。我会在接下来的两个视频中给出它们的定义。本课中，我们将花费最多的精力来讨论这两种学习算法。而另一个会花费大量时间的任务是了解应用学习算法的实用建议。\n\n# 1.3 监督学习\n\n常见的一些监督学习任务, 比如垃圾邮件分类, 语音识别成文本, 英语翻译成西班牙语, 根据用户信息预测用户是否会点击相关广告, 自动驾驶中根据图像、雷达等信息确定其他车辆位置, 根据图像进行工业生产线产品缺陷监测.\n\n\n\n监督学习简单理解: 输入一个x和正确答案的示例(y)来训练模型, 模型从这些输入的输入x、输出y中学习之后形成一个模型, 这样再输入一个新的x时, 这是模型以前从未见过的，然后尝试生成相应的输出y。\n\n\n\n我们用一个例子介绍什么是监督学习把正式的定义放在后面介绍。假如说你想预测房价。 前阵子，一个学生从波特兰俄勒冈州的研究所收集了一些房价的数据。你把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，假如你有一个朋友，他有一套750平方英尺房子，现在他希望把房子卖掉，他想知道这房子能卖多少钱。\n\n那么关于这个问题，机器学习算法将会怎么帮助你呢？\n\n我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，拟合一条直线，根据这条线我们可以推测出，这套房子可能卖$150000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200000。稍后我们将讨论如何选择学习算法，如何决定用直线还是二次方程来拟合。两个方案中有一个能让你朋友的房子出售得更合理。这些都是学习算法里面很好的例子。以上就是监督学习的例子。\n\n可以看出，监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成 用术语来讲，这叫做回归问题。我们试着推测出一个连续值的结果，即房子的价格。\n\n在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。\n\n\n# Jupyter 示例\n\n\n\n# 数据集 usa_housing_price.csv\n\n# 1.4 无监督学习\n\n相对于监督学习，训练集不会有人为标注的结果（无反馈），我们不会给出结果或无法得知训练集的结果是什么样，而是单纯由计算机通过无监督学习算法自行分析，从而“得出结果”。计算机可能会把特定的数据集归为几个不同的簇，故叫做聚类算法。\n\n无监督学习一般分为两种：\n\n 1. 聚类（Clustering）\n    * 新闻聚合\n    * DNA 个体聚类\n    * 天文数据分析\n    * 市场细分\n    * 社交网络分析\n 2. 非聚类（Non-clustering）\n    * 鸡尾酒问题\n\n在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子，即无监督学习中没有任何的标签或者是有相同的标签或者就是没标签。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法。事实证明，它能被用在很多地方。\n\n聚类应用的一个例子就是在谷歌新闻中。如果你以前从来没见过它，你可以到这个URL网址news.google.com去看看。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。\n\n事实证明，聚类算法和无监督学习算法同样还用在很多其它的问题上。\n\n# 二、单变量线性回归(Linear Regression with One Variable)\n\n# 2.1 模型表示\n\n# 2.2 代价函数\n\n\n\n# 2.3 代价函数的直观理解I\n\n# 2.4 代价函数的直观理解II\n\n# 2.5 梯度下降\n\n# 2.6 梯度下降的直观理解\n\n# 2.7 梯度下降的线性回归\n\n# 2.8 接下来的内容\n\n# 三、线性代数回顾(Linear Algebra Review)\n\n# 3.1 矩阵和向量\n\n# 3.2 加法和标量乘法\n\n# 3.3 矩阵向量乘法\n\n# 3.4 矩阵乘法\n\n# 3.5 矩阵乘法的性质\n\n# 3.6 逆、转置",normalizedContent:"# 第一周\n\n\n# 引言(introduction)\n\n> 第一个视频主要讲了什么是机器学习，机器学习能做些什么事情。\n\n# 1.1 欢迎\n\n# 1.2 机器学习是什么？\n\n * 第一个机器学习的定义来自于arthur samuel。他定义机器学习为，在进行特定编程的情况下，给予计算机学习能力的领域。samuel的定义可以回溯到50年代，他编写了一个西洋棋程序。这程序神奇之处在于，编程者自己并不是个下棋高手。但因为他太菜了，于是就通过编程，让西洋棋程序自己跟自己下了上万盘棋。通过观察哪种布局（棋盘位置）会赢，哪种布局会输，久而久之，这西洋棋程序明白了什么是好的布局，什么样是坏的布局。\n * 另一个年代近一点的定义，由tom mitchell提出，来自卡内基梅隆大学，tom定义的机器学习是，一个好的学习问题定义如下，他说，一个程序被认为能从经验e中学习，解决任务t，达到性能度量值p，当且仅当，有了经验e后，经过p评判，程序在处理t时的性能有所提升。我认为经验e 就是程序上万次的自我练习的经验而任务t 就是下棋。性能度量值p呢，就是它在与一些新的对手比赛时，赢得比赛的概率。\n\n> 本课中，我希望教你有关各种不同类型的学习算法。目前存在几种不同类型的学习算法。主要的两种类型被我们称之为监督学习和无监督学习。监督学习这个想法是指，我们将教计算机如何去完成任务，而在无监督学习中，我们打算让它自己进行学习。我会具体介绍这两种学习算法。此外你将听到诸如，强化学习和推荐系统等各种术语。这些都是机器学习算法的一员，以后我们都将介绍到，但学习算法最常用两个类型就是监督学习、无监督学习。我会在接下来的两个视频中给出它们的定义。本课中，我们将花费最多的精力来讨论这两种学习算法。而另一个会花费大量时间的任务是了解应用学习算法的实用建议。\n\n# 1.3 监督学习\n\n常见的一些监督学习任务, 比如垃圾邮件分类, 语音识别成文本, 英语翻译成西班牙语, 根据用户信息预测用户是否会点击相关广告, 自动驾驶中根据图像、雷达等信息确定其他车辆位置, 根据图像进行工业生产线产品缺陷监测.\n\n\n\n监督学习简单理解: 输入一个x和正确答案的示例(y)来训练模型, 模型从这些输入的输入x、输出y中学习之后形成一个模型, 这样再输入一个新的x时, 这是模型以前从未见过的，然后尝试生成相应的输出y。\n\n\n\n我们用一个例子介绍什么是监督学习把正式的定义放在后面介绍。假如说你想预测房价。 前阵子，一个学生从波特兰俄勒冈州的研究所收集了一些房价的数据。你把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，假如你有一个朋友，他有一套750平方英尺房子，现在他希望把房子卖掉，他想知道这房子能卖多少钱。\n\n那么关于这个问题，机器学习算法将会怎么帮助你呢？\n\n我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，拟合一条直线，根据这条线我们可以推测出，这套房子可能卖$150000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200000。稍后我们将讨论如何选择学习算法，如何决定用直线还是二次方程来拟合。两个方案中有一个能让你朋友的房子出售得更合理。这些都是学习算法里面很好的例子。以上就是监督学习的例子。\n\n可以看出，监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成 用术语来讲，这叫做回归问题。我们试着推测出一个连续值的结果，即房子的价格。\n\n在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。\n\n\n# jupyter 示例\n\n\n\n# 数据集 usa_housing_price.csv\n\n# 1.4 无监督学习\n\n相对于监督学习，训练集不会有人为标注的结果（无反馈），我们不会给出结果或无法得知训练集的结果是什么样，而是单纯由计算机通过无监督学习算法自行分析，从而“得出结果”。计算机可能会把特定的数据集归为几个不同的簇，故叫做聚类算法。\n\n无监督学习一般分为两种：\n\n 1. 聚类（clustering）\n    * 新闻聚合\n    * dna 个体聚类\n    * 天文数据分析\n    * 市场细分\n    * 社交网络分析\n 2. 非聚类（non-clustering）\n    * 鸡尾酒问题\n\n在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子，即无监督学习中没有任何的标签或者是有相同的标签或者就是没标签。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法。事实证明，它能被用在很多地方。\n\n聚类应用的一个例子就是在谷歌新闻中。如果你以前从来没见过它，你可以到这个url网址news.google.com去看看。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。\n\n事实证明，聚类算法和无监督学习算法同样还用在很多其它的问题上。\n\n# 二、单变量线性回归(linear regression with one variable)\n\n# 2.1 模型表示\n\n# 2.2 代价函数\n\n\n\n# 2.3 代价函数的直观理解i\n\n# 2.4 代价函数的直观理解ii\n\n# 2.5 梯度下降\n\n# 2.6 梯度下降的直观理解\n\n# 2.7 梯度下降的线性回归\n\n# 2.8 接下来的内容\n\n# 三、线性代数回顾(linear algebra review)\n\n# 3.1 矩阵和向量\n\n# 3.2 加法和标量乘法\n\n# 3.3 矩阵向量乘法\n\n# 3.4 矩阵乘法\n\n# 3.5 矩阵乘法的性质\n\n# 3.6 逆、转置",charsets:{cjk:!0}},{title:"Apisix",frontmatter:{title:"Apisix",date:"2023-09-05T13:32:15.000Z",permalink:"/pages/fbe42b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/03.Apisix.html",relativePath:"05.工具&部署/01.Docker/03.Apisix.md",key:"v-098edc32",path:"/pages/fbe42b/",headers:[{level:2,title:"Apache APISIX 云原生 API 网关",slug:"apache-apisix-云原生-api-网关",normalizedTitle:"apache apisix 云原生 api 网关",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:109},{level:3,title:"主要特性",slug:"主要特性",normalizedTitle:"主要特性",charIndex:312},{level:2,title:"主要概念",slug:"主要概念",normalizedTitle:"主要概念",charIndex:806},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1049},{level:2,title:"apisix_conf/config.yaml",slug:"apisix-conf-config-yaml",normalizedTitle:"apisix_conf/config.yaml",charIndex:1519},{level:2,title:"dashboard_conf/conf.yaml",slug:"dashboard-conf-conf-yaml",normalizedTitle:"dashboard_conf/conf.yaml",charIndex:1250},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:6483}],headersStr:"Apache APISIX 云原生 API 网关 简介 主要特性 主要概念 docker-compose.yml apisix_conf/config.yaml dashboard_conf/conf.yaml deploy.sh",content:'# Apache APISIX 云原生 API 网关\n\n开源网址\n\n官网：https://apisix.apache.org/\n\ngithub：https://github.com/apache/apisix\n\n\n# 简介\n\n> Apache APISIX 是 Apache 软件基金会下的云原生 API 网关，它兼具动态、实时、高性能等特点，提供了负载均衡、动态上游、灰度发布（金丝雀发布）、服务熔断、身份认证、可观测性等丰富的流量管理功能。我们可以使用 Apache APISIX 来处理传统的南北向流量，也可以处理服务间的东西向流量。同时，它也支持作为 K8s Ingress Controller 来使用。\n\n\n# 主要特性\n\n * 多平台支持：APISIX 提供了多平台解决方案，它不但支持裸机运行，也支持在 Kubernetes 中使用，还支持与 AWS Lambda、Azure Function、Lua 函数和 Apache OpenWhisk 等云服务集成。\n * 全动态能力：APISIX 支持热加载，这意味着你不需要重启服务就可以更新 APISIX 的配置。请访问为什么 Apache APISIX 选择 Nginx + Lua 这个技术栈？以了解实现原理。\n * 精细化路由：APISIX 支持使用 NGINX 内置变量做为路由的匹配条件，你可以自定义匹配函数来过滤请求，匹配路由。\n * 运维友好：APISIX 支持与以下工具和平台集成：HashiCorp Vault、Zipkin、Apache SkyWalking、Consul、Nacos、Eureka。通过 APISIX Dashboard，运维人员可以通过友好且直观的 UI 配置 APISIX。\n * 多语言插件支持：APISIX 支持多种开发语言进行插件开发，开发人员可以选择擅长语言的 SDK 开发自定义插件。\n\n\n# 主要概念\n\n下图为 Apache APISIX 的架构：\n\n\n\n下表是本文涉及到的 APISIX 的主要概念和组件：\n\n概念/组件       描述\nRoute       通过路由定义规则来匹配客户端请求，根据匹配结果加载并执行相应的插件，最后把请求转发给到指定的上游应用。\nUpstream    上游的作用是按照配置规则对服务节点进行负载均衡，它的地址信息可以直接配置到路由或服务上。\nAdmin API   用户可以通过 Admin API 控制 APISIX 实例。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\nservices: \n  apisix-dashboard:\n    image: apache/apisix-dashboard:2.13-alpine\n    container_name: apisix-dashboard\n    restart: always\n    volumes:\n    - /etc/apisix/dashboard_conf/conf.yaml:/usr/local/apisix-dashboard/conf/conf.yaml\n    ports:\n    - "9000:9000"\n\n  apisix:\n    image: apache/apisix:2.15.0-alpine\n    container_name: apisix\n    restart: always\n    volumes:\n      - apisix_log:/usr/local/apisix/logs\n      - /etc/apisix/apisix_conf/config.yaml:/usr/local/apisix/conf/config.yaml:ro\n    depends_on:\n      - etcd\n    ##network_mode: host\n    ports:\n      - "9080:9080/tcp"\n      - "9091:9091/tcp"\n      - "9443:9443/tcp"\n      - "9092:9092/tcp"\n\n  etcd:\n    image: bitnami/etcd:3.4.14\n    container_name: etcd\n    restart: always\n    volumes:\n      - etcd:/bitnami/etcd\n    environment:\n      ETCD_ENABLE_V2: "true"\n      ALLOW_NONE_AUTHENTICATION: "yes"\n      ETCD_ADVERTISE_CLIENT_URLS: "http://0.0.0.0:2379"\n      ETCD_LISTEN_CLIENT_URLS: "http://0.0.0.0:2379"\n    ports:\n      - "2379:2379/tcp"\n\nvolumes: \n  apisix_log: \n  etcd: \n\n\n\n# apisix_conf/config.yaml\n\napisix:\n  node_listen: 9080              # APISIX listening port\n  enable_ipv6: false\n\n  allow_admin:                  # http://nginx.org/en/docs/http/ngx_http_access_module.html#allow\n    - 0.0.0.0/0              # We need to restrict ip access rules for security. 0.0.0.0/0 is for test.\n\n  admin_key:\n    - name: "admin"\n      key: edd1c9f034335f136f87ad84b625c8f1\n      role: admin                 # admin: manage all configuration data\n                                  # viewer: only can view configuration data\n    - name: "viewer"\n      key: 4054f7cf07e344346cd3f287985e76a2\n      role: viewer\n  \n  enable_control: true\n  control:\n    ip: "0.0.0.0"\n    port: 9092\n\netcd:\n  host:                           # it\'s possible to define multiple etcd hosts addresses of the same etcd cluster.\n    - "http://etcd:2379"     # multiple etcd address\n  prefix: "/apisix"               # apisix configurations prefix\n  timeout: 30                     # 30 seconds\n\nplugin_attr:\n  prometheus:\n    export_addr:\n      ip: "0.0.0.0"\n      port: 9091\n\n\n\n# dashboard_conf/conf.yaml\n\nconf:\n  listen:\n    host: 0.0.0.0     # `manager api` listening ip or host name\n    port: 9000          # `manager api` listening port\n  allow_list:           # If we don\'t set any IP list, then any IP access is allowed by default.\n    - 0.0.0.0/0\n  etcd:\n    endpoints:          # supports defining multiple etcd host addresses for an etcd cluster\n      - "http://etcd:2379"\n                          # yamllint disable rule:comments-indentation\n                          # etcd basic auth info\n    # username: "root"    # ignore etcd username if not enable etcd auth\n    # password: "123456"  # ignore etcd password if not enable etcd auth\n    mtls:\n      key_file: ""          # Path of your self-signed client side key\n      cert_file: ""         # Path of your self-signed client side cert\n      ca_file: ""           # Path of your self-signed ca cert, the CA is used to sign callers\' certificates\n    # prefix: /apisix     # apisix config\'s prefix in etcd, /apisix by default\n  log:\n    error_log:\n      level: warn       # supports levels, lower to higher: debug, info, warn, error, panic, fatal\n      file_path:\n        logs/error.log  # supports relative path, absolute path, standard output\n                        # such as: logs/error.log, /tmp/logs/error.log, /dev/stdout, /dev/stderr\n    access_log:\n      file_path:\n        logs/access.log  # supports relative path, absolute path, standard output\n                         # such as: logs/access.log, /tmp/logs/access.log, /dev/stdout, /dev/stderr\n                         # log example: 2020-12-09T16:38:09.039+0800\tINFO\tfilter/logging.go:46\t/apisix/admin/routes/r1\t{"status": 401, "host": "127.0.0.1:9000", "query": "asdfsafd=adf&a=a", "requestId": "3d50ecb8-758c-46d1-af5b-cd9d1c820156", "latency": 0, "remoteIP": "127.0.0.1", "method": "PUT", "errs": []}\nauthentication:\n  secret:\n    secret              # secret for jwt token generation.\n                        # NOTE: Highly recommended to modify this value to protect `manager api`.\n                        # if it\'s default value, when `manager api` start, it will generate a random string to replace it.\n  expire_time: 3600     # jwt token expire time, in second\n  users:                # yamllint enable rule:comments-indentation\n    - username: admin   # username and password for login `manager api`\n      password: admin\n    - username: user\n      password: user\n\nplugins:                          # plugin list (sorted in alphabetical order)\n  - api-breaker\n  - authz-keycloak\n  - basic-auth\n  - batch-requests\n  - consumer-restriction\n  - cors\n  # - dubbo-proxy\n  - echo\n  # - error-log-logger\n  # - example-plugin\n  - fault-injection\n  - grpc-transcode\n  - hmac-auth\n  - http-logger\n  - ip-restriction\n  - jwt-auth\n  - kafka-logger\n  - key-auth\n  - limit-conn\n  - limit-count\n  - limit-req\n  # - log-rotate\n  # - node-status\n  - openid-connect\n  - prometheus\n  - proxy-cache\n  - proxy-mirror\n  - proxy-rewrite\n  - redirect\n  - referer-restriction\n  - request-id\n  - request-validation\n  - response-rewrite\n  - serverless-post-function\n  - serverless-pre-function\n  # - skywalking\n  - sls-logger\n  - syslog\n  - tcp-logger\n  - udp-logger\n  - uri-blocker\n  - wolf-rbac\n  - zipkin\n  - server-info\n  - traffic-split\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/apisix/dashboard_conf\nmkdir -p /etc/apisix/apisix_conf\n\\cp ./dashboard_conf/conf.yaml /etc/apisix/dashboard_conf/conf.yaml -f\n\\cp ./apisix_conf/config.yaml /etc/apisix//apisix_conf/config.yaml -f\ndocker-compose up -d\n',normalizedContent:'# apache apisix 云原生 api 网关\n\n开源网址\n\n官网：https://apisix.apache.org/\n\ngithub：https://github.com/apache/apisix\n\n\n# 简介\n\n> apache apisix 是 apache 软件基金会下的云原生 api 网关，它兼具动态、实时、高性能等特点，提供了负载均衡、动态上游、灰度发布（金丝雀发布）、服务熔断、身份认证、可观测性等丰富的流量管理功能。我们可以使用 apache apisix 来处理传统的南北向流量，也可以处理服务间的东西向流量。同时，它也支持作为 k8s ingress controller 来使用。\n\n\n# 主要特性\n\n * 多平台支持：apisix 提供了多平台解决方案，它不但支持裸机运行，也支持在 kubernetes 中使用，还支持与 aws lambda、azure function、lua 函数和 apache openwhisk 等云服务集成。\n * 全动态能力：apisix 支持热加载，这意味着你不需要重启服务就可以更新 apisix 的配置。请访问为什么 apache apisix 选择 nginx + lua 这个技术栈？以了解实现原理。\n * 精细化路由：apisix 支持使用 nginx 内置变量做为路由的匹配条件，你可以自定义匹配函数来过滤请求，匹配路由。\n * 运维友好：apisix 支持与以下工具和平台集成：hashicorp vault、zipkin、apache skywalking、consul、nacos、eureka。通过 apisix dashboard，运维人员可以通过友好且直观的 ui 配置 apisix。\n * 多语言插件支持：apisix 支持多种开发语言进行插件开发，开发人员可以选择擅长语言的 sdk 开发自定义插件。\n\n\n# 主要概念\n\n下图为 apache apisix 的架构：\n\n\n\n下表是本文涉及到的 apisix 的主要概念和组件：\n\n概念/组件       描述\nroute       通过路由定义规则来匹配客户端请求，根据匹配结果加载并执行相应的插件，最后把请求转发给到指定的上游应用。\nupstream    上游的作用是按照配置规则对服务节点进行负载均衡，它的地址信息可以直接配置到路由或服务上。\nadmin api   用户可以通过 admin api 控制 apisix 实例。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\nservices: \n  apisix-dashboard:\n    image: apache/apisix-dashboard:2.13-alpine\n    container_name: apisix-dashboard\n    restart: always\n    volumes:\n    - /etc/apisix/dashboard_conf/conf.yaml:/usr/local/apisix-dashboard/conf/conf.yaml\n    ports:\n    - "9000:9000"\n\n  apisix:\n    image: apache/apisix:2.15.0-alpine\n    container_name: apisix\n    restart: always\n    volumes:\n      - apisix_log:/usr/local/apisix/logs\n      - /etc/apisix/apisix_conf/config.yaml:/usr/local/apisix/conf/config.yaml:ro\n    depends_on:\n      - etcd\n    ##network_mode: host\n    ports:\n      - "9080:9080/tcp"\n      - "9091:9091/tcp"\n      - "9443:9443/tcp"\n      - "9092:9092/tcp"\n\n  etcd:\n    image: bitnami/etcd:3.4.14\n    container_name: etcd\n    restart: always\n    volumes:\n      - etcd:/bitnami/etcd\n    environment:\n      etcd_enable_v2: "true"\n      allow_none_authentication: "yes"\n      etcd_advertise_client_urls: "http://0.0.0.0:2379"\n      etcd_listen_client_urls: "http://0.0.0.0:2379"\n    ports:\n      - "2379:2379/tcp"\n\nvolumes: \n  apisix_log: \n  etcd: \n\n\n\n# apisix_conf/config.yaml\n\napisix:\n  node_listen: 9080              # apisix listening port\n  enable_ipv6: false\n\n  allow_admin:                  # http://nginx.org/en/docs/http/ngx_http_access_module.html#allow\n    - 0.0.0.0/0              # we need to restrict ip access rules for security. 0.0.0.0/0 is for test.\n\n  admin_key:\n    - name: "admin"\n      key: edd1c9f034335f136f87ad84b625c8f1\n      role: admin                 # admin: manage all configuration data\n                                  # viewer: only can view configuration data\n    - name: "viewer"\n      key: 4054f7cf07e344346cd3f287985e76a2\n      role: viewer\n  \n  enable_control: true\n  control:\n    ip: "0.0.0.0"\n    port: 9092\n\netcd:\n  host:                           # it\'s possible to define multiple etcd hosts addresses of the same etcd cluster.\n    - "http://etcd:2379"     # multiple etcd address\n  prefix: "/apisix"               # apisix configurations prefix\n  timeout: 30                     # 30 seconds\n\nplugin_attr:\n  prometheus:\n    export_addr:\n      ip: "0.0.0.0"\n      port: 9091\n\n\n\n# dashboard_conf/conf.yaml\n\nconf:\n  listen:\n    host: 0.0.0.0     # `manager api` listening ip or host name\n    port: 9000          # `manager api` listening port\n  allow_list:           # if we don\'t set any ip list, then any ip access is allowed by default.\n    - 0.0.0.0/0\n  etcd:\n    endpoints:          # supports defining multiple etcd host addresses for an etcd cluster\n      - "http://etcd:2379"\n                          # yamllint disable rule:comments-indentation\n                          # etcd basic auth info\n    # username: "root"    # ignore etcd username if not enable etcd auth\n    # password: "123456"  # ignore etcd password if not enable etcd auth\n    mtls:\n      key_file: ""          # path of your self-signed client side key\n      cert_file: ""         # path of your self-signed client side cert\n      ca_file: ""           # path of your self-signed ca cert, the ca is used to sign callers\' certificates\n    # prefix: /apisix     # apisix config\'s prefix in etcd, /apisix by default\n  log:\n    error_log:\n      level: warn       # supports levels, lower to higher: debug, info, warn, error, panic, fatal\n      file_path:\n        logs/error.log  # supports relative path, absolute path, standard output\n                        # such as: logs/error.log, /tmp/logs/error.log, /dev/stdout, /dev/stderr\n    access_log:\n      file_path:\n        logs/access.log  # supports relative path, absolute path, standard output\n                         # such as: logs/access.log, /tmp/logs/access.log, /dev/stdout, /dev/stderr\n                         # log example: 2020-12-09t16:38:09.039+0800\tinfo\tfilter/logging.go:46\t/apisix/admin/routes/r1\t{"status": 401, "host": "127.0.0.1:9000", "query": "asdfsafd=adf&a=a", "requestid": "3d50ecb8-758c-46d1-af5b-cd9d1c820156", "latency": 0, "remoteip": "127.0.0.1", "method": "put", "errs": []}\nauthentication:\n  secret:\n    secret              # secret for jwt token generation.\n                        # note: highly recommended to modify this value to protect `manager api`.\n                        # if it\'s default value, when `manager api` start, it will generate a random string to replace it.\n  expire_time: 3600     # jwt token expire time, in second\n  users:                # yamllint enable rule:comments-indentation\n    - username: admin   # username and password for login `manager api`\n      password: admin\n    - username: user\n      password: user\n\nplugins:                          # plugin list (sorted in alphabetical order)\n  - api-breaker\n  - authz-keycloak\n  - basic-auth\n  - batch-requests\n  - consumer-restriction\n  - cors\n  # - dubbo-proxy\n  - echo\n  # - error-log-logger\n  # - example-plugin\n  - fault-injection\n  - grpc-transcode\n  - hmac-auth\n  - http-logger\n  - ip-restriction\n  - jwt-auth\n  - kafka-logger\n  - key-auth\n  - limit-conn\n  - limit-count\n  - limit-req\n  # - log-rotate\n  # - node-status\n  - openid-connect\n  - prometheus\n  - proxy-cache\n  - proxy-mirror\n  - proxy-rewrite\n  - redirect\n  - referer-restriction\n  - request-id\n  - request-validation\n  - response-rewrite\n  - serverless-post-function\n  - serverless-pre-function\n  # - skywalking\n  - sls-logger\n  - syslog\n  - tcp-logger\n  - udp-logger\n  - uri-blocker\n  - wolf-rbac\n  - zipkin\n  - server-info\n  - traffic-split\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/apisix/dashboard_conf\nmkdir -p /etc/apisix/apisix_conf\n\\cp ./dashboard_conf/conf.yaml /etc/apisix/dashboard_conf/conf.yaml -f\n\\cp ./apisix_conf/config.yaml /etc/apisix//apisix_conf/config.yaml -f\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Apollo",frontmatter:{title:"Apollo",date:"2023-09-05T13:49:16.000Z",permalink:"/pages/272684/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/04.Apollo.html",relativePath:"05.工具&部署/01.Docker/04.Apollo.md",key:"v-3fa091ca",path:"/pages/272684/",headers:[{level:2,title:"Apollo 阿波罗 分布式配置管理中心",slug:"apollo-阿波罗-分布式配置管理中心",normalizedTitle:"apollo 阿波罗 分布式配置管理中心",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:116},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:396},{level:2,title:"Sql",slug:"sql",normalizedTitle:"sql",charIndex:2458},{level:3,title:"apolloconfigdb.sql",slug:"apolloconfigdb-sql",normalizedTitle:"apolloconfigdb.sql",charIndex:2466},{level:3,title:"apolloportaldb.sql",slug:"apolloportaldb-sql",normalizedTitle:"apolloportaldb.sql",charIndex:22464},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:38657},{level:2,title:"删除项目sql",slug:"删除项目sql",normalizedTitle:"删除项目sql",charIndex:38866}],headersStr:"Apollo 阿波罗 分布式配置管理中心 简介 docker-compose.yml Sql apolloconfigdb.sql apolloportaldb.sql deploy.sh 删除项目sql",content:"# Apollo 阿波罗 分布式配置管理中心\n\n开源网址\n\n官网：https://www.apolloconfig.com/#/\n\ngithub：https://github.com/apolloconfig/apollo\n\n\n# 简介\n\n\n\nApollo（阿波罗）是一款可靠的分布式配置管理中心，诞生于携程框架研发部，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。\n\n服务端基于Spring Boot和Spring Cloud开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。\n\nJava客户端不依赖任何框架，能够运行于所有Java运行时环境，同时对Spring/Spring Boot环境也有较好的支持。\n\n.Net客户端不依赖任何框架，能够运行于所有.Net运行时环境。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\n# http://ip:8070 apollo admin\n\nservices:\n  apollo-all-in-one:\n    container_name: apollo-all-in-one\n    image: idoop/docker-apollo:1.4.0\n    restart: always\n    #  如果portal出现504错误，则使用\"host\"模式\n    # network_mode: \"host\"\n    ports: \n      - 8070:8070\n      - 8080:8080\n      - 8081:8081\n      - 8082:8082\n      - 8083:8083\n      - 8090:8090\n      - 8091:8091\n      - 8092:8092\n      - 8093:8093\n    environment:\n      TZ: Asia/Shanghai\n\n      # 开启Potal,默认端口:8070\n      # 配置数据库ServerConfig表apollo.portal.envs字段值为要开启的环境，这里是：dev,fat,uat\n      PORTAL_DB: jdbc:mysql://apollo-db:3306/ApolloPortalDB?characterEncoding=utf8\n      PORTAL_DB_USER: root\n      PORTAL_DB_PWD: apollo_123456\n\n      # 开启Dev环境，默认端口Admin:8090,Config:8080\n      # 配置数据库ServerConfig表eureka.service.url字段值为http://localhost:8080/eureka/\n      DEV_DB: jdbc:mysql://apollo-db:3306/ApolloConfigDB?characterEncoding=utf8\n      DEV_DB_USER: root\n      DEV_DB_PWD: apollo_123456\n\n      # 开启Fat环境，默认端口Admin:8091,Config:8081\n      # 配置数据库ServerConfig表eureka.service.url字段值为http://localhost:8081/eureka/\n      # FAT_DB: jdbc:mysql://10.0.0.8:3306/ApolloConfigDBFat?characterEncoding=utf8\n      # FAT_DB_USER: root\n      # FAT_DB_PWD: password\n     \n      # 开启Uat环境，如果网络模式为host则可以自定义一下Uat环境的端口\n      # 下方配置config端口为1000,则配置数据库ServerConfig表eureka.service.url字段值为http://localhost:1000/eureka/\n      # UAT_DB: jdbc:mysql://10.0.0.8:3306/ApolloConfigDBUat?characterEncoding=utf8\n      # UAT_DB_USER: root\n      # UAT_DB_PWD: password\n      # UAT_ADMIN_PORT: 2000\n      # UAT_CONFIG_PORT: 1000\n      # 如果需要,还可以配置Pro环境\n    depends_on: ['apollo-db']\n\n  apollo-db:\n    image: mysql:5.7\n    container_name: apollo-db\n    restart: always\n    ports: \n      - 3306:3306\n    # network_mode: \"host\"\n    environment:\n      TZ: Asia/Shanghai\n      # MYSQL_ALLOW_EMPTY_PASSWORD: 'yes'\n      MYSQL_ROOT_PASSWORD: apollo_123456\n      MYSQL_ROOT_HOST: '%'\n    volumes:\n      - /etc/apollo/sql:/docker-entrypoint-initdb.d\n      - apollo_mysqldb:/var/lib/mysql\n\nvolumes:\n  apollo_mysqldb: \n\n\n\n\n# Sql\n\n\n# apolloconfigdb.sql\n\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n/*!40101 SET NAMES utf8 */;\n/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;\n/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\n/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\n\n# Create Database\n# ------------------------------------------------------------\nCREATE DATABASE IF NOT EXISTS ApolloConfigDB DEFAULT CHARACTER SET = utf8mb4;\n\nUse ApolloConfigDB;\n\n# Dump of table app\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `App`;\n\nCREATE TABLE `App` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `Name` varchar(500) NOT NULL DEFAULT 'default' COMMENT '应用名',\n  `OrgId` varchar(32) NOT NULL DEFAULT 'default' COMMENT '部门Id',\n  `OrgName` varchar(64) NOT NULL DEFAULT 'default' COMMENT '部门名字',\n  `OwnerName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerName',\n  `OwnerEmail` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerEmail',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Name` (`Name`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用表';\n\n\n\n# Dump of table appnamespace\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `AppNamespace`;\n\nCREATE TABLE `AppNamespace` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',\n  `Name` varchar(32) NOT NULL DEFAULT '' COMMENT 'namespace名字，注意，需要全局唯一',\n  `AppId` varchar(32) NOT NULL DEFAULT '' COMMENT 'app id',\n  `Format` varchar(32) NOT NULL DEFAULT 'properties' COMMENT 'namespace的format类型',\n  `IsPublic` bit(1) NOT NULL DEFAULT b'0' COMMENT 'namespace是否为公共',\n  `Comment` varchar(64) NOT NULL DEFAULT '' COMMENT '注释',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_AppId` (`AppId`),\n  KEY `Name_AppId` (`Name`,`AppId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用namespace定义';\n\n\n\n# Dump of table audit\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Audit`;\n\nCREATE TABLE `Audit` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `EntityName` varchar(50) NOT NULL DEFAULT 'default' COMMENT '表名',\n  `EntityId` int(10) unsigned DEFAULT NULL COMMENT '记录ID',\n  `OpName` varchar(50) NOT NULL DEFAULT 'default' COMMENT '操作类型',\n  `Comment` varchar(500) DEFAULT NULL COMMENT '备注',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='日志审计表';\n\n\n\n# Dump of table cluster\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Cluster`;\n\nCREATE TABLE `Cluster` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',\n  `Name` varchar(32) NOT NULL DEFAULT '' COMMENT '集群名字',\n  `AppId` varchar(32) NOT NULL DEFAULT '' COMMENT 'App id',\n  `ParentClusterId` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '父cluster',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_AppId_Name` (`AppId`,`Name`),\n  KEY `IX_ParentClusterId` (`ParentClusterId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='集群';\n\n\n\n# Dump of table commit\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Commit`;\n\nCREATE TABLE `Commit` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `ChangeSets` longtext NOT NULL COMMENT '修改变更集',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',\n  `NamespaceName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'namespaceName',\n  `Comment` varchar(500) DEFAULT NULL COMMENT '备注',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `ClusterName` (`ClusterName`(191)),\n  KEY `NamespaceName` (`NamespaceName`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='commit 历史表';\n\n# Dump of table grayreleaserule\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `GrayReleaseRule`;\n\nCREATE TABLE `GrayReleaseRule` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `AppId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Cluster Name',\n  `NamespaceName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Namespace Name',\n  `BranchName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'branch name',\n  `Rules` varchar(16000) DEFAULT '[]' COMMENT '灰度规则',\n  `ReleaseId` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '灰度对应的release',\n  `BranchStatus` tinyint(2) DEFAULT '1' COMMENT '灰度分支状态: 0:删除分支,1:正在使用的规则 2：全量发布',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Namespace` (`AppId`,`ClusterName`,`NamespaceName`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='灰度规则表';\n\n\n# Dump of table instance\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Instance`;\n\nCREATE TABLE `Instance` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `AppId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',\n  `DataCenter` varchar(64) NOT NULL DEFAULT 'default' COMMENT 'Data Center Name',\n  `Ip` varchar(32) NOT NULL DEFAULT '' COMMENT 'instance ip',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  UNIQUE KEY `IX_UNIQUE_KEY` (`AppId`,`ClusterName`,`Ip`,`DataCenter`),\n  KEY `IX_IP` (`Ip`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='使用配置的应用实例';\n\n\n\n# Dump of table instanceconfig\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `InstanceConfig`;\n\nCREATE TABLE `InstanceConfig` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `InstanceId` int(11) unsigned DEFAULT NULL COMMENT 'Instance Id',\n  `ConfigAppId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Config App Id',\n  `ConfigClusterName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Config Cluster Name',\n  `ConfigNamespaceName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'Config Namespace Name',\n  `ReleaseKey` varchar(64) NOT NULL DEFAULT '' COMMENT '发布的Key',\n  `ReleaseDeliveryTime` timestamp NULL DEFAULT NULL COMMENT '配置获取时间',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  UNIQUE KEY `IX_UNIQUE_KEY` (`InstanceId`,`ConfigAppId`,`ConfigNamespaceName`),\n  KEY `IX_ReleaseKey` (`ReleaseKey`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Valid_Namespace` (`ConfigAppId`,`ConfigClusterName`,`ConfigNamespaceName`,`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用实例的配置信息';\n\n\n\n# Dump of table item\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Item`;\n\nCREATE TABLE `Item` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `NamespaceId` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '集群NamespaceId',\n  `Key` varchar(128) NOT NULL DEFAULT 'default' COMMENT '配置项Key',\n  `Value` longtext NOT NULL COMMENT '配置项值',\n  `Comment` varchar(1024) DEFAULT '' COMMENT '注释',\n  `LineNum` int(10) unsigned DEFAULT '0' COMMENT '行号',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_GroupId` (`NamespaceId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='配置项目';\n\n\n\n# Dump of table namespace\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Namespace`;\n\nCREATE TABLE `Namespace` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'Cluster Name',\n  `NamespaceName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'Namespace Name',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `AppId_ClusterName_NamespaceName` (`AppId`(191),`ClusterName`(191),`NamespaceName`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_NamespaceName` (`NamespaceName`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='命名空间';\n\n\n\n# Dump of table namespacelock\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `NamespaceLock`;\n\nCREATE TABLE `NamespaceLock` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增id',\n  `NamespaceId` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '集群NamespaceId',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT 'default' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  `IsDeleted` bit(1) DEFAULT b'0' COMMENT '软删除',\n  PRIMARY KEY (`Id`),\n  UNIQUE KEY `IX_NamespaceId` (`NamespaceId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='namespace的编辑锁';\n\n\n\n# Dump of table release\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Release`;\n\nCREATE TABLE `Release` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',\n  `ReleaseKey` varchar(64) NOT NULL DEFAULT '' COMMENT '发布的Key',\n  `Name` varchar(64) NOT NULL DEFAULT 'default' COMMENT '发布名字',\n  `Comment` varchar(256) DEFAULT NULL COMMENT '发布说明',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',\n  `NamespaceName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'namespaceName',\n  `Configurations` longtext NOT NULL COMMENT '发布配置',\n  `IsAbandoned` bit(1) NOT NULL DEFAULT b'0' COMMENT '是否废弃',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `AppId_ClusterName_GroupName` (`AppId`(191),`ClusterName`(191),`NamespaceName`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_ReleaseKey` (`ReleaseKey`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='发布';\n\n\n# Dump of table releasehistory\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ReleaseHistory`;\n\nCREATE TABLE `ReleaseHistory` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `AppId` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `ClusterName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',\n  `NamespaceName` varchar(32) NOT NULL DEFAULT 'default' COMMENT 'namespaceName',\n  `BranchName` varchar(32) NOT NULL DEFAULT 'default' COMMENT '发布分支名',\n  `ReleaseId` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '关联的Release Id',\n  `PreviousReleaseId` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '前一次发布的ReleaseId',\n  `Operation` tinyint(3) unsigned NOT NULL DEFAULT '0' COMMENT '发布类型，0: 普通发布，1: 回滚，2: 灰度发布，3: 灰度规则更新，4: 灰度合并回主分支发布，5: 主分支发布灰度自动发布，6: 主分支回滚灰度自动发布，7: 放弃灰度',\n  `OperationContext` longtext NOT NULL COMMENT '发布上下文信息',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_Namespace` (`AppId`,`ClusterName`,`NamespaceName`,`BranchName`),\n  KEY `IX_ReleaseId` (`ReleaseId`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='发布历史';\n\n\n# Dump of table releasemessage\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ReleaseMessage`;\n\nCREATE TABLE `ReleaseMessage` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',\n  `Message` varchar(1024) NOT NULL DEFAULT '' COMMENT '发布的消息内容',\n  `DataChange_LastTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Message` (`Message`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='发布消息';\n\n\n\n# Dump of table serverconfig\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ServerConfig`;\n\nCREATE TABLE `ServerConfig` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `Key` varchar(64) NOT NULL DEFAULT 'default' COMMENT '配置项Key',\n  `Cluster` varchar(32) NOT NULL DEFAULT 'default' COMMENT '配置对应的集群，default为不针对特定的集群',\n  `Value` varchar(2048) NOT NULL DEFAULT 'default' COMMENT '配置项值',\n  `Comment` varchar(1024) DEFAULT '' COMMENT '注释',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_Key` (`Key`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='配置服务自身配置';\n\n# Config\n# ------------------------------------------------------------\nINSERT INTO `ServerConfig` (`Key`, `Cluster`, `Value`, `Comment`)\nVALUES\n    ('eureka.service.url', 'default', 'http://localhost:8080/eureka/', 'Eureka服务Url，多个service以英文逗号分隔'),\n    ('namespace.lock.switch', 'default', 'false', '一次发布只能有一个人修改开关'),\n    ('item.value.length.limit', 'default', '20000', 'item value最大长度限制'),\n    ('config-service.cache.enabled', 'default', 'false', 'ConfigService是否开启缓存，开启后能提高性能，但是会增大内存消耗！'),\n    ('item.key.length.limit', 'default', '128', 'item key 最大长度限制');\n\n# Sample Data\n# ------------------------------------------------------------\nINSERT INTO `App` (`AppId`, `Name`, `OrgId`, `OrgName`, `OwnerName`, `OwnerEmail`)\nVALUES\n\t('SampleApp', 'Sample App', 'TEST1', '样例部门1', 'apollo', 'apollo@acme.com');\n\nINSERT INTO `AppNamespace` (`Name`, `AppId`, `Format`, `IsPublic`, `Comment`)\nVALUES\n\t('application', 'SampleApp', 'properties', 0, 'default app namespace');\n\nINSERT INTO `Cluster` (`Name`, `AppId`)\nVALUES\n\t('default', 'SampleApp');\n\nINSERT INTO `Namespace` (`Id`, `AppId`, `ClusterName`, `NamespaceName`)\nVALUES\n\t(1, 'SampleApp', 'default', 'application');\n\n\nINSERT INTO `Item` (`NamespaceId`, `Key`, `Value`, `Comment`, `LineNum`)\nVALUES\n\t(1, 'timeout', '100', 'sample timeout配置', 1);\n\nINSERT INTO `Release` (`ReleaseKey`, `Name`, `Comment`, `AppId`, `ClusterName`, `NamespaceName`, `Configurations`)\nVALUES\n\t('20161009155425-d3a0749c6e20bc15', '20161009155424-release', 'Sample发布', 'SampleApp', 'default', 'application', '{\\\"timeout\\\":\\\"100\\\"}');\n\nINSERT INTO `ReleaseHistory` (`AppId`, `ClusterName`, `NamespaceName`, `BranchName`, `ReleaseId`, `PreviousReleaseId`, `Operation`, `OperationContext`, `DataChange_CreatedBy`, `DataChange_LastModifiedBy`)\nVALUES\n  ('SampleApp', 'default', 'application', 'default', 1, 0, 0, '{}', 'apollo', 'apollo');\n\n\n/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;\n/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;\n/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;\n/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;\n/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;\n/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;\n\n\n\n# apolloportaldb.sql\n\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n/*!40101 SET NAMES utf8 */;\n/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;\n/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\n/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\n\n# Create Database\n# ------------------------------------------------------------\nCREATE DATABASE IF NOT EXISTS ApolloPortalDB DEFAULT CHARACTER SET = utf8mb4;\n\nUse ApolloPortalDB;\n\n# Dump of table app\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `App`;\n\nCREATE TABLE `App` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `Name` varchar(500) NOT NULL DEFAULT 'default' COMMENT '应用名',\n  `OrgId` varchar(32) NOT NULL DEFAULT 'default' COMMENT '部门Id',\n  `OrgName` varchar(64) NOT NULL DEFAULT 'default' COMMENT '部门名字',\n  `OwnerName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerName',\n  `OwnerEmail` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerEmail',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_Name` (`Name`(191))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用表';\n\n\n\n# Dump of table appnamespace\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `AppNamespace`;\n\nCREATE TABLE `AppNamespace` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',\n  `Name` varchar(32) NOT NULL DEFAULT '' COMMENT 'namespace名字，注意，需要全局唯一',\n  `AppId` varchar(32) NOT NULL DEFAULT '' COMMENT 'app id',\n  `Format` varchar(32) NOT NULL DEFAULT 'properties' COMMENT 'namespace的format类型',\n  `IsPublic` bit(1) NOT NULL DEFAULT b'0' COMMENT 'namespace是否为公共',\n  `Comment` varchar(64) NOT NULL DEFAULT '' COMMENT '注释',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_AppId` (`AppId`),\n  KEY `Name_AppId` (`Name`,`AppId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用namespace定义';\n\n\n\n# Dump of table consumer\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Consumer`;\n\nCREATE TABLE `Consumer` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `Name` varchar(500) NOT NULL DEFAULT 'default' COMMENT '应用名',\n  `OrgId` varchar(32) NOT NULL DEFAULT 'default' COMMENT '部门Id',\n  `OrgName` varchar(64) NOT NULL DEFAULT 'default' COMMENT '部门名字',\n  `OwnerName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerName',\n  `OwnerEmail` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerEmail',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='开放API消费者';\n\n\n\n# Dump of table consumeraudit\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ConsumerAudit`;\n\nCREATE TABLE `ConsumerAudit` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `ConsumerId` int(11) unsigned DEFAULT NULL COMMENT 'Consumer Id',\n  `Uri` varchar(1024) NOT NULL DEFAULT '' COMMENT '访问的Uri',\n  `Method` varchar(16) NOT NULL DEFAULT '' COMMENT '访问的Method',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_ConsumerId` (`ConsumerId`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='consumer审计表';\n\n\n\n# Dump of table consumerrole\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ConsumerRole`;\n\nCREATE TABLE `ConsumerRole` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `ConsumerId` int(11) unsigned DEFAULT NULL COMMENT 'Consumer Id',\n  `RoleId` int(10) unsigned DEFAULT NULL COMMENT 'Role Id',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) DEFAULT '' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_RoleId` (`RoleId`),\n  KEY `IX_ConsumerId_RoleId` (`ConsumerId`,`RoleId`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='consumer和role的绑定表';\n\n\n\n# Dump of table consumertoken\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ConsumerToken`;\n\nCREATE TABLE `ConsumerToken` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `ConsumerId` int(11) unsigned DEFAULT NULL COMMENT 'ConsumerId',\n  `Token` varchar(128) NOT NULL DEFAULT '' COMMENT 'token',\n  `Expires` datetime NOT NULL DEFAULT '2099-01-01 00:00:00' COMMENT 'token失效时间',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  UNIQUE KEY `IX_Token` (`Token`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='consumer token表';\n\n# Dump of table favorite\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Favorite`;\n\nCREATE TABLE `Favorite` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `UserId` varchar(32) NOT NULL DEFAULT 'default' COMMENT '收藏的用户',\n  `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',\n  `Position` int(32) NOT NULL DEFAULT '10000' COMMENT '收藏顺序',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `AppId` (`AppId`(191)),\n  KEY `IX_UserId` (`UserId`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB AUTO_INCREMENT=23 DEFAULT CHARSET=utf8mb4 COMMENT='应用收藏表';\n\n# Dump of table permission\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Permission`;\n\nCREATE TABLE `Permission` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `PermissionType` varchar(32) NOT NULL DEFAULT '' COMMENT '权限类型',\n  `TargetId` varchar(256) NOT NULL DEFAULT '' COMMENT '权限对象类型',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_TargetId_PermissionType` (`TargetId`(191),`PermissionType`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='permission表';\n\n\n\n# Dump of table role\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Role`;\n\nCREATE TABLE `Role` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `RoleName` varchar(256) NOT NULL DEFAULT '' COMMENT 'Role name',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_RoleName` (`RoleName`(191)),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='角色表';\n\n\n\n# Dump of table rolepermission\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `RolePermission`;\n\nCREATE TABLE `RolePermission` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `RoleId` int(10) unsigned DEFAULT NULL COMMENT 'Role Id',\n  `PermissionId` int(10) unsigned DEFAULT NULL COMMENT 'Permission Id',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) DEFAULT '' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_RoleId` (`RoleId`),\n  KEY `IX_PermissionId` (`PermissionId`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='角色和权限的绑定表';\n\n\n\n# Dump of table serverconfig\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `ServerConfig`;\n\nCREATE TABLE `ServerConfig` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `Key` varchar(64) NOT NULL DEFAULT 'default' COMMENT '配置项Key',\n  `Value` varchar(2048) NOT NULL DEFAULT 'default' COMMENT '配置项值',\n  `Comment` varchar(1024) DEFAULT '' COMMENT '注释',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_Key` (`Key`),\n  KEY `DataChange_LastTime` (`DataChange_LastTime`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='配置服务自身配置';\n\n\n\n# Dump of table userrole\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `UserRole`;\n\nCREATE TABLE `UserRole` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `UserId` varchar(128) DEFAULT '' COMMENT '用户身份标识',\n  `RoleId` int(10) unsigned DEFAULT NULL COMMENT 'Role Id',\n  `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',\n  `DataChange_CreatedBy` varchar(32) DEFAULT '' COMMENT '创建人邮箱前缀',\n  `DataChange_CreatedTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',\n  `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',\n  PRIMARY KEY (`Id`),\n  KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),\n  KEY `IX_RoleId` (`RoleId`),\n  KEY `IX_UserId_RoleId` (`UserId`,`RoleId`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='用户和role的绑定表';\n\n# Dump of table Users\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Users`;\n\nCREATE TABLE `Users` (\n  `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `Username` varchar(64) NOT NULL DEFAULT 'default' COMMENT '用户名',\n  `Password` varchar(64) NOT NULL DEFAULT 'default' COMMENT '密码',\n  `Email` varchar(64) NOT NULL DEFAULT 'default' COMMENT '邮箱地址',\n  `Enabled` tinyint(4) DEFAULT NULL COMMENT '是否有效',\n  PRIMARY KEY (`Id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='用户表';\n\n\n# Dump of table Authorities\n# ------------------------------------------------------------\n\nDROP TABLE IF EXISTS `Authorities`;\n\nCREATE TABLE `Authorities` (\n  `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',\n  `Username` varchar(64) NOT NULL,\n  `Authority` varchar(50) NOT NULL,\n  PRIMARY KEY (`Id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n\n\n# Config\n# ------------------------------------------------------------\nINSERT INTO `ServerConfig` (`Key`, `Value`, `Comment`)\nVALUES\n    ('apollo.portal.envs', 'dev', '可支持的环境列表'),\n    ('organizations', '[{\\\"orgId\\\":\\\"TEST1\\\",\\\"orgName\\\":\\\"样例部门1\\\"},{\\\"orgId\\\":\\\"TEST2\\\",\\\"orgName\\\":\\\"样例部门2\\\"}]', '部门列表'),\n    ('superAdmin', 'apollo', 'Portal超级管理员'),\n    ('api.readTimeout', '10000', 'http接口read timeout'),\n    ('consumer.token.salt', 'someSalt', 'consumer token salt'),\n    ('admin.createPrivateNamespace.switch', 'true', '是否允许项目管理员创建私有namespace'),\n    ('configView.memberOnly.envs', 'dev', '只对项目成员显示配置信息的环境列表，多个env以英文逗号分隔');\n\nINSERT INTO `Users` (`Username`, `Password`, `Email`, `Enabled`)\nVALUES\n\t('apollo', '$2a$10$7r20uS.BQ9uBpf3Baj3uQOZvMVvB1RN3PYoKE94gtz2.WAOuiiwXS', 'apollo@acme.com', 1);\n\nINSERT INTO `Authorities` (`Username`, `Authority`) VALUES ('apollo', 'ROLE_user');\n\n# Sample Data\n# ------------------------------------------------------------\nINSERT INTO `App` (`AppId`, `Name`, `OrgId`, `OrgName`, `OwnerName`, `OwnerEmail`)\nVALUES\n\t('SampleApp', 'Sample App', 'TEST1', '样例部门1', 'apollo', 'apollo@acme.com');\n\nINSERT INTO `AppNamespace` (`Name`, `AppId`, `Format`, `IsPublic`, `Comment`)\nVALUES\n\t('application', 'SampleApp', 'properties', 0, 'default app namespace');\n\nINSERT INTO `Permission` (`Id`, `PermissionType`, `TargetId`)\nVALUES\n\t(1, 'CreateCluster', 'SampleApp'),\n\t(2, 'CreateNamespace', 'SampleApp'),\n\t(3, 'AssignRole', 'SampleApp'),\n\t(4, 'ModifyNamespace', 'SampleApp+application'),\n\t(5, 'ReleaseNamespace', 'SampleApp+application');\n\nINSERT INTO `Role` (`Id`, `RoleName`)\nVALUES\n\t(1, 'Master+SampleApp'),\n\t(2, 'ModifyNamespace+SampleApp+application'),\n\t(3, 'ReleaseNamespace+SampleApp+application');\n\nINSERT INTO `RolePermission` (`RoleId`, `PermissionId`)\nVALUES\n\t(1, 1),\n\t(1, 2),\n\t(1, 3),\n\t(2, 4),\n\t(3, 5);\n\nINSERT INTO `UserRole` (`UserId`, `RoleId`)\nVALUES\n\t('apollo', 1),\n\t('apollo', 2),\n\t('apollo', 3);\n\n/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;\n/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;\n/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;\n/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;\n/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;\n/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/apollo/sql\n\\cp ./sql/apolloconfigdb.sql /etc/apollo/sql/apolloconfigdb.sql -f\n\\cp ./sql/apolloportaldb.sql /etc/apollo/sql/apolloportaldb.sql -f\ndocker-compose up -d\n\n\n\n# 删除项目sql\n\n# 删除ApolloConfigDB中的数据\n\nset @appId = 'tjs_public';\n \nUse `ApolloConfigDB`;\n \nupdate `App` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `AppNamespace` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Cluster` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Commit` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `GrayReleaseRule` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Release` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `ReleaseHistory` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\ndelete from `Instance` where `AppId` = @appId;\ndelete from `InstanceConfig` where `ConfigAppId` = @appId;\ndelete from `ReleaseMessage` where `Message` like CONCAT(@appId, '+%');\n \n# handle namespaces and items\ncreate temporary table `NamespaceIds` as select `Id` from `Namespace` where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Namespace` set `IsDeleted` = 1 where `Id` in (select `Id` from `NamespaceIds`);\nupdate `Item` set `IsDeleted` = 1 where `NamespaceId` in (select `Id` from `NamespaceIds`);\ndelete from `NamespaceLock` where `NamespaceId` in (select `Id` from `NamespaceIds`);\ndrop temporary table `NamespaceIds`;\n\n\n# 删除ApolloPortalDB中的数据\n\nset @appId = 'tjs_public';\n \nUse `ApolloPortalDB`;\n \nupdate `App` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `AppNamespace` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\nupdate `Favorite` set `IsDeleted` = 1 where `AppId` = @appId and `IsDeleted` = 0;\n \n# handle roles and permissions\ncreate temporary table `PermissionIds` as select `Id` from `Permission` where (`TargetId` = @appId or `TargetId` like CONCAT(@appId, '+%'))  and `IsDeleted` = 0;\nupdate `Permission` set `IsDeleted` = 1 where `Id` in (select `Id` from `PermissionIds`);\nupdate `RolePermission` set `IsDeleted` = 1 where `PermissionId` in (select `Id` from `PermissionIds`);\ndrop temporary table `PermissionIds`;\n \ncreate temporary table `RoleIds` as select `Id` from `Role` where (`RoleName` = CONCAT('Master+', @appId) or `RoleName` like CONCAT('ModifyNamespace+', @appId, '+%') or `RoleName` like CONCAT('ReleaseNamespace+', @appId, '+%')) and `IsDeleted` = 0;\nupdate `Role` set `IsDeleted` = 1 where `Id` in (select `Id` from `RoleIds`);\nupdate `UserRole` set `IsDeleted` = 1 where `RoleId` in (select `Id` from `RoleIds`);\nupdate `ConsumerRole` set `IsDeleted` = 1 where `RoleId` in (select `Id` from `RoleIds`);\ndrop temporary table `RoleIds`;\n",normalizedContent:"# apollo 阿波罗 分布式配置管理中心\n\n开源网址\n\n官网：https://www.apolloconfig.com/#/\n\ngithub：https://github.com/apolloconfig/apollo\n\n\n# 简介\n\n\n\napollo（阿波罗）是一款可靠的分布式配置管理中心，诞生于携程框架研发部，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。\n\n服务端基于spring boot和spring cloud开发，打包后可以直接运行，不需要额外安装tomcat等应用容器。\n\njava客户端不依赖任何框架，能够运行于所有java运行时环境，同时对spring/spring boot环境也有较好的支持。\n\n.net客户端不依赖任何框架，能够运行于所有.net运行时环境。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\n# http://ip:8070 apollo admin\n\nservices:\n  apollo-all-in-one:\n    container_name: apollo-all-in-one\n    image: idoop/docker-apollo:1.4.0\n    restart: always\n    #  如果portal出现504错误，则使用\"host\"模式\n    # network_mode: \"host\"\n    ports: \n      - 8070:8070\n      - 8080:8080\n      - 8081:8081\n      - 8082:8082\n      - 8083:8083\n      - 8090:8090\n      - 8091:8091\n      - 8092:8092\n      - 8093:8093\n    environment:\n      tz: asia/shanghai\n\n      # 开启potal,默认端口:8070\n      # 配置数据库serverconfig表apollo.portal.envs字段值为要开启的环境，这里是：dev,fat,uat\n      portal_db: jdbc:mysql://apollo-db:3306/apolloportaldb?characterencoding=utf8\n      portal_db_user: root\n      portal_db_pwd: apollo_123456\n\n      # 开启dev环境，默认端口admin:8090,config:8080\n      # 配置数据库serverconfig表eureka.service.url字段值为http://localhost:8080/eureka/\n      dev_db: jdbc:mysql://apollo-db:3306/apolloconfigdb?characterencoding=utf8\n      dev_db_user: root\n      dev_db_pwd: apollo_123456\n\n      # 开启fat环境，默认端口admin:8091,config:8081\n      # 配置数据库serverconfig表eureka.service.url字段值为http://localhost:8081/eureka/\n      # fat_db: jdbc:mysql://10.0.0.8:3306/apolloconfigdbfat?characterencoding=utf8\n      # fat_db_user: root\n      # fat_db_pwd: password\n     \n      # 开启uat环境，如果网络模式为host则可以自定义一下uat环境的端口\n      # 下方配置config端口为1000,则配置数据库serverconfig表eureka.service.url字段值为http://localhost:1000/eureka/\n      # uat_db: jdbc:mysql://10.0.0.8:3306/apolloconfigdbuat?characterencoding=utf8\n      # uat_db_user: root\n      # uat_db_pwd: password\n      # uat_admin_port: 2000\n      # uat_config_port: 1000\n      # 如果需要,还可以配置pro环境\n    depends_on: ['apollo-db']\n\n  apollo-db:\n    image: mysql:5.7\n    container_name: apollo-db\n    restart: always\n    ports: \n      - 3306:3306\n    # network_mode: \"host\"\n    environment:\n      tz: asia/shanghai\n      # mysql_allow_empty_password: 'yes'\n      mysql_root_password: apollo_123456\n      mysql_root_host: '%'\n    volumes:\n      - /etc/apollo/sql:/docker-entrypoint-initdb.d\n      - apollo_mysqldb:/var/lib/mysql\n\nvolumes:\n  apollo_mysqldb: \n\n\n\n\n# sql\n\n\n# apolloconfigdb.sql\n\n/*!40101 set @old_character_set_client=@@character_set_client */;\n/*!40101 set @old_character_set_results=@@character_set_results */;\n/*!40101 set @old_collation_connection=@@collation_connection */;\n/*!40101 set names utf8 */;\n/*!40014 set @old_foreign_key_checks=@@foreign_key_checks, foreign_key_checks=0 */;\n/*!40101 set @old_sql_mode=@@sql_mode, sql_mode='no_auto_value_on_zero' */;\n/*!40111 set @old_sql_notes=@@sql_notes, sql_notes=0 */;\n\n# create database\n# ------------------------------------------------------------\ncreate database if not exists apolloconfigdb default character set = utf8mb4;\n\nuse apolloconfigdb;\n\n# dump of table app\n# ------------------------------------------------------------\n\ndrop table if exists `app`;\n\ncreate table `app` (\n  `id` int(10) unsigned not null auto_increment comment '主键',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `name` varchar(500) not null default 'default' comment '应用名',\n  `orgid` varchar(32) not null default 'default' comment '部门id',\n  `orgname` varchar(64) not null default 'default' comment '部门名字',\n  `ownername` varchar(500) not null default 'default' comment 'ownername',\n  `owneremail` varchar(500) not null default 'default' comment 'owneremail',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `appid` (`appid`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_name` (`name`(191))\n) engine=innodb default charset=utf8mb4 comment='应用表';\n\n\n\n# dump of table appnamespace\n# ------------------------------------------------------------\n\ndrop table if exists `appnamespace`;\n\ncreate table `appnamespace` (\n  `id` int(10) unsigned not null auto_increment comment '自增主键',\n  `name` varchar(32) not null default '' comment 'namespace名字，注意，需要全局唯一',\n  `appid` varchar(32) not null default '' comment 'app id',\n  `format` varchar(32) not null default 'properties' comment 'namespace的format类型',\n  `ispublic` bit(1) not null default b'0' comment 'namespace是否为公共',\n  `comment` varchar(64) not null default '' comment '注释',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default '' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_appid` (`appid`),\n  key `name_appid` (`name`,`appid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='应用namespace定义';\n\n\n\n# dump of table audit\n# ------------------------------------------------------------\n\ndrop table if exists `audit`;\n\ncreate table `audit` (\n  `id` int(10) unsigned not null auto_increment comment '主键',\n  `entityname` varchar(50) not null default 'default' comment '表名',\n  `entityid` int(10) unsigned default null comment '记录id',\n  `opname` varchar(50) not null default 'default' comment '操作类型',\n  `comment` varchar(500) default null comment '备注',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='日志审计表';\n\n\n\n# dump of table cluster\n# ------------------------------------------------------------\n\ndrop table if exists `cluster`;\n\ncreate table `cluster` (\n  `id` int(10) unsigned not null auto_increment comment '自增主键',\n  `name` varchar(32) not null default '' comment '集群名字',\n  `appid` varchar(32) not null default '' comment 'app id',\n  `parentclusterid` int(10) unsigned not null default '0' comment '父cluster',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default '' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_appid_name` (`appid`,`name`),\n  key `ix_parentclusterid` (`parentclusterid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='集群';\n\n\n\n# dump of table commit\n# ------------------------------------------------------------\n\ndrop table if exists `commit`;\n\ncreate table `commit` (\n  `id` int(10) unsigned not null auto_increment comment '主键',\n  `changesets` longtext not null comment '修改变更集',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `clustername` varchar(500) not null default 'default' comment 'clustername',\n  `namespacename` varchar(500) not null default 'default' comment 'namespacename',\n  `comment` varchar(500) default null comment '备注',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `appid` (`appid`(191)),\n  key `clustername` (`clustername`(191)),\n  key `namespacename` (`namespacename`(191))\n) engine=innodb default charset=utf8mb4 comment='commit 历史表';\n\n# dump of table grayreleaserule\n# ------------------------------------------------------------\n\ndrop table if exists `grayreleaserule`;\n\ncreate table `grayreleaserule` (\n  `id` int(11) unsigned not null auto_increment comment '主键',\n  `appid` varchar(32) not null default 'default' comment 'appid',\n  `clustername` varchar(32) not null default 'default' comment 'cluster name',\n  `namespacename` varchar(32) not null default 'default' comment 'namespace name',\n  `branchname` varchar(32) not null default 'default' comment 'branch name',\n  `rules` varchar(16000) default '[]' comment '灰度规则',\n  `releaseid` int(11) unsigned not null default '0' comment '灰度对应的release',\n  `branchstatus` tinyint(2) default '1' comment '灰度分支状态: 0:删除分支,1:正在使用的规则 2：全量发布',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_namespace` (`appid`,`clustername`,`namespacename`)\n) engine=innodb default charset=utf8mb4 comment='灰度规则表';\n\n\n# dump of table instance\n# ------------------------------------------------------------\n\ndrop table if exists `instance`;\n\ncreate table `instance` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `appid` varchar(32) not null default 'default' comment 'appid',\n  `clustername` varchar(32) not null default 'default' comment 'clustername',\n  `datacenter` varchar(64) not null default 'default' comment 'data center name',\n  `ip` varchar(32) not null default '' comment 'instance ip',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lasttime` timestamp not null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  unique key `ix_unique_key` (`appid`,`clustername`,`ip`,`datacenter`),\n  key `ix_ip` (`ip`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='使用配置的应用实例';\n\n\n\n# dump of table instanceconfig\n# ------------------------------------------------------------\n\ndrop table if exists `instanceconfig`;\n\ncreate table `instanceconfig` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `instanceid` int(11) unsigned default null comment 'instance id',\n  `configappid` varchar(32) not null default 'default' comment 'config app id',\n  `configclustername` varchar(32) not null default 'default' comment 'config cluster name',\n  `confignamespacename` varchar(32) not null default 'default' comment 'config namespace name',\n  `releasekey` varchar(64) not null default '' comment '发布的key',\n  `releasedeliverytime` timestamp null default null comment '配置获取时间',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lasttime` timestamp not null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  unique key `ix_unique_key` (`instanceid`,`configappid`,`confignamespacename`),\n  key `ix_releasekey` (`releasekey`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_valid_namespace` (`configappid`,`configclustername`,`confignamespacename`,`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='应用实例的配置信息';\n\n\n\n# dump of table item\n# ------------------------------------------------------------\n\ndrop table if exists `item`;\n\ncreate table `item` (\n  `id` int(10) unsigned not null auto_increment comment '自增id',\n  `namespaceid` int(10) unsigned not null default '0' comment '集群namespaceid',\n  `key` varchar(128) not null default 'default' comment '配置项key',\n  `value` longtext not null comment '配置项值',\n  `comment` varchar(1024) default '' comment '注释',\n  `linenum` int(10) unsigned default '0' comment '行号',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_groupid` (`namespaceid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='配置项目';\n\n\n\n# dump of table namespace\n# ------------------------------------------------------------\n\ndrop table if exists `namespace`;\n\ncreate table `namespace` (\n  `id` int(10) unsigned not null auto_increment comment '自增主键',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `clustername` varchar(500) not null default 'default' comment 'cluster name',\n  `namespacename` varchar(500) not null default 'default' comment 'namespace name',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `appid_clustername_namespacename` (`appid`(191),`clustername`(191),`namespacename`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_namespacename` (`namespacename`(191))\n) engine=innodb default charset=utf8mb4 comment='命名空间';\n\n\n\n# dump of table namespacelock\n# ------------------------------------------------------------\n\ndrop table if exists `namespacelock`;\n\ncreate table `namespacelock` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `namespaceid` int(10) unsigned not null default '0' comment '集群namespaceid',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default 'default' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  `isdeleted` bit(1) default b'0' comment '软删除',\n  primary key (`id`),\n  unique key `ix_namespaceid` (`namespaceid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='namespace的编辑锁';\n\n\n\n# dump of table release\n# ------------------------------------------------------------\n\ndrop table if exists `release`;\n\ncreate table `release` (\n  `id` int(10) unsigned not null auto_increment comment '自增主键',\n  `releasekey` varchar(64) not null default '' comment '发布的key',\n  `name` varchar(64) not null default 'default' comment '发布名字',\n  `comment` varchar(256) default null comment '发布说明',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `clustername` varchar(500) not null default 'default' comment 'clustername',\n  `namespacename` varchar(500) not null default 'default' comment 'namespacename',\n  `configurations` longtext not null comment '发布配置',\n  `isabandoned` bit(1) not null default b'0' comment '是否废弃',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `appid_clustername_groupname` (`appid`(191),`clustername`(191),`namespacename`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_releasekey` (`releasekey`)\n) engine=innodb default charset=utf8mb4 comment='发布';\n\n\n# dump of table releasehistory\n# ------------------------------------------------------------\n\ndrop table if exists `releasehistory`;\n\ncreate table `releasehistory` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `appid` varchar(32) not null default 'default' comment 'appid',\n  `clustername` varchar(32) not null default 'default' comment 'clustername',\n  `namespacename` varchar(32) not null default 'default' comment 'namespacename',\n  `branchname` varchar(32) not null default 'default' comment '发布分支名',\n  `releaseid` int(11) unsigned not null default '0' comment '关联的release id',\n  `previousreleaseid` int(11) unsigned not null default '0' comment '前一次发布的releaseid',\n  `operation` tinyint(3) unsigned not null default '0' comment '发布类型，0: 普通发布，1: 回滚，2: 灰度发布，3: 灰度规则更新，4: 灰度合并回主分支发布，5: 主分支发布灰度自动发布，6: 主分支回滚灰度自动发布，7: 放弃灰度',\n  `operationcontext` longtext not null comment '发布上下文信息',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_namespace` (`appid`,`clustername`,`namespacename`,`branchname`),\n  key `ix_releaseid` (`releaseid`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='发布历史';\n\n\n# dump of table releasemessage\n# ------------------------------------------------------------\n\ndrop table if exists `releasemessage`;\n\ncreate table `releasemessage` (\n  `id` int(11) unsigned not null auto_increment comment '自增主键',\n  `message` varchar(1024) not null default '' comment '发布的消息内容',\n  `datachange_lasttime` timestamp not null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_message` (`message`(191))\n) engine=innodb default charset=utf8mb4 comment='发布消息';\n\n\n\n# dump of table serverconfig\n# ------------------------------------------------------------\n\ndrop table if exists `serverconfig`;\n\ncreate table `serverconfig` (\n  `id` int(10) unsigned not null auto_increment comment '自增id',\n  `key` varchar(64) not null default 'default' comment '配置项key',\n  `cluster` varchar(32) not null default 'default' comment '配置对应的集群，default为不针对特定的集群',\n  `value` varchar(2048) not null default 'default' comment '配置项值',\n  `comment` varchar(1024) default '' comment '注释',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_key` (`key`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='配置服务自身配置';\n\n# config\n# ------------------------------------------------------------\ninsert into `serverconfig` (`key`, `cluster`, `value`, `comment`)\nvalues\n    ('eureka.service.url', 'default', 'http://localhost:8080/eureka/', 'eureka服务url，多个service以英文逗号分隔'),\n    ('namespace.lock.switch', 'default', 'false', '一次发布只能有一个人修改开关'),\n    ('item.value.length.limit', 'default', '20000', 'item value最大长度限制'),\n    ('config-service.cache.enabled', 'default', 'false', 'configservice是否开启缓存，开启后能提高性能，但是会增大内存消耗！'),\n    ('item.key.length.limit', 'default', '128', 'item key 最大长度限制');\n\n# sample data\n# ------------------------------------------------------------\ninsert into `app` (`appid`, `name`, `orgid`, `orgname`, `ownername`, `owneremail`)\nvalues\n\t('sampleapp', 'sample app', 'test1', '样例部门1', 'apollo', 'apollo@acme.com');\n\ninsert into `appnamespace` (`name`, `appid`, `format`, `ispublic`, `comment`)\nvalues\n\t('application', 'sampleapp', 'properties', 0, 'default app namespace');\n\ninsert into `cluster` (`name`, `appid`)\nvalues\n\t('default', 'sampleapp');\n\ninsert into `namespace` (`id`, `appid`, `clustername`, `namespacename`)\nvalues\n\t(1, 'sampleapp', 'default', 'application');\n\n\ninsert into `item` (`namespaceid`, `key`, `value`, `comment`, `linenum`)\nvalues\n\t(1, 'timeout', '100', 'sample timeout配置', 1);\n\ninsert into `release` (`releasekey`, `name`, `comment`, `appid`, `clustername`, `namespacename`, `configurations`)\nvalues\n\t('20161009155425-d3a0749c6e20bc15', '20161009155424-release', 'sample发布', 'sampleapp', 'default', 'application', '{\\\"timeout\\\":\\\"100\\\"}');\n\ninsert into `releasehistory` (`appid`, `clustername`, `namespacename`, `branchname`, `releaseid`, `previousreleaseid`, `operation`, `operationcontext`, `datachange_createdby`, `datachange_lastmodifiedby`)\nvalues\n  ('sampleapp', 'default', 'application', 'default', 1, 0, 0, '{}', 'apollo', 'apollo');\n\n\n/*!40111 set sql_notes=@old_sql_notes */;\n/*!40101 set sql_mode=@old_sql_mode */;\n/*!40014 set foreign_key_checks=@old_foreign_key_checks */;\n/*!40101 set character_set_client=@old_character_set_client */;\n/*!40101 set character_set_results=@old_character_set_results */;\n/*!40101 set collation_connection=@old_collation_connection */;\n\n\n\n# apolloportaldb.sql\n\n/*!40101 set @old_character_set_client=@@character_set_client */;\n/*!40101 set @old_character_set_results=@@character_set_results */;\n/*!40101 set @old_collation_connection=@@collation_connection */;\n/*!40101 set names utf8 */;\n/*!40014 set @old_foreign_key_checks=@@foreign_key_checks, foreign_key_checks=0 */;\n/*!40101 set @old_sql_mode=@@sql_mode, sql_mode='no_auto_value_on_zero' */;\n/*!40111 set @old_sql_notes=@@sql_notes, sql_notes=0 */;\n\n# create database\n# ------------------------------------------------------------\ncreate database if not exists apolloportaldb default character set = utf8mb4;\n\nuse apolloportaldb;\n\n# dump of table app\n# ------------------------------------------------------------\n\ndrop table if exists `app`;\n\ncreate table `app` (\n  `id` int(10) unsigned not null auto_increment comment '主键',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `name` varchar(500) not null default 'default' comment '应用名',\n  `orgid` varchar(32) not null default 'default' comment '部门id',\n  `orgname` varchar(64) not null default 'default' comment '部门名字',\n  `ownername` varchar(500) not null default 'default' comment 'ownername',\n  `owneremail` varchar(500) not null default 'default' comment 'owneremail',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `appid` (`appid`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`),\n  key `ix_name` (`name`(191))\n) engine=innodb default charset=utf8mb4 comment='应用表';\n\n\n\n# dump of table appnamespace\n# ------------------------------------------------------------\n\ndrop table if exists `appnamespace`;\n\ncreate table `appnamespace` (\n  `id` int(10) unsigned not null auto_increment comment '自增主键',\n  `name` varchar(32) not null default '' comment 'namespace名字，注意，需要全局唯一',\n  `appid` varchar(32) not null default '' comment 'app id',\n  `format` varchar(32) not null default 'properties' comment 'namespace的format类型',\n  `ispublic` bit(1) not null default b'0' comment 'namespace是否为公共',\n  `comment` varchar(64) not null default '' comment '注释',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default '' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_appid` (`appid`),\n  key `name_appid` (`name`,`appid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='应用namespace定义';\n\n\n\n# dump of table consumer\n# ------------------------------------------------------------\n\ndrop table if exists `consumer`;\n\ncreate table `consumer` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `name` varchar(500) not null default 'default' comment '应用名',\n  `orgid` varchar(32) not null default 'default' comment '部门id',\n  `orgname` varchar(64) not null default 'default' comment '部门名字',\n  `ownername` varchar(500) not null default 'default' comment 'ownername',\n  `owneremail` varchar(500) not null default 'default' comment 'owneremail',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `appid` (`appid`(191)),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='开放api消费者';\n\n\n\n# dump of table consumeraudit\n# ------------------------------------------------------------\n\ndrop table if exists `consumeraudit`;\n\ncreate table `consumeraudit` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `consumerid` int(11) unsigned default null comment 'consumer id',\n  `uri` varchar(1024) not null default '' comment '访问的uri',\n  `method` varchar(16) not null default '' comment '访问的method',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_consumerid` (`consumerid`)\n) engine=innodb default charset=utf8mb4 comment='consumer审计表';\n\n\n\n# dump of table consumerrole\n# ------------------------------------------------------------\n\ndrop table if exists `consumerrole`;\n\ncreate table `consumerrole` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `consumerid` int(11) unsigned default null comment 'consumer id',\n  `roleid` int(10) unsigned default null comment 'role id',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) default '' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_roleid` (`roleid`),\n  key `ix_consumerid_roleid` (`consumerid`,`roleid`)\n) engine=innodb default charset=utf8mb4 comment='consumer和role的绑定表';\n\n\n\n# dump of table consumertoken\n# ------------------------------------------------------------\n\ndrop table if exists `consumertoken`;\n\ncreate table `consumertoken` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `consumerid` int(11) unsigned default null comment 'consumerid',\n  `token` varchar(128) not null default '' comment 'token',\n  `expires` datetime not null default '2099-01-01 00:00:00' comment 'token失效时间',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  unique key `ix_token` (`token`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='consumer token表';\n\n# dump of table favorite\n# ------------------------------------------------------------\n\ndrop table if exists `favorite`;\n\ncreate table `favorite` (\n  `id` int(10) unsigned not null auto_increment comment '主键',\n  `userid` varchar(32) not null default 'default' comment '收藏的用户',\n  `appid` varchar(500) not null default 'default' comment 'appid',\n  `position` int(32) not null default '10000' comment '收藏顺序',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `appid` (`appid`(191)),\n  key `ix_userid` (`userid`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb auto_increment=23 default charset=utf8mb4 comment='应用收藏表';\n\n# dump of table permission\n# ------------------------------------------------------------\n\ndrop table if exists `permission`;\n\ncreate table `permission` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `permissiontype` varchar(32) not null default '' comment '权限类型',\n  `targetid` varchar(256) not null default '' comment '权限对象类型',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default '' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_targetid_permissiontype` (`targetid`(191),`permissiontype`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='permission表';\n\n\n\n# dump of table role\n# ------------------------------------------------------------\n\ndrop table if exists `role`;\n\ncreate table `role` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `rolename` varchar(256) not null default '' comment 'role name',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_rolename` (`rolename`(191)),\n  key `ix_datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='角色表';\n\n\n\n# dump of table rolepermission\n# ------------------------------------------------------------\n\ndrop table if exists `rolepermission`;\n\ncreate table `rolepermission` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `roleid` int(10) unsigned default null comment 'role id',\n  `permissionid` int(10) unsigned default null comment 'permission id',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) default '' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_roleid` (`roleid`),\n  key `ix_permissionid` (`permissionid`)\n) engine=innodb default charset=utf8mb4 comment='角色和权限的绑定表';\n\n\n\n# dump of table serverconfig\n# ------------------------------------------------------------\n\ndrop table if exists `serverconfig`;\n\ncreate table `serverconfig` (\n  `id` int(10) unsigned not null auto_increment comment '自增id',\n  `key` varchar(64) not null default 'default' comment '配置项key',\n  `value` varchar(2048) not null default 'default' comment '配置项值',\n  `comment` varchar(1024) default '' comment '注释',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) not null default 'default' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_key` (`key`),\n  key `datachange_lasttime` (`datachange_lasttime`)\n) engine=innodb default charset=utf8mb4 comment='配置服务自身配置';\n\n\n\n# dump of table userrole\n# ------------------------------------------------------------\n\ndrop table if exists `userrole`;\n\ncreate table `userrole` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `userid` varchar(128) default '' comment '用户身份标识',\n  `roleid` int(10) unsigned default null comment 'role id',\n  `isdeleted` bit(1) not null default b'0' comment '1: deleted, 0: normal',\n  `datachange_createdby` varchar(32) default '' comment '创建人邮箱前缀',\n  `datachange_createdtime` timestamp not null default current_timestamp comment '创建时间',\n  `datachange_lastmodifiedby` varchar(32) default '' comment '最后修改人邮箱前缀',\n  `datachange_lasttime` timestamp null default current_timestamp on update current_timestamp comment '最后修改时间',\n  primary key (`id`),\n  key `ix_datachange_lasttime` (`datachange_lasttime`),\n  key `ix_roleid` (`roleid`),\n  key `ix_userid_roleid` (`userid`,`roleid`)\n) engine=innodb default charset=utf8mb4 comment='用户和role的绑定表';\n\n# dump of table users\n# ------------------------------------------------------------\n\ndrop table if exists `users`;\n\ncreate table `users` (\n  `id` int(10) unsigned not null auto_increment comment '自增id',\n  `username` varchar(64) not null default 'default' comment '用户名',\n  `password` varchar(64) not null default 'default' comment '密码',\n  `email` varchar(64) not null default 'default' comment '邮箱地址',\n  `enabled` tinyint(4) default null comment '是否有效',\n  primary key (`id`)\n) engine=innodb default charset=utf8mb4 comment='用户表';\n\n\n# dump of table authorities\n# ------------------------------------------------------------\n\ndrop table if exists `authorities`;\n\ncreate table `authorities` (\n  `id` int(11) unsigned not null auto_increment comment '自增id',\n  `username` varchar(64) not null,\n  `authority` varchar(50) not null,\n  primary key (`id`)\n) engine=innodb default charset=utf8mb4;\n\n\n# config\n# ------------------------------------------------------------\ninsert into `serverconfig` (`key`, `value`, `comment`)\nvalues\n    ('apollo.portal.envs', 'dev', '可支持的环境列表'),\n    ('organizations', '[{\\\"orgid\\\":\\\"test1\\\",\\\"orgname\\\":\\\"样例部门1\\\"},{\\\"orgid\\\":\\\"test2\\\",\\\"orgname\\\":\\\"样例部门2\\\"}]', '部门列表'),\n    ('superadmin', 'apollo', 'portal超级管理员'),\n    ('api.readtimeout', '10000', 'http接口read timeout'),\n    ('consumer.token.salt', 'somesalt', 'consumer token salt'),\n    ('admin.createprivatenamespace.switch', 'true', '是否允许项目管理员创建私有namespace'),\n    ('configview.memberonly.envs', 'dev', '只对项目成员显示配置信息的环境列表，多个env以英文逗号分隔');\n\ninsert into `users` (`username`, `password`, `email`, `enabled`)\nvalues\n\t('apollo', '$2a$10$7r20us.bq9ubpf3baj3uqozvmvvb1rn3pyoke94gtz2.waouiiwxs', 'apollo@acme.com', 1);\n\ninsert into `authorities` (`username`, `authority`) values ('apollo', 'role_user');\n\n# sample data\n# ------------------------------------------------------------\ninsert into `app` (`appid`, `name`, `orgid`, `orgname`, `ownername`, `owneremail`)\nvalues\n\t('sampleapp', 'sample app', 'test1', '样例部门1', 'apollo', 'apollo@acme.com');\n\ninsert into `appnamespace` (`name`, `appid`, `format`, `ispublic`, `comment`)\nvalues\n\t('application', 'sampleapp', 'properties', 0, 'default app namespace');\n\ninsert into `permission` (`id`, `permissiontype`, `targetid`)\nvalues\n\t(1, 'createcluster', 'sampleapp'),\n\t(2, 'createnamespace', 'sampleapp'),\n\t(3, 'assignrole', 'sampleapp'),\n\t(4, 'modifynamespace', 'sampleapp+application'),\n\t(5, 'releasenamespace', 'sampleapp+application');\n\ninsert into `role` (`id`, `rolename`)\nvalues\n\t(1, 'master+sampleapp'),\n\t(2, 'modifynamespace+sampleapp+application'),\n\t(3, 'releasenamespace+sampleapp+application');\n\ninsert into `rolepermission` (`roleid`, `permissionid`)\nvalues\n\t(1, 1),\n\t(1, 2),\n\t(1, 3),\n\t(2, 4),\n\t(3, 5);\n\ninsert into `userrole` (`userid`, `roleid`)\nvalues\n\t('apollo', 1),\n\t('apollo', 2),\n\t('apollo', 3);\n\n/*!40111 set sql_notes=@old_sql_notes */;\n/*!40101 set sql_mode=@old_sql_mode */;\n/*!40014 set foreign_key_checks=@old_foreign_key_checks */;\n/*!40101 set character_set_client=@old_character_set_client */;\n/*!40101 set character_set_results=@old_character_set_results */;\n/*!40101 set collation_connection=@old_collation_connection */;\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/apollo/sql\n\\cp ./sql/apolloconfigdb.sql /etc/apollo/sql/apolloconfigdb.sql -f\n\\cp ./sql/apolloportaldb.sql /etc/apollo/sql/apolloportaldb.sql -f\ndocker-compose up -d\n\n\n\n# 删除项目sql\n\n# 删除apolloconfigdb中的数据\n\nset @appid = 'tjs_public';\n \nuse `apolloconfigdb`;\n \nupdate `app` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `appnamespace` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `cluster` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `commit` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `grayreleaserule` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `release` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `releasehistory` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\ndelete from `instance` where `appid` = @appid;\ndelete from `instanceconfig` where `configappid` = @appid;\ndelete from `releasemessage` where `message` like concat(@appid, '+%');\n \n# handle namespaces and items\ncreate temporary table `namespaceids` as select `id` from `namespace` where `appid` = @appid and `isdeleted` = 0;\nupdate `namespace` set `isdeleted` = 1 where `id` in (select `id` from `namespaceids`);\nupdate `item` set `isdeleted` = 1 where `namespaceid` in (select `id` from `namespaceids`);\ndelete from `namespacelock` where `namespaceid` in (select `id` from `namespaceids`);\ndrop temporary table `namespaceids`;\n\n\n# 删除apolloportaldb中的数据\n\nset @appid = 'tjs_public';\n \nuse `apolloportaldb`;\n \nupdate `app` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `appnamespace` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\nupdate `favorite` set `isdeleted` = 1 where `appid` = @appid and `isdeleted` = 0;\n \n# handle roles and permissions\ncreate temporary table `permissionids` as select `id` from `permission` where (`targetid` = @appid or `targetid` like concat(@appid, '+%'))  and `isdeleted` = 0;\nupdate `permission` set `isdeleted` = 1 where `id` in (select `id` from `permissionids`);\nupdate `rolepermission` set `isdeleted` = 1 where `permissionid` in (select `id` from `permissionids`);\ndrop temporary table `permissionids`;\n \ncreate temporary table `roleids` as select `id` from `role` where (`rolename` = concat('master+', @appid) or `rolename` like concat('modifynamespace+', @appid, '+%') or `rolename` like concat('releasenamespace+', @appid, '+%')) and `isdeleted` = 0;\nupdate `role` set `isdeleted` = 1 where `id` in (select `id` from `roleids`);\nupdate `userrole` set `isdeleted` = 1 where `roleid` in (select `id` from `roleids`);\nupdate `consumerrole` set `isdeleted` = 1 where `roleid` in (select `id` from `roleids`);\ndrop temporary table `roleids`;\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Cassandra",frontmatter:{title:"Cassandra",date:"2023-09-05T14:43:18.000Z",permalink:"/pages/01958e/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/05.Cassandra.html",relativePath:"05.工具&部署/01.Docker/05.Cassandra.md",key:"v-54077827",path:"/pages/01958e/",headers:[{level:2,title:"Apache Cassandra 分布式 K/V 存储方案",slug:"apache-cassandra-分布式-k-v-存储方案",normalizedTitle:"apache cassandra 分布式 k/v 存储方案",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:123},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1193},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2396}],headersStr:"Apache Cassandra 分布式 K/V 存储方案 简介 docker-compose.yml deploy.sh",content:'# Apache Cassandra 分布式 K/V 存储方案\n\n开源网址\n\n官网：https://cassandra.apache.org/\n\ngithub：https://github.com/apolloconfig/apollo\n\n\n# 简介\n\n\n\n> Apache Cassandra 是一套开源分布式 Key-Value 存储系统。它最初由 Facebook 开发，用于储存特别大的数据。\n\n主要特性：\n\n * 分布式\n * 基于 column 的结构化\n * 高伸展性\n\nCassandra 的主要特点就是它不是一个数据库，而是由一堆数据库节点共同构成的一个分布式网络服务，对 Cassandra 的一个写操作，会被复制到其他节点上去，对 Cassandra 的读操作，也会被路由到某个节点上面去读取。对于一个 Cassandra 群集来说，扩展性能 是比较简单的事情，只管在群集里面添加节点就可以了。\n\nCassandra 是一个混合型的非关系的数据库，类似于 Google 的 BigTable。其主要功能比 Dynomite（分布式的 Key-Value 存 储系统）更丰富，但支持度却不如文档存储 MongoDB（介于关系数据库和非关系数据库之间的开源产品，是非关系数据库当中功能最丰富，最像关系数据库 的。支持的数据结构非常松散，是类似 json 的 bjson 格式，因此可以存储比较复杂的数据类型。）Cassandra 最初由 Facebook 开发，后转变成了开源项目。它是一个网络社交云计算方面理想的数据库。以 Amazon 专有的完全分布式的 Dynamo 为基础，结合了 Google BigTable 基于列族（Column Family）的数据模型。P2P 去中心化的存储。很多方面都可以称之为 Dynamo 2.0。\n\n和其他数据库比较，有几个突出特点：\n\n * 模式灵活 ：使用 Cassandra，像文档存储，你不必提前解决记录中的字段。你可以在系统运行时随意的添加或移除字段。这是一个惊人的效率提升，特别是在大型部 署上。\n * 真正的可扩展性 ：Cassandra 是纯粹意义上的水平扩展。为给集群添加更多容量，可以指向另一台电脑。你不必重启任何进程，改变应用查询，或手动迁移任何数据。\n * 多数据中心识别 ：你可以调整你的节点布局来避免某一个数据中心起火，一个备用的数据中心将至少有每条记录的完全复制。\n\n一些使 Cassandra 提高竞争力的其他功能：\n\n * 范围查询 ：如果你不喜欢全部的键值查询，则可以设置键的范围来查询。\n * 列表数据结构 ：在混合模式可以将超级列添加到 5 维。对于每个用户的索引，这是非常方便的。\n * 分布式写操作 ：有可以在任何地方任何时间集中读或写任何数据。并且不会有任何单点失败。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\n# 3 node cluster\n# If you see exit code 137 (OOM killer) then ensure Docker has access to more resources\nservices:\n\n  cassandra1:\n    image: cassandra:3.11.4\n    container_name: cassandra1\n    restart: always\n    environment:\n      TZ: Asia/Shanghai\n    ports:\n      - 9042:9042   # Native transport\n      - 7199:7199   # JMX\n      - 9160:9160   # Thrift clients\n\n  cassandra2:\n    image: cassandra:3.11.4\n    container_name: cassandra2\n    restart: always\n    command: /bin/bash -c "echo \'Waiting for seed node\' && sleep 30 && /docker-entrypoint.sh cassandra -f"\n    environment:\n      TZ: Asia/Shanghai\n      CASSANDRA_SEEDS: cassandra1\n    depends_on:\n      - "cassandra1"\n\n  # you cannot have multiple nodes join the cluster at the same time when\n  # cassandra.consistent.rangemovement is true so we further delay it to give it time to stabilize\n  cassandra3:\n    image: cassandra:3.11.4\n    container_name: cassandra3\n    restart: always\n    command: /bin/bash -c "echo \'Waiting for seed node\' && sleep 80 && /docker-entrypoint.sh cassandra -f"\n    environment:\n      TZ: Asia/Shanghai\n      CASSANDRA_SEEDS: cassandra1\n    depends_on:\n      - "cassandra1"\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',normalizedContent:'# apache cassandra 分布式 k/v 存储方案\n\n开源网址\n\n官网：https://cassandra.apache.org/\n\ngithub：https://github.com/apolloconfig/apollo\n\n\n# 简介\n\n\n\n> apache cassandra 是一套开源分布式 key-value 存储系统。它最初由 facebook 开发，用于储存特别大的数据。\n\n主要特性：\n\n * 分布式\n * 基于 column 的结构化\n * 高伸展性\n\ncassandra 的主要特点就是它不是一个数据库，而是由一堆数据库节点共同构成的一个分布式网络服务，对 cassandra 的一个写操作，会被复制到其他节点上去，对 cassandra 的读操作，也会被路由到某个节点上面去读取。对于一个 cassandra 群集来说，扩展性能 是比较简单的事情，只管在群集里面添加节点就可以了。\n\ncassandra 是一个混合型的非关系的数据库，类似于 google 的 bigtable。其主要功能比 dynomite（分布式的 key-value 存 储系统）更丰富，但支持度却不如文档存储 mongodb（介于关系数据库和非关系数据库之间的开源产品，是非关系数据库当中功能最丰富，最像关系数据库 的。支持的数据结构非常松散，是类似 json 的 bjson 格式，因此可以存储比较复杂的数据类型。）cassandra 最初由 facebook 开发，后转变成了开源项目。它是一个网络社交云计算方面理想的数据库。以 amazon 专有的完全分布式的 dynamo 为基础，结合了 google bigtable 基于列族（column family）的数据模型。p2p 去中心化的存储。很多方面都可以称之为 dynamo 2.0。\n\n和其他数据库比较，有几个突出特点：\n\n * 模式灵活 ：使用 cassandra，像文档存储，你不必提前解决记录中的字段。你可以在系统运行时随意的添加或移除字段。这是一个惊人的效率提升，特别是在大型部 署上。\n * 真正的可扩展性 ：cassandra 是纯粹意义上的水平扩展。为给集群添加更多容量，可以指向另一台电脑。你不必重启任何进程，改变应用查询，或手动迁移任何数据。\n * 多数据中心识别 ：你可以调整你的节点布局来避免某一个数据中心起火，一个备用的数据中心将至少有每条记录的完全复制。\n\n一些使 cassandra 提高竞争力的其他功能：\n\n * 范围查询 ：如果你不喜欢全部的键值查询，则可以设置键的范围来查询。\n * 列表数据结构 ：在混合模式可以将超级列添加到 5 维。对于每个用户的索引，这是非常方便的。\n * 分布式写操作 ：有可以在任何地方任何时间集中读或写任何数据。并且不会有任何单点失败。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\n# 3 node cluster\n# if you see exit code 137 (oom killer) then ensure docker has access to more resources\nservices:\n\n  cassandra1:\n    image: cassandra:3.11.4\n    container_name: cassandra1\n    restart: always\n    environment:\n      tz: asia/shanghai\n    ports:\n      - 9042:9042   # native transport\n      - 7199:7199   # jmx\n      - 9160:9160   # thrift clients\n\n  cassandra2:\n    image: cassandra:3.11.4\n    container_name: cassandra2\n    restart: always\n    command: /bin/bash -c "echo \'waiting for seed node\' && sleep 30 && /docker-entrypoint.sh cassandra -f"\n    environment:\n      tz: asia/shanghai\n      cassandra_seeds: cassandra1\n    depends_on:\n      - "cassandra1"\n\n  # you cannot have multiple nodes join the cluster at the same time when\n  # cassandra.consistent.rangemovement is true so we further delay it to give it time to stabilize\n  cassandra3:\n    image: cassandra:3.11.4\n    container_name: cassandra3\n    restart: always\n    command: /bin/bash -c "echo \'waiting for seed node\' && sleep 80 && /docker-entrypoint.sh cassandra -f"\n    environment:\n      tz: asia/shanghai\n      cassandra_seeds: cassandra1\n    depends_on:\n      - "cassandra1"\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Cerebro",frontmatter:{title:"Cerebro",date:"2023-09-05T15:06:10.000Z",permalink:"/pages/7e58c5/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/06.Cerebro.html",relativePath:"05.工具&部署/01.Docker/06.Cerebro.md",key:"v-1c067b47",path:"/pages/7e58c5/",headers:[{level:2,title:"Cerebro 简约快速的 Elastic Search 可视化工具",slug:"cerebro-简约快速的-elastic-search-可视化工具",normalizedTitle:"cerebro 简约快速的 elastic search 可视化工具",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:91},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:147},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:576}],headersStr:"Cerebro 简约快速的 Elastic Search 可视化工具 简介 docker-compose.yml deploy.sh",content:"# Cerebro 简约快速的 Elastic Search 可视化工具\n\n开源网址\n\ngithub：https://github.com/lmenezes/cerebro\n\n\n# 简介\n\n\n\n> 一款全能的ES工具，安装配置简单，功能强大。\n\n可以监控集群、配置集群、操作ES数据；\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\n# docker run -p 9000:9000 lmenezes/cerebro:0.9.2\n\nservices: \n\n  cerebro: \n    image: lmenezes/cerebro:0.9.2\n    container_name: cerebro\n    restart: always\n    hostname: cerebro\n    ports:\n      - 9000:9000\n    environment:\n      TZ: Asia/Shanghai\n    command: \n#      - -Dhosts.0.host=http://elasticsearch_node1:9200\n# 这里填ES的默认地址，不填也可以\n      - -Dhosts.0.host=http://192.168.0.110:9200  \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# cerebro 简约快速的 elastic search 可视化工具\n\n开源网址\n\ngithub：https://github.com/lmenezes/cerebro\n\n\n# 简介\n\n\n\n> 一款全能的es工具，安装配置简单，功能强大。\n\n可以监控集群、配置集群、操作es数据；\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\n# docker run -p 9000:9000 lmenezes/cerebro:0.9.2\n\nservices: \n\n  cerebro: \n    image: lmenezes/cerebro:0.9.2\n    container_name: cerebro\n    restart: always\n    hostname: cerebro\n    ports:\n      - 9000:9000\n    environment:\n      tz: asia/shanghai\n    command: \n#      - -dhosts.0.host=http://elasticsearch_node1:9200\n# 这里填es的默认地址，不填也可以\n      - -dhosts.0.host=http://192.168.0.110:9200  \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Consul",frontmatter:{title:"Consul",date:"2023-09-05T15:16:32.000Z",permalink:"/pages/3d230b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/08.Consul.html",relativePath:"05.工具&部署/01.Docker/08.Consul.md",key:"v-54a5a8f1",path:"/pages/3d230b/",headers:[{level:2,title:"Consul 服务的注册和发现",slug:"consul-服务的注册和发现",normalizedTitle:"consul 服务的注册和发现",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:100},{level:2,title:"优势",slug:"优势",normalizedTitle:"优势",charIndex:494},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:808},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1083},{level:2,title:"集群",slug:"集群",normalizedTitle:"集群",charIndex:380},{level:3,title:"docker-compose.yml",slug:"docker-compose-yml-2",normalizedTitle:"docker-compose.yml",charIndex:808},{level:3,title:"deploy.sh",slug:"deploy-sh-2",normalizedTitle:"deploy.sh",charIndex:1083}],headersStr:"Consul 服务的注册和发现 简介 优势 docker-compose.yml deploy.sh 集群 docker-compose.yml deploy.sh",content:"# Consul 服务的注册和发现\n\n开源网址\n\n官网：https://consulproject.org/\n\ngithub：https://github.com/consul/consul\n\n\n# 简介\n\n\n\n> Consul 简化了分布式环境中的服务的注册和发现流程，通过 HTTP 或者 DNS 接口发现。支持外部 SaaS 提供者等。\n\n在线演示：http://demo.consul.io/ui/\n\nConsul是HashiCorp公司推出的开源工具，用于实现分布式系统的服务发现与配置。 Consul是分布式的、高可用的、可横向扩展的。它具备以下特性 :\n\n * 服务发现：consul通过DNS或者HTTP接口使服务注册和服务发现变的很容易，一些外部服务，例如saas提供的也可以一样注册。\n * 健康检查：健康检测使consul可以快速的告警在集群中的操作。和服务发现的集成，可以防止服务转发到故障的服务上面。\n * 键/值存储：一个用来存储动态配置的系统。提供简单的HTTP接口，可以在任何地方操作。\n * 多数据中心：无需复杂的配置，即可支持任意数量的区域。\n\n\n# 优势\n\n * 使用 Raft 算法来保证一致性, 比复杂的 Paxos 算法更直接. 相比较而言, zookeeper 采用的是 Paxos, 而 etcd 使用的则是 Raft.\n * 支持多数据中心，内外网的服务采用不同的端口进行监听。 多数据中心集群可以避免单数据中心的单点故障,而其部署则需要考虑网络延迟, 分片等情况等. zookeeper 和 etcd 均不提供多数据中心功能的支持.\n * 支持健康检查. etcd 不提供此功能.\n * 支持 http 和 dns 协议接口. zookeeper 的集成较为复杂, etcd 只支持 http 协议.\n * 官方提供web管理界面, etcd 无此功能.\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n  consul:\n    image: consul:1.5\n    container_name: consul\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data:/consul/data\n    ports:\n      - 8500:8500\n\nvolumes: \n  consul_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# 集群\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n  consul1:\n    image: consul:1.5\n    container_name: consul1\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data1:/consul/data\n      - /etc/consul/watchs.json:/consul/config/watchs.json\n    command: agent -server -bootstrap-expect=3 -node=consul1 -bind '{{ GetPrivateInterfaces  | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n\n  consul2:\n    image: consul:1.5\n    container_name: consul2\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data2:/consul/data\n    command: agent -server -retry-join=consul1 -node=consul2 -bind '{{ GetPrivateInterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n    depends_on:\n        - consul1\n\n  consul3:\n    image: consul:1.5\n    container_name: consul3\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data3:/consul/data\n    command: agent -server -retry-join=consul1 -node=consul3 -bind '{{ GetPrivateInterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n    depends_on:\n        - consul1\n\n  consul4:\n    image: consul:1.5\n    container_name: consul4\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    volumes: \n      - consul_data4:/consul/data\n    command: agent -retry-join=consul1 -node=consul4 -bind '{{ GetPrivateInterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1 -ui \n    ports:\n      - 8500:8500\n    depends_on:\n        - consul2\n        - consul3\n\nvolumes: \n  consul_data1: \n  consul_data2: \n  consul_data3: \n  consul_data4: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/consul\n\\cp ../config/watchs.json /etc/consul/watchs.json -f\ndocker-compose up -d\n",normalizedContent:"# consul 服务的注册和发现\n\n开源网址\n\n官网：https://consulproject.org/\n\ngithub：https://github.com/consul/consul\n\n\n# 简介\n\n\n\n> consul 简化了分布式环境中的服务的注册和发现流程，通过 http 或者 dns 接口发现。支持外部 saas 提供者等。\n\n在线演示：http://demo.consul.io/ui/\n\nconsul是hashicorp公司推出的开源工具，用于实现分布式系统的服务发现与配置。 consul是分布式的、高可用的、可横向扩展的。它具备以下特性 :\n\n * 服务发现：consul通过dns或者http接口使服务注册和服务发现变的很容易，一些外部服务，例如saas提供的也可以一样注册。\n * 健康检查：健康检测使consul可以快速的告警在集群中的操作。和服务发现的集成，可以防止服务转发到故障的服务上面。\n * 键/值存储：一个用来存储动态配置的系统。提供简单的http接口，可以在任何地方操作。\n * 多数据中心：无需复杂的配置，即可支持任意数量的区域。\n\n\n# 优势\n\n * 使用 raft 算法来保证一致性, 比复杂的 paxos 算法更直接. 相比较而言, zookeeper 采用的是 paxos, 而 etcd 使用的则是 raft.\n * 支持多数据中心，内外网的服务采用不同的端口进行监听。 多数据中心集群可以避免单数据中心的单点故障,而其部署则需要考虑网络延迟, 分片等情况等. zookeeper 和 etcd 均不提供多数据中心功能的支持.\n * 支持健康检查. etcd 不提供此功能.\n * 支持 http 和 dns 协议接口. zookeeper 的集成较为复杂, etcd 只支持 http 协议.\n * 官方提供web管理界面, etcd 无此功能.\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n  consul:\n    image: consul:1.5\n    container_name: consul\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data:/consul/data\n    ports:\n      - 8500:8500\n\nvolumes: \n  consul_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# 集群\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n  consul1:\n    image: consul:1.5\n    container_name: consul1\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data1:/consul/data\n      - /etc/consul/watchs.json:/consul/config/watchs.json\n    command: agent -server -bootstrap-expect=3 -node=consul1 -bind '{{ getprivateinterfaces  | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n\n  consul2:\n    image: consul:1.5\n    container_name: consul2\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data2:/consul/data\n    command: agent -server -retry-join=consul1 -node=consul2 -bind '{{ getprivateinterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n    depends_on:\n        - consul1\n\n  consul3:\n    image: consul:1.5\n    container_name: consul3\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data3:/consul/data\n    command: agent -server -retry-join=consul1 -node=consul3 -bind '{{ getprivateinterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1\n    depends_on:\n        - consul1\n\n  consul4:\n    image: consul:1.5\n    container_name: consul4\n    restart: always\n    environment: \n      tz: asia/shanghai\n    volumes: \n      - consul_data4:/consul/data\n    command: agent -retry-join=consul1 -node=consul4 -bind '{{ getprivateinterfaces | attr \"address\" }}' -client=0.0.0.0 -datacenter=dc1 -ui \n    ports:\n      - 8500:8500\n    depends_on:\n        - consul2\n        - consul3\n\nvolumes: \n  consul_data1: \n  consul_data2: \n  consul_data3: \n  consul_data4: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/consul\n\\cp ../config/watchs.json /etc/consul/watchs.json -f\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"ClickHouse",frontmatter:{title:"ClickHouse",date:"2023-09-05T15:08:57.000Z",permalink:"/pages/3b4977/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/07.ClickHouse.html",relativePath:"05.工具&部署/01.Docker/07.ClickHouse.md",key:"v-4b206a0f",path:"/pages/3b4977/",headers:[{level:2,title:"ClickHouse 列式储存数据库",slug:"clickhouse-列式储存数据库",normalizedTitle:"clickhouse 列式储存数据库",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:108},{level:3,title:"主要功能",slug:"主要功能",normalizedTitle:"主要功能",charIndex:495},{level:3,title:"应用场景",slug:"应用场景",normalizedTitle:"应用场景",charIndex:1085},{level:2,title:"常用sql",slug:"常用sql",normalizedTitle:"常用sql",charIndex:1303},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:2804},{level:2,title:"config.xml",slug:"config-xml",normalizedTitle:"config.xml",charIndex:3065},{level:2,title:"users.xml",slug:"users-xml",normalizedTitle:"users.xml",charIndex:3134},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:61546}],headersStr:"ClickHouse 列式储存数据库 简介 主要功能 应用场景 常用sql docker-compose.yml config.xml users.xml deploy.sh",content:"# ClickHouse 列式储存数据库\n\n开源网址\n\n官网：https://clickhouse.com/\n\ngithub：https://github.com/ClickHouse/ClickHouse\n\n\n# 简介\n\n\n\n> ClickHouse 是俄罗斯第一大搜索引擎 Yandex 开发的列式储存数据库。令人惊喜的是，这个列式储存数据库的性能大幅超越了很多商业 MPP 数据库软件，比如 Vertica,InfiniDB.\n\n相比传统的数据库软件，ClickHouse 要快 100-1000X:\n\n100Million 数据集:\n\n * ClickHouse 比 Vertica 约快 5 倍，比 Hive 快 279 倍，比 My SQL 快 801 倍\n\n1Billion 数据集:\n\n * ClickHouse 比 Vertica 约快 5 倍，MySQL 和 Hive 已经无法完成任务了\n\n该项目当前还有一些不足:\n\n * pre-build 包只有 Ubuntu 平台的可用，并且该项目当前没有任何架构文档\n * 只有 Github 上面的 C++ 源代码\n\n\n# 主要功能\n\n * True column-oriented\n * Vectorized query execution\n * Data compression\n * Parallel and distributed query execution\n * Real-time data ingestion\n * On-disk locality of reference\n * Real-time query processing\n * Cross-datacenter replication\n * High availability\n * SQL support\n * Local and distributed joins\n * Pluggable external dimension tables\n * Arrays and nested data types\n * Approximate query processing\n * Probabilistic data structures\n * Full support of IPv6\n * Features for web analytics\n * State-of-the-art algorithms\n * Detailed documentation\n * Clean documented code\n\n\n# 应用场景\n\n * Web and App analytics\n * Advertising networks and RTB\n * Telecommunications\n * E-commerce\n * Information security\n * Monitoring and telemetry\n * Business intelligence\n * Online games\n * Internet of Things\n\n\n# 常用sql\n\n-- 查询连接数\nSELECT * FROM system.metrics WHERE metric LIKE '%Connection';\n\n\n-- 当前正在执行的查询\nSELECT query_id, user, address, query  FROM system.processes ORDER BY query_id;\n\n-- 存储空间统计\nSELECT name,path,formatReadableSize(free_space) AS free,formatReadableSize(total_space) AS total,formatReadableSize(keep_free_space) AS reserved FROM system.disks;\n\n-- 慢查询\nSELECT\n    user,\n    client_hostname AS host,\n    client_name AS client,\n    formatDateTime(query_start_time, '%T') AS started,\n    query_duration_ms / 1000 AS sec,\n    round(memory_usage / 1048576) AS MEM_MB,\n    result_rows AS RES_CNT,\n    result_bytes / 1048576 AS RES_MB,\n    read_rows AS R_CNT,\n    round(read_bytes / 1048576) AS R_MB,\n    written_rows AS W_CNT,\n    round(written_bytes / 1048576) AS W_MB,\n    query\nFROM system.query_log\nWHERE type = 2\nORDER BY query_duration_ms DESC\n    LIMIT 10;\n\n-- 查看库表资源占用情况\nselect\n    sum(rows) as row,--总行数\n    formatReadableSize(sum(data_uncompressed_bytes)) as ysq,--原始大小\n    formatReadableSize(sum(data_compressed_bytes)) as ysh,--压缩大小\n    round(sum(data_compressed_bytes) / sum(data_uncompressed_bytes) * 100, 0) ys_rate--压缩率\nfrom system.parts\nwhere database='datacenter';\n\n-- 查看库中表行数统计\nselect database,table,sum(rows) as rows\nfrom system.parts\nwhere database='datacenter'\ngroup by database, table\norder by rows desc;\n\n\nselect distinct table from system.parts where database='datacenter';\n\n\n-- drop  database datacenter;\n\nselect * from datacenter.`3cdb162688e14cc6a1bc65befca5347c_YC150`;\n\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  clickhouseserver: \n    image: yandex/clickhouse-server:21\n    container_name: clickhouseserver\n    restart: always\n    hostname: clickhouse\n    volumes: \n      - data:/var/lib/clickhouse\n      - /etc/clickhouse/config.xml:/etc/clickhouse-server/config.xml\n      - /etc/clickhouse/users.xml:/etc/clickhouse-server/users.xml\n    ports:\n      - 8123:8123\n      - 9000:9000\n    environment:\n      TZ: Asia/Shanghai \n  \n  # clickhouseclient:\n  #   image: yandex/clickhouse-client:21\n  #   container_name: clickhouseclient\n  #   restart: always\n  #   environment:\n  #     TZ: Asia/Shanghai\n  #   depends_on: ['clickhouseserver']\n\n  #docker run -it --rm --link clickhouseserver --net swarm_net yandex/clickhouse-client:21 --host clickhouseserver\n\nvolumes: \n  data: \n    driver: local\n\n\n\n# config.xml\n\n<?xml version=\"1.0\"?>\n\x3c!--\n  NOTE: User and query level settings are set up in \"users.xml\" file.\n  If you have accidentally specified user-level settings here, server won't start.\n  You can either move the settings to the right place inside \"users.xml\" file\n   or add <skip_check_for_incorrect_settings>1</skip_check_for_incorrect_settings> here.\n--\x3e\n<yandex>\n    <logger>\n        \x3c!-- Possible levels [1]:\n\n          - none (turns off logging)\n          - fatal\n          - critical\n          - error\n          - warning\n          - notice\n          - information\n          - debug\n          - trace\n\n            [1]: https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/Logger.h#L105-L114\n        --\x3e\n        <level>trace</level>\n        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>\n        \x3c!-- Rotation policy\n             See https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/FileChannel.h#L54-L85\n          --\x3e\n        <size>1000M</size>\n        <count>10</count>\n        \x3c!-- <console>1</console> --\x3e \x3c!-- Default behavior is autodetection (log to console if not daemon mode and is tty) --\x3e\n\n        \x3c!-- Per level overrides (legacy):\n\n        For example to suppress logging of the ConfigReloader you can use:\n        NOTE: levels.logger is reserved, see below.\n        --\x3e\n        \x3c!--\n        <levels>\n          <ConfigReloader>none</ConfigReloader>\n        </levels>\n        --\x3e\n\n        \x3c!-- Per level overrides:\n\n        For example to suppress logging of the RBAC for default user you can use:\n        (But please note that the logger name maybe changed from version to version, even after minor upgrade)\n        --\x3e\n        \x3c!--\n        <levels>\n          <logger>\n            <name>ContextAccess (default)</name>\n            <level>none</level>\n          </logger>\n          <logger>\n            <name>DatabaseOrdinary (test)</name>\n            <level>none</level>\n          </logger>\n        </levels>\n        --\x3e\n    </logger>\n\n    \x3c!-- It is the name that will be shown in the clickhouse-client.\n         By default, anything with \"production\" will be highlighted in red in query prompt.\n    --\x3e\n    \x3c!--display_name>production</display_name--\x3e\n\n    \x3c!-- Port for HTTP API. See also 'https_port' for secure connections.\n         This interface is also used by ODBC and JDBC drivers (DataGrip, Dbeaver, ...)\n         and by most of web interfaces (embedded UI, Grafana, Redash, ...).\n      --\x3e\n    <http_port>8123</http_port>\n\n    \x3c!-- Port for interaction by native protocol with:\n         - clickhouse-client and other native ClickHouse tools (clickhouse-benchmark, clickhouse-copier);\n         - clickhouse-server with other clickhouse-servers for distributed query processing;\n         - ClickHouse drivers and applications supporting native protocol\n         (this protocol is also informally called as \"the TCP protocol\");\n         See also 'tcp_port_secure' for secure connections.\n    --\x3e\n    <tcp_port>9000</tcp_port>\n\n    \x3c!-- Compatibility with MySQL protocol.\n         ClickHouse will pretend to be MySQL for applications connecting to this port.\n    --\x3e\n    <mysql_port>9004</mysql_port>\n\n    \x3c!-- Compatibility with PostgreSQL protocol.\n         ClickHouse will pretend to be PostgreSQL for applications connecting to this port.\n    --\x3e\n    <postgresql_port>9005</postgresql_port>\n\n    \x3c!-- HTTP API with TLS (HTTPS).\n         You have to configure certificate to enable this interface.\n         See the openSSL section below.\n    --\x3e\n    \x3c!-- <https_port>8443</https_port> --\x3e\n\n    \x3c!-- Native interface with TLS.\n         You have to configure certificate to enable this interface.\n         See the openSSL section below.\n    --\x3e\n    \x3c!-- <tcp_port_secure>9440</tcp_port_secure> --\x3e\n\n    \x3c!-- Native interface wrapped with PROXYv1 protocol\n         PROXYv1 header sent for every connection.\n         ClickHouse will extract information about proxy-forwarded client address from the header.\n    --\x3e\n    \x3c!-- <tcp_with_proxy_port>9011</tcp_with_proxy_port> --\x3e\n\n    \x3c!-- Port for communication between replicas. Used for data exchange.\n         It provides low-level data access between servers.\n         This port should not be accessible from untrusted networks.\n         See also 'interserver_http_credentials'.\n         Data transferred over connections to this port should not go through untrusted networks.\n         See also 'interserver_https_port'.\n      --\x3e\n    <interserver_http_port>9009</interserver_http_port>\n\n    \x3c!-- Port for communication between replicas with TLS.\n         You have to configure certificate to enable this interface.\n         See the openSSL section below.\n         See also 'interserver_http_credentials'.\n      --\x3e\n    \x3c!-- <interserver_https_port>9010</interserver_https_port> --\x3e\n\n    \x3c!-- Hostname that is used by other replicas to request this server.\n         If not specified, than it is determined analogous to 'hostname -f' command.\n         This setting could be used to switch replication to another network interface\n         (the server may be connected to multiple networks via multiple addresses)\n      --\x3e\n    \x3c!--\n    <interserver_http_host>example.yandex.ru</interserver_http_host>\n    --\x3e\n\n    \x3c!-- You can specify credentials for authenthication between replicas.\n         This is required when interserver_https_port is accessible from untrusted networks,\n         and also recommended to avoid SSRF attacks from possibly compromised services in your network.\n      --\x3e\n    \x3c!--<interserver_http_credentials>\n        <user>interserver</user>\n        <password></password>\n    </interserver_http_credentials>--\x3e\n\n    \x3c!-- Listen specified address.\n         Use :: (wildcard IPv6 address), if you want to accept connections both with IPv4 and IPv6 from everywhere.\n         Notes:\n         If you open connections from wildcard address, make sure that at least one of the following measures applied:\n         - server is protected by firewall and not accessible from untrusted networks;\n         - all users are restricted to subset of network addresses (see users.xml);\n         - all users have strong passwords, only secure (TLS) interfaces are accessible, or connections are only made via TLS interfaces.\n         - users without password have readonly access.\n         See also: https://www.shodan.io/search?query=clickhouse\n      --\x3e\n    \x3c!-- <listen_host>::</listen_host> --\x3e\n\n    \x3c!-- Same for hosts without support for IPv6: --\x3e\n    \x3c!-- <listen_host>0.0.0.0</listen_host> --\x3e\n\n    \x3c!-- Default values - try listen localhost on IPv4 and IPv6. --\x3e\n    \x3c!--\n    <listen_host>::1</listen_host>\n    <listen_host>127.0.0.1</listen_host>\n    --\x3e\n\n    \x3c!-- Don't exit if IPv6 or IPv4 networks are unavailable while trying to listen. --\x3e\n    \x3c!-- <listen_try>0</listen_try> --\x3e\n\n    \x3c!-- Allow multiple servers to listen on the same address:port. This is not recommended.\n      --\x3e\n    \x3c!-- <listen_reuse_port>0</listen_reuse_port> --\x3e\n\n    \x3c!-- <listen_backlog>64</listen_backlog> --\x3e\n\n    <max_connections>4096</max_connections>\n\n    \x3c!-- For 'Connection: keep-alive' in HTTP 1.1 --\x3e\n    <keep_alive_timeout>3</keep_alive_timeout>\n\n    \x3c!-- gRPC protocol (see src/Server/grpc_protos/clickhouse_grpc.proto for the API) --\x3e\n    \x3c!-- <grpc_port>9100</grpc_port> --\x3e\n    <grpc>\n        <enable_ssl>false</enable_ssl>\n\n        \x3c!-- The following two files are used only if enable_ssl=1 --\x3e\n        <ssl_cert_file>/path/to/ssl_cert_file</ssl_cert_file>\n        <ssl_key_file>/path/to/ssl_key_file</ssl_key_file>\n\n        \x3c!-- Whether server will request client for a certificate --\x3e\n        <ssl_require_client_auth>false</ssl_require_client_auth>\n\n        \x3c!-- The following file is used only if ssl_require_client_auth=1 --\x3e\n        <ssl_ca_cert_file>/path/to/ssl_ca_cert_file</ssl_ca_cert_file>\n\n        \x3c!-- Default compression algorithm (applied if client doesn't specify another algorithm).\n             Supported algorithms: none, deflate, gzip, stream_gzip --\x3e\n        <compression>deflate</compression>\n\n        \x3c!-- Default compression level (applied if client doesn't specify another level).\n             Supported levels: none, low, medium, high --\x3e\n        <compression_level>medium</compression_level>\n\n        \x3c!-- Send/receive message size limits in bytes. -1 means unlimited --\x3e\n        <max_send_message_size>-1</max_send_message_size>\n        <max_receive_message_size>-1</max_receive_message_size>\n\n        \x3c!-- Enable if you want very detailed logs --\x3e\n        <verbose_logs>false</verbose_logs>\n    </grpc>\n\n    \x3c!-- Used with https_port and tcp_port_secure. Full ssl options list: https://github.com/ClickHouse-Extras/poco/blob/master/NetSSL_OpenSSL/include/Poco/Net/SSLManager.h#L71 --\x3e\n    <openSSL>\n        <server> \x3c!-- Used for https server AND secure tcp port --\x3e\n            \x3c!-- openssl req -subj \"/CN=localhost\" -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout /etc/clickhouse-server/server.key -out /etc/clickhouse-server/server.crt --\x3e\n            <certificateFile>/etc/clickhouse-server/server.crt</certificateFile>\n            <privateKeyFile>/etc/clickhouse-server/server.key</privateKeyFile>\n            \x3c!-- dhparams are optional. You can delete the <dhParamsFile> element.\n                 To generate dhparams, use the following command:\n                  openssl dhparam -out /etc/clickhouse-server/dhparam.pem 4096\n                 Only file format with BEGIN DH PARAMETERS is supported.\n              --\x3e\n            <dhParamsFile>/etc/clickhouse-server/dhparam.pem</dhParamsFile>\n            <verificationMode>none</verificationMode>\n            <loadDefaultCAFile>true</loadDefaultCAFile>\n            <cacheSessions>true</cacheSessions>\n            <disableProtocols>sslv2,sslv3</disableProtocols>\n            <preferServerCiphers>true</preferServerCiphers>\n        </server>\n\n        <client> \x3c!-- Used for connecting to https dictionary source and secured Zookeeper communication --\x3e\n            <loadDefaultCAFile>true</loadDefaultCAFile>\n            <cacheSessions>true</cacheSessions>\n            <disableProtocols>sslv2,sslv3</disableProtocols>\n            <preferServerCiphers>true</preferServerCiphers>\n            \x3c!-- Use for self-signed: <verificationMode>none</verificationMode> --\x3e\n            <invalidCertificateHandler>\n                \x3c!-- Use for self-signed: <name>AcceptCertificateHandler</name> --\x3e\n                <name>RejectCertificateHandler</name>\n            </invalidCertificateHandler>\n        </client>\n    </openSSL>\n\n    \x3c!-- Default root page on http[s] server. For example load UI from https://tabix.io/ when opening http://localhost:8123 --\x3e\n    \x3c!--\n    <http_server_default_response><![CDATA[<html ng-app=\"SMI2\"><head><base href=\"http://ui.tabix.io/\"></head><body><div ui-view=\"\" class=\"content-ui\"></div><script src=\"http://loader.tabix.io/master.js\"><\/script></body></html>]]></http_server_default_response>\n    --\x3e\n\n    \x3c!-- Maximum number of concurrent queries. --\x3e\n    <max_concurrent_queries>1000</max_concurrent_queries>\n\n    \x3c!-- Maximum memory usage (resident set size) for server process.\n         Zero value or unset means default. Default is \"max_server_memory_usage_to_ram_ratio\" of available physical RAM.\n         If the value is larger than \"max_server_memory_usage_to_ram_ratio\" of available physical RAM, it will be cut down.\n\n         The constraint is checked on query execution time.\n         If a query tries to allocate memory and the current memory usage plus allocation is greater\n          than specified threshold, exception will be thrown.\n\n         It is not practical to set this constraint to small values like just a few gigabytes,\n          because memory allocator will keep this amount of memory in caches and the server will deny service of queries.\n      --\x3e\n    <max_server_memory_usage>0</max_server_memory_usage>\n\n    \x3c!-- Maximum number of threads in the Global thread pool.\n    This will default to a maximum of 10000 threads if not specified.\n    This setting will be useful in scenarios where there are a large number\n    of distributed queries that are running concurrently but are idling most\n    of the time, in which case a higher number of threads might be required.\n    --\x3e\n\n    <max_thread_pool_size>10000</max_thread_pool_size>\n\n    \x3c!-- On memory constrained environments you may have to set this to value larger than 1.\n      --\x3e\n    <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>\n\n    \x3c!-- Simple server-wide memory profiler. Collect a stack trace at every peak allocation step (in bytes).\n         Data will be stored in system.trace_log table with query_id = empty string.\n         Zero means disabled.\n      --\x3e\n    <total_memory_profiler_step>4194304</total_memory_profiler_step>\n\n    \x3c!-- Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type.\n         The probability is for every alloc/free regardless to the size of the allocation.\n         Note that sampling happens only when the amount of untracked memory exceeds the untracked memory limit,\n          which is 4 MiB by default but can be lowered if 'total_memory_profiler_step' is lowered.\n         You may want to set 'total_memory_profiler_step' to 1 for extra fine grained sampling.\n      --\x3e\n    <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>\n\n    \x3c!-- Set limit on number of open files (default: maximum). This setting makes sense on Mac OS X because getrlimit() fails to retrieve\n         correct maximum value. --\x3e\n    \x3c!-- <max_open_files>262144</max_open_files> --\x3e\n\n    \x3c!-- Size of cache of uncompressed blocks of data, used in tables of MergeTree family.\n         In bytes. Cache is single for server. Memory is allocated only on demand.\n         Cache is used when 'use_uncompressed_cache' user setting turned on (off by default).\n         Uncompressed cache is advantageous only for very short queries and in rare cases.\n\n         Note: uncompressed cache can be pointless for lz4, because memory bandwidth\n         is slower than multi-core decompression on some server configurations.\n         Enabling it can sometimes paradoxically make queries slower.\n      --\x3e\n    <uncompressed_cache_size>8589934592</uncompressed_cache_size>\n\n    \x3c!-- Approximate size of mark cache, used in tables of MergeTree family.\n         In bytes. Cache is single for server. Memory is allocated only on demand.\n         You should not lower this value.\n      --\x3e\n    <mark_cache_size>5368709120</mark_cache_size>\n\n\n    \x3c!-- If you enable the `min_bytes_to_use_mmap_io` setting,\n         the data in MergeTree tables can be read with mmap to avoid copying from kernel to userspace.\n         It makes sense only for large files and helps only if data reside in page cache.\n         To avoid frequent open/mmap/munmap/close calls (which are very expensive due to consequent page faults)\n         and to reuse mappings from several threads and queries,\n         the cache of mapped files is maintained. Its size is the number of mapped regions (usually equal to the number of mapped files).\n         The amount of data in mapped files can be monitored\n         in system.metrics, system.metric_log by the MMappedFiles, MMappedFileBytes metrics\n         and in system.asynchronous_metrics, system.asynchronous_metrics_log by the MMapCacheCells metric,\n         and also in system.events, system.processes, system.query_log, system.query_thread_log by the\n         CreatedReadBufferMMap, CreatedReadBufferMMapFailed, MMappedFileCacheHits, MMappedFileCacheMisses events.\n         Note that the amount of data in mapped files does not consume memory directly and is not accounted\n         in query or server memory usage - because this memory can be discarded similar to OS page cache.\n         The cache is dropped (the files are closed) automatically on removal of old parts in MergeTree,\n         also it can be dropped manually by the SYSTEM DROP MMAP CACHE query.\n      --\x3e\n    <mmap_cache_size>1000</mmap_cache_size>\n\n\n    \x3c!-- Path to data directory, with trailing slash. --\x3e\n    <path>/var/lib/clickhouse/</path>\n\n    \x3c!-- Path to temporary data for processing hard queries. --\x3e\n    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>\n\n    \x3c!-- Policy from the <storage_configuration> for the temporary files.\n         If not set <tmp_path> is used, otherwise <tmp_path> is ignored.\n\n         Notes:\n         - move_factor              is ignored\n         - keep_free_space_bytes    is ignored\n         - max_data_part_size_bytes is ignored\n         - you must have exactly one volume in that policy\n    --\x3e\n    \x3c!-- <tmp_policy>tmp</tmp_policy> --\x3e\n\n    \x3c!-- Directory with user provided files that are accessible by 'file' table function. --\x3e\n    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>\n\n    \x3c!-- LDAP server definitions. --\x3e\n    <ldap_servers>\n        \x3c!-- List LDAP servers with their connection parameters here to later 1) use them as authenticators for dedicated local users,\n              who have 'ldap' authentication mechanism specified instead of 'password', or to 2) use them as remote user directories.\n             Parameters:\n                host - LDAP server hostname or IP, this parameter is mandatory and cannot be empty.\n                port - LDAP server port, default is 636 if enable_tls is set to true, 389 otherwise.\n                bind_dn - template used to construct the DN to bind to.\n                        The resulting DN will be constructed by replacing all '{user_name}' substrings of the template with the actual\n                         user name during each authentication attempt.\n                verification_cooldown - a period of time, in seconds, after a successful bind attempt, during which a user will be assumed\n                         to be successfully authenticated for all consecutive requests without contacting the LDAP server.\n                        Specify 0 (the default) to disable caching and force contacting the LDAP server for each authentication request.\n                enable_tls - flag to trigger use of secure connection to the LDAP server.\n                        Specify 'no' for plain text (ldap://) protocol (not recommended).\n                        Specify 'yes' for LDAP over SSL/TLS (ldaps://) protocol (recommended, the default).\n                        Specify 'starttls' for legacy StartTLS protocol (plain text (ldap://) protocol, upgraded to TLS).\n                tls_minimum_protocol_version - the minimum protocol version of SSL/TLS.\n                        Accepted values are: 'ssl2', 'ssl3', 'tls1.0', 'tls1.1', 'tls1.2' (the default).\n                tls_require_cert - SSL/TLS peer certificate verification behavior.\n                        Accepted values are: 'never', 'allow', 'try', 'demand' (the default).\n                tls_cert_file - path to certificate file.\n                tls_key_file - path to certificate key file.\n                tls_ca_cert_file - path to CA certificate file.\n                tls_ca_cert_dir - path to the directory containing CA certificates.\n                tls_cipher_suite - allowed cipher suite (in OpenSSL notation).\n             Example:\n                <my_ldap_server>\n                    <host>localhost</host>\n                    <port>636</port>\n                    <bind_dn>uid={user_name},ou=users,dc=example,dc=com</bind_dn>\n                    <verification_cooldown>300</verification_cooldown>\n                    <enable_tls>yes</enable_tls>\n                    <tls_minimum_protocol_version>tls1.2</tls_minimum_protocol_version>\n                    <tls_require_cert>demand</tls_require_cert>\n                    <tls_cert_file>/path/to/tls_cert_file</tls_cert_file>\n                    <tls_key_file>/path/to/tls_key_file</tls_key_file>\n                    <tls_ca_cert_file>/path/to/tls_ca_cert_file</tls_ca_cert_file>\n                    <tls_ca_cert_dir>/path/to/tls_ca_cert_dir</tls_ca_cert_dir>\n                    <tls_cipher_suite>ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:AES256-GCM-SHA384</tls_cipher_suite>\n                </my_ldap_server>\n        --\x3e\n    </ldap_servers>\n\n    \x3c!-- To enable Kerberos authentication support for HTTP requests (GSS-SPNEGO), for those users who are explicitly configured\n          to authenticate via Kerberos, define a single 'kerberos' section here.\n         Parameters:\n            principal - canonical service principal name, that will be acquired and used when accepting security contexts.\n                    This parameter is optional, if omitted, the default principal will be used.\n                    This parameter cannot be specified together with 'realm' parameter.\n            realm - a realm, that will be used to restrict authentication to only those requests whose initiator's realm matches it.\n                    This parameter is optional, if omitted, no additional filtering by realm will be applied.\n                    This parameter cannot be specified together with 'principal' parameter.\n         Example:\n            <kerberos />\n         Example:\n            <kerberos>\n                <principal>HTTP/clickhouse.example.com@EXAMPLE.COM</principal>\n            </kerberos>\n         Example:\n            <kerberos>\n                <realm>EXAMPLE.COM</realm>\n            </kerberos>\n    --\x3e\n\n    \x3c!-- Sources to read users, roles, access rights, profiles of settings, quotas. --\x3e\n    <user_directories>\n        <users_xml>\n            \x3c!-- Path to configuration file with predefined users. --\x3e\n            <path>users.xml</path>\n        </users_xml>\n        <local_directory>\n            \x3c!-- Path to folder where users created by SQL commands are stored. --\x3e\n            <path>/var/lib/clickhouse/access/</path>\n        </local_directory>\n\n        \x3c!-- To add an LDAP server as a remote user directory of users that are not defined locally, define a single 'ldap' section\n              with the following parameters:\n                server - one of LDAP server names defined in 'ldap_servers' config section above.\n                        This parameter is mandatory and cannot be empty.\n                roles - section with a list of locally defined roles that will be assigned to each user retrieved from the LDAP server.\n                        If no roles are specified here or assigned during role mapping (below), user will not be able to perform any\n                         actions after authentication.\n                role_mapping - section with LDAP search parameters and mapping rules.\n                        When a user authenticates, while still bound to LDAP, an LDAP search is performed using search_filter and the\n                         name of the logged in user. For each entry found during that search, the value of the specified attribute is\n                         extracted. For each attribute value that has the specified prefix, the prefix is removed, and the rest of the\n                         value becomes the name of a local role defined in ClickHouse, which is expected to be created beforehand by\n                         CREATE ROLE command.\n                        There can be multiple 'role_mapping' sections defined inside the same 'ldap' section. All of them will be\n                         applied.\n                    base_dn - template used to construct the base DN for the LDAP search.\n                            The resulting DN will be constructed by replacing all '{user_name}' and '{bind_dn}' substrings\n                             of the template with the actual user name and bind DN during each LDAP search.\n                    scope - scope of the LDAP search.\n                            Accepted values are: 'base', 'one_level', 'children', 'subtree' (the default).\n                    search_filter - template used to construct the search filter for the LDAP search.\n                            The resulting filter will be constructed by replacing all '{user_name}', '{bind_dn}', and '{base_dn}'\n                             substrings of the template with the actual user name, bind DN, and base DN during each LDAP search.\n                            Note, that the special characters must be escaped properly in XML.\n                    attribute - attribute name whose values will be returned by the LDAP search.\n                    prefix - prefix, that will be expected to be in front of each string in the original list of strings returned by\n                             the LDAP search. Prefix will be removed from the original strings and resulting strings will be treated\n                             as local role names. Empty, by default.\n             Example:\n                <ldap>\n                    <server>my_ldap_server</server>\n                    <roles>\n                        <my_local_role1 />\n                        <my_local_role2 />\n                    </roles>\n                    <role_mapping>\n                        <base_dn>ou=groups,dc=example,dc=com</base_dn>\n                        <scope>subtree</scope>\n                        <search_filter>(&amp;(objectClass=groupOfNames)(member={bind_dn}))</search_filter>\n                        <attribute>cn</attribute>\n                        <prefix>clickhouse_</prefix>\n                    </role_mapping>\n                </ldap>\n        --\x3e\n    </user_directories>\n\n    \x3c!-- Default profile of settings. --\x3e\n    <default_profile>default</default_profile>\n\n    \x3c!-- Comma-separated list of prefixes for user-defined settings. --\x3e\n    <custom_settings_prefixes></custom_settings_prefixes>\n\n    \x3c!-- System profile of settings. This settings are used by internal processes (Distributed DDL worker and so on). --\x3e\n    \x3c!-- <system_profile>default</system_profile> --\x3e\n\n    \x3c!-- Buffer profile of settings.\n         This settings are used by Buffer storage to flush data to the underlying table.\n         Default: used from system_profile directive.\n    --\x3e\n    \x3c!-- <buffer_profile>default</buffer_profile> --\x3e\n\n    \x3c!-- Default database. --\x3e\n    <default_database>default</default_database>\n\n    \x3c!-- Server time zone could be set here.\n\n         Time zone is used when converting between String and DateTime types,\n          when printing DateTime in text formats and parsing DateTime from text,\n          it is used in date and time related functions, if specific time zone was not passed as an argument.\n\n         Time zone is specified as identifier from IANA time zone database, like UTC or Africa/Abidjan.\n         If not specified, system time zone at server startup is used.\n\n         Please note, that server could display time zone alias instead of specified name.\n         Example: W-SU is an alias for Europe/Moscow and Zulu is an alias for UTC.\n    --\x3e\n    \x3c!-- <timezone>Europe/Moscow</timezone> --\x3e\n\n    \x3c!-- You can specify umask here (see \"man umask\"). Server will apply it on startup.\n         Number is always parsed as octal. Default umask is 027 (other users cannot read logs, data files, etc; group can only read).\n    --\x3e\n    \x3c!-- <umask>022</umask> --\x3e\n\n    \x3c!-- Perform mlockall after startup to lower first queries latency\n          and to prevent clickhouse executable from being paged out under high IO load.\n         Enabling this option is recommended but will lead to increased startup time for up to a few seconds.\n    --\x3e\n    <mlock_executable>true</mlock_executable>\n\n    \x3c!-- Reallocate memory for machine code (\"text\") using huge pages. Highly experimental. --\x3e\n    <remap_executable>false</remap_executable>\n\n    \x3c!-- Configuration of clusters that could be used in Distributed tables.\n         https://clickhouse.tech/docs/en/operations/table_engines/distributed/\n      --\x3e\n    <remote_servers>\n        \x3c!-- Test only shard config for testing distributed storage --\x3e\n        <test_shard_localhost>\n            \x3c!-- Inter-server per-cluster secret for Distributed queries\n                 default: no secret (no authentication will be performed)\n\n                 If set, then Distributed queries will be validated on shards, so at least:\n                 - such cluster should exist on the shard,\n                 - such cluster should have the same secret.\n\n                 And also (and which is more important), the initial_user will\n                 be used as current user for the query.\n\n                 Right now the protocol is pretty simple and it only takes into account:\n                 - cluster name\n                 - query\n\n                 Also it will be nice if the following will be implemented:\n                 - source hostname (see interserver_http_host), but then it will depends from DNS,\n                   it can use IP address instead, but then the you need to get correct on the initiator node.\n                 - target hostname / ip address (same notes as for source hostname)\n                 - time-based security tokens\n            --\x3e\n            \x3c!-- <secret></secret> --\x3e\n\n            <shard>\n                \x3c!-- Optional. Whether to write data to just one of the replicas. Default: false (write data to all replicas). --\x3e\n                \x3c!-- <internal_replication>false</internal_replication> --\x3e\n                \x3c!-- Optional. Shard weight when writing data. Default: 1. --\x3e\n                \x3c!-- <weight>1</weight> --\x3e\n                <replica>\n                    <host>localhost</host>\n                    <port>9000</port>\n                    \x3c!-- Optional. Priority of the replica for load_balancing. Default: 1 (less value has more priority). --\x3e\n                    \x3c!-- <priority>1</priority> --\x3e\n                </replica>\n            </shard>\n        </test_shard_localhost>\n        <test_cluster_two_shards_localhost>\n             <shard>\n                 <replica>\n                     <host>localhost</host>\n                     <port>9000</port>\n                 </replica>\n             </shard>\n             <shard>\n                 <replica>\n                     <host>localhost</host>\n                     <port>9000</port>\n                 </replica>\n             </shard>\n        </test_cluster_two_shards_localhost>\n        <test_cluster_two_shards>\n            <shard>\n                <replica>\n                    <host>127.0.0.1</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <replica>\n                    <host>127.0.0.2</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n        </test_cluster_two_shards>\n        <test_cluster_two_shards_internal_replication>\n            <shard>\n                <internal_replication>true</internal_replication>\n                <replica>\n                    <host>127.0.0.1</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <internal_replication>true</internal_replication>\n                <replica>\n                    <host>127.0.0.2</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n        </test_cluster_two_shards_internal_replication>\n        <test_shard_localhost_secure>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>9440</port>\n                    <secure>1</secure>\n                </replica>\n            </shard>\n        </test_shard_localhost_secure>\n        <test_unavailable_shard>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>1</port>\n                </replica>\n            </shard>\n        </test_unavailable_shard>\n    </remote_servers>\n\n    \x3c!-- The list of hosts allowed to use in URL-related storage engines and table functions.\n        If this section is not present in configuration, all hosts are allowed.\n    --\x3e\n    \x3c!--<remote_url_allow_hosts>--\x3e\n        \x3c!-- Host should be specified exactly as in URL. The name is checked before DNS resolution.\n            Example: \"yandex.ru\", \"yandex.ru.\" and \"www.yandex.ru\" are different hosts.\n                    If port is explicitly specified in URL, the host:port is checked as a whole.\n                    If host specified here without port, any port with this host allowed.\n                    \"yandex.ru\" -> \"yandex.ru:443\", \"yandex.ru:80\" etc. is allowed, but \"yandex.ru:80\" -> only \"yandex.ru:80\" is allowed.\n            If the host is specified as IP address, it is checked as specified in URL. Example: \"[2a02:6b8:a::a]\".\n            If there are redirects and support for redirects is enabled, every redirect (the Location field) is checked.\n        --\x3e\n\n        \x3c!-- Regular expression can be specified. RE2 engine is used for regexps.\n            Regexps are not aligned: don't forget to add ^ and $. Also don't forget to escape dot (.) metacharacter\n            (forgetting to do so is a common source of error).\n        --\x3e\n    \x3c!--</remote_url_allow_hosts>--\x3e\n\n    \x3c!-- If element has 'incl' attribute, then for it's value will be used corresponding substitution from another file.\n         By default, path to file with substitutions is /etc/metrika.xml. It could be changed in config in 'include_from' element.\n         Values for substitutions are specified in /yandex/name_of_substitution elements in that file.\n      --\x3e\n\n    \x3c!-- ZooKeeper is used to store metadata about replicas, when using Replicated tables.\n         Optional. If you don't use replicated tables, you could omit that.\n\n         See https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/\n      --\x3e\n\n    \x3c!--\n    <zookeeper>\n        <node>\n            <host>example1</host>\n            <port>2181</port>\n        </node>\n        <node>\n            <host>example2</host>\n            <port>2181</port>\n        </node>\n        <node>\n            <host>example3</host>\n            <port>2181</port>\n        </node>\n    </zookeeper>\n    --\x3e\n\n    \x3c!-- Substitutions for parameters of replicated tables.\n          Optional. If you don't use replicated tables, you could omit that.\n\n         See https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/#creating-replicated-tables\n      --\x3e\n    \x3c!--\n    <macros>\n        <shard>01</shard>\n        <replica>example01-01-1</replica>\n    </macros>\n    --\x3e\n\n\n    \x3c!-- Reloading interval for embedded dictionaries, in seconds. Default: 3600. --\x3e\n    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>\n\n\n    \x3c!-- Maximum session timeout, in seconds. Default: 3600. --\x3e\n    <max_session_timeout>3600</max_session_timeout>\n\n    \x3c!-- Default session timeout, in seconds. Default: 60. --\x3e\n    <default_session_timeout>60</default_session_timeout>\n\n    \x3c!-- Sending data to Graphite for monitoring. Several sections can be defined. --\x3e\n    \x3c!--\n        interval - send every X second\n        root_path - prefix for keys\n        hostname_in_path - append hostname to root_path (default = true)\n        metrics - send data from table system.metrics\n        events - send data from table system.events\n        asynchronous_metrics - send data from table system.asynchronous_metrics\n    --\x3e\n    \x3c!--\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>60</interval>\n        <root_path>one_min</root_path>\n        <hostname_in_path>true</hostname_in_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <events_cumulative>false</events_cumulative>\n        <asynchronous_metrics>true</asynchronous_metrics>\n    </graphite>\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>1</interval>\n        <root_path>one_sec</root_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <events_cumulative>false</events_cumulative>\n        <asynchronous_metrics>false</asynchronous_metrics>\n    </graphite>\n    --\x3e\n\n    \x3c!-- Serve endpoint for Prometheus monitoring. --\x3e\n    \x3c!--\n        endpoint - mertics path (relative to root, statring with \"/\")\n        port - port to setup server. If not defined or 0 than http_port used\n        metrics - send data from table system.metrics\n        events - send data from table system.events\n        asynchronous_metrics - send data from table system.asynchronous_metrics\n        status_info - send data from different component from CH, ex: Dictionaries status\n    --\x3e\n    \x3c!--\n    <prometheus>\n        <endpoint>/metrics</endpoint>\n        <port>9363</port>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <asynchronous_metrics>true</asynchronous_metrics>\n        <status_info>true</status_info>\n    </prometheus>\n    --\x3e\n\n    \x3c!-- Query log. Used only for queries with setting log_queries = 1. --\x3e\n    <query_log>\n        \x3c!-- What table to insert data. If table is not exist, it will be created.\n             When query log structure is changed after system update,\n              then old table will be renamed and new table will be created automatically.\n        --\x3e\n        <database>system</database>\n        <table>query_log</table>\n        \x3c!--\n            PARTITION BY expr: https://clickhouse.yandex/docs/en/table_engines/mergetree-family/custom_partitioning_key/\n            Example:\n                event_date\n                toMonday(event_date)\n                toYYYYMM(event_date)\n                toStartOfHour(event_time)\n        --\x3e\n        <partition_by>toYYYYMM(event_date)</partition_by>\n        \x3c!--\n            Table TTL specification: https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/#mergetree-table-ttl\n            Example:\n                event_date + INTERVAL 1 WEEK\n                event_date + INTERVAL 7 DAY DELETE\n                event_date + INTERVAL 2 WEEK TO DISK 'bbb'\n\n        <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>\n        --\x3e\n\n        \x3c!-- Instead of partition_by, you can provide full engine expression (starting with ENGINE = ) with parameters,\n             Example: <engine>ENGINE = MergeTree PARTITION BY toYYYYMM(event_date) ORDER BY (event_date, event_time) SETTINGS index_granularity = 1024</engine>\n          --\x3e\n\n        \x3c!-- Interval of flushing data. --\x3e\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_log>\n\n    \x3c!-- Trace log. Stores stack traces collected by query profilers.\n         See query_profiler_real_time_period_ns and query_profiler_cpu_time_period_ns settings. --\x3e\n    <trace_log>\n        <database>system</database>\n        <table>trace_log</table>\n\n        <partition_by>toYYYYMM(event_date)</partition_by>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </trace_log>\n\n    \x3c!-- Query thread log. Has information about all threads participated in query execution.\n         Used only for queries with setting log_query_threads = 1. --\x3e\n    <query_thread_log>\n        <database>system</database>\n        <table>query_thread_log</table>\n        <partition_by>toYYYYMM(event_date)</partition_by>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_thread_log>\n\n    \x3c!-- Uncomment if use part log.\n         Part log contains information about all actions with parts in MergeTree tables (creation, deletion, merges, downloads).\n    <part_log>\n        <database>system</database>\n        <table>part_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </part_log>\n    --\x3e\n\n    \x3c!-- Uncomment to write text log into table.\n         Text log contains all information from usual server log but stores it in structured and efficient way.\n         The level of the messages that goes to the table can be limited (<level>), if not specified all messages will go to the table.\n    <text_log>\n        <database>system</database>\n        <table>text_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n        <level></level>\n    </text_log>\n    --\x3e\n\n    \x3c!-- Metric log contains rows with current values of ProfileEvents, CurrentMetrics collected with \"collect_interval_milliseconds\" interval. --\x3e\n    <metric_log>\n        <database>system</database>\n        <table>metric_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n    </metric_log>\n\n    \x3c!--\n        Asynchronous metric log contains values of metrics from\n        system.asynchronous_metrics.\n    --\x3e\n    <asynchronous_metric_log>\n        <database>system</database>\n        <table>asynchronous_metric_log</table>\n        \x3c!--\n            Asynchronous metrics are updated once a minute, so there is\n            no need to flush more often.\n        --\x3e\n        <flush_interval_milliseconds>60000</flush_interval_milliseconds>\n    </asynchronous_metric_log>\n\n    \x3c!--\n        OpenTelemetry log contains OpenTelemetry trace spans.\n    --\x3e\n    <opentelemetry_span_log>\n        \x3c!--\n            The default table creation code is insufficient, this <engine> spec\n            is a workaround. There is no 'event_time' for this log, but two times,\n            start and finish. It is sorted by finish time, to avoid inserting\n            data too far away in the past (probably we can sometimes insert a span\n            that is seconds earlier than the last span in the table, due to a race\n            between several spans inserted in parallel). This gives the spans a\n            global order that we can use to e.g. retry insertion into some external\n            system.\n        --\x3e\n        <engine>\n            engine MergeTree\n            partition by toYYYYMM(finish_date)\n            order by (finish_date, finish_time_us, trace_id)\n        </engine>\n        <database>system</database>\n        <table>opentelemetry_span_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </opentelemetry_span_log>\n\n\n    \x3c!-- Crash log. Stores stack traces for fatal errors.\n         This table is normally empty. --\x3e\n    <crash_log>\n        <database>system</database>\n        <table>crash_log</table>\n\n        <partition_by />\n        <flush_interval_milliseconds>1000</flush_interval_milliseconds>\n    </crash_log>\n\n    \x3c!-- Parameters for embedded dictionaries, used in Yandex.Metrica.\n         See https://clickhouse.yandex/docs/en/dicts/internal_dicts/\n    --\x3e\n\n    \x3c!-- Path to file with region hierarchy. --\x3e\n    \x3c!-- <path_to_regions_hierarchy_file>/opt/geo/regions_hierarchy.txt</path_to_regions_hierarchy_file> --\x3e\n\n    \x3c!-- Path to directory with files containing names of regions --\x3e\n    \x3c!-- <path_to_regions_names_files>/opt/geo/</path_to_regions_names_files> --\x3e\n\n\n    \x3c!-- <top_level_domains_path>/var/lib/clickhouse/top_level_domains/</top_level_domains_path> --\x3e\n    \x3c!-- Custom TLD lists.\n         Format: <name>/path/to/file</name>\n\n         Changes will not be applied w/o server restart.\n         Path to the list is under top_level_domains_path (see above).\n    --\x3e\n    <top_level_domains_lists>\n        \x3c!--\n        <public_suffix_list>/path/to/public_suffix_list.dat</public_suffix_list>\n        --\x3e\n    </top_level_domains_lists>\n\n    \x3c!-- Configuration of external dictionaries. See:\n         https://clickhouse.tech/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts\n    --\x3e\n    <dictionaries_config>*_dictionary.xml</dictionaries_config>\n\n    \x3c!-- Uncomment if you want data to be compressed 30-100% better.\n         Don't do that if you just started using ClickHouse.\n      --\x3e\n    \x3c!--\n    <compression>\n        <!- - Set of variants. Checked in order. Last matching case wins. If nothing matches, lz4 will be used. - ->\n        <case>\n\n            <!- - Conditions. All must be satisfied. Some conditions may be omitted. - ->\n            <min_part_size>10000000000</min_part_size>        <!- - Min part size in bytes. - ->\n            <min_part_size_ratio>0.01</min_part_size_ratio>   <!- - Min size of part relative to whole table size. - ->\n\n            <!- - What compression method to use. - ->\n            <method>zstd</method>\n        </case>\n    </compression>\n    --\x3e\n\n    \x3c!-- Allow to execute distributed DDL queries (CREATE, DROP, ALTER, RENAME) on cluster.\n         Works only if ZooKeeper is enabled. Comment it if such functionality isn't required. --\x3e\n    <distributed_ddl>\n        \x3c!-- Path in ZooKeeper to queue with DDL queries --\x3e\n        <path>/clickhouse/task_queue/ddl</path>\n\n        \x3c!-- Settings from this profile will be used to execute DDL queries --\x3e\n        \x3c!-- <profile>default</profile> --\x3e\n\n        \x3c!-- Controls how much ON CLUSTER queries can be run simultaneously. --\x3e\n        \x3c!-- <pool_size>1</pool_size> --\x3e\n\n        \x3c!--\n             Cleanup settings (active tasks will not be removed)\n        --\x3e\n\n        \x3c!-- Controls task TTL (default 1 week) --\x3e\n        \x3c!-- <task_max_lifetime>604800</task_max_lifetime> --\x3e\n\n        \x3c!-- Controls how often cleanup should be performed (in seconds) --\x3e\n        \x3c!-- <cleanup_delay_period>60</cleanup_delay_period> --\x3e\n\n        \x3c!-- Controls how many tasks could be in the queue --\x3e\n        \x3c!-- <max_tasks_in_queue>1000</max_tasks_in_queue> --\x3e\n    </distributed_ddl>\n\n    \x3c!-- Settings to fine tune MergeTree tables. See documentation in source code, in MergeTreeSettings.h --\x3e\n    \x3c!--\n    <merge_tree>\n        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>\n    </merge_tree>\n    --\x3e\n\n    \x3c!-- Protection from accidental DROP.\n         If size of a MergeTree table is greater than max_table_size_to_drop (in bytes) than table could not be dropped with any DROP query.\n         If you want do delete one table and don't want to change clickhouse-server config, you could create special file <clickhouse-path>/flags/force_drop_table and make DROP once.\n         By default max_table_size_to_drop is 50GB; max_table_size_to_drop=0 allows to DROP any tables.\n         The same for max_partition_size_to_drop.\n         Uncomment to disable protection.\n    --\x3e\n    \x3c!-- <max_table_size_to_drop>0</max_table_size_to_drop> --\x3e\n    \x3c!-- <max_partition_size_to_drop>0</max_partition_size_to_drop> --\x3e\n\n    \x3c!-- Example of parameters for GraphiteMergeTree table engine --\x3e\n    <graphite_rollup_example>\n        <pattern>\n            <regexp>click_cost</regexp>\n            <function>any</function>\n            <retention>\n                <age>0</age>\n                <precision>3600</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>60</precision>\n            </retention>\n        </pattern>\n        <default>\n            <function>max</function>\n            <retention>\n                <age>0</age>\n                <precision>60</precision>\n            </retention>\n            <retention>\n                <age>3600</age>\n                <precision>300</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>3600</precision>\n            </retention>\n        </default>\n    </graphite_rollup_example>\n\n    \x3c!-- Directory in <clickhouse-path> containing schema files for various input formats.\n         The directory will be created if it doesn't exist.\n      --\x3e\n    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>\n\n    \x3c!-- Default query masking rules, matching lines would be replaced with something else in the logs\n        (both text logs and system.query_log).\n        name - name for the rule (optional)\n        regexp - RE2 compatible regular expression (mandatory)\n        replace - substitution string for sensitive data (optional, by default - six asterisks)\n    --\x3e\n    <query_masking_rules>\n        <rule>\n            <name>hide encrypt/decrypt arguments</name>\n            <regexp>((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\\s*\\(\\s*(?:'(?:\\\\'|.)+'|.*?)\\s*\\)</regexp>\n            \x3c!-- or more secure, but also more invasive:\n                (aes_\\w+)\\s*\\(.*\\)\n            --\x3e\n            <replace>\\1(???)</replace>\n        </rule>\n    </query_masking_rules>\n\n    \x3c!-- Uncomment to use custom http handlers.\n        rules are checked from top to bottom, first match runs the handler\n            url - to match request URL, you can use 'regex:' prefix to use regex match(optional)\n            methods - to match request method, you can use commas to separate multiple method matches(optional)\n            headers - to match request headers, match each child element(child element name is header name), you can use 'regex:' prefix to use regex match(optional)\n        handler is request handler\n            type - supported types: static, dynamic_query_handler, predefined_query_handler\n            query - use with predefined_query_handler type, executes query when the handler is called\n            query_param_name - use with dynamic_query_handler type, extracts and executes the value corresponding to the <query_param_name> value in HTTP request params\n            status - use with static type, response status code\n            content_type - use with static type, response content-type\n            response_content - use with static type, Response content sent to client, when using the prefix 'file://' or 'config://', find the content from the file or configuration send to client.\n\n    <http_handlers>\n        <rule>\n            <url>/</url>\n            <methods>POST,GET</methods>\n            <headers><pragma>no-cache</pragma></headers>\n            <handler>\n                <type>dynamic_query_handler</type>\n                <query_param_name>query</query_param_name>\n            </handler>\n        </rule>\n\n        <rule>\n            <url>/predefined_query</url>\n            <methods>POST,GET</methods>\n            <handler>\n                <type>predefined_query_handler</type>\n                <query>SELECT * FROM system.settings</query>\n            </handler>\n        </rule>\n\n        <rule>\n            <handler>\n                <type>static</type>\n                <status>200</status>\n                <content_type>text/plain; charset=UTF-8</content_type>\n                <response_content>config://http_server_default_response</response_content>\n            </handler>\n        </rule>\n    </http_handlers>\n    --\x3e\n\n    <send_crash_reports>\n        \x3c!-- Changing <enabled> to true allows sending crash reports to --\x3e\n        \x3c!-- the ClickHouse core developers team via Sentry https://sentry.io --\x3e\n        \x3c!-- Doing so at least in pre-production environments is highly appreciated --\x3e\n        <enabled>false</enabled>\n        \x3c!-- Change <anonymize> to true if you don't feel comfortable attaching the server hostname to the crash report --\x3e\n        <anonymize>false</anonymize>\n        \x3c!-- Default endpoint should be changed to different Sentry DSN only if you have --\x3e\n        \x3c!-- some in-house engineers or hired consultants who're going to debug ClickHouse issues for you --\x3e\n        <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>\n    </send_crash_reports>\n\n    \x3c!-- Uncomment to disable ClickHouse internal DNS caching. --\x3e\n    \x3c!-- <disable_internal_dns_cache>1</disable_internal_dns_cache> --\x3e\n</yandex>\n\n\n\n# users.xml\n\n<?xml version=\"1.0\"?>\n<yandex>\n    \x3c!-- Profiles of settings. --\x3e\n    <profiles>\n        \x3c!-- Default settings. --\x3e\n        <default>\n            \x3c!-- Maximum memory usage for processing single query, in bytes. --\x3e\n            <max_memory_usage>10000000000</max_memory_usage>\n\n            \x3c!-- How to choose between replicas during distributed query processing.\n                 random - choose random replica from set of replicas with minimum number of errors\n                 nearest_hostname - from set of replicas with minimum number of errors, choose replica\n                  with minimum number of different symbols between replica's hostname and local hostname\n                  (Hamming distance).\n                 in_order - first live replica is chosen in specified order.\n                 first_or_random - if first replica one has higher number of errors, pick a random one from replicas with minimum number of errors.\n            --\x3e\n            <load_balancing>random</load_balancing>\n            <max_query_size>1073741824</max_query_size>\n            <max_ast_elements>10000000</max_ast_elements>\n            <max_expanded_ast_elements>10000000</max_expanded_ast_elements>\n        </default>\n\n        \x3c!-- Profile that allows only read queries. --\x3e\n        <readonly>\n            <readonly>1</readonly>\n        </readonly>\n    </profiles>\n\n    \x3c!-- Users and ACL. --\x3e\n    <users>\n        \x3c!-- If user name was not specified, 'default' user is used. --\x3e\n        <default>\n            \x3c!-- Password could be specified in plaintext or in SHA256 (in hex format).\n\n                 If you want to specify password in plaintext (not recommended), place it in 'password' element.\n                 Example: <password>qwerty</password>.\n                 Password could be empty.\n\n                 If you want to specify SHA256, place it in 'password_sha256_hex' element.\n                 Example: <password_sha256_hex>65e84be33532fb784c48129675f9eff3a682b27168c0ea744b2cf58ee02337c5</password_sha256_hex>\n                 Restrictions of SHA256: impossibility to connect to ClickHouse using MySQL JS client (as of July 2019).\n\n                 If you want to specify double SHA1, place it in 'password_double_sha1_hex' element.\n                 Example: <password_double_sha1_hex>e395796d6546b1b65db9d665cd43f0e858dd4303</password_double_sha1_hex>\n\n                 If you want to specify a previously defined LDAP server (see 'ldap_servers' in the main config) for authentication,\n                  place its name in 'server' element inside 'ldap' element.\n                 Example: <ldap><server>my_ldap_server</server></ldap>\n\n                 If you want to authenticate the user via Kerberos (assuming Kerberos is enabled, see 'kerberos' in the main config),\n                  place 'kerberos' element instead of 'password' (and similar) elements.\n                 The name part of the canonical principal name of the initiator must match the user name for authentication to succeed.\n                 You can also place 'realm' element inside 'kerberos' element to further restrict authentication to only those requests\n                  whose initiator's realm matches it. \n                 Example: <kerberos />\n                 Example: <kerberos><realm>EXAMPLE.COM</realm></kerberos>\n\n                 How to generate decent password:\n                 Execute: PASSWORD=$(base64 < /dev/urandom | head -c8); echo \"$PASSWORD\"; echo -n \"$PASSWORD\" | sha256sum | tr -d '-'\n                 In first line will be password and in second - corresponding SHA256.\n\n                 How to generate double SHA1:\n                 Execute: PASSWORD=$(base64 < /dev/urandom | head -c8); echo \"$PASSWORD\"; echo -n \"$PASSWORD\" | sha1sum | tr -d '-' | xxd -r -p | sha1sum | tr -d '-'\n                 In first line will be password and in second - corresponding double SHA1.\n            --\x3e\n            <password>Clickhouse123$</password>\n\n            \x3c!-- List of networks with open access.\n\n                 To open access from everywhere, specify:\n                    <ip>::/0</ip>\n\n                 To open access only from localhost, specify:\n                    <ip>::1</ip>\n                    <ip>127.0.0.1</ip>\n\n                 Each element of list has one of the following forms:\n                 <ip> IP-address or network mask. Examples: 213.180.204.3 or 10.0.0.1/8 or 10.0.0.1/255.255.255.0\n                     2a02:6b8::3 or 2a02:6b8::3/64 or 2a02:6b8::3/ffff:ffff:ffff:ffff::.\n                 <host> Hostname. Example: server01.yandex.ru.\n                     To check access, DNS query is performed, and all received addresses compared to peer address.\n                 <host_regexp> Regular expression for host names. Example, ^server\\d\\d-\\d\\d-\\d\\.yandex\\.ru$\n                     To check access, DNS PTR query is performed for peer address and then regexp is applied.\n                     Then, for result of PTR query, another DNS query is performed and all received addresses compared to peer address.\n                     Strongly recommended that regexp is ends with $\n                 All results of DNS requests are cached till server restart.\n            --\x3e\n            <networks>\n                <ip>::/0</ip>\n            </networks>\n\n            \x3c!-- Settings profile for user. --\x3e\n            <profile>default</profile>\n\n            \x3c!-- Quota for user. --\x3e\n            <quota>default</quota>\n\n            \x3c!-- User can create other users and grant rights to them. --\x3e\n            \x3c!-- <access_management>1</access_management> --\x3e\n        </default>\n    </users>\n\n    \x3c!-- Quotas. --\x3e\n    <quotas>\n        \x3c!-- Name of quota. --\x3e\n        <default>\n            \x3c!-- Limits for time interval. You could specify many intervals with different limits. --\x3e\n            <interval>\n                \x3c!-- Length of interval. --\x3e\n                <duration>3600</duration>\n\n                \x3c!-- No limits. Just calculate resource usage for time interval. --\x3e\n                <queries>0</queries>\n                <errors>0</errors>\n                <result_rows>0</result_rows>\n                <read_rows>0</read_rows>\n                <execution_time>0</execution_time>\n            </interval>\n        </default>\n    </quotas>\n</yandex>\n\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/clickhouse\n\\cp ./config.xml /etc/clickhouse/config.xml -f\n\\cp ./users.xml /etc/clickhouse/users.xml -f\ndocker-compose up -d\n",normalizedContent:"# clickhouse 列式储存数据库\n\n开源网址\n\n官网：https://clickhouse.com/\n\ngithub：https://github.com/clickhouse/clickhouse\n\n\n# 简介\n\n\n\n> clickhouse 是俄罗斯第一大搜索引擎 yandex 开发的列式储存数据库。令人惊喜的是，这个列式储存数据库的性能大幅超越了很多商业 mpp 数据库软件，比如 vertica,infinidb.\n\n相比传统的数据库软件，clickhouse 要快 100-1000x:\n\n100million 数据集:\n\n * clickhouse 比 vertica 约快 5 倍，比 hive 快 279 倍，比 my sql 快 801 倍\n\n1billion 数据集:\n\n * clickhouse 比 vertica 约快 5 倍，mysql 和 hive 已经无法完成任务了\n\n该项目当前还有一些不足:\n\n * pre-build 包只有 ubuntu 平台的可用，并且该项目当前没有任何架构文档\n * 只有 github 上面的 c++ 源代码\n\n\n# 主要功能\n\n * true column-oriented\n * vectorized query execution\n * data compression\n * parallel and distributed query execution\n * real-time data ingestion\n * on-disk locality of reference\n * real-time query processing\n * cross-datacenter replication\n * high availability\n * sql support\n * local and distributed joins\n * pluggable external dimension tables\n * arrays and nested data types\n * approximate query processing\n * probabilistic data structures\n * full support of ipv6\n * features for web analytics\n * state-of-the-art algorithms\n * detailed documentation\n * clean documented code\n\n\n# 应用场景\n\n * web and app analytics\n * advertising networks and rtb\n * telecommunications\n * e-commerce\n * information security\n * monitoring and telemetry\n * business intelligence\n * online games\n * internet of things\n\n\n# 常用sql\n\n-- 查询连接数\nselect * from system.metrics where metric like '%connection';\n\n\n-- 当前正在执行的查询\nselect query_id, user, address, query  from system.processes order by query_id;\n\n-- 存储空间统计\nselect name,path,formatreadablesize(free_space) as free,formatreadablesize(total_space) as total,formatreadablesize(keep_free_space) as reserved from system.disks;\n\n-- 慢查询\nselect\n    user,\n    client_hostname as host,\n    client_name as client,\n    formatdatetime(query_start_time, '%t') as started,\n    query_duration_ms / 1000 as sec,\n    round(memory_usage / 1048576) as mem_mb,\n    result_rows as res_cnt,\n    result_bytes / 1048576 as res_mb,\n    read_rows as r_cnt,\n    round(read_bytes / 1048576) as r_mb,\n    written_rows as w_cnt,\n    round(written_bytes / 1048576) as w_mb,\n    query\nfrom system.query_log\nwhere type = 2\norder by query_duration_ms desc\n    limit 10;\n\n-- 查看库表资源占用情况\nselect\n    sum(rows) as row,--总行数\n    formatreadablesize(sum(data_uncompressed_bytes)) as ysq,--原始大小\n    formatreadablesize(sum(data_compressed_bytes)) as ysh,--压缩大小\n    round(sum(data_compressed_bytes) / sum(data_uncompressed_bytes) * 100, 0) ys_rate--压缩率\nfrom system.parts\nwhere database='datacenter';\n\n-- 查看库中表行数统计\nselect database,table,sum(rows) as rows\nfrom system.parts\nwhere database='datacenter'\ngroup by database, table\norder by rows desc;\n\n\nselect distinct table from system.parts where database='datacenter';\n\n\n-- drop  database datacenter;\n\nselect * from datacenter.`3cdb162688e14cc6a1bc65befca5347c_yc150`;\n\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  clickhouseserver: \n    image: yandex/clickhouse-server:21\n    container_name: clickhouseserver\n    restart: always\n    hostname: clickhouse\n    volumes: \n      - data:/var/lib/clickhouse\n      - /etc/clickhouse/config.xml:/etc/clickhouse-server/config.xml\n      - /etc/clickhouse/users.xml:/etc/clickhouse-server/users.xml\n    ports:\n      - 8123:8123\n      - 9000:9000\n    environment:\n      tz: asia/shanghai \n  \n  # clickhouseclient:\n  #   image: yandex/clickhouse-client:21\n  #   container_name: clickhouseclient\n  #   restart: always\n  #   environment:\n  #     tz: asia/shanghai\n  #   depends_on: ['clickhouseserver']\n\n  #docker run -it --rm --link clickhouseserver --net swarm_net yandex/clickhouse-client:21 --host clickhouseserver\n\nvolumes: \n  data: \n    driver: local\n\n\n\n# config.xml\n\n<?xml version=\"1.0\"?>\n\x3c!--\n  note: user and query level settings are set up in \"users.xml\" file.\n  if you have accidentally specified user-level settings here, server won't start.\n  you can either move the settings to the right place inside \"users.xml\" file\n   or add <skip_check_for_incorrect_settings>1</skip_check_for_incorrect_settings> here.\n--\x3e\n<yandex>\n    <logger>\n        \x3c!-- possible levels [1]:\n\n          - none (turns off logging)\n          - fatal\n          - critical\n          - error\n          - warning\n          - notice\n          - information\n          - debug\n          - trace\n\n            [1]: https://github.com/pocoproject/poco/blob/poco-1.9.4-release/foundation/include/poco/logger.h#l105-l114\n        --\x3e\n        <level>trace</level>\n        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>\n        \x3c!-- rotation policy\n             see https://github.com/pocoproject/poco/blob/poco-1.9.4-release/foundation/include/poco/filechannel.h#l54-l85\n          --\x3e\n        <size>1000m</size>\n        <count>10</count>\n        \x3c!-- <console>1</console> --\x3e \x3c!-- default behavior is autodetection (log to console if not daemon mode and is tty) --\x3e\n\n        \x3c!-- per level overrides (legacy):\n\n        for example to suppress logging of the configreloader you can use:\n        note: levels.logger is reserved, see below.\n        --\x3e\n        \x3c!--\n        <levels>\n          <configreloader>none</configreloader>\n        </levels>\n        --\x3e\n\n        \x3c!-- per level overrides:\n\n        for example to suppress logging of the rbac for default user you can use:\n        (but please note that the logger name maybe changed from version to version, even after minor upgrade)\n        --\x3e\n        \x3c!--\n        <levels>\n          <logger>\n            <name>contextaccess (default)</name>\n            <level>none</level>\n          </logger>\n          <logger>\n            <name>databaseordinary (test)</name>\n            <level>none</level>\n          </logger>\n        </levels>\n        --\x3e\n    </logger>\n\n    \x3c!-- it is the name that will be shown in the clickhouse-client.\n         by default, anything with \"production\" will be highlighted in red in query prompt.\n    --\x3e\n    \x3c!--display_name>production</display_name--\x3e\n\n    \x3c!-- port for http api. see also 'https_port' for secure connections.\n         this interface is also used by odbc and jdbc drivers (datagrip, dbeaver, ...)\n         and by most of web interfaces (embedded ui, grafana, redash, ...).\n      --\x3e\n    <http_port>8123</http_port>\n\n    \x3c!-- port for interaction by native protocol with:\n         - clickhouse-client and other native clickhouse tools (clickhouse-benchmark, clickhouse-copier);\n         - clickhouse-server with other clickhouse-servers for distributed query processing;\n         - clickhouse drivers and applications supporting native protocol\n         (this protocol is also informally called as \"the tcp protocol\");\n         see also 'tcp_port_secure' for secure connections.\n    --\x3e\n    <tcp_port>9000</tcp_port>\n\n    \x3c!-- compatibility with mysql protocol.\n         clickhouse will pretend to be mysql for applications connecting to this port.\n    --\x3e\n    <mysql_port>9004</mysql_port>\n\n    \x3c!-- compatibility with postgresql protocol.\n         clickhouse will pretend to be postgresql for applications connecting to this port.\n    --\x3e\n    <postgresql_port>9005</postgresql_port>\n\n    \x3c!-- http api with tls (https).\n         you have to configure certificate to enable this interface.\n         see the openssl section below.\n    --\x3e\n    \x3c!-- <https_port>8443</https_port> --\x3e\n\n    \x3c!-- native interface with tls.\n         you have to configure certificate to enable this interface.\n         see the openssl section below.\n    --\x3e\n    \x3c!-- <tcp_port_secure>9440</tcp_port_secure> --\x3e\n\n    \x3c!-- native interface wrapped with proxyv1 protocol\n         proxyv1 header sent for every connection.\n         clickhouse will extract information about proxy-forwarded client address from the header.\n    --\x3e\n    \x3c!-- <tcp_with_proxy_port>9011</tcp_with_proxy_port> --\x3e\n\n    \x3c!-- port for communication between replicas. used for data exchange.\n         it provides low-level data access between servers.\n         this port should not be accessible from untrusted networks.\n         see also 'interserver_http_credentials'.\n         data transferred over connections to this port should not go through untrusted networks.\n         see also 'interserver_https_port'.\n      --\x3e\n    <interserver_http_port>9009</interserver_http_port>\n\n    \x3c!-- port for communication between replicas with tls.\n         you have to configure certificate to enable this interface.\n         see the openssl section below.\n         see also 'interserver_http_credentials'.\n      --\x3e\n    \x3c!-- <interserver_https_port>9010</interserver_https_port> --\x3e\n\n    \x3c!-- hostname that is used by other replicas to request this server.\n         if not specified, than it is determined analogous to 'hostname -f' command.\n         this setting could be used to switch replication to another network interface\n         (the server may be connected to multiple networks via multiple addresses)\n      --\x3e\n    \x3c!--\n    <interserver_http_host>example.yandex.ru</interserver_http_host>\n    --\x3e\n\n    \x3c!-- you can specify credentials for authenthication between replicas.\n         this is required when interserver_https_port is accessible from untrusted networks,\n         and also recommended to avoid ssrf attacks from possibly compromised services in your network.\n      --\x3e\n    \x3c!--<interserver_http_credentials>\n        <user>interserver</user>\n        <password></password>\n    </interserver_http_credentials>--\x3e\n\n    \x3c!-- listen specified address.\n         use :: (wildcard ipv6 address), if you want to accept connections both with ipv4 and ipv6 from everywhere.\n         notes:\n         if you open connections from wildcard address, make sure that at least one of the following measures applied:\n         - server is protected by firewall and not accessible from untrusted networks;\n         - all users are restricted to subset of network addresses (see users.xml);\n         - all users have strong passwords, only secure (tls) interfaces are accessible, or connections are only made via tls interfaces.\n         - users without password have readonly access.\n         see also: https://www.shodan.io/search?query=clickhouse\n      --\x3e\n    \x3c!-- <listen_host>::</listen_host> --\x3e\n\n    \x3c!-- same for hosts without support for ipv6: --\x3e\n    \x3c!-- <listen_host>0.0.0.0</listen_host> --\x3e\n\n    \x3c!-- default values - try listen localhost on ipv4 and ipv6. --\x3e\n    \x3c!--\n    <listen_host>::1</listen_host>\n    <listen_host>127.0.0.1</listen_host>\n    --\x3e\n\n    \x3c!-- don't exit if ipv6 or ipv4 networks are unavailable while trying to listen. --\x3e\n    \x3c!-- <listen_try>0</listen_try> --\x3e\n\n    \x3c!-- allow multiple servers to listen on the same address:port. this is not recommended.\n      --\x3e\n    \x3c!-- <listen_reuse_port>0</listen_reuse_port> --\x3e\n\n    \x3c!-- <listen_backlog>64</listen_backlog> --\x3e\n\n    <max_connections>4096</max_connections>\n\n    \x3c!-- for 'connection: keep-alive' in http 1.1 --\x3e\n    <keep_alive_timeout>3</keep_alive_timeout>\n\n    \x3c!-- grpc protocol (see src/server/grpc_protos/clickhouse_grpc.proto for the api) --\x3e\n    \x3c!-- <grpc_port>9100</grpc_port> --\x3e\n    <grpc>\n        <enable_ssl>false</enable_ssl>\n\n        \x3c!-- the following two files are used only if enable_ssl=1 --\x3e\n        <ssl_cert_file>/path/to/ssl_cert_file</ssl_cert_file>\n        <ssl_key_file>/path/to/ssl_key_file</ssl_key_file>\n\n        \x3c!-- whether server will request client for a certificate --\x3e\n        <ssl_require_client_auth>false</ssl_require_client_auth>\n\n        \x3c!-- the following file is used only if ssl_require_client_auth=1 --\x3e\n        <ssl_ca_cert_file>/path/to/ssl_ca_cert_file</ssl_ca_cert_file>\n\n        \x3c!-- default compression algorithm (applied if client doesn't specify another algorithm).\n             supported algorithms: none, deflate, gzip, stream_gzip --\x3e\n        <compression>deflate</compression>\n\n        \x3c!-- default compression level (applied if client doesn't specify another level).\n             supported levels: none, low, medium, high --\x3e\n        <compression_level>medium</compression_level>\n\n        \x3c!-- send/receive message size limits in bytes. -1 means unlimited --\x3e\n        <max_send_message_size>-1</max_send_message_size>\n        <max_receive_message_size>-1</max_receive_message_size>\n\n        \x3c!-- enable if you want very detailed logs --\x3e\n        <verbose_logs>false</verbose_logs>\n    </grpc>\n\n    \x3c!-- used with https_port and tcp_port_secure. full ssl options list: https://github.com/clickhouse-extras/poco/blob/master/netssl_openssl/include/poco/net/sslmanager.h#l71 --\x3e\n    <openssl>\n        <server> \x3c!-- used for https server and secure tcp port --\x3e\n            \x3c!-- openssl req -subj \"/cn=localhost\" -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout /etc/clickhouse-server/server.key -out /etc/clickhouse-server/server.crt --\x3e\n            <certificatefile>/etc/clickhouse-server/server.crt</certificatefile>\n            <privatekeyfile>/etc/clickhouse-server/server.key</privatekeyfile>\n            \x3c!-- dhparams are optional. you can delete the <dhparamsfile> element.\n                 to generate dhparams, use the following command:\n                  openssl dhparam -out /etc/clickhouse-server/dhparam.pem 4096\n                 only file format with begin dh parameters is supported.\n              --\x3e\n            <dhparamsfile>/etc/clickhouse-server/dhparam.pem</dhparamsfile>\n            <verificationmode>none</verificationmode>\n            <loaddefaultcafile>true</loaddefaultcafile>\n            <cachesessions>true</cachesessions>\n            <disableprotocols>sslv2,sslv3</disableprotocols>\n            <preferserverciphers>true</preferserverciphers>\n        </server>\n\n        <client> \x3c!-- used for connecting to https dictionary source and secured zookeeper communication --\x3e\n            <loaddefaultcafile>true</loaddefaultcafile>\n            <cachesessions>true</cachesessions>\n            <disableprotocols>sslv2,sslv3</disableprotocols>\n            <preferserverciphers>true</preferserverciphers>\n            \x3c!-- use for self-signed: <verificationmode>none</verificationmode> --\x3e\n            <invalidcertificatehandler>\n                \x3c!-- use for self-signed: <name>acceptcertificatehandler</name> --\x3e\n                <name>rejectcertificatehandler</name>\n            </invalidcertificatehandler>\n        </client>\n    </openssl>\n\n    \x3c!-- default root page on http[s] server. for example load ui from https://tabix.io/ when opening http://localhost:8123 --\x3e\n    \x3c!--\n    <http_server_default_response><![cdata[<html ng-app=\"smi2\"><head><base href=\"http://ui.tabix.io/\"></head><body><div ui-view=\"\" class=\"content-ui\"></div><script src=\"http://loader.tabix.io/master.js\"><\/script></body></html>]]></http_server_default_response>\n    --\x3e\n\n    \x3c!-- maximum number of concurrent queries. --\x3e\n    <max_concurrent_queries>1000</max_concurrent_queries>\n\n    \x3c!-- maximum memory usage (resident set size) for server process.\n         zero value or unset means default. default is \"max_server_memory_usage_to_ram_ratio\" of available physical ram.\n         if the value is larger than \"max_server_memory_usage_to_ram_ratio\" of available physical ram, it will be cut down.\n\n         the constraint is checked on query execution time.\n         if a query tries to allocate memory and the current memory usage plus allocation is greater\n          than specified threshold, exception will be thrown.\n\n         it is not practical to set this constraint to small values like just a few gigabytes,\n          because memory allocator will keep this amount of memory in caches and the server will deny service of queries.\n      --\x3e\n    <max_server_memory_usage>0</max_server_memory_usage>\n\n    \x3c!-- maximum number of threads in the global thread pool.\n    this will default to a maximum of 10000 threads if not specified.\n    this setting will be useful in scenarios where there are a large number\n    of distributed queries that are running concurrently but are idling most\n    of the time, in which case a higher number of threads might be required.\n    --\x3e\n\n    <max_thread_pool_size>10000</max_thread_pool_size>\n\n    \x3c!-- on memory constrained environments you may have to set this to value larger than 1.\n      --\x3e\n    <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>\n\n    \x3c!-- simple server-wide memory profiler. collect a stack trace at every peak allocation step (in bytes).\n         data will be stored in system.trace_log table with query_id = empty string.\n         zero means disabled.\n      --\x3e\n    <total_memory_profiler_step>4194304</total_memory_profiler_step>\n\n    \x3c!-- collect random allocations and deallocations and write them into system.trace_log with 'memorysample' trace_type.\n         the probability is for every alloc/free regardless to the size of the allocation.\n         note that sampling happens only when the amount of untracked memory exceeds the untracked memory limit,\n          which is 4 mib by default but can be lowered if 'total_memory_profiler_step' is lowered.\n         you may want to set 'total_memory_profiler_step' to 1 for extra fine grained sampling.\n      --\x3e\n    <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>\n\n    \x3c!-- set limit on number of open files (default: maximum). this setting makes sense on mac os x because getrlimit() fails to retrieve\n         correct maximum value. --\x3e\n    \x3c!-- <max_open_files>262144</max_open_files> --\x3e\n\n    \x3c!-- size of cache of uncompressed blocks of data, used in tables of mergetree family.\n         in bytes. cache is single for server. memory is allocated only on demand.\n         cache is used when 'use_uncompressed_cache' user setting turned on (off by default).\n         uncompressed cache is advantageous only for very short queries and in rare cases.\n\n         note: uncompressed cache can be pointless for lz4, because memory bandwidth\n         is slower than multi-core decompression on some server configurations.\n         enabling it can sometimes paradoxically make queries slower.\n      --\x3e\n    <uncompressed_cache_size>8589934592</uncompressed_cache_size>\n\n    \x3c!-- approximate size of mark cache, used in tables of mergetree family.\n         in bytes. cache is single for server. memory is allocated only on demand.\n         you should not lower this value.\n      --\x3e\n    <mark_cache_size>5368709120</mark_cache_size>\n\n\n    \x3c!-- if you enable the `min_bytes_to_use_mmap_io` setting,\n         the data in mergetree tables can be read with mmap to avoid copying from kernel to userspace.\n         it makes sense only for large files and helps only if data reside in page cache.\n         to avoid frequent open/mmap/munmap/close calls (which are very expensive due to consequent page faults)\n         and to reuse mappings from several threads and queries,\n         the cache of mapped files is maintained. its size is the number of mapped regions (usually equal to the number of mapped files).\n         the amount of data in mapped files can be monitored\n         in system.metrics, system.metric_log by the mmappedfiles, mmappedfilebytes metrics\n         and in system.asynchronous_metrics, system.asynchronous_metrics_log by the mmapcachecells metric,\n         and also in system.events, system.processes, system.query_log, system.query_thread_log by the\n         createdreadbuffermmap, createdreadbuffermmapfailed, mmappedfilecachehits, mmappedfilecachemisses events.\n         note that the amount of data in mapped files does not consume memory directly and is not accounted\n         in query or server memory usage - because this memory can be discarded similar to os page cache.\n         the cache is dropped (the files are closed) automatically on removal of old parts in mergetree,\n         also it can be dropped manually by the system drop mmap cache query.\n      --\x3e\n    <mmap_cache_size>1000</mmap_cache_size>\n\n\n    \x3c!-- path to data directory, with trailing slash. --\x3e\n    <path>/var/lib/clickhouse/</path>\n\n    \x3c!-- path to temporary data for processing hard queries. --\x3e\n    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>\n\n    \x3c!-- policy from the <storage_configuration> for the temporary files.\n         if not set <tmp_path> is used, otherwise <tmp_path> is ignored.\n\n         notes:\n         - move_factor              is ignored\n         - keep_free_space_bytes    is ignored\n         - max_data_part_size_bytes is ignored\n         - you must have exactly one volume in that policy\n    --\x3e\n    \x3c!-- <tmp_policy>tmp</tmp_policy> --\x3e\n\n    \x3c!-- directory with user provided files that are accessible by 'file' table function. --\x3e\n    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>\n\n    \x3c!-- ldap server definitions. --\x3e\n    <ldap_servers>\n        \x3c!-- list ldap servers with their connection parameters here to later 1) use them as authenticators for dedicated local users,\n              who have 'ldap' authentication mechanism specified instead of 'password', or to 2) use them as remote user directories.\n             parameters:\n                host - ldap server hostname or ip, this parameter is mandatory and cannot be empty.\n                port - ldap server port, default is 636 if enable_tls is set to true, 389 otherwise.\n                bind_dn - template used to construct the dn to bind to.\n                        the resulting dn will be constructed by replacing all '{user_name}' substrings of the template with the actual\n                         user name during each authentication attempt.\n                verification_cooldown - a period of time, in seconds, after a successful bind attempt, during which a user will be assumed\n                         to be successfully authenticated for all consecutive requests without contacting the ldap server.\n                        specify 0 (the default) to disable caching and force contacting the ldap server for each authentication request.\n                enable_tls - flag to trigger use of secure connection to the ldap server.\n                        specify 'no' for plain text (ldap://) protocol (not recommended).\n                        specify 'yes' for ldap over ssl/tls (ldaps://) protocol (recommended, the default).\n                        specify 'starttls' for legacy starttls protocol (plain text (ldap://) protocol, upgraded to tls).\n                tls_minimum_protocol_version - the minimum protocol version of ssl/tls.\n                        accepted values are: 'ssl2', 'ssl3', 'tls1.0', 'tls1.1', 'tls1.2' (the default).\n                tls_require_cert - ssl/tls peer certificate verification behavior.\n                        accepted values are: 'never', 'allow', 'try', 'demand' (the default).\n                tls_cert_file - path to certificate file.\n                tls_key_file - path to certificate key file.\n                tls_ca_cert_file - path to ca certificate file.\n                tls_ca_cert_dir - path to the directory containing ca certificates.\n                tls_cipher_suite - allowed cipher suite (in openssl notation).\n             example:\n                <my_ldap_server>\n                    <host>localhost</host>\n                    <port>636</port>\n                    <bind_dn>uid={user_name},ou=users,dc=example,dc=com</bind_dn>\n                    <verification_cooldown>300</verification_cooldown>\n                    <enable_tls>yes</enable_tls>\n                    <tls_minimum_protocol_version>tls1.2</tls_minimum_protocol_version>\n                    <tls_require_cert>demand</tls_require_cert>\n                    <tls_cert_file>/path/to/tls_cert_file</tls_cert_file>\n                    <tls_key_file>/path/to/tls_key_file</tls_key_file>\n                    <tls_ca_cert_file>/path/to/tls_ca_cert_file</tls_ca_cert_file>\n                    <tls_ca_cert_dir>/path/to/tls_ca_cert_dir</tls_ca_cert_dir>\n                    <tls_cipher_suite>ecdhe-ecdsa-aes256-gcm-sha384:ecdhe-rsa-aes256-gcm-sha384:aes256-gcm-sha384</tls_cipher_suite>\n                </my_ldap_server>\n        --\x3e\n    </ldap_servers>\n\n    \x3c!-- to enable kerberos authentication support for http requests (gss-spnego), for those users who are explicitly configured\n          to authenticate via kerberos, define a single 'kerberos' section here.\n         parameters:\n            principal - canonical service principal name, that will be acquired and used when accepting security contexts.\n                    this parameter is optional, if omitted, the default principal will be used.\n                    this parameter cannot be specified together with 'realm' parameter.\n            realm - a realm, that will be used to restrict authentication to only those requests whose initiator's realm matches it.\n                    this parameter is optional, if omitted, no additional filtering by realm will be applied.\n                    this parameter cannot be specified together with 'principal' parameter.\n         example:\n            <kerberos />\n         example:\n            <kerberos>\n                <principal>http/clickhouse.example.com@example.com</principal>\n            </kerberos>\n         example:\n            <kerberos>\n                <realm>example.com</realm>\n            </kerberos>\n    --\x3e\n\n    \x3c!-- sources to read users, roles, access rights, profiles of settings, quotas. --\x3e\n    <user_directories>\n        <users_xml>\n            \x3c!-- path to configuration file with predefined users. --\x3e\n            <path>users.xml</path>\n        </users_xml>\n        <local_directory>\n            \x3c!-- path to folder where users created by sql commands are stored. --\x3e\n            <path>/var/lib/clickhouse/access/</path>\n        </local_directory>\n\n        \x3c!-- to add an ldap server as a remote user directory of users that are not defined locally, define a single 'ldap' section\n              with the following parameters:\n                server - one of ldap server names defined in 'ldap_servers' config section above.\n                        this parameter is mandatory and cannot be empty.\n                roles - section with a list of locally defined roles that will be assigned to each user retrieved from the ldap server.\n                        if no roles are specified here or assigned during role mapping (below), user will not be able to perform any\n                         actions after authentication.\n                role_mapping - section with ldap search parameters and mapping rules.\n                        when a user authenticates, while still bound to ldap, an ldap search is performed using search_filter and the\n                         name of the logged in user. for each entry found during that search, the value of the specified attribute is\n                         extracted. for each attribute value that has the specified prefix, the prefix is removed, and the rest of the\n                         value becomes the name of a local role defined in clickhouse, which is expected to be created beforehand by\n                         create role command.\n                        there can be multiple 'role_mapping' sections defined inside the same 'ldap' section. all of them will be\n                         applied.\n                    base_dn - template used to construct the base dn for the ldap search.\n                            the resulting dn will be constructed by replacing all '{user_name}' and '{bind_dn}' substrings\n                             of the template with the actual user name and bind dn during each ldap search.\n                    scope - scope of the ldap search.\n                            accepted values are: 'base', 'one_level', 'children', 'subtree' (the default).\n                    search_filter - template used to construct the search filter for the ldap search.\n                            the resulting filter will be constructed by replacing all '{user_name}', '{bind_dn}', and '{base_dn}'\n                             substrings of the template with the actual user name, bind dn, and base dn during each ldap search.\n                            note, that the special characters must be escaped properly in xml.\n                    attribute - attribute name whose values will be returned by the ldap search.\n                    prefix - prefix, that will be expected to be in front of each string in the original list of strings returned by\n                             the ldap search. prefix will be removed from the original strings and resulting strings will be treated\n                             as local role names. empty, by default.\n             example:\n                <ldap>\n                    <server>my_ldap_server</server>\n                    <roles>\n                        <my_local_role1 />\n                        <my_local_role2 />\n                    </roles>\n                    <role_mapping>\n                        <base_dn>ou=groups,dc=example,dc=com</base_dn>\n                        <scope>subtree</scope>\n                        <search_filter>(&amp;(objectclass=groupofnames)(member={bind_dn}))</search_filter>\n                        <attribute>cn</attribute>\n                        <prefix>clickhouse_</prefix>\n                    </role_mapping>\n                </ldap>\n        --\x3e\n    </user_directories>\n\n    \x3c!-- default profile of settings. --\x3e\n    <default_profile>default</default_profile>\n\n    \x3c!-- comma-separated list of prefixes for user-defined settings. --\x3e\n    <custom_settings_prefixes></custom_settings_prefixes>\n\n    \x3c!-- system profile of settings. this settings are used by internal processes (distributed ddl worker and so on). --\x3e\n    \x3c!-- <system_profile>default</system_profile> --\x3e\n\n    \x3c!-- buffer profile of settings.\n         this settings are used by buffer storage to flush data to the underlying table.\n         default: used from system_profile directive.\n    --\x3e\n    \x3c!-- <buffer_profile>default</buffer_profile> --\x3e\n\n    \x3c!-- default database. --\x3e\n    <default_database>default</default_database>\n\n    \x3c!-- server time zone could be set here.\n\n         time zone is used when converting between string and datetime types,\n          when printing datetime in text formats and parsing datetime from text,\n          it is used in date and time related functions, if specific time zone was not passed as an argument.\n\n         time zone is specified as identifier from iana time zone database, like utc or africa/abidjan.\n         if not specified, system time zone at server startup is used.\n\n         please note, that server could display time zone alias instead of specified name.\n         example: w-su is an alias for europe/moscow and zulu is an alias for utc.\n    --\x3e\n    \x3c!-- <timezone>europe/moscow</timezone> --\x3e\n\n    \x3c!-- you can specify umask here (see \"man umask\"). server will apply it on startup.\n         number is always parsed as octal. default umask is 027 (other users cannot read logs, data files, etc; group can only read).\n    --\x3e\n    \x3c!-- <umask>022</umask> --\x3e\n\n    \x3c!-- perform mlockall after startup to lower first queries latency\n          and to prevent clickhouse executable from being paged out under high io load.\n         enabling this option is recommended but will lead to increased startup time for up to a few seconds.\n    --\x3e\n    <mlock_executable>true</mlock_executable>\n\n    \x3c!-- reallocate memory for machine code (\"text\") using huge pages. highly experimental. --\x3e\n    <remap_executable>false</remap_executable>\n\n    \x3c!-- configuration of clusters that could be used in distributed tables.\n         https://clickhouse.tech/docs/en/operations/table_engines/distributed/\n      --\x3e\n    <remote_servers>\n        \x3c!-- test only shard config for testing distributed storage --\x3e\n        <test_shard_localhost>\n            \x3c!-- inter-server per-cluster secret for distributed queries\n                 default: no secret (no authentication will be performed)\n\n                 if set, then distributed queries will be validated on shards, so at least:\n                 - such cluster should exist on the shard,\n                 - such cluster should have the same secret.\n\n                 and also (and which is more important), the initial_user will\n                 be used as current user for the query.\n\n                 right now the protocol is pretty simple and it only takes into account:\n                 - cluster name\n                 - query\n\n                 also it will be nice if the following will be implemented:\n                 - source hostname (see interserver_http_host), but then it will depends from dns,\n                   it can use ip address instead, but then the you need to get correct on the initiator node.\n                 - target hostname / ip address (same notes as for source hostname)\n                 - time-based security tokens\n            --\x3e\n            \x3c!-- <secret></secret> --\x3e\n\n            <shard>\n                \x3c!-- optional. whether to write data to just one of the replicas. default: false (write data to all replicas). --\x3e\n                \x3c!-- <internal_replication>false</internal_replication> --\x3e\n                \x3c!-- optional. shard weight when writing data. default: 1. --\x3e\n                \x3c!-- <weight>1</weight> --\x3e\n                <replica>\n                    <host>localhost</host>\n                    <port>9000</port>\n                    \x3c!-- optional. priority of the replica for load_balancing. default: 1 (less value has more priority). --\x3e\n                    \x3c!-- <priority>1</priority> --\x3e\n                </replica>\n            </shard>\n        </test_shard_localhost>\n        <test_cluster_two_shards_localhost>\n             <shard>\n                 <replica>\n                     <host>localhost</host>\n                     <port>9000</port>\n                 </replica>\n             </shard>\n             <shard>\n                 <replica>\n                     <host>localhost</host>\n                     <port>9000</port>\n                 </replica>\n             </shard>\n        </test_cluster_two_shards_localhost>\n        <test_cluster_two_shards>\n            <shard>\n                <replica>\n                    <host>127.0.0.1</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <replica>\n                    <host>127.0.0.2</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n        </test_cluster_two_shards>\n        <test_cluster_two_shards_internal_replication>\n            <shard>\n                <internal_replication>true</internal_replication>\n                <replica>\n                    <host>127.0.0.1</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <internal_replication>true</internal_replication>\n                <replica>\n                    <host>127.0.0.2</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n        </test_cluster_two_shards_internal_replication>\n        <test_shard_localhost_secure>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>9440</port>\n                    <secure>1</secure>\n                </replica>\n            </shard>\n        </test_shard_localhost_secure>\n        <test_unavailable_shard>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>1</port>\n                </replica>\n            </shard>\n        </test_unavailable_shard>\n    </remote_servers>\n\n    \x3c!-- the list of hosts allowed to use in url-related storage engines and table functions.\n        if this section is not present in configuration, all hosts are allowed.\n    --\x3e\n    \x3c!--<remote_url_allow_hosts>--\x3e\n        \x3c!-- host should be specified exactly as in url. the name is checked before dns resolution.\n            example: \"yandex.ru\", \"yandex.ru.\" and \"www.yandex.ru\" are different hosts.\n                    if port is explicitly specified in url, the host:port is checked as a whole.\n                    if host specified here without port, any port with this host allowed.\n                    \"yandex.ru\" -> \"yandex.ru:443\", \"yandex.ru:80\" etc. is allowed, but \"yandex.ru:80\" -> only \"yandex.ru:80\" is allowed.\n            if the host is specified as ip address, it is checked as specified in url. example: \"[2a02:6b8:a::a]\".\n            if there are redirects and support for redirects is enabled, every redirect (the location field) is checked.\n        --\x3e\n\n        \x3c!-- regular expression can be specified. re2 engine is used for regexps.\n            regexps are not aligned: don't forget to add ^ and $. also don't forget to escape dot (.) metacharacter\n            (forgetting to do so is a common source of error).\n        --\x3e\n    \x3c!--</remote_url_allow_hosts>--\x3e\n\n    \x3c!-- if element has 'incl' attribute, then for it's value will be used corresponding substitution from another file.\n         by default, path to file with substitutions is /etc/metrika.xml. it could be changed in config in 'include_from' element.\n         values for substitutions are specified in /yandex/name_of_substitution elements in that file.\n      --\x3e\n\n    \x3c!-- zookeeper is used to store metadata about replicas, when using replicated tables.\n         optional. if you don't use replicated tables, you could omit that.\n\n         see https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/\n      --\x3e\n\n    \x3c!--\n    <zookeeper>\n        <node>\n            <host>example1</host>\n            <port>2181</port>\n        </node>\n        <node>\n            <host>example2</host>\n            <port>2181</port>\n        </node>\n        <node>\n            <host>example3</host>\n            <port>2181</port>\n        </node>\n    </zookeeper>\n    --\x3e\n\n    \x3c!-- substitutions for parameters of replicated tables.\n          optional. if you don't use replicated tables, you could omit that.\n\n         see https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/#creating-replicated-tables\n      --\x3e\n    \x3c!--\n    <macros>\n        <shard>01</shard>\n        <replica>example01-01-1</replica>\n    </macros>\n    --\x3e\n\n\n    \x3c!-- reloading interval for embedded dictionaries, in seconds. default: 3600. --\x3e\n    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>\n\n\n    \x3c!-- maximum session timeout, in seconds. default: 3600. --\x3e\n    <max_session_timeout>3600</max_session_timeout>\n\n    \x3c!-- default session timeout, in seconds. default: 60. --\x3e\n    <default_session_timeout>60</default_session_timeout>\n\n    \x3c!-- sending data to graphite for monitoring. several sections can be defined. --\x3e\n    \x3c!--\n        interval - send every x second\n        root_path - prefix for keys\n        hostname_in_path - append hostname to root_path (default = true)\n        metrics - send data from table system.metrics\n        events - send data from table system.events\n        asynchronous_metrics - send data from table system.asynchronous_metrics\n    --\x3e\n    \x3c!--\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>60</interval>\n        <root_path>one_min</root_path>\n        <hostname_in_path>true</hostname_in_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <events_cumulative>false</events_cumulative>\n        <asynchronous_metrics>true</asynchronous_metrics>\n    </graphite>\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>1</interval>\n        <root_path>one_sec</root_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <events_cumulative>false</events_cumulative>\n        <asynchronous_metrics>false</asynchronous_metrics>\n    </graphite>\n    --\x3e\n\n    \x3c!-- serve endpoint for prometheus monitoring. --\x3e\n    \x3c!--\n        endpoint - mertics path (relative to root, statring with \"/\")\n        port - port to setup server. if not defined or 0 than http_port used\n        metrics - send data from table system.metrics\n        events - send data from table system.events\n        asynchronous_metrics - send data from table system.asynchronous_metrics\n        status_info - send data from different component from ch, ex: dictionaries status\n    --\x3e\n    \x3c!--\n    <prometheus>\n        <endpoint>/metrics</endpoint>\n        <port>9363</port>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <asynchronous_metrics>true</asynchronous_metrics>\n        <status_info>true</status_info>\n    </prometheus>\n    --\x3e\n\n    \x3c!-- query log. used only for queries with setting log_queries = 1. --\x3e\n    <query_log>\n        \x3c!-- what table to insert data. if table is not exist, it will be created.\n             when query log structure is changed after system update,\n              then old table will be renamed and new table will be created automatically.\n        --\x3e\n        <database>system</database>\n        <table>query_log</table>\n        \x3c!--\n            partition by expr: https://clickhouse.yandex/docs/en/table_engines/mergetree-family/custom_partitioning_key/\n            example:\n                event_date\n                tomonday(event_date)\n                toyyyymm(event_date)\n                tostartofhour(event_time)\n        --\x3e\n        <partition_by>toyyyymm(event_date)</partition_by>\n        \x3c!--\n            table ttl specification: https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/#mergetree-table-ttl\n            example:\n                event_date + interval 1 week\n                event_date + interval 7 day delete\n                event_date + interval 2 week to disk 'bbb'\n\n        <ttl>event_date + interval 30 day delete</ttl>\n        --\x3e\n\n        \x3c!-- instead of partition_by, you can provide full engine expression (starting with engine = ) with parameters,\n             example: <engine>engine = mergetree partition by toyyyymm(event_date) order by (event_date, event_time) settings index_granularity = 1024</engine>\n          --\x3e\n\n        \x3c!-- interval of flushing data. --\x3e\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_log>\n\n    \x3c!-- trace log. stores stack traces collected by query profilers.\n         see query_profiler_real_time_period_ns and query_profiler_cpu_time_period_ns settings. --\x3e\n    <trace_log>\n        <database>system</database>\n        <table>trace_log</table>\n\n        <partition_by>toyyyymm(event_date)</partition_by>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </trace_log>\n\n    \x3c!-- query thread log. has information about all threads participated in query execution.\n         used only for queries with setting log_query_threads = 1. --\x3e\n    <query_thread_log>\n        <database>system</database>\n        <table>query_thread_log</table>\n        <partition_by>toyyyymm(event_date)</partition_by>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_thread_log>\n\n    \x3c!-- uncomment if use part log.\n         part log contains information about all actions with parts in mergetree tables (creation, deletion, merges, downloads).\n    <part_log>\n        <database>system</database>\n        <table>part_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </part_log>\n    --\x3e\n\n    \x3c!-- uncomment to write text log into table.\n         text log contains all information from usual server log but stores it in structured and efficient way.\n         the level of the messages that goes to the table can be limited (<level>), if not specified all messages will go to the table.\n    <text_log>\n        <database>system</database>\n        <table>text_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n        <level></level>\n    </text_log>\n    --\x3e\n\n    \x3c!-- metric log contains rows with current values of profileevents, currentmetrics collected with \"collect_interval_milliseconds\" interval. --\x3e\n    <metric_log>\n        <database>system</database>\n        <table>metric_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n        <collect_interval_milliseconds>1000</collect_interval_milliseconds>\n    </metric_log>\n\n    \x3c!--\n        asynchronous metric log contains values of metrics from\n        system.asynchronous_metrics.\n    --\x3e\n    <asynchronous_metric_log>\n        <database>system</database>\n        <table>asynchronous_metric_log</table>\n        \x3c!--\n            asynchronous metrics are updated once a minute, so there is\n            no need to flush more often.\n        --\x3e\n        <flush_interval_milliseconds>60000</flush_interval_milliseconds>\n    </asynchronous_metric_log>\n\n    \x3c!--\n        opentelemetry log contains opentelemetry trace spans.\n    --\x3e\n    <opentelemetry_span_log>\n        \x3c!--\n            the default table creation code is insufficient, this <engine> spec\n            is a workaround. there is no 'event_time' for this log, but two times,\n            start and finish. it is sorted by finish time, to avoid inserting\n            data too far away in the past (probably we can sometimes insert a span\n            that is seconds earlier than the last span in the table, due to a race\n            between several spans inserted in parallel). this gives the spans a\n            global order that we can use to e.g. retry insertion into some external\n            system.\n        --\x3e\n        <engine>\n            engine mergetree\n            partition by toyyyymm(finish_date)\n            order by (finish_date, finish_time_us, trace_id)\n        </engine>\n        <database>system</database>\n        <table>opentelemetry_span_log</table>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </opentelemetry_span_log>\n\n\n    \x3c!-- crash log. stores stack traces for fatal errors.\n         this table is normally empty. --\x3e\n    <crash_log>\n        <database>system</database>\n        <table>crash_log</table>\n\n        <partition_by />\n        <flush_interval_milliseconds>1000</flush_interval_milliseconds>\n    </crash_log>\n\n    \x3c!-- parameters for embedded dictionaries, used in yandex.metrica.\n         see https://clickhouse.yandex/docs/en/dicts/internal_dicts/\n    --\x3e\n\n    \x3c!-- path to file with region hierarchy. --\x3e\n    \x3c!-- <path_to_regions_hierarchy_file>/opt/geo/regions_hierarchy.txt</path_to_regions_hierarchy_file> --\x3e\n\n    \x3c!-- path to directory with files containing names of regions --\x3e\n    \x3c!-- <path_to_regions_names_files>/opt/geo/</path_to_regions_names_files> --\x3e\n\n\n    \x3c!-- <top_level_domains_path>/var/lib/clickhouse/top_level_domains/</top_level_domains_path> --\x3e\n    \x3c!-- custom tld lists.\n         format: <name>/path/to/file</name>\n\n         changes will not be applied w/o server restart.\n         path to the list is under top_level_domains_path (see above).\n    --\x3e\n    <top_level_domains_lists>\n        \x3c!--\n        <public_suffix_list>/path/to/public_suffix_list.dat</public_suffix_list>\n        --\x3e\n    </top_level_domains_lists>\n\n    \x3c!-- configuration of external dictionaries. see:\n         https://clickhouse.tech/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts\n    --\x3e\n    <dictionaries_config>*_dictionary.xml</dictionaries_config>\n\n    \x3c!-- uncomment if you want data to be compressed 30-100% better.\n         don't do that if you just started using clickhouse.\n      --\x3e\n    \x3c!--\n    <compression>\n        <!- - set of variants. checked in order. last matching case wins. if nothing matches, lz4 will be used. - ->\n        <case>\n\n            <!- - conditions. all must be satisfied. some conditions may be omitted. - ->\n            <min_part_size>10000000000</min_part_size>        <!- - min part size in bytes. - ->\n            <min_part_size_ratio>0.01</min_part_size_ratio>   <!- - min size of part relative to whole table size. - ->\n\n            <!- - what compression method to use. - ->\n            <method>zstd</method>\n        </case>\n    </compression>\n    --\x3e\n\n    \x3c!-- allow to execute distributed ddl queries (create, drop, alter, rename) on cluster.\n         works only if zookeeper is enabled. comment it if such functionality isn't required. --\x3e\n    <distributed_ddl>\n        \x3c!-- path in zookeeper to queue with ddl queries --\x3e\n        <path>/clickhouse/task_queue/ddl</path>\n\n        \x3c!-- settings from this profile will be used to execute ddl queries --\x3e\n        \x3c!-- <profile>default</profile> --\x3e\n\n        \x3c!-- controls how much on cluster queries can be run simultaneously. --\x3e\n        \x3c!-- <pool_size>1</pool_size> --\x3e\n\n        \x3c!--\n             cleanup settings (active tasks will not be removed)\n        --\x3e\n\n        \x3c!-- controls task ttl (default 1 week) --\x3e\n        \x3c!-- <task_max_lifetime>604800</task_max_lifetime> --\x3e\n\n        \x3c!-- controls how often cleanup should be performed (in seconds) --\x3e\n        \x3c!-- <cleanup_delay_period>60</cleanup_delay_period> --\x3e\n\n        \x3c!-- controls how many tasks could be in the queue --\x3e\n        \x3c!-- <max_tasks_in_queue>1000</max_tasks_in_queue> --\x3e\n    </distributed_ddl>\n\n    \x3c!-- settings to fine tune mergetree tables. see documentation in source code, in mergetreesettings.h --\x3e\n    \x3c!--\n    <merge_tree>\n        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>\n    </merge_tree>\n    --\x3e\n\n    \x3c!-- protection from accidental drop.\n         if size of a mergetree table is greater than max_table_size_to_drop (in bytes) than table could not be dropped with any drop query.\n         if you want do delete one table and don't want to change clickhouse-server config, you could create special file <clickhouse-path>/flags/force_drop_table and make drop once.\n         by default max_table_size_to_drop is 50gb; max_table_size_to_drop=0 allows to drop any tables.\n         the same for max_partition_size_to_drop.\n         uncomment to disable protection.\n    --\x3e\n    \x3c!-- <max_table_size_to_drop>0</max_table_size_to_drop> --\x3e\n    \x3c!-- <max_partition_size_to_drop>0</max_partition_size_to_drop> --\x3e\n\n    \x3c!-- example of parameters for graphitemergetree table engine --\x3e\n    <graphite_rollup_example>\n        <pattern>\n            <regexp>click_cost</regexp>\n            <function>any</function>\n            <retention>\n                <age>0</age>\n                <precision>3600</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>60</precision>\n            </retention>\n        </pattern>\n        <default>\n            <function>max</function>\n            <retention>\n                <age>0</age>\n                <precision>60</precision>\n            </retention>\n            <retention>\n                <age>3600</age>\n                <precision>300</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>3600</precision>\n            </retention>\n        </default>\n    </graphite_rollup_example>\n\n    \x3c!-- directory in <clickhouse-path> containing schema files for various input formats.\n         the directory will be created if it doesn't exist.\n      --\x3e\n    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>\n\n    \x3c!-- default query masking rules, matching lines would be replaced with something else in the logs\n        (both text logs and system.query_log).\n        name - name for the rule (optional)\n        regexp - re2 compatible regular expression (mandatory)\n        replace - substitution string for sensitive data (optional, by default - six asterisks)\n    --\x3e\n    <query_masking_rules>\n        <rule>\n            <name>hide encrypt/decrypt arguments</name>\n            <regexp>((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\\s*\\(\\s*(?:'(?:\\\\'|.)+'|.*?)\\s*\\)</regexp>\n            \x3c!-- or more secure, but also more invasive:\n                (aes_\\w+)\\s*\\(.*\\)\n            --\x3e\n            <replace>\\1(???)</replace>\n        </rule>\n    </query_masking_rules>\n\n    \x3c!-- uncomment to use custom http handlers.\n        rules are checked from top to bottom, first match runs the handler\n            url - to match request url, you can use 'regex:' prefix to use regex match(optional)\n            methods - to match request method, you can use commas to separate multiple method matches(optional)\n            headers - to match request headers, match each child element(child element name is header name), you can use 'regex:' prefix to use regex match(optional)\n        handler is request handler\n            type - supported types: static, dynamic_query_handler, predefined_query_handler\n            query - use with predefined_query_handler type, executes query when the handler is called\n            query_param_name - use with dynamic_query_handler type, extracts and executes the value corresponding to the <query_param_name> value in http request params\n            status - use with static type, response status code\n            content_type - use with static type, response content-type\n            response_content - use with static type, response content sent to client, when using the prefix 'file://' or 'config://', find the content from the file or configuration send to client.\n\n    <http_handlers>\n        <rule>\n            <url>/</url>\n            <methods>post,get</methods>\n            <headers><pragma>no-cache</pragma></headers>\n            <handler>\n                <type>dynamic_query_handler</type>\n                <query_param_name>query</query_param_name>\n            </handler>\n        </rule>\n\n        <rule>\n            <url>/predefined_query</url>\n            <methods>post,get</methods>\n            <handler>\n                <type>predefined_query_handler</type>\n                <query>select * from system.settings</query>\n            </handler>\n        </rule>\n\n        <rule>\n            <handler>\n                <type>static</type>\n                <status>200</status>\n                <content_type>text/plain; charset=utf-8</content_type>\n                <response_content>config://http_server_default_response</response_content>\n            </handler>\n        </rule>\n    </http_handlers>\n    --\x3e\n\n    <send_crash_reports>\n        \x3c!-- changing <enabled> to true allows sending crash reports to --\x3e\n        \x3c!-- the clickhouse core developers team via sentry https://sentry.io --\x3e\n        \x3c!-- doing so at least in pre-production environments is highly appreciated --\x3e\n        <enabled>false</enabled>\n        \x3c!-- change <anonymize> to true if you don't feel comfortable attaching the server hostname to the crash report --\x3e\n        <anonymize>false</anonymize>\n        \x3c!-- default endpoint should be changed to different sentry dsn only if you have --\x3e\n        \x3c!-- some in-house engineers or hired consultants who're going to debug clickhouse issues for you --\x3e\n        <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>\n    </send_crash_reports>\n\n    \x3c!-- uncomment to disable clickhouse internal dns caching. --\x3e\n    \x3c!-- <disable_internal_dns_cache>1</disable_internal_dns_cache> --\x3e\n</yandex>\n\n\n\n# users.xml\n\n<?xml version=\"1.0\"?>\n<yandex>\n    \x3c!-- profiles of settings. --\x3e\n    <profiles>\n        \x3c!-- default settings. --\x3e\n        <default>\n            \x3c!-- maximum memory usage for processing single query, in bytes. --\x3e\n            <max_memory_usage>10000000000</max_memory_usage>\n\n            \x3c!-- how to choose between replicas during distributed query processing.\n                 random - choose random replica from set of replicas with minimum number of errors\n                 nearest_hostname - from set of replicas with minimum number of errors, choose replica\n                  with minimum number of different symbols between replica's hostname and local hostname\n                  (hamming distance).\n                 in_order - first live replica is chosen in specified order.\n                 first_or_random - if first replica one has higher number of errors, pick a random one from replicas with minimum number of errors.\n            --\x3e\n            <load_balancing>random</load_balancing>\n            <max_query_size>1073741824</max_query_size>\n            <max_ast_elements>10000000</max_ast_elements>\n            <max_expanded_ast_elements>10000000</max_expanded_ast_elements>\n        </default>\n\n        \x3c!-- profile that allows only read queries. --\x3e\n        <readonly>\n            <readonly>1</readonly>\n        </readonly>\n    </profiles>\n\n    \x3c!-- users and acl. --\x3e\n    <users>\n        \x3c!-- if user name was not specified, 'default' user is used. --\x3e\n        <default>\n            \x3c!-- password could be specified in plaintext or in sha256 (in hex format).\n\n                 if you want to specify password in plaintext (not recommended), place it in 'password' element.\n                 example: <password>qwerty</password>.\n                 password could be empty.\n\n                 if you want to specify sha256, place it in 'password_sha256_hex' element.\n                 example: <password_sha256_hex>65e84be33532fb784c48129675f9eff3a682b27168c0ea744b2cf58ee02337c5</password_sha256_hex>\n                 restrictions of sha256: impossibility to connect to clickhouse using mysql js client (as of july 2019).\n\n                 if you want to specify double sha1, place it in 'password_double_sha1_hex' element.\n                 example: <password_double_sha1_hex>e395796d6546b1b65db9d665cd43f0e858dd4303</password_double_sha1_hex>\n\n                 if you want to specify a previously defined ldap server (see 'ldap_servers' in the main config) for authentication,\n                  place its name in 'server' element inside 'ldap' element.\n                 example: <ldap><server>my_ldap_server</server></ldap>\n\n                 if you want to authenticate the user via kerberos (assuming kerberos is enabled, see 'kerberos' in the main config),\n                  place 'kerberos' element instead of 'password' (and similar) elements.\n                 the name part of the canonical principal name of the initiator must match the user name for authentication to succeed.\n                 you can also place 'realm' element inside 'kerberos' element to further restrict authentication to only those requests\n                  whose initiator's realm matches it. \n                 example: <kerberos />\n                 example: <kerberos><realm>example.com</realm></kerberos>\n\n                 how to generate decent password:\n                 execute: password=$(base64 < /dev/urandom | head -c8); echo \"$password\"; echo -n \"$password\" | sha256sum | tr -d '-'\n                 in first line will be password and in second - corresponding sha256.\n\n                 how to generate double sha1:\n                 execute: password=$(base64 < /dev/urandom | head -c8); echo \"$password\"; echo -n \"$password\" | sha1sum | tr -d '-' | xxd -r -p | sha1sum | tr -d '-'\n                 in first line will be password and in second - corresponding double sha1.\n            --\x3e\n            <password>clickhouse123$</password>\n\n            \x3c!-- list of networks with open access.\n\n                 to open access from everywhere, specify:\n                    <ip>::/0</ip>\n\n                 to open access only from localhost, specify:\n                    <ip>::1</ip>\n                    <ip>127.0.0.1</ip>\n\n                 each element of list has one of the following forms:\n                 <ip> ip-address or network mask. examples: 213.180.204.3 or 10.0.0.1/8 or 10.0.0.1/255.255.255.0\n                     2a02:6b8::3 or 2a02:6b8::3/64 or 2a02:6b8::3/ffff:ffff:ffff:ffff::.\n                 <host> hostname. example: server01.yandex.ru.\n                     to check access, dns query is performed, and all received addresses compared to peer address.\n                 <host_regexp> regular expression for host names. example, ^server\\d\\d-\\d\\d-\\d\\.yandex\\.ru$\n                     to check access, dns ptr query is performed for peer address and then regexp is applied.\n                     then, for result of ptr query, another dns query is performed and all received addresses compared to peer address.\n                     strongly recommended that regexp is ends with $\n                 all results of dns requests are cached till server restart.\n            --\x3e\n            <networks>\n                <ip>::/0</ip>\n            </networks>\n\n            \x3c!-- settings profile for user. --\x3e\n            <profile>default</profile>\n\n            \x3c!-- quota for user. --\x3e\n            <quota>default</quota>\n\n            \x3c!-- user can create other users and grant rights to them. --\x3e\n            \x3c!-- <access_management>1</access_management> --\x3e\n        </default>\n    </users>\n\n    \x3c!-- quotas. --\x3e\n    <quotas>\n        \x3c!-- name of quota. --\x3e\n        <default>\n            \x3c!-- limits for time interval. you could specify many intervals with different limits. --\x3e\n            <interval>\n                \x3c!-- length of interval. --\x3e\n                <duration>3600</duration>\n\n                \x3c!-- no limits. just calculate resource usage for time interval. --\x3e\n                <queries>0</queries>\n                <errors>0</errors>\n                <result_rows>0</result_rows>\n                <read_rows>0</read_rows>\n                <execution_time>0</execution_time>\n            </interval>\n        </default>\n    </quotas>\n</yandex>\n\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/clickhouse\n\\cp ./config.xml /etc/clickhouse/config.xml -f\n\\cp ./users.xml /etc/clickhouse/users.xml -f\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"EasyMock",frontmatter:{title:"EasyMock",date:"2023-09-05T15:22:11.000Z",permalink:"/pages/ca4b88/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/09.EasyMock.html",relativePath:"05.工具&部署/01.Docker/09.EasyMock.md",key:"v-10f613aa",path:"/pages/ca4b88/",headers:[{level:2,title:"EasyMock 模拟测试辅助工具",slug:"easymock-模拟测试辅助工具",normalizedTitle:"easymock 模拟测试辅助工具",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:113},{level:2,title:"特性",slug:"特性",normalizedTitle:"特性",charIndex:161},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:433},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:738}],headersStr:"EasyMock 模拟测试辅助工具 简介 特性 docker-compose.yml deploy.sh",content:"# EasyMock 模拟测试辅助工具\n\n开源网址\n\n官网：https://easy-mock.com/ (暂时无法访问)\n\ngithub：https://github.com/easy-mock/easy-mock\n\n\n# 简介\n\n\n\n> Easy Mock 是一个可视化，并且能快速生成模拟数据的持久化服务。\n\n\n# 特性\n\n * 支持接口代理\n * 支持快捷键操作\n * 支持协同编辑\n * 支持团队项目\n * 支持 RESTful\n * 支持 Swagger | OpenAPI Specification (1.2 & 2.0 & 3.0)\n   * 基于 Swagger 快速创建项目\n   * 支持显示接口入参与返回值\n   * 支持显示实体类\n * 支持灵活性与扩展性更高的响应式数据开发\n * 支持自定义响应配置（例：status/headers/cookies）\n * 支持 Mock.js 语法\n * 支持 restc 方式的接口预览\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  easymock: \n    image: jptx1234/easy-mock-all-in-one\n    container_name: easymock\n    restart: always\n    ports:\n      - 7300:7300\n    environment:\n      TZ: Asia/Shanghai\n    networks: \n      - swarm_net \n\nnetworks: \n  swarm_net: \n    external: true\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# easymock 模拟测试辅助工具\n\n开源网址\n\n官网：https://easy-mock.com/ (暂时无法访问)\n\ngithub：https://github.com/easy-mock/easy-mock\n\n\n# 简介\n\n\n\n> easy mock 是一个可视化，并且能快速生成模拟数据的持久化服务。\n\n\n# 特性\n\n * 支持接口代理\n * 支持快捷键操作\n * 支持协同编辑\n * 支持团队项目\n * 支持 restful\n * 支持 swagger | openapi specification (1.2 & 2.0 & 3.0)\n   * 基于 swagger 快速创建项目\n   * 支持显示接口入参与返回值\n   * 支持显示实体类\n * 支持灵活性与扩展性更高的响应式数据开发\n * 支持自定义响应配置（例：status/headers/cookies）\n * 支持 mock.js 语法\n * 支持 restc 方式的接口预览\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  easymock: \n    image: jptx1234/easy-mock-all-in-one\n    container_name: easymock\n    restart: always\n    ports:\n      - 7300:7300\n    environment:\n      tz: asia/shanghai\n    networks: \n      - swarm_net \n\nnetworks: \n  swarm_net: \n    external: true\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Emqx",frontmatter:{title:"Emqx",date:"2023-09-05T16:32:35.000Z",permalink:"/pages/d93c0b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/11.Emqx.html",relativePath:"05.工具&部署/01.Docker/11.Emqx.md",key:"v-0c164253",path:"/pages/d93c0b/",headers:[{level:2,title:"EMQX 物联网 MQTT 消息服务器",slug:"emqx-物联网-mqtt-消息服务器",normalizedTitle:"emqx 物联网 mqtt 消息服务器",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:94},{level:3,title:"软件简介",slug:"软件简介",normalizedTitle:"软件简介",charIndex:233},{level:2,title:"产品优势",slug:"产品优势",normalizedTitle:"产品优势",charIndex:370},{level:2,title:"功能概览",slug:"功能概览",normalizedTitle:"功能概览",charIndex:681},{level:3,title:"连接",slug:"连接",normalizedTitle:"连接",charIndex:183},{level:3,title:"安全",slug:"安全",normalizedTitle:"安全",charIndex:476},{level:3,title:"可伸缩性",slug:"可伸缩性",normalizedTitle:"可伸缩性",charIndex:1368},{level:3,title:"数据集成",slug:"数据集成",normalizedTitle:"数据集成",charIndex:1454},{level:3,title:"可靠性",slug:"可靠性",normalizedTitle:"可靠性",charIndex:480},{level:3,title:"可观测性",slug:"可观测性",normalizedTitle:"可观测性",charIndex:1662},{level:3,title:"可扩展性",slug:"可扩展性",normalizedTitle:"可扩展性",charIndex:1773},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1821},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2425}],headersStr:"EMQX 物联网 MQTT 消息服务器 简介 软件简介 产品优势 功能概览 连接 安全 可伸缩性 数据集成 可靠性 可观测性 可扩展性 docker-compose.yml deploy.sh",content:"# EMQX 物联网 MQTT 消息服务器\n\n开源网址\n\n官网：https://www.emqx.io/\n\ngithub：https://github.com/emqx/emqx\n\n\n# 简介\n\n\n\n> EMQX 是一款大规模可弹性伸缩的云原生分布式物联网 MQTT 消息服务器。\n\n作为全球最具扩展性的 MQTT 消息服务器，EMQX 提供了高效可靠海量物联网设备连接，能够高性能实时移动与处理消息和事件流数据，帮助您快速构建关键业务的物联网平台与应用。\n\n\n# 软件简介\n\nEMQX 是一款大规模可弹性伸缩的云原生分布式物联网 MQTT 消息服务器。\n\n作为全球最具扩展性的 MQTT 消息服务器，EMQX 提供了高效可靠海量物联网设备连接，能够高性能实时移动与处理消息和事件流数据，帮助您快速构建关键业务的物联网平台与应用。\n\n\n# 产品优势\n\n * 开放源码：基于 Apache 2.0 许可证完全开源，自 2013 年起 200+ 开源版本迭代。\n * MQTT 5.0：100% 支持 MQTT 5.0 和 3.x 协议标准，更好的伸缩性、安全性和可靠性。\n * 海量连接：单节点支持 500 万 MQTT 设备连接，集群可扩展至 1 亿并发 MQTT 连接。\n * 高性能：单节点支持每秒实时接收、移动、处理与分发数百万条的 MQTT 消息。\n * 低时延：基于 Erlang/OTP 软实时的运行时系统设计，消息分发与投递时延低于 1 毫秒。\n * 高可用：采用 Masterless 的大规模分布式集群架构，实现系统高可用和水平扩展。\n\n\n# 功能概览\n\n以下是 EMQX 不完全功能列表。\n\n\n# 连接\n\n * 完整支持 MQTT v3.1、v3.1.1 和 v5.0 协议规范\n   * QoS 0、QoS 1、QoS 2 消息支持\n   * 持久会话和离线消息支持\n   * 保留消息（Retained Message）支持\n   * 遗嘱消息（Will Message）支持\n   * 共享订阅支持\n   * $SYS/ 系统主题支持\n * MQTT 支持 4 种传输协议\n   * TCP\n   * TLS\n   * WebSocket\n   * QUIC（实验性）\n * HTTP 消息发布接口\n * 网关\n   * CoAP\n   * LwM2M\n   * MQTT-SN\n   * Stomp\n   * GB/T 32960（企业版）\n   * JT/T 808（企业版）\n\n更多 MQTT 扩展支持：\n\n * 延迟发布\n * 代理订阅\n * 主题重写\n\n\n# 安全\n\n * 基于用户名/密码的身份认证，支持使用内置数据库、Redis、MySQL、PostgreSQL、MongoDB 作为数据源，也支持使用 HTTP Server 提供认证服务\n * 基于 JWT 的身份认证与权限控制，支持 JWKs\n * MQTT 5.0 增强认证\n * PSK 身份验证\n * 基于 Client ID、IP 地址，用户名的访问控制，支持使用内置数据库、Redis、MySQL、PostgreSQL、MongoDB 作为数据源，也支持使用 HTTP Server 提供授权服务\n * 客户端黑名单支持\n\n\n# 可伸缩性\n\n * 多节点集群 (Cluster)\n * 支持手动、mcast、dns、etcd、k8s 集群发现方式集群\n * 多服务器节点桥接 (Bridge)\n\n\n# 数据集成\n\n * SQL 语法数据集成，实时提取、过滤、丰富和转换 MQTT 消息或内部事件为用户所需格式，并将其发送到外部数据平台\n * 通过 MQTT 与其他 Broker 或物联网平台进行双向数据桥接（如 EMQX Cloud，AWS IoT Core，Azure IoT Hub）\n * 通过 Webhook 与其他应用集成\n\n\n# 可靠性\n\n * 过载保护\n * 消息速率限制\n * 连接速率限制\n\n\n# 可观测性\n\n * 客户端在线状态查询\n * 集群状态与指标查询\n * Prometheus/StatsD 集成\n * 自动网络分区恢复\n * 在线日志追踪(Log Trace)\n * Erlang 运行时追踪工具\n\n\n# 可扩展性\n\n * 插件\n * 钩子\n * gRPC 钩子扩展\n * gRPC 协议扩展\n\n\n# docker-compose.yml\n\n\nversion: '3.7'\nservices: \n  emqx: \n    #image: emqx/emqx:v3.2.0\n    image: emqx/emqx:4.4.4\n    container_name: emqx\n    restart: always\n    environment:\n      TZ: Asia/Shanghai\n    ports: \n      - 1883:1883 \n      - 8083:8083\n      - 8883:8883\n      - 8084:8084\n      - 18083:18083\n      - 11883:11883\n      - 4369:4369\n      - 5369:5369\n      - 6369:6369\n      - 8080:8080\n    volumes: \n      - emqx_data:/opt/emqx/data\n      - emqx_etc:/opt/emqx/etc\n      - emqx_lib:/opt/emqx/lib\n      - emqx_log:/opt/emqx/log\n\nvolumes: \n  emqx_data: \n  emqx_etc: \n  emqx_lib: \n  emqx_log: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# emqx 物联网 mqtt 消息服务器\n\n开源网址\n\n官网：https://www.emqx.io/\n\ngithub：https://github.com/emqx/emqx\n\n\n# 简介\n\n\n\n> emqx 是一款大规模可弹性伸缩的云原生分布式物联网 mqtt 消息服务器。\n\n作为全球最具扩展性的 mqtt 消息服务器，emqx 提供了高效可靠海量物联网设备连接，能够高性能实时移动与处理消息和事件流数据，帮助您快速构建关键业务的物联网平台与应用。\n\n\n# 软件简介\n\nemqx 是一款大规模可弹性伸缩的云原生分布式物联网 mqtt 消息服务器。\n\n作为全球最具扩展性的 mqtt 消息服务器，emqx 提供了高效可靠海量物联网设备连接，能够高性能实时移动与处理消息和事件流数据，帮助您快速构建关键业务的物联网平台与应用。\n\n\n# 产品优势\n\n * 开放源码：基于 apache 2.0 许可证完全开源，自 2013 年起 200+ 开源版本迭代。\n * mqtt 5.0：100% 支持 mqtt 5.0 和 3.x 协议标准，更好的伸缩性、安全性和可靠性。\n * 海量连接：单节点支持 500 万 mqtt 设备连接，集群可扩展至 1 亿并发 mqtt 连接。\n * 高性能：单节点支持每秒实时接收、移动、处理与分发数百万条的 mqtt 消息。\n * 低时延：基于 erlang/otp 软实时的运行时系统设计，消息分发与投递时延低于 1 毫秒。\n * 高可用：采用 masterless 的大规模分布式集群架构，实现系统高可用和水平扩展。\n\n\n# 功能概览\n\n以下是 emqx 不完全功能列表。\n\n\n# 连接\n\n * 完整支持 mqtt v3.1、v3.1.1 和 v5.0 协议规范\n   * qos 0、qos 1、qos 2 消息支持\n   * 持久会话和离线消息支持\n   * 保留消息（retained message）支持\n   * 遗嘱消息（will message）支持\n   * 共享订阅支持\n   * $sys/ 系统主题支持\n * mqtt 支持 4 种传输协议\n   * tcp\n   * tls\n   * websocket\n   * quic（实验性）\n * http 消息发布接口\n * 网关\n   * coap\n   * lwm2m\n   * mqtt-sn\n   * stomp\n   * gb/t 32960（企业版）\n   * jt/t 808（企业版）\n\n更多 mqtt 扩展支持：\n\n * 延迟发布\n * 代理订阅\n * 主题重写\n\n\n# 安全\n\n * 基于用户名/密码的身份认证，支持使用内置数据库、redis、mysql、postgresql、mongodb 作为数据源，也支持使用 http server 提供认证服务\n * 基于 jwt 的身份认证与权限控制，支持 jwks\n * mqtt 5.0 增强认证\n * psk 身份验证\n * 基于 client id、ip 地址，用户名的访问控制，支持使用内置数据库、redis、mysql、postgresql、mongodb 作为数据源，也支持使用 http server 提供授权服务\n * 客户端黑名单支持\n\n\n# 可伸缩性\n\n * 多节点集群 (cluster)\n * 支持手动、mcast、dns、etcd、k8s 集群发现方式集群\n * 多服务器节点桥接 (bridge)\n\n\n# 数据集成\n\n * sql 语法数据集成，实时提取、过滤、丰富和转换 mqtt 消息或内部事件为用户所需格式，并将其发送到外部数据平台\n * 通过 mqtt 与其他 broker 或物联网平台进行双向数据桥接（如 emqx cloud，aws iot core，azure iot hub）\n * 通过 webhook 与其他应用集成\n\n\n# 可靠性\n\n * 过载保护\n * 消息速率限制\n * 连接速率限制\n\n\n# 可观测性\n\n * 客户端在线状态查询\n * 集群状态与指标查询\n * prometheus/statsd 集成\n * 自动网络分区恢复\n * 在线日志追踪(log trace)\n * erlang 运行时追踪工具\n\n\n# 可扩展性\n\n * 插件\n * 钩子\n * grpc 钩子扩展\n * grpc 协议扩展\n\n\n# docker-compose.yml\n\n\nversion: '3.7'\nservices: \n  emqx: \n    #image: emqx/emqx:v3.2.0\n    image: emqx/emqx:4.4.4\n    container_name: emqx\n    restart: always\n    environment:\n      tz: asia/shanghai\n    ports: \n      - 1883:1883 \n      - 8083:8083\n      - 8883:8883\n      - 8084:8084\n      - 18083:18083\n      - 11883:11883\n      - 4369:4369\n      - 5369:5369\n      - 6369:6369\n      - 8080:8080\n    volumes: \n      - emqx_data:/opt/emqx/data\n      - emqx_etc:/opt/emqx/etc\n      - emqx_lib:/opt/emqx/lib\n      - emqx_log:/opt/emqx/log\n\nvolumes: \n  emqx_data: \n  emqx_etc: \n  emqx_lib: \n  emqx_log: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"FastDFS",frontmatter:{title:"FastDFS",date:"2023-09-05T16:34:51.000Z",permalink:"/pages/7bfded/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/12.FastDFS.html",relativePath:"05.工具&部署/01.Docker/12.FastDFS.md",key:"v-65b952f2",path:"/pages/7bfded/",headers:[{level:2,title:"FastDFS 分布式文件系统",slug:"fastdfs-分布式文件系统",normalizedTitle:"fastdfs 分布式文件系统",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:76},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1218},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1744}],headersStr:"FastDFS 分布式文件系统 简介 docker-compose.yml deploy.sh",content:'# FastDFS 分布式文件系统\n\n开源网址\n\ngithub：https://github.com/happyfish100/fastdfs\n\n\n# 简介\n\n> FastDFS 是一个开源的分布式文件系统，她对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。\n\nFastDFS 服务端有两个角色：跟踪器（tracker）和存储节点（storage）。跟踪器主要做调度工作，在访问上起负载均衡的作用。\n\n存储节点存储文件，完成文件管理的所有功能：存储、同步和提供存取接口，FastDFS 同时对文件的 meta data 进行管理。所谓文件的 meta data 就是文件的相关属性，以键值对（key value pair）方式表示，如：width=1024，其中的 key 为 width，value 为 1024。文件 meta data 是文件属性列表，可以包含多个键值对。\n\nFastDFS 系统结构如下图所示：\n\n\n\n跟踪器和存储节点都可以由一台多台服务器构成。跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务。其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。\n\n为了支持大容量，存储节点（服务器）采用了分卷（或分组）的组织方式。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷 的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起 到了冗余备份和负载均衡的作用。\n\n在卷中增加服务器时，同步已有的文件由系统自动完成，同步完成后，系统自动将新增服务器切换到线上提供服务。\n\n当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。 FastDFS 中的文件标识分为两个部分：卷名和文件名，二者缺一不可。\n\n\n\n上传文件交互过程：\n\n 1. client 询问 tracker 上传到的 storage，不需要附加参数；\n 2. tracker 返回一台可用的 storage；\n 3. client 直接和 storage 通讯完成文件上传。\n\n\n\n下载文件交互过程：\n\n 1. client 询问 tracker 下载文件的 storage，参数为文件标识（卷名和文件名）；\n 2. tracker 返回一台可用的 storage；\n 3. client 直接和 storage 通讯完成文件下载。\n\n需要说明的是，client 为使用 FastDFS 服务的调用方，client 也应该是一台服务器，它对 tracker 和 storage 的调用均为服务器间的调用。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\nservices: \n  tracker:\n    image: delron/fastdfs\n    container_name: tracker\n    network_mode: "host"\n    volumes:\n      - tracker_data:/var/fdfs\n    command: tracker\n  storage:\n    image: delron/fastdfs\n    container_name: storage\n    network_mode: "host"\n    volumes:\n      - storage_data:/var/fdfs\n    environment:\n      - TRACKER_SERVER=192.168.23.134:22122\n      - GROUP_NAME=group1 \n    command: storage\n    depends_on:\n      - tracker\n\nvolumes: \n  tracker_data: \n  storage_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',normalizedContent:'# fastdfs 分布式文件系统\n\n开源网址\n\ngithub：https://github.com/happyfish100/fastdfs\n\n\n# 简介\n\n> fastdfs 是一个开源的分布式文件系统，她对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。\n\nfastdfs 服务端有两个角色：跟踪器（tracker）和存储节点（storage）。跟踪器主要做调度工作，在访问上起负载均衡的作用。\n\n存储节点存储文件，完成文件管理的所有功能：存储、同步和提供存取接口，fastdfs 同时对文件的 meta data 进行管理。所谓文件的 meta data 就是文件的相关属性，以键值对（key value pair）方式表示，如：width=1024，其中的 key 为 width，value 为 1024。文件 meta data 是文件属性列表，可以包含多个键值对。\n\nfastdfs 系统结构如下图所示：\n\n\n\n跟踪器和存储节点都可以由一台多台服务器构成。跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务。其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。\n\n为了支持大容量，存储节点（服务器）采用了分卷（或分组）的组织方式。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷 的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起 到了冗余备份和负载均衡的作用。\n\n在卷中增加服务器时，同步已有的文件由系统自动完成，同步完成后，系统自动将新增服务器切换到线上提供服务。\n\n当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。 fastdfs 中的文件标识分为两个部分：卷名和文件名，二者缺一不可。\n\n\n\n上传文件交互过程：\n\n 1. client 询问 tracker 上传到的 storage，不需要附加参数；\n 2. tracker 返回一台可用的 storage；\n 3. client 直接和 storage 通讯完成文件上传。\n\n\n\n下载文件交互过程：\n\n 1. client 询问 tracker 下载文件的 storage，参数为文件标识（卷名和文件名）；\n 2. tracker 返回一台可用的 storage；\n 3. client 直接和 storage 通讯完成文件下载。\n\n需要说明的是，client 为使用 fastdfs 服务的调用方，client 也应该是一台服务器，它对 tracker 和 storage 的调用均为服务器间的调用。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\nservices: \n  tracker:\n    image: delron/fastdfs\n    container_name: tracker\n    network_mode: "host"\n    volumes:\n      - tracker_data:/var/fdfs\n    command: tracker\n  storage:\n    image: delron/fastdfs\n    container_name: storage\n    network_mode: "host"\n    volumes:\n      - storage_data:/var/fdfs\n    environment:\n      - tracker_server=192.168.23.134:22122\n      - group_name=group1 \n    command: storage\n    depends_on:\n      - tracker\n\nvolumes: \n  tracker_data: \n  storage_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Elasticsearch",frontmatter:{title:"Elasticsearch",date:"2023-09-05T15:23:58.000Z",permalink:"/pages/18fff0/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/10.Elasticsearch.html",relativePath:"05.工具&部署/01.Docker/10.Elasticsearch.md",key:"v-672547f2",path:"/pages/18fff0/",headers:[{level:2,title:"Elasticsearch - 分布式搜索引擎",slug:"elasticsearch-分布式搜索引擎",normalizedTitle:"elasticsearch - 分布式搜索引擎",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:130},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:898},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1722}],headersStr:"Elasticsearch - 分布式搜索引擎 简介 docker-compose.yml deploy.sh",content:"# Elasticsearch - 分布式搜索引擎\n\n开源网址\n\n官网：https://www.elastic.co/cn/elasticsearch/\n\ngithub：https://github.com/elastic/elasticsearch\n\n\n# 简介\n\n\n\n> Elasticsearch 是一个分布式的 RESTful 风格的搜索和数据分析引擎，能够解决越来越多的用例。作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。\n\nElasticsearch 是一个实时的分布式搜索分析引擎， 它能让你以一个之前从未有过的速度和规模，去探索你的数据。 它被用作全文检索、结构化搜索、分析以及这三个功能的组合：\n\n * Wikipedia 使用 Elasticsearch 提供带有高亮片段的全文搜索，还有 search-as-you-type 和 did-you-mean 的建议。\n * 卫报 使用 Elasticsearch 将网络社交数据结合到访客日志中，实时的给它的编辑们提供公众对于新文章的反馈。\n * Stack Overflow 将地理位置查询融入全文检索中去，并且使用 more-like-this 接口去查找相关的问题与答案。\n * GitHub 使用 Elasticsearch 对 1300 亿行代码进行查询。\n\n然而 Elasticsearch 不仅仅为巨头公司服务。它也帮助了很多初创公司，像 Datadog 和 Klout， 帮助他们将想法用原型实现，并转化为可扩展的解决方案。Elasticsearch 能运行在你的笔记本电脑上，或者扩展到上百台服务器上去处理 PB 级数据。\n\nElasticsearch 中没有一个单独的组件是全新的或者是革命性的。全文搜索很久之前就已经可以做到了， 就像早就出现了的分析系统和分布式数据库。革命性的成果在于将这些单独的，有用的组件融合到一个单一的、一致的、实时的应用中。它对于初学者而言有一个较低的门槛， 而当你的技能提升或需求增加时，它也始终能满足你的需求。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  elasticsearch: \n    image: elasticsearch:6.8.1\n    container_name: elasticsearch\n    restart: always\n    hostname: elasticsearch\n    volumes: \n      - es_data:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n      - 9300:9300\n    environment:\n      - discovery.type=single-node\n      - \"TZ=Asia/Shanghai\"\n      # 设置宿主机内存大小\n      - \"ES_JAVA_OPTS=-Xms6g -Xmx6g\"\n    deploy:\n      resources:\n        limits:\n          #cpus: '2'\n          memory: 6G      \n  \n  kibana:\n    image: kibana:6.8.1\n    container_name: kibana\n    restart: always\n    ports:\n      - 5601:5601\n    environment:\n      SERVER_NAME: kibana\n      ELASTICSEARCH_URL: http://elasticsearch:9200\n      TZ: Asia/Shanghai\n    depends_on: ['elasticsearch']\n\nvolumes: \n  es_data: \n    driver: local\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# elasticsearch - 分布式搜索引擎\n\n开源网址\n\n官网：https://www.elastic.co/cn/elasticsearch/\n\ngithub：https://github.com/elastic/elasticsearch\n\n\n# 简介\n\n\n\n> elasticsearch 是一个分布式的 restful 风格的搜索和数据分析引擎，能够解决越来越多的用例。作为 elastic stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。\n\nelasticsearch 是一个实时的分布式搜索分析引擎， 它能让你以一个之前从未有过的速度和规模，去探索你的数据。 它被用作全文检索、结构化搜索、分析以及这三个功能的组合：\n\n * wikipedia 使用 elasticsearch 提供带有高亮片段的全文搜索，还有 search-as-you-type 和 did-you-mean 的建议。\n * 卫报 使用 elasticsearch 将网络社交数据结合到访客日志中，实时的给它的编辑们提供公众对于新文章的反馈。\n * stack overflow 将地理位置查询融入全文检索中去，并且使用 more-like-this 接口去查找相关的问题与答案。\n * github 使用 elasticsearch 对 1300 亿行代码进行查询。\n\n然而 elasticsearch 不仅仅为巨头公司服务。它也帮助了很多初创公司，像 datadog 和 klout， 帮助他们将想法用原型实现，并转化为可扩展的解决方案。elasticsearch 能运行在你的笔记本电脑上，或者扩展到上百台服务器上去处理 pb 级数据。\n\nelasticsearch 中没有一个单独的组件是全新的或者是革命性的。全文搜索很久之前就已经可以做到了， 就像早就出现了的分析系统和分布式数据库。革命性的成果在于将这些单独的，有用的组件融合到一个单一的、一致的、实时的应用中。它对于初学者而言有一个较低的门槛， 而当你的技能提升或需求增加时，它也始终能满足你的需求。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  elasticsearch: \n    image: elasticsearch:6.8.1\n    container_name: elasticsearch\n    restart: always\n    hostname: elasticsearch\n    volumes: \n      - es_data:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n      - 9300:9300\n    environment:\n      - discovery.type=single-node\n      - \"tz=asia/shanghai\"\n      # 设置宿主机内存大小\n      - \"es_java_opts=-xms6g -xmx6g\"\n    deploy:\n      resources:\n        limits:\n          #cpus: '2'\n          memory: 6g      \n  \n  kibana:\n    image: kibana:6.8.1\n    container_name: kibana\n    restart: always\n    ports:\n      - 5601:5601\n    environment:\n      server_name: kibana\n      elasticsearch_url: http://elasticsearch:9200\n      tz: asia/shanghai\n    depends_on: ['elasticsearch']\n\nvolumes: \n  es_data: \n    driver: local\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Flink",frontmatter:{title:"Flink",date:"2023-09-05T16:38:01.000Z",permalink:"/pages/53b154/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/13.Flink.html",relativePath:"05.工具&部署/01.Docker/13.Flink.md",key:"v-21a1b472",path:"/pages/53b154/",headers:[{level:2,title:"Apache Flink® - 数据流上的有状态计算",slug:"apache-flink®-数据流上的有状态计算",normalizedTitle:"apache flink® - 数据流上的有状态计算",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:109},{level:2,title:"处理无界和有界数据",slug:"处理无界和有界数据",normalizedTitle:"处理无界和有界数据",charIndex:238},{level:2,title:"部署应用到任意地方",slug:"部署应用到任意地方",normalizedTitle:"部署应用到任意地方",charIndex:725},{level:2,title:"运行任意规模应用",slug:"运行任意规模应用",normalizedTitle:"运行任意规模应用",charIndex:1110},{level:2,title:"利用内存性能",slug:"利用内存性能",normalizedTitle:"利用内存性能",charIndex:1366},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1539},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2190}],headersStr:"Apache Flink® - 数据流上的有状态计算 简介 处理无界和有界数据 部署应用到任意地方 运行任意规模应用 利用内存性能 docker-compose.yml deploy.sh",content:'# Apache Flink® - 数据流上的有状态计算\n\n开源网址\n\n官网：https://flink.apache.org/\n\ngithub：https://github.com/apache/flink\n\n\n# 简介\n\n\n\n> Apache Flink 是一个框架和分布式处理引擎，用于在无边界和有边界数据流上进行有状态的计算。Flink 能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。\n\n接下来，我们来介绍一下 Flink 架构中的重要方面。\n\n\n# 处理无界和有界数据\n\n任何类型的数据都可以形成一种事件流。信用卡交易、传感器测量、机器日志、网站或移动应用程序上的用户交互记录，所有这些数据都形成一种流。\n\n数据可以被作为 无界 或者 有界 流来处理。\n\n 1. 无界流 有定义流的开始，但没有定义流的结束。它们会无休止地产生数据。无界流的数据必须持续处理，即数据被摄取后需要立刻处理。我们不能等到所有数据都到达再处理，因为输入是无限的，在任何时候输入都不会完成。处理无界数据通常要求以特定顺序摄取事件，例如事件发生的顺序，以便能够推断结果的完整性。\n 2. 有界流 有定义流的开始，也有定义流的结束。有界流可以在摄取所有数据后再进行计算。有界流所有数据可以被排序，所以并不需要有序摄取。有界流处理通常被称为批处理\n\n\n\nApache Flink 擅长处理无界和有界数据集 精确的时间控制和状态化使得 Flink 的运行时(runtime)能够运行任何处理无界流的应用。有界流则由一些专为固定大小数据集特殊设计的算法和数据结构进行内部处理，产生了出色的性能。\n\n通过探索 Flink 之上构建的 用例 来加深理解。\n\n\n# 部署应用到任意地方\n\nApache Flink 是一个分布式系统，它需要计算资源来执行应用程序。Flink 集成了所有常见的集群资源管理器，例如 Hadoop YARN、 Apache Mesos 和 Kubernetes，但同时也可以作为独立集群运行。\n\nFlink 被设计为能够很好地工作在上述每个资源管理器中，这是通过资源管理器特定(resource-manager-specific)的部署模式实现的。Flink 可以采用与当前资源管理器相适应的方式进行交互。\n\n部署 Flink 应用程序时，Flink 会根据应用程序配置的并行性自动标识所需的资源，并从资源管理器请求这些资源。在发生故障的情况下，Flink 通过请求新资源来替换发生故障的容器。提交或控制应用程序的所有通信都是通过 REST 调用进行的，这可以简化 Flink 与各种环境中的集成。\n\n\n# 运行任意规模应用\n\nFlink 旨在任意规模上运行有状态流式应用。因此，应用程序被并行化为可能数千个任务，这些任务分布在集群中并发执行。所以应用程序能够充分利用无尽的 CPU、内存、磁盘和网络 IO。而且 Flink 很容易维护非常大的应用程序状态。其异步和增量的检查点算法对处理延迟产生最小的影响，同时保证精确一次状态的一致性。\n\nFlink 用户报告了其生产环境中一些令人印象深刻的扩展性数字\n\n * 处理每天处理数万亿的事件,\n * 应用维护几TB大小的状态, 和\n * 应用在数千个内核上运行。\n\n\n# 利用内存性能\n\n有状态的 Flink 程序针对本地状态访问进行了优化。任务的状态始终保留在内存中，如果状态大小超过可用内存，则会保存在能高效访问的磁盘数据结构中。任务通过访问本地（通常在内存中）状态来进行所有的计算，从而产生非常低的处理延迟。Flink 通过定期和异步地对本地状态进行持久化存储来保证故障场景下精确一次的状态一致性。\n\n\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\n# docker run --name flink_jobmanager -d -t flink jobmanager\n# docker run --name flink_taskmanager -d -t flink taskmanager\n\nservices: \n\n  jobmanager:\n    image: flink:1.15.2\n    expose:\n      - "6123"\n    ports:\n      - "8081:8081"\n    command: jobmanager\n    environment:\n      - JOB_MANAGER_RPC_ADDRESS=jobmanager\n      - TZ=Asia/Shanghai\n\n  taskmanager:\n    image: flink:1.15.2\n    expose:\n      - "6121"\n      - "6122"\n    depends_on:\n      - jobmanager\n    command: taskmanager\n    links:\n      - "jobmanager:jobmanager"\n    environment:\n      - JOB_MANAGER_RPC_ADDRESS=jobmanager\n      - TZ=Asia/Shanghai\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',normalizedContent:'# apache flink® - 数据流上的有状态计算\n\n开源网址\n\n官网：https://flink.apache.org/\n\ngithub：https://github.com/apache/flink\n\n\n# 简介\n\n\n\n> apache flink 是一个框架和分布式处理引擎，用于在无边界和有边界数据流上进行有状态的计算。flink 能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。\n\n接下来，我们来介绍一下 flink 架构中的重要方面。\n\n\n# 处理无界和有界数据\n\n任何类型的数据都可以形成一种事件流。信用卡交易、传感器测量、机器日志、网站或移动应用程序上的用户交互记录，所有这些数据都形成一种流。\n\n数据可以被作为 无界 或者 有界 流来处理。\n\n 1. 无界流 有定义流的开始，但没有定义流的结束。它们会无休止地产生数据。无界流的数据必须持续处理，即数据被摄取后需要立刻处理。我们不能等到所有数据都到达再处理，因为输入是无限的，在任何时候输入都不会完成。处理无界数据通常要求以特定顺序摄取事件，例如事件发生的顺序，以便能够推断结果的完整性。\n 2. 有界流 有定义流的开始，也有定义流的结束。有界流可以在摄取所有数据后再进行计算。有界流所有数据可以被排序，所以并不需要有序摄取。有界流处理通常被称为批处理\n\n\n\napache flink 擅长处理无界和有界数据集 精确的时间控制和状态化使得 flink 的运行时(runtime)能够运行任何处理无界流的应用。有界流则由一些专为固定大小数据集特殊设计的算法和数据结构进行内部处理，产生了出色的性能。\n\n通过探索 flink 之上构建的 用例 来加深理解。\n\n\n# 部署应用到任意地方\n\napache flink 是一个分布式系统，它需要计算资源来执行应用程序。flink 集成了所有常见的集群资源管理器，例如 hadoop yarn、 apache mesos 和 kubernetes，但同时也可以作为独立集群运行。\n\nflink 被设计为能够很好地工作在上述每个资源管理器中，这是通过资源管理器特定(resource-manager-specific)的部署模式实现的。flink 可以采用与当前资源管理器相适应的方式进行交互。\n\n部署 flink 应用程序时，flink 会根据应用程序配置的并行性自动标识所需的资源，并从资源管理器请求这些资源。在发生故障的情况下，flink 通过请求新资源来替换发生故障的容器。提交或控制应用程序的所有通信都是通过 rest 调用进行的，这可以简化 flink 与各种环境中的集成。\n\n\n# 运行任意规模应用\n\nflink 旨在任意规模上运行有状态流式应用。因此，应用程序被并行化为可能数千个任务，这些任务分布在集群中并发执行。所以应用程序能够充分利用无尽的 cpu、内存、磁盘和网络 io。而且 flink 很容易维护非常大的应用程序状态。其异步和增量的检查点算法对处理延迟产生最小的影响，同时保证精确一次状态的一致性。\n\nflink 用户报告了其生产环境中一些令人印象深刻的扩展性数字\n\n * 处理每天处理数万亿的事件,\n * 应用维护几tb大小的状态, 和\n * 应用在数千个内核上运行。\n\n\n# 利用内存性能\n\n有状态的 flink 程序针对本地状态访问进行了优化。任务的状态始终保留在内存中，如果状态大小超过可用内存，则会保存在能高效访问的磁盘数据结构中。任务通过访问本地（通常在内存中）状态来进行所有的计算，从而产生非常低的处理延迟。flink 通过定期和异步地对本地状态进行持久化存储来保证故障场景下精确一次的状态一致性。\n\n\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\n# docker run --name flink_jobmanager -d -t flink jobmanager\n# docker run --name flink_taskmanager -d -t flink taskmanager\n\nservices: \n\n  jobmanager:\n    image: flink:1.15.2\n    expose:\n      - "6123"\n    ports:\n      - "8081:8081"\n    command: jobmanager\n    environment:\n      - job_manager_rpc_address=jobmanager\n      - tz=asia/shanghai\n\n  taskmanager:\n    image: flink:1.15.2\n    expose:\n      - "6121"\n      - "6122"\n    depends_on:\n      - jobmanager\n    command: taskmanager\n    links:\n      - "jobmanager:jobmanager"\n    environment:\n      - job_manager_rpc_address=jobmanager\n      - tz=asia/shanghai\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Gitlab",frontmatter:{title:"Gitlab",date:"2023-09-05T16:40:38.000Z",permalink:"/pages/83a3e2/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/14.Gitlab.html",relativePath:"05.工具&部署/01.Docker/14.Gitlab.md",key:"v-24c0bbfe",path:"/pages/83a3e2/",headers:[{level:2,title:"GitLab 项目管理和代码托管平台",slug:"gitlab-项目管理和代码托管平台",normalizedTitle:"gitlab 项目管理和代码托管平台",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:61},{level:2,title:"主要特性",slug:"主要特性",normalizedTitle:"主要特性",charIndex:214},{level:2,title:"部署方式",slug:"部署方式",normalizedTitle:"部署方式",charIndex:708},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:866},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1012},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2254},{level:2,title:"GitlabRunner",slug:"gitlabrunner",normalizedTitle:"gitlabrunner",charIndex:2304},{level:3,title:"docker-compose.yml",slug:"docker-compose-yml-2",normalizedTitle:"docker-compose.yml",charIndex:1012},{level:3,title:"deploy.sh",slug:"deploy-sh-2",normalizedTitle:"deploy.sh",charIndex:2254},{level:3,title:"注册流程",slug:"注册流程",normalizedTitle:"注册流程",charIndex:2752}],headersStr:"GitLab 项目管理和代码托管平台 简介 主要特性 部署方式 总结 docker-compose.yml deploy.sh GitlabRunner docker-compose.yml deploy.sh 注册流程",content:"# GitLab 项目管理和代码托管平台\n\n开源网址\n\n官网：https://about.gitlab.com/\n\n\n# 简介\n\n\n\n> GitLab 是一个开源的代码托管和协作平台，旨在帮助开发团队更高效地管理代码、进行协作和持续集成/持续交付。它提供了一系列强大的功能，包括代码仓库管理、问题跟踪、持续集成、持续交付、代码审查、Wiki 文档、项目管理等，使开发团队能够在一个集成的平台上管理整个软件开发生命周期。\n\n\n# 主要特性\n\nGitLab 提供了许多功能，以支持团队在一个平台上协作开发和管理项目：\n\n * 代码托管 ：支持 Git 版本控制系统，团队可以在 GitLab 上创建和管理代码仓库，跟踪代码的历史变更，并支持分支和合并请求。\n * 问题跟踪 ：可以在 GitLab 上创建和管理项目中的问题、任务和需求。团队成员可以讨论、分配、标记和跟踪问题的状态。\n * 持续集成/持续交付 ：GitLab 提供了强大的 CI/CD（持续集成/持续交付）功能，可以自动化构建、测试和部署代码。用户可以配置流水线来实现自动化的软件交付流程。\n * 代码审查 ：支持合并请求（Merge Requests），团队成员可以创建合并请求并邀请其他成员审查代码变更。这有助于确保代码质量并促进团队合作。\n * Wiki 文档 ：每个项目都有一个集成的 Wiki，可以用来记录项目文档、知识库和指南。\n * 项目管理 ：GitLab 提供项目看板和里程碑等功能，帮助团队进行项目计划、任务跟踪和进度管理。\n * 安全性 ：GitLab 提供代码静态分析、容器扫描等安全功能，帮助识别和解决潜在的安全风险。\n\n\n# 部署方式\n\nGitLab 提供了不同的部署方式，以适应不同的需求：\n\n * GitLab.com ：GitLab 官方托管的 SaaS 版本，无需自行部署，适用于小型团队和个人开发者。\n * 自托管 ：用户可以自行在私有服务器上部署 GitLab，以获得更高的定制性和控制权，适用于企业和大型组织。\n * \n\n\n# 总结\n\nGitLab 是一个功能丰富的开源代码托管和协作平台，帮助团队高效地进行代码管理、协作和持续集成/持续交付。无论是个人项目还是大型团队，GitLab 都提供了一系列工具来支持软件开发的各个方面。无论您是开发者、项目经理还是企业领导，GitLab 都是一个值得考虑的强大工具。\n\n\n# docker-compose.yml\n\nversion: '3.7'\nservices: \n  gitlab:\n    container_name: gitlab\n    image: 'gitlab/gitlab-ce:15.2.2-ce.0'\n    restart: always\n    hostname: '10.142.51.100'\n    environment:\n      GITLAB_OMNIBUS_CONFIG: |\n        external_url 'http://10.142.51.100:1230'\n        gitlab_rails['gitlab_shell_ssh_port'] = 1232\n        gitlab_rails['time_zone'] = 'Asia/Shanghai'\n        gitlab_rails['gitlab_email_enabled'] = true\n        gitlab_rails['smtp_enable'] = true\n        gitlab_rails['smtp_address'] = \"smtp.163.com\"\n        gitlab_rails['smtp_port'] = 465\n        gitlab_rails['smtp_user_name'] = \"\"\n        gitlab_rails['smtp_password'] = \"\"\n        gitlab_rails['smtp_domain'] = \"163.com\"\n        gitlab_rails['smtp_authentication'] = \"login\"\n        gitlab_rails['smtp_enable_starttls_auto'] = true\n        gitlab_rails['smtp_tls'] = true\n        gitlab_rails['gitlab_email_from'] = 'ego_it@163.com'\n        gitlab_rails['initial_root_password'] = 'Gitlab123$'\n    ports:\n      - '1230:1230'\n      - '1231:443'\n      - '1232:22'\n    volumes:\n      - 'gitlab_data:/etc/gitlab'\n      - 'gitlab_log_data:/var/log/gitlab'\n      - 'gitlab_opt_data:/var/opt/gitlab'\nvolumes: \n  gitlab_data: \n  gitlab_log_data:\n  gitlab_opt_data:\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# GitlabRunner\n\n\n# docker-compose.yml\n\nversion: '3.7'\nservices: \n  gitlab-runner:\n    container_name: gitlab-runner\n    image: 'gitlab/gitlab-runner:v15.2.1'\n    restart: always\n    privileged: true\n    volumes:\n      - 'data:/etc/gitlab-runner'\n      - '/var/run/docker.sock:/var/run/docker.sock'\n    networks: \n      - swarm_net\nvolumes: \n  data: \nnetworks: \n  swarm_net: \n    external: true \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# 注册流程\n\n * docker in docker 方案\n\n// 执行注册流程\ndocker exec -it gitlab-runner bash\ngitlab-runner register\n// 在交互式终端中填入 Git Lab 提供的 URL 和 token\n[root@localhost-0002 GitLabRunner]# docker exec -it 8afd63e9abbb bash\nroot@8afd63e9abbb:/# gitlab-runner register\nRuntime platform                                    arch=amd64 os=linux pid=33 revision=58272c27 version=12.7.0\nRunning in system-mode.                            \n                                                   \nPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):\nhttp://192.168.0.123:1230/\nPlease enter the gitlab-ci token for this runner:\ni6aQMeza7Hxa1t_bAjzT\nPlease enter the gitlab-ci description for this runner:\n[8afd63e9abbb]: \nPlease enter the gitlab-ci tags for this runner (comma separated):\n\nRegistering runner... succeeded                     runner=i6aQMeza\nPlease enter the executor: custom, docker, docker-ssh, shell, docker+machine, docker-ssh+machine, kubernetes, parallels, ssh, virtualbox:\ndocker\nRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! \ndocker:19.03.8\n// 这里跳过了 description 与 tags ，tags表示什么时候触发，为空表示任何时候都触发，deploy表示部署时触发，下面是执行器，这里填入 docker\n// 回到 GitLab ，可以看到已经注册成功\n/usr/local/bin/docker-compose -f /data/composefile/GitLabRunner/docker-compose.yml down\ndocker system prune -f --volumes\n/usr/local/bin/docker-compose -f /data/composefile/GitLabRunner/docker-compose.yml up -d\n\ndocker exec -it gitlab-runner sh\ngitlab-runner --help\ngitlab-runner restart\ncat /etc/gitlab-runner/config.toml\nvi /etc/gitlab-runner/config.toml\nprivileged = true\nvolumes = [\"/var/run/docker.sock:/var/run/docker.sock\", \"/cache\"]\nvi config.toml\n",normalizedContent:"# gitlab 项目管理和代码托管平台\n\n开源网址\n\n官网：https://about.gitlab.com/\n\n\n# 简介\n\n\n\n> gitlab 是一个开源的代码托管和协作平台，旨在帮助开发团队更高效地管理代码、进行协作和持续集成/持续交付。它提供了一系列强大的功能，包括代码仓库管理、问题跟踪、持续集成、持续交付、代码审查、wiki 文档、项目管理等，使开发团队能够在一个集成的平台上管理整个软件开发生命周期。\n\n\n# 主要特性\n\ngitlab 提供了许多功能，以支持团队在一个平台上协作开发和管理项目：\n\n * 代码托管 ：支持 git 版本控制系统，团队可以在 gitlab 上创建和管理代码仓库，跟踪代码的历史变更，并支持分支和合并请求。\n * 问题跟踪 ：可以在 gitlab 上创建和管理项目中的问题、任务和需求。团队成员可以讨论、分配、标记和跟踪问题的状态。\n * 持续集成/持续交付 ：gitlab 提供了强大的 ci/cd（持续集成/持续交付）功能，可以自动化构建、测试和部署代码。用户可以配置流水线来实现自动化的软件交付流程。\n * 代码审查 ：支持合并请求（merge requests），团队成员可以创建合并请求并邀请其他成员审查代码变更。这有助于确保代码质量并促进团队合作。\n * wiki 文档 ：每个项目都有一个集成的 wiki，可以用来记录项目文档、知识库和指南。\n * 项目管理 ：gitlab 提供项目看板和里程碑等功能，帮助团队进行项目计划、任务跟踪和进度管理。\n * 安全性 ：gitlab 提供代码静态分析、容器扫描等安全功能，帮助识别和解决潜在的安全风险。\n\n\n# 部署方式\n\ngitlab 提供了不同的部署方式，以适应不同的需求：\n\n * gitlab.com ：gitlab 官方托管的 saas 版本，无需自行部署，适用于小型团队和个人开发者。\n * 自托管 ：用户可以自行在私有服务器上部署 gitlab，以获得更高的定制性和控制权，适用于企业和大型组织。\n * \n\n\n# 总结\n\ngitlab 是一个功能丰富的开源代码托管和协作平台，帮助团队高效地进行代码管理、协作和持续集成/持续交付。无论是个人项目还是大型团队，gitlab 都提供了一系列工具来支持软件开发的各个方面。无论您是开发者、项目经理还是企业领导，gitlab 都是一个值得考虑的强大工具。\n\n\n# docker-compose.yml\n\nversion: '3.7'\nservices: \n  gitlab:\n    container_name: gitlab\n    image: 'gitlab/gitlab-ce:15.2.2-ce.0'\n    restart: always\n    hostname: '10.142.51.100'\n    environment:\n      gitlab_omnibus_config: |\n        external_url 'http://10.142.51.100:1230'\n        gitlab_rails['gitlab_shell_ssh_port'] = 1232\n        gitlab_rails['time_zone'] = 'asia/shanghai'\n        gitlab_rails['gitlab_email_enabled'] = true\n        gitlab_rails['smtp_enable'] = true\n        gitlab_rails['smtp_address'] = \"smtp.163.com\"\n        gitlab_rails['smtp_port'] = 465\n        gitlab_rails['smtp_user_name'] = \"\"\n        gitlab_rails['smtp_password'] = \"\"\n        gitlab_rails['smtp_domain'] = \"163.com\"\n        gitlab_rails['smtp_authentication'] = \"login\"\n        gitlab_rails['smtp_enable_starttls_auto'] = true\n        gitlab_rails['smtp_tls'] = true\n        gitlab_rails['gitlab_email_from'] = 'ego_it@163.com'\n        gitlab_rails['initial_root_password'] = 'gitlab123$'\n    ports:\n      - '1230:1230'\n      - '1231:443'\n      - '1232:22'\n    volumes:\n      - 'gitlab_data:/etc/gitlab'\n      - 'gitlab_log_data:/var/log/gitlab'\n      - 'gitlab_opt_data:/var/opt/gitlab'\nvolumes: \n  gitlab_data: \n  gitlab_log_data:\n  gitlab_opt_data:\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# gitlabrunner\n\n\n# docker-compose.yml\n\nversion: '3.7'\nservices: \n  gitlab-runner:\n    container_name: gitlab-runner\n    image: 'gitlab/gitlab-runner:v15.2.1'\n    restart: always\n    privileged: true\n    volumes:\n      - 'data:/etc/gitlab-runner'\n      - '/var/run/docker.sock:/var/run/docker.sock'\n    networks: \n      - swarm_net\nvolumes: \n  data: \nnetworks: \n  swarm_net: \n    external: true \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n\n\n\n# 注册流程\n\n * docker in docker 方案\n\n// 执行注册流程\ndocker exec -it gitlab-runner bash\ngitlab-runner register\n// 在交互式终端中填入 git lab 提供的 url 和 token\n[root@localhost-0002 gitlabrunner]# docker exec -it 8afd63e9abbb bash\nroot@8afd63e9abbb:/# gitlab-runner register\nruntime platform                                    arch=amd64 os=linux pid=33 revision=58272c27 version=12.7.0\nrunning in system-mode.                            \n                                                   \nplease enter the gitlab-ci coordinator url (e.g. https://gitlab.com/):\nhttp://192.168.0.123:1230/\nplease enter the gitlab-ci token for this runner:\ni6aqmeza7hxa1t_bajzt\nplease enter the gitlab-ci description for this runner:\n[8afd63e9abbb]: \nplease enter the gitlab-ci tags for this runner (comma separated):\n\nregistering runner... succeeded                     runner=i6aqmeza\nplease enter the executor: custom, docker, docker-ssh, shell, docker+machine, docker-ssh+machine, kubernetes, parallels, ssh, virtualbox:\ndocker\nrunner registered successfully. feel free to start it, but if it's running already the config should be automatically reloaded! \ndocker:19.03.8\n// 这里跳过了 description 与 tags ，tags表示什么时候触发，为空表示任何时候都触发，deploy表示部署时触发，下面是执行器，这里填入 docker\n// 回到 gitlab ，可以看到已经注册成功\n/usr/local/bin/docker-compose -f /data/composefile/gitlabrunner/docker-compose.yml down\ndocker system prune -f --volumes\n/usr/local/bin/docker-compose -f /data/composefile/gitlabrunner/docker-compose.yml up -d\n\ndocker exec -it gitlab-runner sh\ngitlab-runner --help\ngitlab-runner restart\ncat /etc/gitlab-runner/config.toml\nvi /etc/gitlab-runner/config.toml\nprivileged = true\nvolumes = [\"/var/run/docker.sock:/var/run/docker.sock\", \"/cache\"]\nvi config.toml\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Jrebel",frontmatter:{title:"Jrebel",date:"2023-09-05T16:50:31.000Z",permalink:"/pages/8e9d93/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/16.Jrebel.html",relativePath:"05.工具&部署/01.Docker/16.Jrebel.md",key:"v-558dc8ba",path:"/pages/8e9d93/",headers:[{level:2,title:"JRebel - J2EE开发工具",slug:"jrebel-j2ee开发工具",normalizedTitle:"jrebel - j2ee开发工具",charIndex:2},{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:58},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:433},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:676}],headersStr:"JRebel - J2EE开发工具 简介 docker-compose.yml deploy.sh",content:'# JRebel - J2EE开发工具\n\n开源网址\n\n官网：https://www.jrebel.com/\n\n\n# 简介\n\n\n\nJRebel是一套JavaEE开发工具。JRebel允许开发团队在有限的时间内完成更多的任务修正更多的问题，发布更高质量的软件产品。\n\nJRebel可快速实现热部署，节省了大量重启时间，提高了个人开发效率。\n\nJRebel是一款JAVA虚拟机插件，它使得JAVA程序员能在不进行重部署的情况下，即时看到代码的改变对一个应用程序带来的影响。JRebel使你能即时分别看到代码、类和资源的变化，你可以一个个地上传而不是一次性全部部署。当程序员在开发环境中对任何一个类或者资源作出修改的时候，这个变化会直接反应在部署好的应用程序上，从而跳过了构建和部署的过程，每年可以省去部署用的时间花费高达5.25个星期。\n\n以上摘自百度百科,简单来说,用了Jreble,你启动一次,就能一直搞,不管你怎么改代码,他都能立马部署进去,这就是热部署。\n\n\n# docker-compose.yml\n\nversion: "3.7"\n\nservices:\n  jrebel:\n    image: nn200433/jrebel\n    container_name: jrebel\n    privileged: true\n    restart: always\n    environment:\n      TZ: Asia/Shanghai\n      PORT: 9001\n    ports:\n      - 9001:9001\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',normalizedContent:'# jrebel - j2ee开发工具\n\n开源网址\n\n官网：https://www.jrebel.com/\n\n\n# 简介\n\n\n\njrebel是一套javaee开发工具。jrebel允许开发团队在有限的时间内完成更多的任务修正更多的问题，发布更高质量的软件产品。\n\njrebel可快速实现热部署，节省了大量重启时间，提高了个人开发效率。\n\njrebel是一款java虚拟机插件，它使得java程序员能在不进行重部署的情况下，即时看到代码的改变对一个应用程序带来的影响。jrebel使你能即时分别看到代码、类和资源的变化，你可以一个个地上传而不是一次性全部部署。当程序员在开发环境中对任何一个类或者资源作出修改的时候，这个变化会直接反应在部署好的应用程序上，从而跳过了构建和部署的过程，每年可以省去部署用的时间花费高达5.25个星期。\n\n以上摘自百度百科,简单来说,用了jreble,你启动一次,就能一直搞,不管你怎么改代码,他都能立马部署进去,这就是热部署。\n\n\n# docker-compose.yml\n\nversion: "3.7"\n\nservices:\n  jrebel:\n    image: nn200433/jrebel\n    container_name: jrebel\n    privileged: true\n    restart: always\n    environment:\n      tz: asia/shanghai\n      port: 9001\n    ports:\n      - 9001:9001\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"MariaDB",frontmatter:{title:"MariaDB",date:"2023-09-05T17:06:09.000Z",permalink:"/pages/ee069d/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/17.MariaDB.html",relativePath:"05.工具&部署/01.Docker/17.MariaDB.md",key:"v-c8daa3f2",path:"/pages/ee069d/",headers:[{level:2,title:"MariaDB MySQL 分支",slug:"mariadb-mysql-分支",normalizedTitle:"mariadb mysql 分支",charIndex:2},{level:2,title:"开源简介",slug:"开源简介",normalizedTitle:"开源简介",charIndex:94},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:390},{level:2,title:"my.cnf",slug:"my-cnf",normalizedTitle:"my.cnf",charIndex:826},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1196}],headersStr:"MariaDB MySQL 分支 开源简介 docker-compose.yml my.cnf deploy.sh",content:'# MariaDB MySQL 分支\n\n网址\n\n官网：https://mariadb.org/\n\ngithub：https://github.com/MariaDB/server\n\n\n# 开源简介\n\n\n\n> MariaDB Server 是最流行的开源关系型数据库之一。它由 MySQL 的原始开发者制作，并保证保持开源。它是大多数云产品的一部分，也是大多数 Linux 发行版的默认配置。MariaDB 被设计为 MySQL 的直接替代产品，具有更多功能，新的存储引擎，更少的错误和更好的性能。\n\n它建立在性能、稳定性和开放性的价值之上，MariaDB 基金会确保将根据技术优点接受贡献。最近的新功能包括与 Galera Cluster 4 的高级集群，与 Oracle 数据库和 Temporal Data Tables 的兼容功能，允许人们查询过去任何时候的数据。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\nservices: \n  mariadb: \n    image: mariadb:10.6.4\n    container_name: mariadb\n    # command: --default-authentication-plugin=mysql_native_password --lower_case_table_names=1\n    restart: always\n    ports: \n      - 3306:3306\n    environment: \n      - MYSQL_ROOT_PASSWORD=Mysql123$\n      # - MYSQL_ROOT_HOST=%\n      - TZ=Asia/Shanghai\n    volumes: \n      - mysql_data:/var/lib/mysql\n      - "/etc/mysql/my.cnf:/etc/mysql/my.cnf"\n\nvolumes: \n  mysql_data: \n\n\n\n# my.cnf\n\n[client-server]\n# Port or socket location where to connect\n# port = 3306\nsocket = /run/mysqld/mysqld.sock\nlower_case_table_name=1\n\n# Import all .cnf files from configuration directory\n[mariadbd]\nskip-host-cache\nskip-name-resolve\n\n!includedir /etc/mysql/mariadb.conf.d/\n!includedir /etc/mysql/conf.d/\n\n\n\n# deploy.sh\n\nmkdir -p /etc/mysql/\n\n\\cp ./my.cnf /etc/mysql/my.cnf -rf\n"/usr/local/bin/docker-compose" -f docker-compose.yml up -d\n',normalizedContent:'# mariadb mysql 分支\n\n网址\n\n官网：https://mariadb.org/\n\ngithub：https://github.com/mariadb/server\n\n\n# 开源简介\n\n\n\n> mariadb server 是最流行的开源关系型数据库之一。它由 mysql 的原始开发者制作，并保证保持开源。它是大多数云产品的一部分，也是大多数 linux 发行版的默认配置。mariadb 被设计为 mysql 的直接替代产品，具有更多功能，新的存储引擎，更少的错误和更好的性能。\n\n它建立在性能、稳定性和开放性的价值之上，mariadb 基金会确保将根据技术优点接受贡献。最近的新功能包括与 galera cluster 4 的高级集群，与 oracle 数据库和 temporal data tables 的兼容功能，允许人们查询过去任何时候的数据。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\nservices: \n  mariadb: \n    image: mariadb:10.6.4\n    container_name: mariadb\n    # command: --default-authentication-plugin=mysql_native_password --lower_case_table_names=1\n    restart: always\n    ports: \n      - 3306:3306\n    environment: \n      - mysql_root_password=mysql123$\n      # - mysql_root_host=%\n      - tz=asia/shanghai\n    volumes: \n      - mysql_data:/var/lib/mysql\n      - "/etc/mysql/my.cnf:/etc/mysql/my.cnf"\n\nvolumes: \n  mysql_data: \n\n\n\n# my.cnf\n\n[client-server]\n# port or socket location where to connect\n# port = 3306\nsocket = /run/mysqld/mysqld.sock\nlower_case_table_name=1\n\n# import all .cnf files from configuration directory\n[mariadbd]\nskip-host-cache\nskip-name-resolve\n\n!includedir /etc/mysql/mariadb.conf.d/\n!includedir /etc/mysql/conf.d/\n\n\n\n# deploy.sh\n\nmkdir -p /etc/mysql/\n\n\\cp ./my.cnf /etc/mysql/my.cnf -rf\n"/usr/local/bin/docker-compose" -f docker-compose.yml up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"MySQL",frontmatter:{title:"MySQL",date:"2023-09-05T19:38:05.000Z",permalink:"/pages/cff07b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/18.MySQL.html",relativePath:"05.工具&部署/01.Docker/18.MySQL.md",key:"v-0c46eaa7",path:"/pages/cff07b/",headers:[{level:2,title:"MySQL 数据库服务器",slug:"mysql-数据库服务器",normalizedTitle:"mysql 数据库服务器",charIndex:2},{level:2,title:"开源简介",slug:"开源简介",normalizedTitle:"开源简介",charIndex:96},{level:2,title:"MySQL 的特性",slug:"mysql-的特性",normalizedTitle:"mysql 的特性",charIndex:259},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:774},{level:2,title:"my.cnf",slug:"my-cnf",normalizedTitle:"my.cnf",charIndex:1237},{level:2,title:"init.sql",slug:"init-sql",normalizedTitle:"init.sql",charIndex:1172},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:2123}],headersStr:"MySQL 数据库服务器 开源简介 MySQL 的特性 docker-compose.yml my.cnf init.sql deploy.sh",content:"# MySQL 数据库服务器\n\n网址\n\n官网：https://www.mysql.com/\n\ngithub：https://github.com/mysql/mysql-server\n\n\n# 开源简介\n\n\n\nMySQL 是一个开放源码的小型关联式数据库管理系统，开发者为瑞典 MySQL AB 公司。目前 MySQL 被广泛地应用在 Internet 上的中小型网站中。由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，许多中小型网站为了降低网站总体拥有成本而选择了 MySQL 作为网站数据库。\n\n\n# MySQL 的特性\n\n * 使用 C 和 C++ 编写，并使用了多种编译器进行测试，保证源代码的可移植性。\n * 支持 AIX、BSDi、FreeBSD、HP-UX、Linux、Mac OS、Novell Netware、NetBSD、OpenBSD、OS/2 Wrap、Solaris、SunOS、Windows 等多种操作系统。\n * 为多种编程语言提供了 API。这些编程语言包括 C、C++、C#、Delphi、Eiffel、Java、Perl、PHP、Python、Ruby 和 Tcl 等。\n * 支持多线程，充分利用 CPU 资源，支持多用户。\n * 优化的 SQL 查询算法，有效地提高查询速度。\n * 既能够作为一个单独的应用程序应用在客户端服务器网络环境中，也能够作为一个库而嵌入到其他的软件中。\n * 提供多语言支持，常见的编码如中文的 GB 2312、BIG5，日文的 Shift_JIS 等都可以用作数据表名和数据列名。\n * 提供 TCP/IP、ODBC 和 JDBC 等多种数据库连接途径。\n * 提供用于管理、检查、优化数据库操作的管理工具。\n * 可以处理拥有上千万条记录的大型数据库。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  mysql8: \n    image: mysql:8.0.16\n    container_name: mysql8\n    command: --default-authentication-plugin=mysql_native_password --lower_case_table_names=1\n    restart: always\n    ports: \n      - 3306:3306\n    environment: \n      - MYSQL_ROOT_PASSWORD=Mysql123$\n      - MYSQL_ROOT_HOST=%\n      - TZ=Asia/Shanghai\n    volumes: \n      - /etc/mysql/sql/init.sql:/docker-entrypoint-initdb.d/init.sql\n      - /etc/mysql/my.cnf:/etc/mysql/my.cnf\n      - mysql_data:/var/lib/mysql\n\n  phpmyadmin: \n    image: phpmyadmin:5\n    container_name: phpmyadmin\n    restart: always\n    ports: \n      - 80:80\n    environment: \n      - PMA_ARBITRARY=1\n\nvolumes: \n  mysql_data: \n\n\n\n# my.cnf\n\n[mysqld]\ncharacter-set-server=utf8mb4\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\ndatadir         = /var/lib/mysql\nsecure-file-priv= NULL\n# Disabling symbolic-links is recommended to prevent assorted security risks\nsymbolic-links=0\n\n# Custom config should go here\n!includedir /etc/mysql/conf.d/\n\n[client]\ndefault-character-set=utf8mb4 \n[mysql]\ndefault-character-set=utf8mb4\n\n\n\n# init.sql\n\nuse mysql;\n# navicat连接mysql报错1251解决方案\nCREATE USER 'root'@'%' IDENTIFIED BY 'Mysql123$';\nALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY 'Mysql123$';\n\n# 刷新\nFLUSH PRIVILEGES;\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/mysql/sql\n\\cp ./sql/init.sql /etc/mysql/sql/init.sql -rf\n\\cp ./my.cnf /etc/mysql/my.cnf -rf\ndocker-compose up -d\n",normalizedContent:"# mysql 数据库服务器\n\n网址\n\n官网：https://www.mysql.com/\n\ngithub：https://github.com/mysql/mysql-server\n\n\n# 开源简介\n\n\n\nmysql 是一个开放源码的小型关联式数据库管理系统，开发者为瑞典 mysql ab 公司。目前 mysql 被广泛地应用在 internet 上的中小型网站中。由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，许多中小型网站为了降低网站总体拥有成本而选择了 mysql 作为网站数据库。\n\n\n# mysql 的特性\n\n * 使用 c 和 c++ 编写，并使用了多种编译器进行测试，保证源代码的可移植性。\n * 支持 aix、bsdi、freebsd、hp-ux、linux、mac os、novell netware、netbsd、openbsd、os/2 wrap、solaris、sunos、windows 等多种操作系统。\n * 为多种编程语言提供了 api。这些编程语言包括 c、c++、c#、delphi、eiffel、java、perl、php、python、ruby 和 tcl 等。\n * 支持多线程，充分利用 cpu 资源，支持多用户。\n * 优化的 sql 查询算法，有效地提高查询速度。\n * 既能够作为一个单独的应用程序应用在客户端服务器网络环境中，也能够作为一个库而嵌入到其他的软件中。\n * 提供多语言支持，常见的编码如中文的 gb 2312、big5，日文的 shift_jis 等都可以用作数据表名和数据列名。\n * 提供 tcp/ip、odbc 和 jdbc 等多种数据库连接途径。\n * 提供用于管理、检查、优化数据库操作的管理工具。\n * 可以处理拥有上千万条记录的大型数据库。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  mysql8: \n    image: mysql:8.0.16\n    container_name: mysql8\n    command: --default-authentication-plugin=mysql_native_password --lower_case_table_names=1\n    restart: always\n    ports: \n      - 3306:3306\n    environment: \n      - mysql_root_password=mysql123$\n      - mysql_root_host=%\n      - tz=asia/shanghai\n    volumes: \n      - /etc/mysql/sql/init.sql:/docker-entrypoint-initdb.d/init.sql\n      - /etc/mysql/my.cnf:/etc/mysql/my.cnf\n      - mysql_data:/var/lib/mysql\n\n  phpmyadmin: \n    image: phpmyadmin:5\n    container_name: phpmyadmin\n    restart: always\n    ports: \n      - 80:80\n    environment: \n      - pma_arbitrary=1\n\nvolumes: \n  mysql_data: \n\n\n\n# my.cnf\n\n[mysqld]\ncharacter-set-server=utf8mb4\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\ndatadir         = /var/lib/mysql\nsecure-file-priv= null\n# disabling symbolic-links is recommended to prevent assorted security risks\nsymbolic-links=0\n\n# custom config should go here\n!includedir /etc/mysql/conf.d/\n\n[client]\ndefault-character-set=utf8mb4 \n[mysql]\ndefault-character-set=utf8mb4\n\n\n\n# init.sql\n\nuse mysql;\n# navicat连接mysql报错1251解决方案\ncreate user 'root'@'%' identified by 'mysql123$';\nalter user 'root'@'%' identified with mysql_native_password by 'mysql123$';\n\n# 刷新\nflush privileges;\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /etc/mysql/sql\n\\cp ./sql/init.sql /etc/mysql/sql/init.sql -rf\n\\cp ./my.cnf /etc/mysql/my.cnf -rf\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"Percona",frontmatter:{title:"Percona",date:"2023-09-05T19:47:04.000Z",permalink:"/pages/862a97/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/19.Percona.html",relativePath:"05.工具&部署/01.Docker/19.Percona.md",key:"v-20feecc7",path:"/pages/862a97/",headers:[{level:2,title:"Percona MySQL 分支",slug:"percona-mysql-分支",normalizedTitle:"percona mysql 分支",charIndex:2},{level:2,title:"开源简介",slug:"开源简介",normalizedTitle:"开源简介",charIndex:105},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:457},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:969}],headersStr:"Percona MySQL 分支 开源简介 docker-compose.yml deploy.sh",content:"# Percona MySQL 分支\n\n网址\n\n官网：https://www.percona.com\n\ngithub：https://github.com/percona/percona-server\n\n\n# 开源简介\n\n\n\n> Percona Server由领先的MySQL咨询公司Percona发布。 Percona Server是一款独立的数据库产品，其可以完全与MySQL兼容，可以在不更改代码的情况了下将存储引擎更换成XtraDB。\n\nPercona团队的最终声明是“Percona Server是由Oracle发布的最接近官方MySQL Enterprise发行版的版本”，因此与其他更改了大量基本核心MySQL代码的分支有所区别。 Percona Server的一个缺点是他们自己管理代码，不接受外部开发人员的贡献，以这种方式确保他们对产品中所包含功能的控制。 Percona提供了高性能XtraDB引擎，还提供PXC高可用解决方案，并且附带了perconatoolkit等DBA管理工具箱\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n\n  percona: \n    image: percona/percona-xtradb-cluster:5.7.26\n    container_name: percona\n    restart: always\n    environment: \n      - TZ=Asia/Shanghai\n      - MYSQL_ROOT_PASSWORD=Percona123$\n      - CLUSTER_NAME=pxc\n      - XTRABACKUP_PASSWORD=Percona123 \n    ports:\n      - 3306:3306\n    volumes:\n      - percona_mysql:/var/lib/mysql\n      - percona_log:/var/log/mysql\n      - percona_data:/data\n\nvolumes: \n  percona_mysql: \n  percona_log: \n  percona_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# percona mysql 分支\n\n网址\n\n官网：https://www.percona.com\n\ngithub：https://github.com/percona/percona-server\n\n\n# 开源简介\n\n\n\n> percona server由领先的mysql咨询公司percona发布。 percona server是一款独立的数据库产品，其可以完全与mysql兼容，可以在不更改代码的情况了下将存储引擎更换成xtradb。\n\npercona团队的最终声明是“percona server是由oracle发布的最接近官方mysql enterprise发行版的版本”，因此与其他更改了大量基本核心mysql代码的分支有所区别。 percona server的一个缺点是他们自己管理代码，不接受外部开发人员的贡献，以这种方式确保他们对产品中所包含功能的控制。 percona提供了高性能xtradb引擎，还提供pxc高可用解决方案，并且附带了perconatoolkit等dba管理工具箱\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n\n  percona: \n    image: percona/percona-xtradb-cluster:5.7.26\n    container_name: percona\n    restart: always\n    environment: \n      - tz=asia/shanghai\n      - mysql_root_password=percona123$\n      - cluster_name=pxc\n      - xtrabackup_password=percona123 \n    ports:\n      - 3306:3306\n    volumes:\n      - percona_mysql:/var/lib/mysql\n      - percona_log:/var/log/mysql\n      - percona_data:/data\n\nvolumes: \n  percona_mysql: \n  percona_log: \n  percona_data: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"Jenkins",frontmatter:{title:"Jenkins",article:!1,date:"2023-09-11T15:36:13.000Z",permalink:"/pages/f90f99/"},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/15.Jenkins.html",relativePath:"05.工具&部署/01.Docker/15.Jenkins.md",key:"v-1deb9607",path:"/pages/f90f99/",headers:[{level:2,title:"Jenkins 持续集成工具",slug:"jenkins-持续集成工具",normalizedTitle:"jenkins 持续集成工具",charIndex:2},{level:2,title:"开源简介",slug:"开源简介",normalizedTitle:"开源简介",charIndex:98},{level:2,title:"使用场景",slug:"使用场景",normalizedTitle:"使用场景",charIndex:567},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:808},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1391}],headersStr:"Jenkins 持续集成工具 开源简介 使用场景 docker-compose.yml deploy.sh",content:"# Jenkins 持续集成工具\n\n网址\n\n官网：https://www.jenkins.io/\n\ngithub：https://github.com/jenkinsci/jenkins\n\n\n# 开源简介\n\n\n\n> Jenkins 是一个开源的持续集成（CI）和持续交付（CD）工具，旨在帮助开发团队自动化软件开发和交付过程。它是一个非常强大和灵活的工具，广泛用于各种规模的软件项目。\n\nJenkins 提供了许多强大的特性，包括：\n\n * 自动构建 ：Jenkins 可以自动构建代码，确保每次提交都能够编译和测试，从而降低了代码集成的风险。\n * 插件生态系统 ：Jenkins 拥有庞大的插件生态系统，允许用户轻松扩展其功能，以满足特定项目的需求。\n * 分布式构建 ：Jenkins 允许在多个构建代理上分发构建任务，从而提高了构建的效率。\n * 可视化构建和部署流程 ：通过 Jenkins 的用户友好界面，用户可以轻松定义和管理构建和部署流程。\n * 通知和报告 ：Jenkins 可以通过电子邮件、Slack、JIRA 等方式发送通知，还可以生成详细的构建报告，帮助团队了解构建的状态和问题。\n * 安全性 ：Jenkins 提供了一系列安全性功能，包括用户身份验证、授权和安全插件，以保护您的构建和部署流程。\n\n\n# 使用场景\n\nJenkins 可以用于各种不同的应用场景，包括：\n\n * 持续集成 ：自动构建和测试代码，确保每次提交都是可部署的。\n * 持续交付 ：自动化部署和交付代码到生产环境，以缩短交付周期。\n * 自动化测试 ：运行各种测试，包括单元测试、集成测试和端到端测试，以确保代码质量。\n * 任务调度 ：定期执行计划任务，例如数据备份或定时报告生成。\n * 基础设施自动化 ：管理和自动化基础设施操作，如服务器部署和配置管理。\n\n> jenkins不建议docker部署\n\n\n# docker-compose.yml\n\nversion: \"3.7\"\n\nservices:\n  jenkins:\n    image: jenkins/jenkins:lts-jdk11\n    container_name: jenkins\n    privileged: true\n    restart: always\n    environment:\n      TZ: Asia/Shanghai\n      JAVA_OPTS: '-Djava.util.logging.config.file=/var/jenkins_home/log.properties'\n    volumes:\n      - jenkins_home:/var/jenkins_home\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /usr/bin/docker:/usr/bin/docker\n      - /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7\n    ports:\n      - 18080:8080\n      - 50000:50000\nvolumes: \n  jenkins_home: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /var/jenkins_data/\ncat > /var/jenkins_data/log.properties <<EOF\nhandlers=java.util.logging.ConsoleHandler\njenkins.level=FINEST\njava.util.logging.ConsoleHandler.level=FINEST\nEOF\ndocker-compose up -d\n",normalizedContent:"# jenkins 持续集成工具\n\n网址\n\n官网：https://www.jenkins.io/\n\ngithub：https://github.com/jenkinsci/jenkins\n\n\n# 开源简介\n\n\n\n> jenkins 是一个开源的持续集成（ci）和持续交付（cd）工具，旨在帮助开发团队自动化软件开发和交付过程。它是一个非常强大和灵活的工具，广泛用于各种规模的软件项目。\n\njenkins 提供了许多强大的特性，包括：\n\n * 自动构建 ：jenkins 可以自动构建代码，确保每次提交都能够编译和测试，从而降低了代码集成的风险。\n * 插件生态系统 ：jenkins 拥有庞大的插件生态系统，允许用户轻松扩展其功能，以满足特定项目的需求。\n * 分布式构建 ：jenkins 允许在多个构建代理上分发构建任务，从而提高了构建的效率。\n * 可视化构建和部署流程 ：通过 jenkins 的用户友好界面，用户可以轻松定义和管理构建和部署流程。\n * 通知和报告 ：jenkins 可以通过电子邮件、slack、jira 等方式发送通知，还可以生成详细的构建报告，帮助团队了解构建的状态和问题。\n * 安全性 ：jenkins 提供了一系列安全性功能，包括用户身份验证、授权和安全插件，以保护您的构建和部署流程。\n\n\n# 使用场景\n\njenkins 可以用于各种不同的应用场景，包括：\n\n * 持续集成 ：自动构建和测试代码，确保每次提交都是可部署的。\n * 持续交付 ：自动化部署和交付代码到生产环境，以缩短交付周期。\n * 自动化测试 ：运行各种测试，包括单元测试、集成测试和端到端测试，以确保代码质量。\n * 任务调度 ：定期执行计划任务，例如数据备份或定时报告生成。\n * 基础设施自动化 ：管理和自动化基础设施操作，如服务器部署和配置管理。\n\n> jenkins不建议docker部署\n\n\n# docker-compose.yml\n\nversion: \"3.7\"\n\nservices:\n  jenkins:\n    image: jenkins/jenkins:lts-jdk11\n    container_name: jenkins\n    privileged: true\n    restart: always\n    environment:\n      tz: asia/shanghai\n      java_opts: '-djava.util.logging.config.file=/var/jenkins_home/log.properties'\n    volumes:\n      - jenkins_home:/var/jenkins_home\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /usr/bin/docker:/usr/bin/docker\n      - /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7\n    ports:\n      - 18080:8080\n      - 50000:50000\nvolumes: \n  jenkins_home: \n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\nmkdir -p /var/jenkins_data/\ncat > /var/jenkins_data/log.properties <<eof\nhandlers=java.util.logging.consolehandler\njenkins.level=finest\njava.util.logging.consolehandler.level=finest\neof\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"Phpmyadmin",frontmatter:{title:"Phpmyadmin",date:"2023-09-05T19:49:09.000Z",permalink:"/pages/a560de/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/20.Phpmyadmin.html",relativePath:"05.工具&部署/01.Docker/20.Phpmyadmin.md",key:"v-ce147052",path:"/pages/a560de/",headers:[{level:2,title:"phpMyAdmin MySQL 管理工具",slug:"phpmyadmin-mysql-管理工具",normalizedTitle:"phpmyadmin mysql 管理工具",charIndex:2},{level:2,title:"开源简介",slug:"开源简介",normalizedTitle:"开源简介",charIndex:113},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:224},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:435}],headersStr:"phpMyAdmin MySQL 管理工具 开源简介 docker-compose.yml deploy.sh",content:"# phpMyAdmin MySQL 管理工具\n\n网址\n\n官网：https://www.phpmyadmin.net/\n\ngithub：https://github.com/phpmyadmin/phpmyadmin\n\n\n# 开源简介\n\n\n\n> phpMyAdmin 是一个非常受欢迎的基于 web 的 MySQL 数据库管理工具。它能够创建和删除数据库，创建 / 删除 / 修改表格，删除 / 编辑 / 新增字段，执行 SQL 脚本等。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  phpmyadmin: \n    image: phpmyadmin:5\n    container_name: phpmyadmin\n    restart: always\n    ports: \n      - 80:80\n    environment: \n      - PMA_ARBITRARY=1\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# phpmyadmin mysql 管理工具\n\n网址\n\n官网：https://www.phpmyadmin.net/\n\ngithub：https://github.com/phpmyadmin/phpmyadmin\n\n\n# 开源简介\n\n\n\n> phpmyadmin 是一个非常受欢迎的基于 web 的 mysql 数据库管理工具。它能够创建和删除数据库，创建 / 删除 / 修改表格，删除 / 编辑 / 新增字段，执行 sql 脚本等。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices: \n\n  phpmyadmin: \n    image: phpmyadmin:5\n    container_name: phpmyadmin\n    restart: always\n    ports: \n      - 80:80\n    environment: \n      - pma_arbitrary=1\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/12, 03:21:58",lastUpdatedTimestamp:1694460118e3},{title:"PostgreSQL",frontmatter:{title:"PostgreSQL",date:"2023-09-05T19:51:18.000Z",permalink:"/pages/230ca1/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/21.PostgreSQL.html",relativePath:"05.工具&部署/01.Docker/21.PostgreSQL.md",key:"v-79dbae07",path:"/pages/230ca1/",headers:[{level:2,title:"PostgreSQL 对象-关系数据库",slug:"postgresql-对象-关系数据库",normalizedTitle:"postgresql 对象-关系数据库",charIndex:2},{level:2,title:"开源简介",slug:"开源简介",normalizedTitle:"开源简介",charIndex:107},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:783},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:1122}],headersStr:"PostgreSQL 对象-关系数据库 开源简介 docker-compose.yml deploy.sh",content:"# PostgreSQL 对象-关系数据库\n\n网址\n\n官网：https://www.postgresql.org/\n\ngithub：https://github.com/postgres/postgres\n\n\n# 开源简介\n\n> PostgreSQL 是一个先进的对象关系数据库管理系统，支持SQL标准的扩展子集，包括事务、外键、子查询、触发器、用户定义类型和功能。\n\n提供的功能包括：\n\n1：函数：通过函数，可以在数据库服务器端执行指令程序。 2：索引：用户可以自定义索引方法，或使用内置的 B 树，哈希表与 GiST 索引。 3：触发器：触发器是由SQL语句查询所触发的事件。如：一个INSERT语句可能触发一个检查数据完整性的触发器。触发器通常由INSERT或UPDATE语句触发。 多版本并发控制：PostgreSQL使用多版本并发控制（MVCC，Multiversion concurrency control）系统进行并发控制，该系统向每个用户提供了一个数据库的\"快照\"，用户在事务内所作的每个修改，对于其他的用户都不可见，直到该事务成功提交。 4：规则：规则（RULE）允许一个查询能被重写，通常用来实现对视图（VIEW）的操作，如插入（INSERT）、更新（UPDATE）、删除（DELETE）。 5：数据类型：包括文本、任意精度的数值数组、JSON 数据、枚举类型、XML 数据 等。 6：全文检索：通过 Tsearch2 或 OpenFTS，8.3版本中内嵌 Tsearch2。 7：NoSQL：JSON，JSONB，XML，HStore 原生支持，至 NoSQL 数据库的外部数据包装器。 8：数据仓库：能平滑迁移至同属 PostgreSQL 生态的 GreenPlum，DeepGreen，HAWK 等，使用 FDW 进行 ETL。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n\n  postgres:\n    image: postgres:11.4\n    container_name: postgres\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n      POSTGRES_PASSWORD: postgres_123456\n    ports:\n      - 5432:5432\n    volumes: \n      - postgres_data:/var/lib/postgresql/data\n\nvolumes: \n  postgres_data:\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",normalizedContent:"# postgresql 对象-关系数据库\n\n网址\n\n官网：https://www.postgresql.org/\n\ngithub：https://github.com/postgres/postgres\n\n\n# 开源简介\n\n> postgresql 是一个先进的对象关系数据库管理系统，支持sql标准的扩展子集，包括事务、外键、子查询、触发器、用户定义类型和功能。\n\n提供的功能包括：\n\n1：函数：通过函数，可以在数据库服务器端执行指令程序。 2：索引：用户可以自定义索引方法，或使用内置的 b 树，哈希表与 gist 索引。 3：触发器：触发器是由sql语句查询所触发的事件。如：一个insert语句可能触发一个检查数据完整性的触发器。触发器通常由insert或update语句触发。 多版本并发控制：postgresql使用多版本并发控制（mvcc，multiversion concurrency control）系统进行并发控制，该系统向每个用户提供了一个数据库的\"快照\"，用户在事务内所作的每个修改，对于其他的用户都不可见，直到该事务成功提交。 4：规则：规则（rule）允许一个查询能被重写，通常用来实现对视图（view）的操作，如插入（insert）、更新（update）、删除（delete）。 5：数据类型：包括文本、任意精度的数值数组、json 数据、枚举类型、xml 数据 等。 6：全文检索：通过 tsearch2 或 openfts，8.3版本中内嵌 tsearch2。 7：nosql：json，jsonb，xml，hstore 原生支持，至 nosql 数据库的外部数据包装器。 8：数据仓库：能平滑迁移至同属 postgresql 生态的 greenplum，deepgreen，hawk 等，使用 fdw 进行 etl。\n\n\n# docker-compose.yml\n\nversion: '3.7'\n\nservices:\n\n  postgres:\n    image: postgres:11.4\n    container_name: postgres\n    restart: always\n    environment: \n      tz: asia/shanghai\n      postgres_password: postgres_123456\n    ports:\n      - 5432:5432\n    volumes: \n      - postgres_data:/var/lib/postgresql/data\n\nvolumes: \n  postgres_data:\n\n\n\n# deploy.sh\n\n#!\\bin\\bash\n\ndocker-compose up -d\n",charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"查看Linux系统信息",frontmatter:{title:"查看Linux系统信息",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/aa794b/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/01.%E6%9F%A5%E7%9C%8BLinux%E7%B3%BB%E7%BB%9F%E4%BF%A1%E6%81%AF.html",relativePath:"05.工具&部署/02.Linux/01.查看Linux系统信息.md",key:"v-686ae17b",path:"/pages/aa794b/",headersStr:null,content:"# Bench.sh\n\n查看您的 Linux 系统信息，还可以测试网络带宽及硬盘读写速率\n\ncurl -Lso- bench.sh | bash\n\n\n或者\n\nwget -qO- bench.sh | bash\n\n\n示例结果\n\n-------------------- A Bench.sh Script By Teddysun -------------------\n Version            : v2022-06-01\n Usage              : wget -qO- bench.sh | bash\n----------------------------------------------------------------------\n CPU Model          : Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz\n CPU Cores          : 8 @ 800.024 MHz\n CPU Cache          : 6144 KB\n AES-NI             : Enabled\n VM-x/AMD-V         : Enabled\n Total Disk         : 449.8 GB (2.5 GB Used)\n Total Mem          : 31.3 GB (370.9 MB Used)\n Total Swap         : 15.7 GB (0 Used)\n System uptime      : 1 days, 2 hour 31 min\n Load average       : 0.00, 0.01, 0.05\n OS                 : CentOS Linux release 7.6.1810 (Core)\n Arch               : x86_64 (64 Bit)\n Kernel             : 3.10.0-957.el7.x86_64\n TCP CC             : cubic\n Virtualization     : Dedicated\n Organization       : AS4134 CHINANET-BACKBONE\n Location           : Nanjing / CN\n Region             : Jiangsu\n----------------------------------------------------------------------\n I/O Speed(1st run) : 428 MB/s\n I/O Speed(2nd run) : 424 MB/s\n I/O Speed(3rd run) : 425 MB/s\n I/O Speed(average) : 425.7 MB/s\n----------------------------------------------------------------------\n",normalizedContent:"# bench.sh\n\n查看您的 linux 系统信息，还可以测试网络带宽及硬盘读写速率\n\ncurl -lso- bench.sh | bash\n\n\n或者\n\nwget -qo- bench.sh | bash\n\n\n示例结果\n\n-------------------- a bench.sh script by teddysun -------------------\n version            : v2022-06-01\n usage              : wget -qo- bench.sh | bash\n----------------------------------------------------------------------\n cpu model          : intel(r) core(tm) i5-8250u cpu @ 1.60ghz\n cpu cores          : 8 @ 800.024 mhz\n cpu cache          : 6144 kb\n aes-ni             : enabled\n vm-x/amd-v         : enabled\n total disk         : 449.8 gb (2.5 gb used)\n total mem          : 31.3 gb (370.9 mb used)\n total swap         : 15.7 gb (0 used)\n system uptime      : 1 days, 2 hour 31 min\n load average       : 0.00, 0.01, 0.05\n os                 : centos linux release 7.6.1810 (core)\n arch               : x86_64 (64 bit)\n kernel             : 3.10.0-957.el7.x86_64\n tcp cc             : cubic\n virtualization     : dedicated\n organization       : as4134 chinanet-backbone\n location           : nanjing / cn\n region             : jiangsu\n----------------------------------------------------------------------\n i/o speed(1st run) : 428 mb/s\n i/o speed(2nd run) : 424 mb/s\n i/o speed(3rd run) : 425 mb/s\n i/o speed(average) : 425.7 mb/s\n----------------------------------------------------------------------\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Redis",frontmatter:{title:"Redis",date:"2023-09-05T19:53:07.000Z",permalink:"/pages/be7f5d/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/01.Docker/22.Redis.html",relativePath:"05.工具&部署/01.Docker/22.Redis.md",key:"v-0a9184e7",path:"/pages/be7f5d/",headers:[{level:2,title:"Redis 高性能的key-value数据库",slug:"redis-高性能的key-value数据库",normalizedTitle:"redis 高性能的key-value数据库",charIndex:2},{level:2,title:"开源简介",slug:"开源简介",normalizedTitle:"开源简介",charIndex:94},{level:2,title:"主要特性",slug:"主要特性",normalizedTitle:"主要特性",charIndex:253},{level:2,title:"使用场景",slug:"使用场景",normalizedTitle:"使用场景",charIndex:696},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:983},{level:2,title:"docker-compose.yml",slug:"docker-compose-yml",normalizedTitle:"docker-compose.yml",charIndex:1084},{level:2,title:"redis.conf",slug:"redis-conf",normalizedTitle:"redis.conf",charIndex:1360},{level:2,title:"deploy.sh",slug:"deploy-sh",normalizedTitle:"deploy.sh",charIndex:64548}],headersStr:"Redis 高性能的key-value数据库 开源简介 主要特性 使用场景 总结 docker-compose.yml redis.conf deploy.sh",content:'# Redis 高性能的key-value数据库\n\n网址\n\n官网：https://redis.io/\n\ngithub：https://github.com/redis/redis\n\n\n# 开源简介\n\n> Redis（Remote Dictionary Server的缩写）是一个高性能的开源内存数据存储系统，它可以用作缓存、消息中间件和数据库。Redis最初由Salvatore Sanfilippo开发，于2009年首次发布。它以其快速的读写操作、多种数据结构和灵活的用途而受到广泛关注和使用。\n\n\n# 主要特性\n\n 1. 内存存储 ：Redis将数据存储在内存中，这使得它能够实现非常快速的读写操作。这使得Redis成为处理实时数据和高并发访问的理想选择。\n 2. 持久化 ：虽然数据存储在内存中，但Redis可以通过不同的持久化机制将数据写入磁盘，以便在重启后恢复数据。这有助于确保数据的持久性和可靠性。\n 3. 丰富的数据结构 ：Redis支持多种数据结构，包括字符串、哈希、列表、集合、有序集合等。这使得开发人员能够根据不同的用例选择适当的数据结构，从而更有效地存储和处理数据。\n 4. 发布订阅 ：Redis支持发布订阅模式，允许客户端订阅特定的频道并接收发布到该频道的消息。这在构建实时通知和消息系统时非常有用。\n 5. 事务 ：Redis支持简单的事务操作，开发人员可以将多个命令打包到一个事务中，然后一次性执行，从而确保这些命令要么全部执行成功，要么全部不执行。\n 6. 分布式 ：Redis可以作为分布式系统的一部分运行，通过复制和分片来提供高可用性和横向扩展。\n\n\n# 使用场景\n\n 1. 缓存 ：Redis常用作缓存层，以加速读取频繁的数据，减轻后端数据库的负担。\n 2. 会话存储 ：将用户会话数据存储在Redis中，以实现快速的用户认证和状态管理。\n 3. 计数器和排行榜 ：利用Redis的原子计数特性，可以轻松实现计数器和排行榜功能。\n 4. 实时分析 ：通过存储实时数据并使用Redis的复杂数据结构，可以构建实时分析和统计系统。\n 5. 消息中间件 ：利用发布订阅功能，Redis可用于构建实时消息系统，用于通知、事件处理等场景。\n 6. 地理空间索引 ：Redis支持地理位置数据，可以用于构建位置服务和附近搜索功能。\n\n\n# 总结\n\nRedis是一个功能强大的内存数据存储系统，具有高性能、丰富的数据结构和多样化的应用场景。它在缓存、实时数据处理、消息系统等方面都具有出色的表现，成为众多开发人员和企业的首选技术之一。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\nservices: \n  redis:\n    image: redis:7.0.3\n    container_name: redis\n    restart: always\n    environment: \n      TZ: Asia/Shanghai\n    ports:\n      - 6379:6379\n    volumes: \n      - data:/data\n    command: redis-server /usr/local/etc/redis/redis.conf\n    sysctls:\n      net.core.somaxconn: 65535\n\nvolumes: \n  data: \n\n\n\n# redis.conf\n\n# Redis configuration file example.\n#\n# Note that in order to read the configuration file, Redis must be\n# started with the file path as first argument:\n#\n# ./redis-server /path/to/redis.conf\n\n# Note on units: when memory size is needed, it is possible to specify\n# it in the usual form of 1k 5GB 4M and so forth:\n#\n# 1k => 1000 bytes\n# 1kb => 1024 bytes\n# 1m => 1000000 bytes\n# 1mb => 1024*1024 bytes\n# 1g => 1000000000 bytes\n# 1gb => 1024*1024*1024 bytes\n#\n# units are case insensitive so 1GB 1Gb 1gB are all the same.\n\n################################## INCLUDES ###################################\n\n# Include one or more other config files here.  This is useful if you\n# have a standard template that goes to all Redis servers but also need\n# to customize a few per-server settings.  Include files can include\n# other files, so use this wisely.\n#\n# Notice option "include" won\'t be rewritten by command "CONFIG REWRITE"\n# from admin or Redis Sentinel. Since Redis always uses the last processed\n# line as value of a configuration directive, you\'d better put includes\n# at the beginning of this file to avoid overwriting config change at runtime.\n#\n# If instead you are interested in using includes to override configuration\n# options, it is better to use include as the last line.\n#\n# include /path/to/local.conf\n# include /path/to/other.conf\n\n################################## MODULES #####################################\n\n# Load modules at startup. If the server is not able to load modules\n# it will abort. It is possible to use multiple loadmodule directives.\n#\n# loadmodule /path/to/my_module.so\n# loadmodule /path/to/other_module.so\n\n################################## NETWORK #####################################\n\n# By default, if no "bind" configuration directive is specified, Redis listens\n# for connections from all the network interfaces available on the server.\n# It is possible to listen to just one or multiple selected interfaces using\n# the "bind" configuration directive, followed by one or more IP addresses.\n#\n# Examples:\n#\n# bind 192.168.1.100 10.0.0.1\n# bind 127.0.0.1 ::1\n#\n# ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the\n# internet, binding to all the interfaces is dangerous and will expose the\n# instance to everybody on the internet. So by default we uncomment the\n# following bind directive, that will force Redis to listen only into\n# the IPv4 loopback interface address (this means Redis will be able to\n# accept connections only from clients running into the same computer it\n# is running).\n#\n# IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES\n# JUST COMMENT THE FOLLOWING LINE.\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# bind 127.0.0.1\n\n# Protected mode is a layer of security protection, in order to avoid that\n# Redis instances left open on the internet are accessed and exploited.\n#\n# When protected mode is on and if:\n#\n# 1) The server is not binding explicitly to a set of addresses using the\n#    "bind" directive.\n# 2) No password is configured.\n#\n# The server only accepts connections from clients connecting from the\n# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain\n# sockets.\n#\n# By default protected mode is enabled. You should disable it only if\n# you are sure you want clients from other hosts to connect to Redis\n# even if no authentication is configured, nor a specific set of interfaces\n# are explicitly listed using the "bind" directive.\nprotected-mode no\n\n# Accept connections on the specified port, default is 6379 (IANA #815344).\n# If port 0 is specified Redis will not listen on a TCP socket.\nport 6379\n\n# TCP listen() backlog.\n#\n# In high requests-per-second environments you need an high backlog in order\n# to avoid slow clients connections issues. Note that the Linux kernel\n# will silently truncate it to the value of /proc/sys/net/core/somaxconn so\n# make sure to raise both the value of somaxconn and tcp_max_syn_backlog\n# in order to get the desired effect.\ntcp-backlog 511\n\n# Unix socket.\n#\n# Specify the path for the Unix socket that will be used to listen for\n# incoming connections. There is no default, so Redis will not listen\n# on a unix socket when not specified.\n#\n# unixsocket /tmp/redis.sock\n# unixsocketperm 700\n\n# Close the connection after a client is idle for N seconds (0 to disable)\ntimeout 0\n\n# TCP keepalive.\n#\n# If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence\n# of communication. This is useful for two reasons:\n#\n# 1) Detect dead peers.\n# 2) Take the connection alive from the point of view of network\n#    equipment in the middle.\n#\n# On Linux, the specified value (in seconds) is the period used to send ACKs.\n# Note that to close the connection the double of the time is needed.\n# On other kernels the period depends on the kernel configuration.\n#\n# A reasonable value for this option is 300 seconds, which is the new\n# Redis default starting with Redis 3.2.1.\ntcp-keepalive 300\n\n################################# GENERAL #####################################\n\n# By default Redis does not run as a daemon. Use \'yes\' if you need it.\n# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.\ndaemonize no\n\n# If you run Redis from upstart or systemd, Redis can interact with your\n# supervision tree. Options:\n#   supervised no      - no supervision interaction\n#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode\n#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET\n#   supervised auto    - detect upstart or systemd method based on\n#                        UPSTART_JOB or NOTIFY_SOCKET environment variables\n# Note: these supervision methods only signal "process is ready."\n#       They do not enable continuous liveness pings back to your supervisor.\nsupervised no\n\n# If a pid file is specified, Redis writes it where specified at startup\n# and removes it at exit.\n#\n# When the server runs non daemonized, no pid file is created if none is\n# specified in the configuration. When the server is daemonized, the pid file\n# is used even if not specified, defaulting to "/var/run/redis.pid".\n#\n# Creating a pid file is best effort: if Redis is not able to create it\n# nothing bad happens, the server will start and run normally.\npidfile /var/run/redis_6379.pid\n\n# Specify the server verbosity level.\n# This can be one of:\n# debug (a lot of information, useful for development/testing)\n# verbose (many rarely useful info, but not a mess like the debug level)\n# notice (moderately verbose, what you want in production probably)\n# warning (only very important / critical messages are logged)\nloglevel notice\n\n# Specify the log file name. Also the empty string can be used to force\n# Redis to log on the standard output. Note that if you use standard\n# output for logging but daemonize, logs will be sent to /dev/null\nlogfile ""\n\n# To enable logging to the system logger, just set \'syslog-enabled\' to yes,\n# and optionally update the other syslog parameters to suit your needs.\n# syslog-enabled no\n\n# Specify the syslog identity.\n# syslog-ident redis\n\n# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.\n# syslog-facility local0\n\n# Set the number of databases. The default database is DB 0, you can select\n# a different one on a per-connection basis using SELECT <dbid> where\n# dbid is a number between 0 and \'databases\'-1\ndatabases 20\n\n# By default Redis shows an ASCII art logo only when started to log to the\n# standard output and if the standard output is a TTY. Basically this means\n# that normally a logo is displayed only in interactive sessions.\n#\n# However it is possible to force the pre-4.0 behavior and always show a\n# ASCII art logo in startup logs by setting the following option to yes.\nalways-show-logo yes\n\n################################ SNAPSHOTTING  ################################\n#\n# Save the DB on disk:\n#\n#   save <seconds> <changes>\n#\n#   Will save the DB if both the given number of seconds and the given\n#   number of write operations against the DB occurred.\n#\n#   In the example below the behaviour will be to save:\n#   after 900 sec (15 min) if at least 1 key changed\n#   after 300 sec (5 min) if at least 10 keys changed\n#   after 60 sec if at least 10000 keys changed\n#\n#   Note: you can disable saving completely by commenting out all "save" lines.\n#\n#   It is also possible to remove all the previously configured save\n#   points by adding a save directive with a single empty string argument\n#   like in the following example:\n#\n#   save ""\n\nsave 900 1\nsave 300 10\nsave 60 10000\n\n# By default Redis will stop accepting writes if RDB snapshots are enabled\n# (at least one save point) and the latest background save failed.\n# This will make the user aware (in a hard way) that data is not persisting\n# on disk properly, otherwise chances are that no one will notice and some\n# disaster will happen.\n#\n# If the background saving process will start working again Redis will\n# automatically allow writes again.\n#\n# However if you have setup your proper monitoring of the Redis server\n# and persistence, you may want to disable this feature so that Redis will\n# continue to work as usual even if there are problems with disk,\n# permissions, and so forth.\nstop-writes-on-bgsave-error yes\n\n# Compress string objects using LZF when dump .rdb databases?\n# For default that\'s set to \'yes\' as it\'s almost always a win.\n# If you want to save some CPU in the saving child set it to \'no\' but\n# the dataset will likely be bigger if you have compressible values or keys.\nrdbcompression yes\n\n# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.\n# This makes the format more resistant to corruption but there is a performance\n# hit to pay (around 10%) when saving and loading RDB files, so you can disable it\n# for maximum performances.\n#\n# RDB files created with checksum disabled have a checksum of zero that will\n# tell the loading code to skip the check.\nrdbchecksum yes\n\n# The filename where to dump the DB\ndbfilename dump.rdb\n\n# The working directory.\n#\n# The DB will be written inside this directory, with the filename specified\n# above using the \'dbfilename\' configuration directive.\n#\n# The Append Only File will also be created inside this directory.\n#\n# Note that you must specify a directory here, not a file name.\ndir /data/\n\n################################# REPLICATION #################################\n\n# Master-Replica replication. Use replicaof to make a Redis instance a copy of\n# another Redis server. A few things to understand ASAP about Redis replication.\n#\n#   +------------------+      +---------------+\n#   |      Master      | ---\x3e |    Replica    |\n#   | (receive writes) |      |  (exact copy) |\n#   +------------------+      +---------------+\n#\n# 1) Redis replication is asynchronous, but you can configure a master to\n#    stop accepting writes if it appears to be not connected with at least\n#    a given number of replicas.\n# 2) Redis replicas are able to perform a partial resynchronization with the\n#    master if the replication link is lost for a relatively small amount of\n#    time. You may want to configure the replication backlog size (see the next\n#    sections of this file) with a sensible value depending on your needs.\n# 3) Replication is automatic and does not need user intervention. After a\n#    network partition replicas automatically try to reconnect to masters\n#    and resynchronize with them.\n#\n# replicaof <masterip> <masterport>\n\n# If the master is password protected (using the "requirepass" configuration\n# directive below) it is possible to tell the replica to authenticate before\n# starting the replication synchronization process, otherwise the master will\n# refuse the replica request.\n#\n# masterauth <master-password>\n\n# When a replica loses its connection with the master, or when the replication\n# is still in progress, the replica can act in two different ways:\n#\n# 1) if replica-serve-stale-data is set to \'yes\' (the default) the replica will\n#    still reply to client requests, possibly with out of date data, or the\n#    data set may just be empty if this is the first synchronization.\n#\n# 2) if replica-serve-stale-data is set to \'no\' the replica will reply with\n#    an error "SYNC with master in progress" to all the kind of commands\n#    but to INFO, replicaOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG,\n#    SUBSCRIBE, UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB,\n#    COMMAND, POST, HOST: and LATENCY.\n#\nreplica-serve-stale-data yes\n\n# You can configure a replica instance to accept writes or not. Writing against\n# a replica instance may be useful to store some ephemeral data (because data\n# written on a replica will be easily deleted after resync with the master) but\n# may also cause problems if clients are writing to it because of a\n# misconfiguration.\n#\n# Since Redis 2.6 by default replicas are read-only.\n#\n# Note: read only replicas are not designed to be exposed to untrusted clients\n# on the internet. It\'s just a protection layer against misuse of the instance.\n# Still a read only replica exports by default all the administrative commands\n# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve\n# security of read only replicas using \'rename-command\' to shadow all the\n# administrative / dangerous commands.\nreplica-read-only yes\n\n# Replication SYNC strategy: disk or socket.\n#\n# -------------------------------------------------------\n# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY\n# -------------------------------------------------------\n#\n# New replicas and reconnecting replicas that are not able to continue the replication\n# process just receiving differences, need to do what is called a "full\n# synchronization". An RDB file is transmitted from the master to the replicas.\n# The transmission can happen in two different ways:\n#\n# 1) Disk-backed: The Redis master creates a new process that writes the RDB\n#                 file on disk. Later the file is transferred by the parent\n#                 process to the replicas incrementally.\n# 2) Diskless: The Redis master creates a new process that directly writes the\n#              RDB file to replica sockets, without touching the disk at all.\n#\n# With disk-backed replication, while the RDB file is generated, more replicas\n# can be queued and served with the RDB file as soon as the current child producing\n# the RDB file finishes its work. With diskless replication instead once\n# the transfer starts, new replicas arriving will be queued and a new transfer\n# will start when the current one terminates.\n#\n# When diskless replication is used, the master waits a configurable amount of\n# time (in seconds) before starting the transfer in the hope that multiple replicas\n# will arrive and the transfer can be parallelized.\n#\n# With slow disks and fast (large bandwidth) networks, diskless replication\n# works better.\nrepl-diskless-sync no\n\n# When diskless replication is enabled, it is possible to configure the delay\n# the server waits in order to spawn the child that transfers the RDB via socket\n# to the replicas.\n#\n# This is important since once the transfer starts, it is not possible to serve\n# new replicas arriving, that will be queued for the next RDB transfer, so the server\n# waits a delay in order to let more replicas arrive.\n#\n# The delay is specified in seconds, and by default is 5 seconds. To disable\n# it entirely just set it to 0 seconds and the transfer will start ASAP.\nrepl-diskless-sync-delay 5\n\n# Replicas send PINGs to server in a predefined interval. It\'s possible to change\n# this interval with the repl_ping_replica_period option. The default value is 10\n# seconds.\n#\n# repl-ping-replica-period 10\n\n# The following option sets the replication timeout for:\n#\n# 1) Bulk transfer I/O during SYNC, from the point of view of replica.\n# 2) Master timeout from the point of view of replicas (data, pings).\n# 3) Replica timeout from the point of view of masters (REPLCONF ACK pings).\n#\n# It is important to make sure that this value is greater than the value\n# specified for repl-ping-replica-period otherwise a timeout will be detected\n# every time there is low traffic between the master and the replica.\n#\n# repl-timeout 60\n\n# Disable TCP_NODELAY on the replica socket after SYNC?\n#\n# If you select "yes" Redis will use a smaller number of TCP packets and\n# less bandwidth to send data to replicas. But this can add a delay for\n# the data to appear on the replica side, up to 40 milliseconds with\n# Linux kernels using a default configuration.\n#\n# If you select "no" the delay for data to appear on the replica side will\n# be reduced but more bandwidth will be used for replication.\n#\n# By default we optimize for low latency, but in very high traffic conditions\n# or when the master and replicas are many hops away, turning this to "yes" may\n# be a good idea.\nrepl-disable-tcp-nodelay no\n\n# Set the replication backlog size. The backlog is a buffer that accumulates\n# replica data when replicas are disconnected for some time, so that when a replica\n# wants to reconnect again, often a full resync is not needed, but a partial\n# resync is enough, just passing the portion of data the replica missed while\n# disconnected.\n#\n# The bigger the replication backlog, the longer the time the replica can be\n# disconnected and later be able to perform a partial resynchronization.\n#\n# The backlog is only allocated once there is at least a replica connected.\n#\n# repl-backlog-size 1mb\n\n# After a master has no longer connected replicas for some time, the backlog\n# will be freed. The following option configures the amount of seconds that\n# need to elapse, starting from the time the last replica disconnected, for\n# the backlog buffer to be freed.\n#\n# Note that replicas never free the backlog for timeout, since they may be\n# promoted to masters later, and should be able to correctly "partially\n# resynchronize" with the replicas: hence they should always accumulate backlog.\n#\n# A value of 0 means to never release the backlog.\n#\n# repl-backlog-ttl 3600\n\n# The replica priority is an integer number published by Redis in the INFO output.\n# It is used by Redis Sentinel in order to select a replica to promote into a\n# master if the master is no longer working correctly.\n#\n# A replica with a low priority number is considered better for promotion, so\n# for instance if there are three replicas with priority 10, 100, 25 Sentinel will\n# pick the one with priority 10, that is the lowest.\n#\n# However a special priority of 0 marks the replica as not able to perform the\n# role of master, so a replica with priority of 0 will never be selected by\n# Redis Sentinel for promotion.\n#\n# By default the priority is 100.\nreplica-priority 100\n\n# It is possible for a master to stop accepting writes if there are less than\n# N replicas connected, having a lag less or equal than M seconds.\n#\n# The N replicas need to be in "online" state.\n#\n# The lag in seconds, that must be <= the specified value, is calculated from\n# the last ping received from the replica, that is usually sent every second.\n#\n# This option does not GUARANTEE that N replicas will accept the write, but\n# will limit the window of exposure for lost writes in case not enough replicas\n# are available, to the specified number of seconds.\n#\n# For example to require at least 3 replicas with a lag <= 10 seconds use:\n#\n# min-replicas-to-write 3\n# min-replicas-max-lag 10\n#\n# Setting one or the other to 0 disables the feature.\n#\n# By default min-replicas-to-write is set to 0 (feature disabled) and\n# min-replicas-max-lag is set to 10.\n\n# A Redis master is able to list the address and port of the attached\n# replicas in different ways. For example the "INFO replication" section\n# offers this information, which is used, among other tools, by\n# Redis Sentinel in order to discover replica instances.\n# Another place where this info is available is in the output of the\n# "ROLE" command of a master.\n#\n# The listed IP and address normally reported by a replica is obtained\n# in the following way:\n#\n#   IP: The address is auto detected by checking the peer address\n#   of the socket used by the replica to connect with the master.\n#\n#   Port: The port is communicated by the replica during the replication\n#   handshake, and is normally the port that the replica is using to\n#   listen for connections.\n#\n# However when port forwarding or Network Address Translation (NAT) is\n# used, the replica may be actually reachable via different IP and port\n# pairs. The following two options can be used by a replica in order to\n# report to its master a specific set of IP and port, so that both INFO\n# and ROLE will report those values.\n#\n# There is no need to use both the options if you need to override just\n# the port or the IP address.\n#\n# replica-announce-ip 5.5.5.5\n# replica-announce-port 1234\n\n################################## SECURITY ###################################\n\n# Require clients to issue AUTH <PASSWORD> before processing any other\n# commands.  This might be useful in environments in which you do not trust\n# others with access to the host running redis-server.\n#\n# This should stay commented out for backward compatibility and because most\n# people do not need auth (e.g. they run their own servers).\n#\n# Warning: since Redis is pretty fast an outside user can try up to\n# 150k passwords per second against a good box. This means that you should\n# use a very strong password otherwise it will be very easy to break.\n#\nrequirepass 123456\n\n# Command renaming.\n#\n# It is possible to change the name of dangerous commands in a shared\n# environment. For instance the CONFIG command may be renamed into something\n# hard to guess so that it will still be available for internal-use tools\n# but not available for general clients.\n#\n# Example:\n#\n# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52\n#\n# It is also possible to completely kill a command by renaming it into\n# an empty string:\n#\n# rename-command CONFIG ""\n#\n# Please note that changing the name of commands that are logged into the\n# AOF file or transmitted to replicas may cause problems.\n\n################################### CLIENTS ####################################\n\n# Set the max number of connected clients at the same time. By default\n# this limit is set to 10000 clients, however if the Redis server is not\n# able to configure the process file limit to allow for the specified limit\n# the max number of allowed clients is set to the current file limit\n# minus 32 (as Redis reserves a few file descriptors for internal uses).\n#\n# Once the limit is reached Redis will close all the new connections sending\n# an error \'max number of clients reached\'.\n#\n# maxclients 10000\n\n############################## MEMORY MANAGEMENT ################################\n\n# Set a memory usage limit to the specified amount of bytes.\n# When the memory limit is reached Redis will try to remove keys\n# according to the eviction policy selected (see maxmemory-policy).\n#\n# If Redis can\'t remove keys according to the policy, or if the policy is\n# set to \'noeviction\', Redis will start to reply with errors to commands\n# that would use more memory, like SET, LPUSH, and so on, and will continue\n# to reply to read-only commands like GET.\n#\n# This option is usually useful when using Redis as an LRU or LFU cache, or to\n# set a hard memory limit for an instance (using the \'noeviction\' policy).\n#\n# WARNING: If you have replicas attached to an instance with maxmemory on,\n# the size of the output buffers needed to feed the replicas are subtracted\n# from the used memory count, so that network problems / resyncs will\n# not trigger a loop where keys are evicted, and in turn the output\n# buffer of replicas is full with DELs of keys evicted triggering the deletion\n# of more keys, and so forth until the database is completely emptied.\n#\n# In short... if you have replicas attached it is suggested that you set a lower\n# limit for maxmemory so that there is some free RAM on the system for replica\n# output buffers (but this is not needed if the policy is \'noeviction\').\n#\n# maxmemory <bytes>\n\n# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory\n# is reached. You can select among five behaviors:\n#\n# volatile-lru -> Evict using approximated LRU among the keys with an expire set.\n# allkeys-lru -> Evict any key using approximated LRU.\n# volatile-lfu -> Evict using approximated LFU among the keys with an expire set.\n# allkeys-lfu -> Evict any key using approximated LFU.\n# volatile-random -> Remove a random key among the ones with an expire set.\n# allkeys-random -> Remove a random key, any key.\n# volatile-ttl -> Remove the key with the nearest expire time (minor TTL)\n# noeviction -> Don\'t evict anything, just return an error on write operations.\n#\n# LRU means Least Recently Used\n# LFU means Least Frequently Used\n#\n# Both LRU, LFU and volatile-ttl are implemented using approximated\n# randomized algorithms.\n#\n# Note: with any of the above policies, Redis will return an error on write\n#       operations, when there are no suitable keys for eviction.\n#\n#       At the date of writing these commands are: set setnx setex append\n#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd\n#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby\n#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby\n#       getset mset msetnx exec sort\n#\n# The default is:\n#\n# maxmemory-policy noeviction\n\n# LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated\n# algorithms (in order to save memory), so you can tune it for speed or\n# accuracy. For default Redis will check five keys and pick the one that was\n# used less recently, you can change the sample size using the following\n# configuration directive.\n#\n# The default of 5 produces good enough results. 10 Approximates very closely\n# true LRU but costs more CPU. 3 is faster but not very accurate.\n#\n# maxmemory-samples 5\n\n# Starting from Redis 5, by default a replica will ignore its maxmemory setting\n# (unless it is promoted to master after a failover or manually). It means\n# that the eviction of keys will be just handled by the master, sending the\n# DEL commands to the replica as keys evict in the master side.\n#\n# This behavior ensures that masters and replicas stay consistent, and is usually\n# what you want, however if your replica is writable, or you want the replica to have\n# a different memory setting, and you are sure all the writes performed to the\n# replica are idempotent, then you may change this default (but be sure to understand\n# what you are doing).\n#\n# Note that since the replica by default does not evict, it may end using more\n# memory than the one set via maxmemory (there are certain buffers that may\n# be larger on the replica, or data structures may sometimes take more memory and so\n# forth). So make sure you monitor your replicas and make sure they have enough\n# memory to never hit a real out-of-memory condition before the master hits\n# the configured maxmemory setting.\n#\n# replica-ignore-maxmemory yes\n\n############################# LAZY FREEING ####################################\n\n# Redis has two primitives to delete keys. One is called DEL and is a blocking\n# deletion of the object. It means that the server stops processing new commands\n# in order to reclaim all the memory associated with an object in a synchronous\n# way. If the key deleted is associated with a small object, the time needed\n# in order to execute the DEL command is very small and comparable to most other\n# O(1) or O(log_N) commands in Redis. However if the key is associated with an\n# aggregated value containing millions of elements, the server can block for\n# a long time (even seconds) in order to complete the operation.\n#\n# For the above reasons Redis also offers non blocking deletion primitives\n# such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and\n# FLUSHDB commands, in order to reclaim memory in background. Those commands\n# are executed in constant time. Another thread will incrementally free the\n# object in the background as fast as possible.\n#\n# DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.\n# It\'s up to the design of the application to understand when it is a good\n# idea to use one or the other. However the Redis server sometimes has to\n# delete keys or flush the whole database as a side effect of other operations.\n# Specifically Redis deletes objects independently of a user call in the\n# following scenarios:\n#\n# 1) On eviction, because of the maxmemory and maxmemory policy configurations,\n#    in order to make room for new data, without going over the specified\n#    memory limit.\n# 2) Because of expire: when a key with an associated time to live (see the\n#    EXPIRE command) must be deleted from memory.\n# 3) Because of a side effect of a command that stores data on a key that may\n#    already exist. For example the RENAME command may delete the old key\n#    content when it is replaced with another one. Similarly SUNIONSTORE\n#    or SORT with STORE option may delete existing keys. The SET command\n#    itself removes any old content of the specified key in order to replace\n#    it with the specified string.\n# 4) During replication, when a replica performs a full resynchronization with\n#    its master, the content of the whole database is removed in order to\n#    load the RDB file just transferred.\n#\n# In all the above cases the default is to delete objects in a blocking way,\n# like if DEL was called. However you can configure each case specifically\n# in order to instead release memory in a non-blocking way like if UNLINK\n# was called, using the following configuration directives:\n\nlazyfree-lazy-eviction no\nlazyfree-lazy-expire no\nlazyfree-lazy-server-del no\nreplica-lazy-flush no\n\n############################## APPEND ONLY MODE ###############################\n\n# By default Redis asynchronously dumps the dataset on disk. This mode is\n# good enough in many applications, but an issue with the Redis process or\n# a power outage may result into a few minutes of writes lost (depending on\n# the configured save points).\n#\n# The Append Only File is an alternative persistence mode that provides\n# much better durability. For instance using the default data fsync policy\n# (see later in the config file) Redis can lose just one second of writes in a\n# dramatic event like a server power outage, or a single write if something\n# wrong with the Redis process itself happens, but the operating system is\n# still running correctly.\n#\n# AOF and RDB persistence can be enabled at the same time without problems.\n# If the AOF is enabled on startup Redis will load the AOF, that is the file\n# with the better durability guarantees.\n#\n# Please check http://redis.io/topics/persistence for more information.\n\nappendonly no\n\n# The name of the append only file (default: "appendonly.aof")\n\nappendfilename "appendonly.aof"\n\n# The fsync() call tells the Operating System to actually write data on disk\n# instead of waiting for more data in the output buffer. Some OS will really flush\n# data on disk, some other OS will just try to do it ASAP.\n#\n# Redis supports three different modes:\n#\n# no: don\'t fsync, just let the OS flush the data when it wants. Faster.\n# always: fsync after every write to the append only log. Slow, Safest.\n# everysec: fsync only one time every second. Compromise.\n#\n# The default is "everysec", as that\'s usually the right compromise between\n# speed and data safety. It\'s up to you to understand if you can relax this to\n# "no" that will let the operating system flush the output buffer when\n# it wants, for better performances (but if you can live with the idea of\n# some data loss consider the default persistence mode that\'s snapshotting),\n# or on the contrary, use "always" that\'s very slow but a bit safer than\n# everysec.\n#\n# More details please check the following article:\n# http://antirez.com/post/redis-persistence-demystified.html\n#\n# If unsure, use "everysec".\n\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n\n# When the AOF fsync policy is set to always or everysec, and a background\n# saving process (a background save or AOF log background rewriting) is\n# performing a lot of I/O against the disk, in some Linux configurations\n# Redis may block too long on the fsync() call. Note that there is no fix for\n# this currently, as even performing fsync in a different thread will block\n# our synchronous write(2) call.\n#\n# In order to mitigate this problem it\'s possible to use the following option\n# that will prevent fsync() from being called in the main process while a\n# BGSAVE or BGREWRITEAOF is in progress.\n#\n# This means that while another child is saving, the durability of Redis is\n# the same as "appendfsync none". In practical terms, this means that it is\n# possible to lose up to 30 seconds of log in the worst scenario (with the\n# default Linux settings).\n#\n# If you have latency problems turn this to "yes". Otherwise leave it as\n# "no" that is the safest pick from the point of view of durability.\n\nno-appendfsync-on-rewrite no\n\n# Automatic rewrite of the append only file.\n# Redis is able to automatically rewrite the log file implicitly calling\n# BGREWRITEAOF when the AOF log size grows by the specified percentage.\n#\n# This is how it works: Redis remembers the size of the AOF file after the\n# latest rewrite (if no rewrite has happened since the restart, the size of\n# the AOF at startup is used).\n#\n# This base size is compared to the current size. If the current size is\n# bigger than the specified percentage, the rewrite is triggered. Also\n# you need to specify a minimal size for the AOF file to be rewritten, this\n# is useful to avoid rewriting the AOF file even if the percentage increase\n# is reached but it is still pretty small.\n#\n# Specify a percentage of zero in order to disable the automatic AOF\n# rewrite feature.\n\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n\n# An AOF file may be found to be truncated at the end during the Redis\n# startup process, when the AOF data gets loaded back into memory.\n# This may happen when the system where Redis is running\n# crashes, especially when an ext4 filesystem is mounted without the\n# data=ordered option (however this can\'t happen when Redis itself\n# crashes or aborts but the operating system still works correctly).\n#\n# Redis can either exit with an error when this happens, or load as much\n# data as possible (the default now) and start if the AOF file is found\n# to be truncated at the end. The following option controls this behavior.\n#\n# If aof-load-truncated is set to yes, a truncated AOF file is loaded and\n# the Redis server starts emitting a log to inform the user of the event.\n# Otherwise if the option is set to no, the server aborts with an error\n# and refuses to start. When the option is set to no, the user requires\n# to fix the AOF file using the "redis-check-aof" utility before to restart\n# the server.\n#\n# Note that if the AOF file will be found to be corrupted in the middle\n# the server will still exit with an error. This option only applies when\n# Redis will try to read more data from the AOF file but not enough bytes\n# will be found.\naof-load-truncated yes\n\n# When rewriting the AOF file, Redis is able to use an RDB preamble in the\n# AOF file for faster rewrites and recoveries. When this option is turned\n# on the rewritten AOF file is composed of two different stanzas:\n#\n#   [RDB file][AOF tail]\n#\n# When loading Redis recognizes that the AOF file starts with the "REDIS"\n# string and loads the prefixed RDB file, and continues loading the AOF\n# tail.\naof-use-rdb-preamble yes\n\n################################ LUA SCRIPTING  ###############################\n\n# Max execution time of a Lua script in milliseconds.\n#\n# If the maximum execution time is reached Redis will log that a script is\n# still in execution after the maximum allowed time and will start to\n# reply to queries with an error.\n#\n# When a long running script exceeds the maximum execution time only the\n# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be\n# used to stop a script that did not yet called write commands. The second\n# is the only way to shut down the server in the case a write command was\n# already issued by the script but the user doesn\'t want to wait for the natural\n# termination of the script.\n#\n# Set it to 0 or a negative value for unlimited execution without warnings.\nlua-time-limit 5000\n\n################################ REDIS CLUSTER  ###############################\n\n# Normal Redis instances can\'t be part of a Redis Cluster; only nodes that are\n# started as cluster nodes can. In order to start a Redis instance as a\n# cluster node enable the cluster support uncommenting the following:\n#\n# cluster-enabled yes\n\n# Every cluster node has a cluster configuration file. This file is not\n# intended to be edited by hand. It is created and updated by Redis nodes.\n# Every Redis Cluster node requires a different cluster configuration file.\n# Make sure that instances running in the same system do not have\n# overlapping cluster configuration file names.\n#\n# cluster-config-file nodes-6379.conf\n\n# Cluster node timeout is the amount of milliseconds a node must be unreachable\n# for it to be considered in failure state.\n# Most other internal time limits are multiple of the node timeout.\n#\n# cluster-node-timeout 15000\n\n# A replica of a failing master will avoid to start a failover if its data\n# looks too old.\n#\n# There is no simple way for a replica to actually have an exact measure of\n# its "data age", so the following two checks are performed:\n#\n# 1) If there are multiple replicas able to failover, they exchange messages\n#    in order to try to give an advantage to the replica with the best\n#    replication offset (more data from the master processed).\n#    Replicas will try to get their rank by offset, and apply to the start\n#    of the failover a delay proportional to their rank.\n#\n# 2) Every single replica computes the time of the last interaction with\n#    its master. This can be the last ping or command received (if the master\n#    is still in the "connected" state), or the time that elapsed since the\n#    disconnection with the master (if the replication link is currently down).\n#    If the last interaction is too old, the replica will not try to failover\n#    at all.\n#\n# The point "2" can be tuned by user. Specifically a replica will not perform\n# the failover if, since the last interaction with the master, the time\n# elapsed is greater than:\n#\n#   (node-timeout * replica-validity-factor) + repl-ping-replica-period\n#\n# So for example if node-timeout is 30 seconds, and the replica-validity-factor\n# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the\n# replica will not try to failover if it was not able to talk with the master\n# for longer than 310 seconds.\n#\n# A large replica-validity-factor may allow replicas with too old data to failover\n# a master, while a too small value may prevent the cluster from being able to\n# elect a replica at all.\n#\n# For maximum availability, it is possible to set the replica-validity-factor\n# to a value of 0, which means, that replicas will always try to failover the\n# master regardless of the last time they interacted with the master.\n# (However they\'ll always try to apply a delay proportional to their\n# offset rank).\n#\n# Zero is the only value able to guarantee that when all the partitions heal\n# the cluster will always be able to continue.\n#\n# cluster-replica-validity-factor 10\n\n# Cluster replicas are able to migrate to orphaned masters, that are masters\n# that are left without working replicas. This improves the cluster ability\n# to resist to failures as otherwise an orphaned master can\'t be failed over\n# in case of failure if it has no working replicas.\n#\n# Replicas migrate to orphaned masters only if there are still at least a\n# given number of other working replicas for their old master. This number\n# is the "migration barrier". A migration barrier of 1 means that a replica\n# will migrate only if there is at least 1 other working replica for its master\n# and so forth. It usually reflects the number of replicas you want for every\n# master in your cluster.\n#\n# Default is 1 (replicas migrate only if their masters remain with at least\n# one replica). To disable migration just set it to a very large value.\n# A value of 0 can be set but is useful only for debugging and dangerous\n# in production.\n#\n# cluster-migration-barrier 1\n\n# By default Redis Cluster nodes stop accepting queries if they detect there\n# is at least an hash slot uncovered (no available node is serving it).\n# This way if the cluster is partially down (for example a range of hash slots\n# are no longer covered) all the cluster becomes, eventually, unavailable.\n# It automatically returns available as soon as all the slots are covered again.\n#\n# However sometimes you want the subset of the cluster which is working,\n# to continue to accept queries for the part of the key space that is still\n# covered. In order to do so, just set the cluster-require-full-coverage\n# option to no.\n#\n# cluster-require-full-coverage yes\n\n# This option, when set to yes, prevents replicas from trying to failover its\n# master during master failures. However the master can still perform a\n# manual failover, if forced to do so.\n#\n# This is useful in different scenarios, especially in the case of multiple\n# data center operations, where we want one side to never be promoted if not\n# in the case of a total DC failure.\n#\n# cluster-replica-no-failover no\n\n# In order to setup your cluster make sure to read the documentation\n# available at http://redis.io web site.\n\n########################## CLUSTER DOCKER/NAT support  ########################\n\n# In certain deployments, Redis Cluster nodes address discovery fails, because\n# addresses are NAT-ted or because ports are forwarded (the typical case is\n# Docker and other containers).\n#\n# In order to make Redis Cluster working in such environments, a static\n# configuration where each node knows its public address is needed. The\n# following two options are used for this scope, and are:\n#\n# * cluster-announce-ip\n# * cluster-announce-port\n# * cluster-announce-bus-port\n#\n# Each instruct the node about its address, client port, and cluster message\n# bus port. The information is then published in the header of the bus packets\n# so that other nodes will be able to correctly map the address of the node\n# publishing the information.\n#\n# If the above options are not used, the normal Redis Cluster auto-detection\n# will be used instead.\n#\n# Note that when remapped, the bus port may not be at the fixed offset of\n# clients port + 10000, so you can specify any port and bus-port depending\n# on how they get remapped. If the bus-port is not set, a fixed offset of\n# 10000 will be used as usually.\n#\n# Example:\n#\n# cluster-announce-ip 10.1.1.5\n# cluster-announce-port 6379\n# cluster-announce-bus-port 6380\n\n################################## SLOW LOG ###################################\n\n# The Redis Slow Log is a system to log queries that exceeded a specified\n# execution time. The execution time does not include the I/O operations\n# like talking with the client, sending the reply and so forth,\n# but just the time needed to actually execute the command (this is the only\n# stage of command execution where the thread is blocked and can not serve\n# other requests in the meantime).\n#\n# You can configure the slow log with two parameters: one tells Redis\n# what is the execution time, in microseconds, to exceed in order for the\n# command to get logged, and the other parameter is the length of the\n# slow log. When a new command is logged the oldest one is removed from the\n# queue of logged commands.\n\n# The following time is expressed in microseconds, so 1000000 is equivalent\n# to one second. Note that a negative number disables the slow log, while\n# a value of zero forces the logging of every command.\nslowlog-log-slower-than 10000\n\n# There is no limit to this length. Just be aware that it will consume memory.\n# You can reclaim memory used by the slow log with SLOWLOG RESET.\nslowlog-max-len 128\n\n################################ LATENCY MONITOR ##############################\n\n# The Redis latency monitoring subsystem samples different operations\n# at runtime in order to collect data related to possible sources of\n# latency of a Redis instance.\n#\n# Via the LATENCY command this information is available to the user that can\n# print graphs and obtain reports.\n#\n# The system only logs operations that were performed in a time equal or\n# greater than the amount of milliseconds specified via the\n# latency-monitor-threshold configuration directive. When its value is set\n# to zero, the latency monitor is turned off.\n#\n# By default latency monitoring is disabled since it is mostly not needed\n# if you don\'t have latency issues, and collecting data has a performance\n# impact, that while very small, can be measured under big load. Latency\n# monitoring can easily be enabled at runtime using the command\n# "CONFIG SET latency-monitor-threshold <milliseconds>" if needed.\nlatency-monitor-threshold 0\n\n############################# EVENT NOTIFICATION ##############################\n\n# Redis can notify Pub/Sub clients about events happening in the key space.\n# This feature is documented at http://redis.io/topics/notifications\n#\n# For instance if keyspace events notification is enabled, and a client\n# performs a DEL operation on key "foo" stored in the Database 0, two\n# messages will be published via Pub/Sub:\n#\n# PUBLISH __keyspace@0__:foo del\n# PUBLISH __keyevent@0__:del foo\n#\n# It is possible to select the events that Redis will notify among a set\n# of classes. Every class is identified by a single character:\n#\n#  K     Keyspace events, published with __keyspace@<db>__ prefix.\n#  E     Keyevent events, published with __keyevent@<db>__ prefix.\n#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...\n#  $     String commands\n#  l     List commands\n#  s     Set commands\n#  h     Hash commands\n#  z     Sorted set commands\n#  x     Expired events (events generated every time a key expires)\n#  e     Evicted events (events generated when a key is evicted for maxmemory)\n#  A     Alias for g$lshzxe, so that the "AKE" string means all the events.\n#\n#  The "notify-keyspace-events" takes as argument a string that is composed\n#  of zero or multiple characters. The empty string means that notifications\n#  are disabled.\n#\n#  Example: to enable list and generic events, from the point of view of the\n#           event name, use:\n#\n#  notify-keyspace-events Elg\n#\n#  Example 2: to get the stream of the expired keys subscribing to channel\n#             name __keyevent@0__:expired use:\n#\n#  notify-keyspace-events Ex\n#\n#  By default all notifications are disabled because most users don\'t need\n#  this feature and the feature has some overhead. Note that if you don\'t\n#  specify at least one of K or E, no events will be delivered.\nnotify-keyspace-events ""\n\n############################### ADVANCED CONFIG ###############################\n\n# Hashes are encoded using a memory efficient data structure when they have a\n# small number of entries, and the biggest entry does not exceed a given\n# threshold. These thresholds can be configured using the following directives.\nhash-max-ziplist-entries 512\nhash-max-ziplist-value 64\n\n# Lists are also encoded in a special way to save a lot of space.\n# The number of entries allowed per internal list node can be specified\n# as a fixed maximum size or a maximum number of elements.\n# For a fixed maximum size, use -5 through -1, meaning:\n# -5: max size: 64 Kb  <-- not recommended for normal workloads\n# -4: max size: 32 Kb  <-- not recommended\n# -3: max size: 16 Kb  <-- probably not recommended\n# -2: max size: 8 Kb   <-- good\n# -1: max size: 4 Kb   <-- good\n# Positive numbers mean store up to _exactly_ that number of elements\n# per list node.\n# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),\n# but if your use case is unique, adjust the settings as necessary.\nlist-max-ziplist-size -2\n\n# Lists may also be compressed.\n# Compress depth is the number of quicklist ziplist nodes from *each* side of\n# the list to *exclude* from compression.  The head and tail of the list\n# are always uncompressed for fast push/pop operations.  Settings are:\n# 0: disable all list compression\n# 1: depth 1 means "don\'t start compressing until after 1 node into the list,\n#    going from either the head or tail"\n#    So: [head]->node->node->...->node->[tail]\n#    [head], [tail] will always be uncompressed; inner nodes will compress.\n# 2: [head]->[next]->node->node->...->node->[prev]->[tail]\n#    2 here means: don\'t compress head or head->next or tail->prev or tail,\n#    but compress all nodes between them.\n# 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail]\n# etc.\nlist-compress-depth 0\n\n# Sets have a special encoding in just one case: when a set is composed\n# of just strings that happen to be integers in radix 10 in the range\n# of 64 bit signed integers.\n# The following configuration setting sets the limit in the size of the\n# set in order to use this special memory saving encoding.\nset-max-intset-entries 512\n\n# Similarly to hashes and lists, sorted sets are also specially encoded in\n# order to save a lot of space. This encoding is only used when the length and\n# elements of a sorted set are below the following limits:\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\n\n# HyperLogLog sparse representation bytes limit. The limit includes the\n# 16 bytes header. When an HyperLogLog using the sparse representation crosses\n# this limit, it is converted into the dense representation.\n#\n# A value greater than 16000 is totally useless, since at that point the\n# dense representation is more memory efficient.\n#\n# The suggested value is ~ 3000 in order to have the benefits of\n# the space efficient encoding without slowing down too much PFADD,\n# which is O(N) with the sparse encoding. The value can be raised to\n# ~ 10000 when CPU is not a concern, but space is, and the data set is\n# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.\nhll-sparse-max-bytes 3000\n\n# Streams macro node max size / items. The stream data structure is a radix\n# tree of big nodes that encode multiple items inside. Using this configuration\n# it is possible to configure how big a single node can be in bytes, and the\n# maximum number of items it may contain before switching to a new node when\n# appending new stream entries. If any of the following settings are set to\n# zero, the limit is ignored, so for instance it is possible to set just a\n# max entires limit by setting max-bytes to 0 and max-entries to the desired\n# value.\nstream-node-max-bytes 4096\nstream-node-max-entries 100\n\n# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in\n# order to help rehashing the main Redis hash table (the one mapping top-level\n# keys to values). The hash table implementation Redis uses (see dict.c)\n# performs a lazy rehashing: the more operation you run into a hash table\n# that is rehashing, the more rehashing "steps" are performed, so if the\n# server is idle the rehashing is never complete and some more memory is used\n# by the hash table.\n#\n# The default is to use this millisecond 10 times every second in order to\n# actively rehash the main dictionaries, freeing memory when possible.\n#\n# If unsure:\n# use "activerehashing no" if you have hard latency requirements and it is\n# not a good thing in your environment that Redis can reply from time to time\n# to queries with 2 milliseconds delay.\n#\n# use "activerehashing yes" if you don\'t have such hard requirements but\n# want to free memory asap when possible.\nactiverehashing yes\n\n# The client output buffer limits can be used to force disconnection of clients\n# that are not reading data from the server fast enough for some reason (a\n# common reason is that a Pub/Sub client can\'t consume messages as fast as the\n# publisher can produce them).\n#\n# The limit can be set differently for the three different classes of clients:\n#\n# normal -> normal clients including MONITOR clients\n# replica  -> replica clients\n# pubsub -> clients subscribed to at least one pubsub channel or pattern\n#\n# The syntax of every client-output-buffer-limit directive is the following:\n#\n# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>\n#\n# A client is immediately disconnected once the hard limit is reached, or if\n# the soft limit is reached and remains reached for the specified number of\n# seconds (continuously).\n# So for instance if the hard limit is 32 megabytes and the soft limit is\n# 16 megabytes / 10 seconds, the client will get disconnected immediately\n# if the size of the output buffers reach 32 megabytes, but will also get\n# disconnected if the client reaches 16 megabytes and continuously overcomes\n# the limit for 10 seconds.\n#\n# By default normal clients are not limited because they don\'t receive data\n# without asking (in a push way), but just after a request, so only\n# asynchronous clients may create a scenario where data is requested faster\n# than it can read.\n#\n# Instead there is a default limit for pubsub and replica clients, since\n# subscribers and replicas receive data in a push fashion.\n#\n# Both the hard or the soft limit can be disabled by setting them to zero.\nclient-output-buffer-limit normal 0 0 0\nclient-output-buffer-limit replica 256mb 64mb 60\nclient-output-buffer-limit pubsub 32mb 8mb 60\n\n# Client query buffers accumulate new commands. They are limited to a fixed\n# amount by default in order to avoid that a protocol desynchronization (for\n# instance due to a bug in the client) will lead to unbound memory usage in\n# the query buffer. However you can configure it here if you have very special\n# needs, such us huge multi/exec requests or alike.\n#\n# client-query-buffer-limit 1gb\n\n# In the Redis protocol, bulk requests, that are, elements representing single\n# strings, are normally limited ot 512 mb. However you can change this limit\n# here.\n#\n# proto-max-bulk-len 512mb\n\n# Redis calls an internal function to perform many background tasks, like\n# closing connections of clients in timeout, purging expired keys that are\n# never requested, and so forth.\n#\n# Not all tasks are performed with the same frequency, but Redis checks for\n# tasks to perform according to the specified "hz" value.\n#\n# By default "hz" is set to 10. Raising the value will use more CPU when\n# Redis is idle, but at the same time will make Redis more responsive when\n# there are many keys expiring at the same time, and timeouts may be\n# handled with more precision.\n#\n# The range is between 1 and 500, however a value over 100 is usually not\n# a good idea. Most users should use the default of 10 and raise this up to\n# 100 only in environments where very low latency is required.\nhz 10\n\n# Normally it is useful to have an HZ value which is proportional to the\n# number of clients connected. This is useful in order, for instance, to\n# avoid too many clients are processed for each background task invocation\n# in order to avoid latency spikes.\n#\n# Since the default HZ value by default is conservatively set to 10, Redis\n# offers, and enables by default, the ability to use an adaptive HZ value\n# which will temporary raise when there are many connected clients.\n#\n# When dynamic HZ is enabled, the actual configured HZ will be used as\n# as a baseline, but multiples of the configured HZ value will be actually\n# used as needed once more clients are connected. In this way an idle\n# instance will use very little CPU time while a busy instance will be\n# more responsive.\ndynamic-hz yes\n\n# When a child rewrites the AOF file, if the following option is enabled\n# the file will be fsync-ed every 32 MB of data generated. This is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\naof-rewrite-incremental-fsync yes\n\n# When redis saves RDB file, if the following option is enabled\n# the file will be fsync-ed every 32 MB of data generated. This is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\nrdb-save-incremental-fsync yes\n\n# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good\n# idea to start with the default settings and only change them after investigating\n# how to improve the performances and how the keys LFU change over time, which\n# is possible to inspect via the OBJECT FREQ command.\n#\n# There are two tunable parameters in the Redis LFU implementation: the\n# counter logarithm factor and the counter decay time. It is important to\n# understand what the two parameters mean before changing them.\n#\n# The LFU counter is just 8 bits per key, it\'s maximum value is 255, so Redis\n# uses a probabilistic increment with logarithmic behavior. Given the value\n# of the old counter, when a key is accessed, the counter is incremented in\n# this way:\n#\n# 1. A random number R between 0 and 1 is extracted.\n# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).\n# 3. The counter is incremented only if R < P.\n#\n# The default lfu-log-factor is 10. This is a table of how the frequency\n# counter changes with a different number of accesses with different\n# logarithmic factors:\n#\n# +--------+------------+------------+------------+------------+------------+\n# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |\n# +--------+------------+------------+------------+------------+------------+\n# | 0      | 104        | 255        | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 1      | 18         | 49         | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 10     | 10         | 18         | 142        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 100    | 8          | 11         | 49         | 143        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n#\n# NOTE: The above table was obtained by running the following commands:\n#\n#   redis-benchmark -n 1000000 incr foo\n#   redis-cli object freq foo\n#\n# NOTE 2: The counter initial value is 5 in order to give new objects a chance\n# to accumulate hits.\n#\n# The counter decay time is the time, in minutes, that must elapse in order\n# for the key counter to be divided by two (or decremented if it has a value\n# less <= 10).\n#\n# The default value for the lfu-decay-time is 1. A Special value of 0 means to\n# decay the counter every time it happens to be scanned.\n#\n# lfu-log-factor 10\n# lfu-decay-time 1\n\n########################### ACTIVE DEFRAGMENTATION #######################\n#\n# WARNING THIS FEATURE IS EXPERIMENTAL. However it was stress tested\n# even in production and manually tested by multiple engineers for some\n# time.\n#\n# What is active defragmentation?\n# -------------------------------\n#\n# Active (online) defragmentation allows a Redis server to compact the\n# spaces left between small allocations and deallocations of data in memory,\n# thus allowing to reclaim back memory.\n#\n# Fragmentation is a natural process that happens with every allocator (but\n# less so with Jemalloc, fortunately) and certain workloads. Normally a server\n# restart is needed in order to lower the fragmentation, or at least to flush\n# away all the data and create it again. However thanks to this feature\n# implemented by Oran Agra for Redis 4.0 this process can happen at runtime\n# in an "hot" way, while the server is running.\n#\n# Basically when the fragmentation is over a certain level (see the\n# configuration options below) Redis will start to create new copies of the\n# values in contiguous memory regions by exploiting certain specific Jemalloc\n# features (in order to understand if an allocation is causing fragmentation\n# and to allocate it in a better place), and at the same time, will release the\n# old copies of the data. This process, repeated incrementally for all the keys\n# will cause the fragmentation to drop back to normal values.\n#\n# Important things to understand:\n#\n# 1. This feature is disabled by default, and only works if you compiled Redis\n#    to use the copy of Jemalloc we ship with the source code of Redis.\n#    This is the default with Linux builds.\n#\n# 2. You never need to enable this feature if you don\'t have fragmentation\n#    issues.\n#\n# 3. Once you experience fragmentation, you can enable this feature when\n#    needed with the command "CONFIG SET activedefrag yes".\n#\n# The configuration parameters are able to fine tune the behavior of the\n# defragmentation process. If you are not sure about what they mean it is\n# a good idea to leave the defaults untouched.\n\n# Enabled active defragmentation\n# activedefrag yes\n\n# Minimum amount of fragmentation waste to start active defrag\n# active-defrag-ignore-bytes 100mb\n\n# Minimum percentage of fragmentation to start active defrag\n# active-defrag-threshold-lower 10\n\n# Maximum percentage of fragmentation at which we use maximum effort\n# active-defrag-threshold-upper 100\n\n# Minimal effort for defrag in CPU percentage\n# active-defrag-cycle-min 5\n\n# Maximal effort for defrag in CPU percentage\n# active-defrag-cycle-max 75\n\n# Maximum number of set/hash/zset/list fields that will be processed from\n# the main dictionary scan\n# active-defrag-max-scan-fields 1000\n\n# It is possible to pin different threads and processes of Redis to specific\n# CPUs in your system, in order to maximize the performances of the server.\n# This is useful both in order to pin different Redis threads in different\n# CPUs, but also in order to make sure that multiple Redis instances running\n# in the same host will be pinned to different CPUs.\n#\n# Normally you can do this using the "taskset" command, however it is also\n# possible to this via Redis configuration directly, both in Linux and FreeBSD.\n#\n# You can pin the server/IO threads, bio threads, aof rewrite child process, and\n# the bgsave child process. The syntax to specify the cpu list is the same as\n# the taskset command:\n#\n# Set redis server/io threads to cpu affinity 0,2,4,6:\n# server_cpulist 0-7:2\n#\n# Set bio threads to cpu affinity 1,3:\n# bio_cpulist 1,3\n#\n# Set aof rewrite child process to cpu affinity 8,9,10,11:\n# aof_rewrite_cpulist 8-11\n#\n# Set bgsave child process to cpu affinity 1,10,11\n# bgsave_cpulist 1,10-11\n\n# In some cases redis will emit warnings and even refuse to start if it detects\n# that the system is in bad state, it is possible to suppress these warnings\n# by setting the following config which takes a space delimited list of warnings\n# to suppress\n#\n# ignore-warnings ARM64-COW-BUG\n\n\n\n\n# deploy.sh\n\nmkdir -p /etc/redis/\n\n\\cp ./redis.conf /etc/redis/redis.conf\ndocker-compose up -d\n',normalizedContent:'# redis 高性能的key-value数据库\n\n网址\n\n官网：https://redis.io/\n\ngithub：https://github.com/redis/redis\n\n\n# 开源简介\n\n> redis（remote dictionary server的缩写）是一个高性能的开源内存数据存储系统，它可以用作缓存、消息中间件和数据库。redis最初由salvatore sanfilippo开发，于2009年首次发布。它以其快速的读写操作、多种数据结构和灵活的用途而受到广泛关注和使用。\n\n\n# 主要特性\n\n 1. 内存存储 ：redis将数据存储在内存中，这使得它能够实现非常快速的读写操作。这使得redis成为处理实时数据和高并发访问的理想选择。\n 2. 持久化 ：虽然数据存储在内存中，但redis可以通过不同的持久化机制将数据写入磁盘，以便在重启后恢复数据。这有助于确保数据的持久性和可靠性。\n 3. 丰富的数据结构 ：redis支持多种数据结构，包括字符串、哈希、列表、集合、有序集合等。这使得开发人员能够根据不同的用例选择适当的数据结构，从而更有效地存储和处理数据。\n 4. 发布订阅 ：redis支持发布订阅模式，允许客户端订阅特定的频道并接收发布到该频道的消息。这在构建实时通知和消息系统时非常有用。\n 5. 事务 ：redis支持简单的事务操作，开发人员可以将多个命令打包到一个事务中，然后一次性执行，从而确保这些命令要么全部执行成功，要么全部不执行。\n 6. 分布式 ：redis可以作为分布式系统的一部分运行，通过复制和分片来提供高可用性和横向扩展。\n\n\n# 使用场景\n\n 1. 缓存 ：redis常用作缓存层，以加速读取频繁的数据，减轻后端数据库的负担。\n 2. 会话存储 ：将用户会话数据存储在redis中，以实现快速的用户认证和状态管理。\n 3. 计数器和排行榜 ：利用redis的原子计数特性，可以轻松实现计数器和排行榜功能。\n 4. 实时分析 ：通过存储实时数据并使用redis的复杂数据结构，可以构建实时分析和统计系统。\n 5. 消息中间件 ：利用发布订阅功能，redis可用于构建实时消息系统，用于通知、事件处理等场景。\n 6. 地理空间索引 ：redis支持地理位置数据，可以用于构建位置服务和附近搜索功能。\n\n\n# 总结\n\nredis是一个功能强大的内存数据存储系统，具有高性能、丰富的数据结构和多样化的应用场景。它在缓存、实时数据处理、消息系统等方面都具有出色的表现，成为众多开发人员和企业的首选技术之一。\n\n\n# docker-compose.yml\n\nversion: \'3.7\'\n\nservices: \n  redis:\n    image: redis:7.0.3\n    container_name: redis\n    restart: always\n    environment: \n      tz: asia/shanghai\n    ports:\n      - 6379:6379\n    volumes: \n      - data:/data\n    command: redis-server /usr/local/etc/redis/redis.conf\n    sysctls:\n      net.core.somaxconn: 65535\n\nvolumes: \n  data: \n\n\n\n# redis.conf\n\n# redis configuration file example.\n#\n# note that in order to read the configuration file, redis must be\n# started with the file path as first argument:\n#\n# ./redis-server /path/to/redis.conf\n\n# note on units: when memory size is needed, it is possible to specify\n# it in the usual form of 1k 5gb 4m and so forth:\n#\n# 1k => 1000 bytes\n# 1kb => 1024 bytes\n# 1m => 1000000 bytes\n# 1mb => 1024*1024 bytes\n# 1g => 1000000000 bytes\n# 1gb => 1024*1024*1024 bytes\n#\n# units are case insensitive so 1gb 1gb 1gb are all the same.\n\n################################## includes ###################################\n\n# include one or more other config files here.  this is useful if you\n# have a standard template that goes to all redis servers but also need\n# to customize a few per-server settings.  include files can include\n# other files, so use this wisely.\n#\n# notice option "include" won\'t be rewritten by command "config rewrite"\n# from admin or redis sentinel. since redis always uses the last processed\n# line as value of a configuration directive, you\'d better put includes\n# at the beginning of this file to avoid overwriting config change at runtime.\n#\n# if instead you are interested in using includes to override configuration\n# options, it is better to use include as the last line.\n#\n# include /path/to/local.conf\n# include /path/to/other.conf\n\n################################## modules #####################################\n\n# load modules at startup. if the server is not able to load modules\n# it will abort. it is possible to use multiple loadmodule directives.\n#\n# loadmodule /path/to/my_module.so\n# loadmodule /path/to/other_module.so\n\n################################## network #####################################\n\n# by default, if no "bind" configuration directive is specified, redis listens\n# for connections from all the network interfaces available on the server.\n# it is possible to listen to just one or multiple selected interfaces using\n# the "bind" configuration directive, followed by one or more ip addresses.\n#\n# examples:\n#\n# bind 192.168.1.100 10.0.0.1\n# bind 127.0.0.1 ::1\n#\n# ~~~ warning ~~~ if the computer running redis is directly exposed to the\n# internet, binding to all the interfaces is dangerous and will expose the\n# instance to everybody on the internet. so by default we uncomment the\n# following bind directive, that will force redis to listen only into\n# the ipv4 loopback interface address (this means redis will be able to\n# accept connections only from clients running into the same computer it\n# is running).\n#\n# if you are sure you want your instance to listen to all the interfaces\n# just comment the following line.\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# bind 127.0.0.1\n\n# protected mode is a layer of security protection, in order to avoid that\n# redis instances left open on the internet are accessed and exploited.\n#\n# when protected mode is on and if:\n#\n# 1) the server is not binding explicitly to a set of addresses using the\n#    "bind" directive.\n# 2) no password is configured.\n#\n# the server only accepts connections from clients connecting from the\n# ipv4 and ipv6 loopback addresses 127.0.0.1 and ::1, and from unix domain\n# sockets.\n#\n# by default protected mode is enabled. you should disable it only if\n# you are sure you want clients from other hosts to connect to redis\n# even if no authentication is configured, nor a specific set of interfaces\n# are explicitly listed using the "bind" directive.\nprotected-mode no\n\n# accept connections on the specified port, default is 6379 (iana #815344).\n# if port 0 is specified redis will not listen on a tcp socket.\nport 6379\n\n# tcp listen() backlog.\n#\n# in high requests-per-second environments you need an high backlog in order\n# to avoid slow clients connections issues. note that the linux kernel\n# will silently truncate it to the value of /proc/sys/net/core/somaxconn so\n# make sure to raise both the value of somaxconn and tcp_max_syn_backlog\n# in order to get the desired effect.\ntcp-backlog 511\n\n# unix socket.\n#\n# specify the path for the unix socket that will be used to listen for\n# incoming connections. there is no default, so redis will not listen\n# on a unix socket when not specified.\n#\n# unixsocket /tmp/redis.sock\n# unixsocketperm 700\n\n# close the connection after a client is idle for n seconds (0 to disable)\ntimeout 0\n\n# tcp keepalive.\n#\n# if non-zero, use so_keepalive to send tcp acks to clients in absence\n# of communication. this is useful for two reasons:\n#\n# 1) detect dead peers.\n# 2) take the connection alive from the point of view of network\n#    equipment in the middle.\n#\n# on linux, the specified value (in seconds) is the period used to send acks.\n# note that to close the connection the double of the time is needed.\n# on other kernels the period depends on the kernel configuration.\n#\n# a reasonable value for this option is 300 seconds, which is the new\n# redis default starting with redis 3.2.1.\ntcp-keepalive 300\n\n################################# general #####################################\n\n# by default redis does not run as a daemon. use \'yes\' if you need it.\n# note that redis will write a pid file in /var/run/redis.pid when daemonized.\ndaemonize no\n\n# if you run redis from upstart or systemd, redis can interact with your\n# supervision tree. options:\n#   supervised no      - no supervision interaction\n#   supervised upstart - signal upstart by putting redis into sigstop mode\n#   supervised systemd - signal systemd by writing ready=1 to $notify_socket\n#   supervised auto    - detect upstart or systemd method based on\n#                        upstart_job or notify_socket environment variables\n# note: these supervision methods only signal "process is ready."\n#       they do not enable continuous liveness pings back to your supervisor.\nsupervised no\n\n# if a pid file is specified, redis writes it where specified at startup\n# and removes it at exit.\n#\n# when the server runs non daemonized, no pid file is created if none is\n# specified in the configuration. when the server is daemonized, the pid file\n# is used even if not specified, defaulting to "/var/run/redis.pid".\n#\n# creating a pid file is best effort: if redis is not able to create it\n# nothing bad happens, the server will start and run normally.\npidfile /var/run/redis_6379.pid\n\n# specify the server verbosity level.\n# this can be one of:\n# debug (a lot of information, useful for development/testing)\n# verbose (many rarely useful info, but not a mess like the debug level)\n# notice (moderately verbose, what you want in production probably)\n# warning (only very important / critical messages are logged)\nloglevel notice\n\n# specify the log file name. also the empty string can be used to force\n# redis to log on the standard output. note that if you use standard\n# output for logging but daemonize, logs will be sent to /dev/null\nlogfile ""\n\n# to enable logging to the system logger, just set \'syslog-enabled\' to yes,\n# and optionally update the other syslog parameters to suit your needs.\n# syslog-enabled no\n\n# specify the syslog identity.\n# syslog-ident redis\n\n# specify the syslog facility. must be user or between local0-local7.\n# syslog-facility local0\n\n# set the number of databases. the default database is db 0, you can select\n# a different one on a per-connection basis using select <dbid> where\n# dbid is a number between 0 and \'databases\'-1\ndatabases 20\n\n# by default redis shows an ascii art logo only when started to log to the\n# standard output and if the standard output is a tty. basically this means\n# that normally a logo is displayed only in interactive sessions.\n#\n# however it is possible to force the pre-4.0 behavior and always show a\n# ascii art logo in startup logs by setting the following option to yes.\nalways-show-logo yes\n\n################################ snapshotting  ################################\n#\n# save the db on disk:\n#\n#   save <seconds> <changes>\n#\n#   will save the db if both the given number of seconds and the given\n#   number of write operations against the db occurred.\n#\n#   in the example below the behaviour will be to save:\n#   after 900 sec (15 min) if at least 1 key changed\n#   after 300 sec (5 min) if at least 10 keys changed\n#   after 60 sec if at least 10000 keys changed\n#\n#   note: you can disable saving completely by commenting out all "save" lines.\n#\n#   it is also possible to remove all the previously configured save\n#   points by adding a save directive with a single empty string argument\n#   like in the following example:\n#\n#   save ""\n\nsave 900 1\nsave 300 10\nsave 60 10000\n\n# by default redis will stop accepting writes if rdb snapshots are enabled\n# (at least one save point) and the latest background save failed.\n# this will make the user aware (in a hard way) that data is not persisting\n# on disk properly, otherwise chances are that no one will notice and some\n# disaster will happen.\n#\n# if the background saving process will start working again redis will\n# automatically allow writes again.\n#\n# however if you have setup your proper monitoring of the redis server\n# and persistence, you may want to disable this feature so that redis will\n# continue to work as usual even if there are problems with disk,\n# permissions, and so forth.\nstop-writes-on-bgsave-error yes\n\n# compress string objects using lzf when dump .rdb databases?\n# for default that\'s set to \'yes\' as it\'s almost always a win.\n# if you want to save some cpu in the saving child set it to \'no\' but\n# the dataset will likely be bigger if you have compressible values or keys.\nrdbcompression yes\n\n# since version 5 of rdb a crc64 checksum is placed at the end of the file.\n# this makes the format more resistant to corruption but there is a performance\n# hit to pay (around 10%) when saving and loading rdb files, so you can disable it\n# for maximum performances.\n#\n# rdb files created with checksum disabled have a checksum of zero that will\n# tell the loading code to skip the check.\nrdbchecksum yes\n\n# the filename where to dump the db\ndbfilename dump.rdb\n\n# the working directory.\n#\n# the db will be written inside this directory, with the filename specified\n# above using the \'dbfilename\' configuration directive.\n#\n# the append only file will also be created inside this directory.\n#\n# note that you must specify a directory here, not a file name.\ndir /data/\n\n################################# replication #################################\n\n# master-replica replication. use replicaof to make a redis instance a copy of\n# another redis server. a few things to understand asap about redis replication.\n#\n#   +------------------+      +---------------+\n#   |      master      | ---\x3e |    replica    |\n#   | (receive writes) |      |  (exact copy) |\n#   +------------------+      +---------------+\n#\n# 1) redis replication is asynchronous, but you can configure a master to\n#    stop accepting writes if it appears to be not connected with at least\n#    a given number of replicas.\n# 2) redis replicas are able to perform a partial resynchronization with the\n#    master if the replication link is lost for a relatively small amount of\n#    time. you may want to configure the replication backlog size (see the next\n#    sections of this file) with a sensible value depending on your needs.\n# 3) replication is automatic and does not need user intervention. after a\n#    network partition replicas automatically try to reconnect to masters\n#    and resynchronize with them.\n#\n# replicaof <masterip> <masterport>\n\n# if the master is password protected (using the "requirepass" configuration\n# directive below) it is possible to tell the replica to authenticate before\n# starting the replication synchronization process, otherwise the master will\n# refuse the replica request.\n#\n# masterauth <master-password>\n\n# when a replica loses its connection with the master, or when the replication\n# is still in progress, the replica can act in two different ways:\n#\n# 1) if replica-serve-stale-data is set to \'yes\' (the default) the replica will\n#    still reply to client requests, possibly with out of date data, or the\n#    data set may just be empty if this is the first synchronization.\n#\n# 2) if replica-serve-stale-data is set to \'no\' the replica will reply with\n#    an error "sync with master in progress" to all the kind of commands\n#    but to info, replicaof, auth, ping, shutdown, replconf, role, config,\n#    subscribe, unsubscribe, psubscribe, punsubscribe, publish, pubsub,\n#    command, post, host: and latency.\n#\nreplica-serve-stale-data yes\n\n# you can configure a replica instance to accept writes or not. writing against\n# a replica instance may be useful to store some ephemeral data (because data\n# written on a replica will be easily deleted after resync with the master) but\n# may also cause problems if clients are writing to it because of a\n# misconfiguration.\n#\n# since redis 2.6 by default replicas are read-only.\n#\n# note: read only replicas are not designed to be exposed to untrusted clients\n# on the internet. it\'s just a protection layer against misuse of the instance.\n# still a read only replica exports by default all the administrative commands\n# such as config, debug, and so forth. to a limited extent you can improve\n# security of read only replicas using \'rename-command\' to shadow all the\n# administrative / dangerous commands.\nreplica-read-only yes\n\n# replication sync strategy: disk or socket.\n#\n# -------------------------------------------------------\n# warning: diskless replication is experimental currently\n# -------------------------------------------------------\n#\n# new replicas and reconnecting replicas that are not able to continue the replication\n# process just receiving differences, need to do what is called a "full\n# synchronization". an rdb file is transmitted from the master to the replicas.\n# the transmission can happen in two different ways:\n#\n# 1) disk-backed: the redis master creates a new process that writes the rdb\n#                 file on disk. later the file is transferred by the parent\n#                 process to the replicas incrementally.\n# 2) diskless: the redis master creates a new process that directly writes the\n#              rdb file to replica sockets, without touching the disk at all.\n#\n# with disk-backed replication, while the rdb file is generated, more replicas\n# can be queued and served with the rdb file as soon as the current child producing\n# the rdb file finishes its work. with diskless replication instead once\n# the transfer starts, new replicas arriving will be queued and a new transfer\n# will start when the current one terminates.\n#\n# when diskless replication is used, the master waits a configurable amount of\n# time (in seconds) before starting the transfer in the hope that multiple replicas\n# will arrive and the transfer can be parallelized.\n#\n# with slow disks and fast (large bandwidth) networks, diskless replication\n# works better.\nrepl-diskless-sync no\n\n# when diskless replication is enabled, it is possible to configure the delay\n# the server waits in order to spawn the child that transfers the rdb via socket\n# to the replicas.\n#\n# this is important since once the transfer starts, it is not possible to serve\n# new replicas arriving, that will be queued for the next rdb transfer, so the server\n# waits a delay in order to let more replicas arrive.\n#\n# the delay is specified in seconds, and by default is 5 seconds. to disable\n# it entirely just set it to 0 seconds and the transfer will start asap.\nrepl-diskless-sync-delay 5\n\n# replicas send pings to server in a predefined interval. it\'s possible to change\n# this interval with the repl_ping_replica_period option. the default value is 10\n# seconds.\n#\n# repl-ping-replica-period 10\n\n# the following option sets the replication timeout for:\n#\n# 1) bulk transfer i/o during sync, from the point of view of replica.\n# 2) master timeout from the point of view of replicas (data, pings).\n# 3) replica timeout from the point of view of masters (replconf ack pings).\n#\n# it is important to make sure that this value is greater than the value\n# specified for repl-ping-replica-period otherwise a timeout will be detected\n# every time there is low traffic between the master and the replica.\n#\n# repl-timeout 60\n\n# disable tcp_nodelay on the replica socket after sync?\n#\n# if you select "yes" redis will use a smaller number of tcp packets and\n# less bandwidth to send data to replicas. but this can add a delay for\n# the data to appear on the replica side, up to 40 milliseconds with\n# linux kernels using a default configuration.\n#\n# if you select "no" the delay for data to appear on the replica side will\n# be reduced but more bandwidth will be used for replication.\n#\n# by default we optimize for low latency, but in very high traffic conditions\n# or when the master and replicas are many hops away, turning this to "yes" may\n# be a good idea.\nrepl-disable-tcp-nodelay no\n\n# set the replication backlog size. the backlog is a buffer that accumulates\n# replica data when replicas are disconnected for some time, so that when a replica\n# wants to reconnect again, often a full resync is not needed, but a partial\n# resync is enough, just passing the portion of data the replica missed while\n# disconnected.\n#\n# the bigger the replication backlog, the longer the time the replica can be\n# disconnected and later be able to perform a partial resynchronization.\n#\n# the backlog is only allocated once there is at least a replica connected.\n#\n# repl-backlog-size 1mb\n\n# after a master has no longer connected replicas for some time, the backlog\n# will be freed. the following option configures the amount of seconds that\n# need to elapse, starting from the time the last replica disconnected, for\n# the backlog buffer to be freed.\n#\n# note that replicas never free the backlog for timeout, since they may be\n# promoted to masters later, and should be able to correctly "partially\n# resynchronize" with the replicas: hence they should always accumulate backlog.\n#\n# a value of 0 means to never release the backlog.\n#\n# repl-backlog-ttl 3600\n\n# the replica priority is an integer number published by redis in the info output.\n# it is used by redis sentinel in order to select a replica to promote into a\n# master if the master is no longer working correctly.\n#\n# a replica with a low priority number is considered better for promotion, so\n# for instance if there are three replicas with priority 10, 100, 25 sentinel will\n# pick the one with priority 10, that is the lowest.\n#\n# however a special priority of 0 marks the replica as not able to perform the\n# role of master, so a replica with priority of 0 will never be selected by\n# redis sentinel for promotion.\n#\n# by default the priority is 100.\nreplica-priority 100\n\n# it is possible for a master to stop accepting writes if there are less than\n# n replicas connected, having a lag less or equal than m seconds.\n#\n# the n replicas need to be in "online" state.\n#\n# the lag in seconds, that must be <= the specified value, is calculated from\n# the last ping received from the replica, that is usually sent every second.\n#\n# this option does not guarantee that n replicas will accept the write, but\n# will limit the window of exposure for lost writes in case not enough replicas\n# are available, to the specified number of seconds.\n#\n# for example to require at least 3 replicas with a lag <= 10 seconds use:\n#\n# min-replicas-to-write 3\n# min-replicas-max-lag 10\n#\n# setting one or the other to 0 disables the feature.\n#\n# by default min-replicas-to-write is set to 0 (feature disabled) and\n# min-replicas-max-lag is set to 10.\n\n# a redis master is able to list the address and port of the attached\n# replicas in different ways. for example the "info replication" section\n# offers this information, which is used, among other tools, by\n# redis sentinel in order to discover replica instances.\n# another place where this info is available is in the output of the\n# "role" command of a master.\n#\n# the listed ip and address normally reported by a replica is obtained\n# in the following way:\n#\n#   ip: the address is auto detected by checking the peer address\n#   of the socket used by the replica to connect with the master.\n#\n#   port: the port is communicated by the replica during the replication\n#   handshake, and is normally the port that the replica is using to\n#   listen for connections.\n#\n# however when port forwarding or network address translation (nat) is\n# used, the replica may be actually reachable via different ip and port\n# pairs. the following two options can be used by a replica in order to\n# report to its master a specific set of ip and port, so that both info\n# and role will report those values.\n#\n# there is no need to use both the options if you need to override just\n# the port or the ip address.\n#\n# replica-announce-ip 5.5.5.5\n# replica-announce-port 1234\n\n################################## security ###################################\n\n# require clients to issue auth <password> before processing any other\n# commands.  this might be useful in environments in which you do not trust\n# others with access to the host running redis-server.\n#\n# this should stay commented out for backward compatibility and because most\n# people do not need auth (e.g. they run their own servers).\n#\n# warning: since redis is pretty fast an outside user can try up to\n# 150k passwords per second against a good box. this means that you should\n# use a very strong password otherwise it will be very easy to break.\n#\nrequirepass 123456\n\n# command renaming.\n#\n# it is possible to change the name of dangerous commands in a shared\n# environment. for instance the config command may be renamed into something\n# hard to guess so that it will still be available for internal-use tools\n# but not available for general clients.\n#\n# example:\n#\n# rename-command config b840fc02d524045429941cc15f59e41cb7be6c52\n#\n# it is also possible to completely kill a command by renaming it into\n# an empty string:\n#\n# rename-command config ""\n#\n# please note that changing the name of commands that are logged into the\n# aof file or transmitted to replicas may cause problems.\n\n################################### clients ####################################\n\n# set the max number of connected clients at the same time. by default\n# this limit is set to 10000 clients, however if the redis server is not\n# able to configure the process file limit to allow for the specified limit\n# the max number of allowed clients is set to the current file limit\n# minus 32 (as redis reserves a few file descriptors for internal uses).\n#\n# once the limit is reached redis will close all the new connections sending\n# an error \'max number of clients reached\'.\n#\n# maxclients 10000\n\n############################## memory management ################################\n\n# set a memory usage limit to the specified amount of bytes.\n# when the memory limit is reached redis will try to remove keys\n# according to the eviction policy selected (see maxmemory-policy).\n#\n# if redis can\'t remove keys according to the policy, or if the policy is\n# set to \'noeviction\', redis will start to reply with errors to commands\n# that would use more memory, like set, lpush, and so on, and will continue\n# to reply to read-only commands like get.\n#\n# this option is usually useful when using redis as an lru or lfu cache, or to\n# set a hard memory limit for an instance (using the \'noeviction\' policy).\n#\n# warning: if you have replicas attached to an instance with maxmemory on,\n# the size of the output buffers needed to feed the replicas are subtracted\n# from the used memory count, so that network problems / resyncs will\n# not trigger a loop where keys are evicted, and in turn the output\n# buffer of replicas is full with dels of keys evicted triggering the deletion\n# of more keys, and so forth until the database is completely emptied.\n#\n# in short... if you have replicas attached it is suggested that you set a lower\n# limit for maxmemory so that there is some free ram on the system for replica\n# output buffers (but this is not needed if the policy is \'noeviction\').\n#\n# maxmemory <bytes>\n\n# maxmemory policy: how redis will select what to remove when maxmemory\n# is reached. you can select among five behaviors:\n#\n# volatile-lru -> evict using approximated lru among the keys with an expire set.\n# allkeys-lru -> evict any key using approximated lru.\n# volatile-lfu -> evict using approximated lfu among the keys with an expire set.\n# allkeys-lfu -> evict any key using approximated lfu.\n# volatile-random -> remove a random key among the ones with an expire set.\n# allkeys-random -> remove a random key, any key.\n# volatile-ttl -> remove the key with the nearest expire time (minor ttl)\n# noeviction -> don\'t evict anything, just return an error on write operations.\n#\n# lru means least recently used\n# lfu means least frequently used\n#\n# both lru, lfu and volatile-ttl are implemented using approximated\n# randomized algorithms.\n#\n# note: with any of the above policies, redis will return an error on write\n#       operations, when there are no suitable keys for eviction.\n#\n#       at the date of writing these commands are: set setnx setex append\n#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd\n#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby\n#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby\n#       getset mset msetnx exec sort\n#\n# the default is:\n#\n# maxmemory-policy noeviction\n\n# lru, lfu and minimal ttl algorithms are not precise algorithms but approximated\n# algorithms (in order to save memory), so you can tune it for speed or\n# accuracy. for default redis will check five keys and pick the one that was\n# used less recently, you can change the sample size using the following\n# configuration directive.\n#\n# the default of 5 produces good enough results. 10 approximates very closely\n# true lru but costs more cpu. 3 is faster but not very accurate.\n#\n# maxmemory-samples 5\n\n# starting from redis 5, by default a replica will ignore its maxmemory setting\n# (unless it is promoted to master after a failover or manually). it means\n# that the eviction of keys will be just handled by the master, sending the\n# del commands to the replica as keys evict in the master side.\n#\n# this behavior ensures that masters and replicas stay consistent, and is usually\n# what you want, however if your replica is writable, or you want the replica to have\n# a different memory setting, and you are sure all the writes performed to the\n# replica are idempotent, then you may change this default (but be sure to understand\n# what you are doing).\n#\n# note that since the replica by default does not evict, it may end using more\n# memory than the one set via maxmemory (there are certain buffers that may\n# be larger on the replica, or data structures may sometimes take more memory and so\n# forth). so make sure you monitor your replicas and make sure they have enough\n# memory to never hit a real out-of-memory condition before the master hits\n# the configured maxmemory setting.\n#\n# replica-ignore-maxmemory yes\n\n############################# lazy freeing ####################################\n\n# redis has two primitives to delete keys. one is called del and is a blocking\n# deletion of the object. it means that the server stops processing new commands\n# in order to reclaim all the memory associated with an object in a synchronous\n# way. if the key deleted is associated with a small object, the time needed\n# in order to execute the del command is very small and comparable to most other\n# o(1) or o(log_n) commands in redis. however if the key is associated with an\n# aggregated value containing millions of elements, the server can block for\n# a long time (even seconds) in order to complete the operation.\n#\n# for the above reasons redis also offers non blocking deletion primitives\n# such as unlink (non blocking del) and the async option of flushall and\n# flushdb commands, in order to reclaim memory in background. those commands\n# are executed in constant time. another thread will incrementally free the\n# object in the background as fast as possible.\n#\n# del, unlink and async option of flushall and flushdb are user-controlled.\n# it\'s up to the design of the application to understand when it is a good\n# idea to use one or the other. however the redis server sometimes has to\n# delete keys or flush the whole database as a side effect of other operations.\n# specifically redis deletes objects independently of a user call in the\n# following scenarios:\n#\n# 1) on eviction, because of the maxmemory and maxmemory policy configurations,\n#    in order to make room for new data, without going over the specified\n#    memory limit.\n# 2) because of expire: when a key with an associated time to live (see the\n#    expire command) must be deleted from memory.\n# 3) because of a side effect of a command that stores data on a key that may\n#    already exist. for example the rename command may delete the old key\n#    content when it is replaced with another one. similarly sunionstore\n#    or sort with store option may delete existing keys. the set command\n#    itself removes any old content of the specified key in order to replace\n#    it with the specified string.\n# 4) during replication, when a replica performs a full resynchronization with\n#    its master, the content of the whole database is removed in order to\n#    load the rdb file just transferred.\n#\n# in all the above cases the default is to delete objects in a blocking way,\n# like if del was called. however you can configure each case specifically\n# in order to instead release memory in a non-blocking way like if unlink\n# was called, using the following configuration directives:\n\nlazyfree-lazy-eviction no\nlazyfree-lazy-expire no\nlazyfree-lazy-server-del no\nreplica-lazy-flush no\n\n############################## append only mode ###############################\n\n# by default redis asynchronously dumps the dataset on disk. this mode is\n# good enough in many applications, but an issue with the redis process or\n# a power outage may result into a few minutes of writes lost (depending on\n# the configured save points).\n#\n# the append only file is an alternative persistence mode that provides\n# much better durability. for instance using the default data fsync policy\n# (see later in the config file) redis can lose just one second of writes in a\n# dramatic event like a server power outage, or a single write if something\n# wrong with the redis process itself happens, but the operating system is\n# still running correctly.\n#\n# aof and rdb persistence can be enabled at the same time without problems.\n# if the aof is enabled on startup redis will load the aof, that is the file\n# with the better durability guarantees.\n#\n# please check http://redis.io/topics/persistence for more information.\n\nappendonly no\n\n# the name of the append only file (default: "appendonly.aof")\n\nappendfilename "appendonly.aof"\n\n# the fsync() call tells the operating system to actually write data on disk\n# instead of waiting for more data in the output buffer. some os will really flush\n# data on disk, some other os will just try to do it asap.\n#\n# redis supports three different modes:\n#\n# no: don\'t fsync, just let the os flush the data when it wants. faster.\n# always: fsync after every write to the append only log. slow, safest.\n# everysec: fsync only one time every second. compromise.\n#\n# the default is "everysec", as that\'s usually the right compromise between\n# speed and data safety. it\'s up to you to understand if you can relax this to\n# "no" that will let the operating system flush the output buffer when\n# it wants, for better performances (but if you can live with the idea of\n# some data loss consider the default persistence mode that\'s snapshotting),\n# or on the contrary, use "always" that\'s very slow but a bit safer than\n# everysec.\n#\n# more details please check the following article:\n# http://antirez.com/post/redis-persistence-demystified.html\n#\n# if unsure, use "everysec".\n\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n\n# when the aof fsync policy is set to always or everysec, and a background\n# saving process (a background save or aof log background rewriting) is\n# performing a lot of i/o against the disk, in some linux configurations\n# redis may block too long on the fsync() call. note that there is no fix for\n# this currently, as even performing fsync in a different thread will block\n# our synchronous write(2) call.\n#\n# in order to mitigate this problem it\'s possible to use the following option\n# that will prevent fsync() from being called in the main process while a\n# bgsave or bgrewriteaof is in progress.\n#\n# this means that while another child is saving, the durability of redis is\n# the same as "appendfsync none". in practical terms, this means that it is\n# possible to lose up to 30 seconds of log in the worst scenario (with the\n# default linux settings).\n#\n# if you have latency problems turn this to "yes". otherwise leave it as\n# "no" that is the safest pick from the point of view of durability.\n\nno-appendfsync-on-rewrite no\n\n# automatic rewrite of the append only file.\n# redis is able to automatically rewrite the log file implicitly calling\n# bgrewriteaof when the aof log size grows by the specified percentage.\n#\n# this is how it works: redis remembers the size of the aof file after the\n# latest rewrite (if no rewrite has happened since the restart, the size of\n# the aof at startup is used).\n#\n# this base size is compared to the current size. if the current size is\n# bigger than the specified percentage, the rewrite is triggered. also\n# you need to specify a minimal size for the aof file to be rewritten, this\n# is useful to avoid rewriting the aof file even if the percentage increase\n# is reached but it is still pretty small.\n#\n# specify a percentage of zero in order to disable the automatic aof\n# rewrite feature.\n\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n\n# an aof file may be found to be truncated at the end during the redis\n# startup process, when the aof data gets loaded back into memory.\n# this may happen when the system where redis is running\n# crashes, especially when an ext4 filesystem is mounted without the\n# data=ordered option (however this can\'t happen when redis itself\n# crashes or aborts but the operating system still works correctly).\n#\n# redis can either exit with an error when this happens, or load as much\n# data as possible (the default now) and start if the aof file is found\n# to be truncated at the end. the following option controls this behavior.\n#\n# if aof-load-truncated is set to yes, a truncated aof file is loaded and\n# the redis server starts emitting a log to inform the user of the event.\n# otherwise if the option is set to no, the server aborts with an error\n# and refuses to start. when the option is set to no, the user requires\n# to fix the aof file using the "redis-check-aof" utility before to restart\n# the server.\n#\n# note that if the aof file will be found to be corrupted in the middle\n# the server will still exit with an error. this option only applies when\n# redis will try to read more data from the aof file but not enough bytes\n# will be found.\naof-load-truncated yes\n\n# when rewriting the aof file, redis is able to use an rdb preamble in the\n# aof file for faster rewrites and recoveries. when this option is turned\n# on the rewritten aof file is composed of two different stanzas:\n#\n#   [rdb file][aof tail]\n#\n# when loading redis recognizes that the aof file starts with the "redis"\n# string and loads the prefixed rdb file, and continues loading the aof\n# tail.\naof-use-rdb-preamble yes\n\n################################ lua scripting  ###############################\n\n# max execution time of a lua script in milliseconds.\n#\n# if the maximum execution time is reached redis will log that a script is\n# still in execution after the maximum allowed time and will start to\n# reply to queries with an error.\n#\n# when a long running script exceeds the maximum execution time only the\n# script kill and shutdown nosave commands are available. the first can be\n# used to stop a script that did not yet called write commands. the second\n# is the only way to shut down the server in the case a write command was\n# already issued by the script but the user doesn\'t want to wait for the natural\n# termination of the script.\n#\n# set it to 0 or a negative value for unlimited execution without warnings.\nlua-time-limit 5000\n\n################################ redis cluster  ###############################\n\n# normal redis instances can\'t be part of a redis cluster; only nodes that are\n# started as cluster nodes can. in order to start a redis instance as a\n# cluster node enable the cluster support uncommenting the following:\n#\n# cluster-enabled yes\n\n# every cluster node has a cluster configuration file. this file is not\n# intended to be edited by hand. it is created and updated by redis nodes.\n# every redis cluster node requires a different cluster configuration file.\n# make sure that instances running in the same system do not have\n# overlapping cluster configuration file names.\n#\n# cluster-config-file nodes-6379.conf\n\n# cluster node timeout is the amount of milliseconds a node must be unreachable\n# for it to be considered in failure state.\n# most other internal time limits are multiple of the node timeout.\n#\n# cluster-node-timeout 15000\n\n# a replica of a failing master will avoid to start a failover if its data\n# looks too old.\n#\n# there is no simple way for a replica to actually have an exact measure of\n# its "data age", so the following two checks are performed:\n#\n# 1) if there are multiple replicas able to failover, they exchange messages\n#    in order to try to give an advantage to the replica with the best\n#    replication offset (more data from the master processed).\n#    replicas will try to get their rank by offset, and apply to the start\n#    of the failover a delay proportional to their rank.\n#\n# 2) every single replica computes the time of the last interaction with\n#    its master. this can be the last ping or command received (if the master\n#    is still in the "connected" state), or the time that elapsed since the\n#    disconnection with the master (if the replication link is currently down).\n#    if the last interaction is too old, the replica will not try to failover\n#    at all.\n#\n# the point "2" can be tuned by user. specifically a replica will not perform\n# the failover if, since the last interaction with the master, the time\n# elapsed is greater than:\n#\n#   (node-timeout * replica-validity-factor) + repl-ping-replica-period\n#\n# so for example if node-timeout is 30 seconds, and the replica-validity-factor\n# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the\n# replica will not try to failover if it was not able to talk with the master\n# for longer than 310 seconds.\n#\n# a large replica-validity-factor may allow replicas with too old data to failover\n# a master, while a too small value may prevent the cluster from being able to\n# elect a replica at all.\n#\n# for maximum availability, it is possible to set the replica-validity-factor\n# to a value of 0, which means, that replicas will always try to failover the\n# master regardless of the last time they interacted with the master.\n# (however they\'ll always try to apply a delay proportional to their\n# offset rank).\n#\n# zero is the only value able to guarantee that when all the partitions heal\n# the cluster will always be able to continue.\n#\n# cluster-replica-validity-factor 10\n\n# cluster replicas are able to migrate to orphaned masters, that are masters\n# that are left without working replicas. this improves the cluster ability\n# to resist to failures as otherwise an orphaned master can\'t be failed over\n# in case of failure if it has no working replicas.\n#\n# replicas migrate to orphaned masters only if there are still at least a\n# given number of other working replicas for their old master. this number\n# is the "migration barrier". a migration barrier of 1 means that a replica\n# will migrate only if there is at least 1 other working replica for its master\n# and so forth. it usually reflects the number of replicas you want for every\n# master in your cluster.\n#\n# default is 1 (replicas migrate only if their masters remain with at least\n# one replica). to disable migration just set it to a very large value.\n# a value of 0 can be set but is useful only for debugging and dangerous\n# in production.\n#\n# cluster-migration-barrier 1\n\n# by default redis cluster nodes stop accepting queries if they detect there\n# is at least an hash slot uncovered (no available node is serving it).\n# this way if the cluster is partially down (for example a range of hash slots\n# are no longer covered) all the cluster becomes, eventually, unavailable.\n# it automatically returns available as soon as all the slots are covered again.\n#\n# however sometimes you want the subset of the cluster which is working,\n# to continue to accept queries for the part of the key space that is still\n# covered. in order to do so, just set the cluster-require-full-coverage\n# option to no.\n#\n# cluster-require-full-coverage yes\n\n# this option, when set to yes, prevents replicas from trying to failover its\n# master during master failures. however the master can still perform a\n# manual failover, if forced to do so.\n#\n# this is useful in different scenarios, especially in the case of multiple\n# data center operations, where we want one side to never be promoted if not\n# in the case of a total dc failure.\n#\n# cluster-replica-no-failover no\n\n# in order to setup your cluster make sure to read the documentation\n# available at http://redis.io web site.\n\n########################## cluster docker/nat support  ########################\n\n# in certain deployments, redis cluster nodes address discovery fails, because\n# addresses are nat-ted or because ports are forwarded (the typical case is\n# docker and other containers).\n#\n# in order to make redis cluster working in such environments, a static\n# configuration where each node knows its public address is needed. the\n# following two options are used for this scope, and are:\n#\n# * cluster-announce-ip\n# * cluster-announce-port\n# * cluster-announce-bus-port\n#\n# each instruct the node about its address, client port, and cluster message\n# bus port. the information is then published in the header of the bus packets\n# so that other nodes will be able to correctly map the address of the node\n# publishing the information.\n#\n# if the above options are not used, the normal redis cluster auto-detection\n# will be used instead.\n#\n# note that when remapped, the bus port may not be at the fixed offset of\n# clients port + 10000, so you can specify any port and bus-port depending\n# on how they get remapped. if the bus-port is not set, a fixed offset of\n# 10000 will be used as usually.\n#\n# example:\n#\n# cluster-announce-ip 10.1.1.5\n# cluster-announce-port 6379\n# cluster-announce-bus-port 6380\n\n################################## slow log ###################################\n\n# the redis slow log is a system to log queries that exceeded a specified\n# execution time. the execution time does not include the i/o operations\n# like talking with the client, sending the reply and so forth,\n# but just the time needed to actually execute the command (this is the only\n# stage of command execution where the thread is blocked and can not serve\n# other requests in the meantime).\n#\n# you can configure the slow log with two parameters: one tells redis\n# what is the execution time, in microseconds, to exceed in order for the\n# command to get logged, and the other parameter is the length of the\n# slow log. when a new command is logged the oldest one is removed from the\n# queue of logged commands.\n\n# the following time is expressed in microseconds, so 1000000 is equivalent\n# to one second. note that a negative number disables the slow log, while\n# a value of zero forces the logging of every command.\nslowlog-log-slower-than 10000\n\n# there is no limit to this length. just be aware that it will consume memory.\n# you can reclaim memory used by the slow log with slowlog reset.\nslowlog-max-len 128\n\n################################ latency monitor ##############################\n\n# the redis latency monitoring subsystem samples different operations\n# at runtime in order to collect data related to possible sources of\n# latency of a redis instance.\n#\n# via the latency command this information is available to the user that can\n# print graphs and obtain reports.\n#\n# the system only logs operations that were performed in a time equal or\n# greater than the amount of milliseconds specified via the\n# latency-monitor-threshold configuration directive. when its value is set\n# to zero, the latency monitor is turned off.\n#\n# by default latency monitoring is disabled since it is mostly not needed\n# if you don\'t have latency issues, and collecting data has a performance\n# impact, that while very small, can be measured under big load. latency\n# monitoring can easily be enabled at runtime using the command\n# "config set latency-monitor-threshold <milliseconds>" if needed.\nlatency-monitor-threshold 0\n\n############################# event notification ##############################\n\n# redis can notify pub/sub clients about events happening in the key space.\n# this feature is documented at http://redis.io/topics/notifications\n#\n# for instance if keyspace events notification is enabled, and a client\n# performs a del operation on key "foo" stored in the database 0, two\n# messages will be published via pub/sub:\n#\n# publish __keyspace@0__:foo del\n# publish __keyevent@0__:del foo\n#\n# it is possible to select the events that redis will notify among a set\n# of classes. every class is identified by a single character:\n#\n#  k     keyspace events, published with __keyspace@<db>__ prefix.\n#  e     keyevent events, published with __keyevent@<db>__ prefix.\n#  g     generic commands (non-type specific) like del, expire, rename, ...\n#  $     string commands\n#  l     list commands\n#  s     set commands\n#  h     hash commands\n#  z     sorted set commands\n#  x     expired events (events generated every time a key expires)\n#  e     evicted events (events generated when a key is evicted for maxmemory)\n#  a     alias for g$lshzxe, so that the "ake" string means all the events.\n#\n#  the "notify-keyspace-events" takes as argument a string that is composed\n#  of zero or multiple characters. the empty string means that notifications\n#  are disabled.\n#\n#  example: to enable list and generic events, from the point of view of the\n#           event name, use:\n#\n#  notify-keyspace-events elg\n#\n#  example 2: to get the stream of the expired keys subscribing to channel\n#             name __keyevent@0__:expired use:\n#\n#  notify-keyspace-events ex\n#\n#  by default all notifications are disabled because most users don\'t need\n#  this feature and the feature has some overhead. note that if you don\'t\n#  specify at least one of k or e, no events will be delivered.\nnotify-keyspace-events ""\n\n############################### advanced config ###############################\n\n# hashes are encoded using a memory efficient data structure when they have a\n# small number of entries, and the biggest entry does not exceed a given\n# threshold. these thresholds can be configured using the following directives.\nhash-max-ziplist-entries 512\nhash-max-ziplist-value 64\n\n# lists are also encoded in a special way to save a lot of space.\n# the number of entries allowed per internal list node can be specified\n# as a fixed maximum size or a maximum number of elements.\n# for a fixed maximum size, use -5 through -1, meaning:\n# -5: max size: 64 kb  <-- not recommended for normal workloads\n# -4: max size: 32 kb  <-- not recommended\n# -3: max size: 16 kb  <-- probably not recommended\n# -2: max size: 8 kb   <-- good\n# -1: max size: 4 kb   <-- good\n# positive numbers mean store up to _exactly_ that number of elements\n# per list node.\n# the highest performing option is usually -2 (8 kb size) or -1 (4 kb size),\n# but if your use case is unique, adjust the settings as necessary.\nlist-max-ziplist-size -2\n\n# lists may also be compressed.\n# compress depth is the number of quicklist ziplist nodes from *each* side of\n# the list to *exclude* from compression.  the head and tail of the list\n# are always uncompressed for fast push/pop operations.  settings are:\n# 0: disable all list compression\n# 1: depth 1 means "don\'t start compressing until after 1 node into the list,\n#    going from either the head or tail"\n#    so: [head]->node->node->...->node->[tail]\n#    [head], [tail] will always be uncompressed; inner nodes will compress.\n# 2: [head]->[next]->node->node->...->node->[prev]->[tail]\n#    2 here means: don\'t compress head or head->next or tail->prev or tail,\n#    but compress all nodes between them.\n# 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail]\n# etc.\nlist-compress-depth 0\n\n# sets have a special encoding in just one case: when a set is composed\n# of just strings that happen to be integers in radix 10 in the range\n# of 64 bit signed integers.\n# the following configuration setting sets the limit in the size of the\n# set in order to use this special memory saving encoding.\nset-max-intset-entries 512\n\n# similarly to hashes and lists, sorted sets are also specially encoded in\n# order to save a lot of space. this encoding is only used when the length and\n# elements of a sorted set are below the following limits:\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\n\n# hyperloglog sparse representation bytes limit. the limit includes the\n# 16 bytes header. when an hyperloglog using the sparse representation crosses\n# this limit, it is converted into the dense representation.\n#\n# a value greater than 16000 is totally useless, since at that point the\n# dense representation is more memory efficient.\n#\n# the suggested value is ~ 3000 in order to have the benefits of\n# the space efficient encoding without slowing down too much pfadd,\n# which is o(n) with the sparse encoding. the value can be raised to\n# ~ 10000 when cpu is not a concern, but space is, and the data set is\n# composed of many hyperloglogs with cardinality in the 0 - 15000 range.\nhll-sparse-max-bytes 3000\n\n# streams macro node max size / items. the stream data structure is a radix\n# tree of big nodes that encode multiple items inside. using this configuration\n# it is possible to configure how big a single node can be in bytes, and the\n# maximum number of items it may contain before switching to a new node when\n# appending new stream entries. if any of the following settings are set to\n# zero, the limit is ignored, so for instance it is possible to set just a\n# max entires limit by setting max-bytes to 0 and max-entries to the desired\n# value.\nstream-node-max-bytes 4096\nstream-node-max-entries 100\n\n# active rehashing uses 1 millisecond every 100 milliseconds of cpu time in\n# order to help rehashing the main redis hash table (the one mapping top-level\n# keys to values). the hash table implementation redis uses (see dict.c)\n# performs a lazy rehashing: the more operation you run into a hash table\n# that is rehashing, the more rehashing "steps" are performed, so if the\n# server is idle the rehashing is never complete and some more memory is used\n# by the hash table.\n#\n# the default is to use this millisecond 10 times every second in order to\n# actively rehash the main dictionaries, freeing memory when possible.\n#\n# if unsure:\n# use "activerehashing no" if you have hard latency requirements and it is\n# not a good thing in your environment that redis can reply from time to time\n# to queries with 2 milliseconds delay.\n#\n# use "activerehashing yes" if you don\'t have such hard requirements but\n# want to free memory asap when possible.\nactiverehashing yes\n\n# the client output buffer limits can be used to force disconnection of clients\n# that are not reading data from the server fast enough for some reason (a\n# common reason is that a pub/sub client can\'t consume messages as fast as the\n# publisher can produce them).\n#\n# the limit can be set differently for the three different classes of clients:\n#\n# normal -> normal clients including monitor clients\n# replica  -> replica clients\n# pubsub -> clients subscribed to at least one pubsub channel or pattern\n#\n# the syntax of every client-output-buffer-limit directive is the following:\n#\n# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>\n#\n# a client is immediately disconnected once the hard limit is reached, or if\n# the soft limit is reached and remains reached for the specified number of\n# seconds (continuously).\n# so for instance if the hard limit is 32 megabytes and the soft limit is\n# 16 megabytes / 10 seconds, the client will get disconnected immediately\n# if the size of the output buffers reach 32 megabytes, but will also get\n# disconnected if the client reaches 16 megabytes and continuously overcomes\n# the limit for 10 seconds.\n#\n# by default normal clients are not limited because they don\'t receive data\n# without asking (in a push way), but just after a request, so only\n# asynchronous clients may create a scenario where data is requested faster\n# than it can read.\n#\n# instead there is a default limit for pubsub and replica clients, since\n# subscribers and replicas receive data in a push fashion.\n#\n# both the hard or the soft limit can be disabled by setting them to zero.\nclient-output-buffer-limit normal 0 0 0\nclient-output-buffer-limit replica 256mb 64mb 60\nclient-output-buffer-limit pubsub 32mb 8mb 60\n\n# client query buffers accumulate new commands. they are limited to a fixed\n# amount by default in order to avoid that a protocol desynchronization (for\n# instance due to a bug in the client) will lead to unbound memory usage in\n# the query buffer. however you can configure it here if you have very special\n# needs, such us huge multi/exec requests or alike.\n#\n# client-query-buffer-limit 1gb\n\n# in the redis protocol, bulk requests, that are, elements representing single\n# strings, are normally limited ot 512 mb. however you can change this limit\n# here.\n#\n# proto-max-bulk-len 512mb\n\n# redis calls an internal function to perform many background tasks, like\n# closing connections of clients in timeout, purging expired keys that are\n# never requested, and so forth.\n#\n# not all tasks are performed with the same frequency, but redis checks for\n# tasks to perform according to the specified "hz" value.\n#\n# by default "hz" is set to 10. raising the value will use more cpu when\n# redis is idle, but at the same time will make redis more responsive when\n# there are many keys expiring at the same time, and timeouts may be\n# handled with more precision.\n#\n# the range is between 1 and 500, however a value over 100 is usually not\n# a good idea. most users should use the default of 10 and raise this up to\n# 100 only in environments where very low latency is required.\nhz 10\n\n# normally it is useful to have an hz value which is proportional to the\n# number of clients connected. this is useful in order, for instance, to\n# avoid too many clients are processed for each background task invocation\n# in order to avoid latency spikes.\n#\n# since the default hz value by default is conservatively set to 10, redis\n# offers, and enables by default, the ability to use an adaptive hz value\n# which will temporary raise when there are many connected clients.\n#\n# when dynamic hz is enabled, the actual configured hz will be used as\n# as a baseline, but multiples of the configured hz value will be actually\n# used as needed once more clients are connected. in this way an idle\n# instance will use very little cpu time while a busy instance will be\n# more responsive.\ndynamic-hz yes\n\n# when a child rewrites the aof file, if the following option is enabled\n# the file will be fsync-ed every 32 mb of data generated. this is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\naof-rewrite-incremental-fsync yes\n\n# when redis saves rdb file, if the following option is enabled\n# the file will be fsync-ed every 32 mb of data generated. this is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\nrdb-save-incremental-fsync yes\n\n# redis lfu eviction (see maxmemory setting) can be tuned. however it is a good\n# idea to start with the default settings and only change them after investigating\n# how to improve the performances and how the keys lfu change over time, which\n# is possible to inspect via the object freq command.\n#\n# there are two tunable parameters in the redis lfu implementation: the\n# counter logarithm factor and the counter decay time. it is important to\n# understand what the two parameters mean before changing them.\n#\n# the lfu counter is just 8 bits per key, it\'s maximum value is 255, so redis\n# uses a probabilistic increment with logarithmic behavior. given the value\n# of the old counter, when a key is accessed, the counter is incremented in\n# this way:\n#\n# 1. a random number r between 0 and 1 is extracted.\n# 2. a probability p is calculated as 1/(old_value*lfu_log_factor+1).\n# 3. the counter is incremented only if r < p.\n#\n# the default lfu-log-factor is 10. this is a table of how the frequency\n# counter changes with a different number of accesses with different\n# logarithmic factors:\n#\n# +--------+------------+------------+------------+------------+------------+\n# | factor | 100 hits   | 1000 hits  | 100k hits  | 1m hits    | 10m hits   |\n# +--------+------------+------------+------------+------------+------------+\n# | 0      | 104        | 255        | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 1      | 18         | 49         | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 10     | 10         | 18         | 142        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 100    | 8          | 11         | 49         | 143        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n#\n# note: the above table was obtained by running the following commands:\n#\n#   redis-benchmark -n 1000000 incr foo\n#   redis-cli object freq foo\n#\n# note 2: the counter initial value is 5 in order to give new objects a chance\n# to accumulate hits.\n#\n# the counter decay time is the time, in minutes, that must elapse in order\n# for the key counter to be divided by two (or decremented if it has a value\n# less <= 10).\n#\n# the default value for the lfu-decay-time is 1. a special value of 0 means to\n# decay the counter every time it happens to be scanned.\n#\n# lfu-log-factor 10\n# lfu-decay-time 1\n\n########################### active defragmentation #######################\n#\n# warning this feature is experimental. however it was stress tested\n# even in production and manually tested by multiple engineers for some\n# time.\n#\n# what is active defragmentation?\n# -------------------------------\n#\n# active (online) defragmentation allows a redis server to compact the\n# spaces left between small allocations and deallocations of data in memory,\n# thus allowing to reclaim back memory.\n#\n# fragmentation is a natural process that happens with every allocator (but\n# less so with jemalloc, fortunately) and certain workloads. normally a server\n# restart is needed in order to lower the fragmentation, or at least to flush\n# away all the data and create it again. however thanks to this feature\n# implemented by oran agra for redis 4.0 this process can happen at runtime\n# in an "hot" way, while the server is running.\n#\n# basically when the fragmentation is over a certain level (see the\n# configuration options below) redis will start to create new copies of the\n# values in contiguous memory regions by exploiting certain specific jemalloc\n# features (in order to understand if an allocation is causing fragmentation\n# and to allocate it in a better place), and at the same time, will release the\n# old copies of the data. this process, repeated incrementally for all the keys\n# will cause the fragmentation to drop back to normal values.\n#\n# important things to understand:\n#\n# 1. this feature is disabled by default, and only works if you compiled redis\n#    to use the copy of jemalloc we ship with the source code of redis.\n#    this is the default with linux builds.\n#\n# 2. you never need to enable this feature if you don\'t have fragmentation\n#    issues.\n#\n# 3. once you experience fragmentation, you can enable this feature when\n#    needed with the command "config set activedefrag yes".\n#\n# the configuration parameters are able to fine tune the behavior of the\n# defragmentation process. if you are not sure about what they mean it is\n# a good idea to leave the defaults untouched.\n\n# enabled active defragmentation\n# activedefrag yes\n\n# minimum amount of fragmentation waste to start active defrag\n# active-defrag-ignore-bytes 100mb\n\n# minimum percentage of fragmentation to start active defrag\n# active-defrag-threshold-lower 10\n\n# maximum percentage of fragmentation at which we use maximum effort\n# active-defrag-threshold-upper 100\n\n# minimal effort for defrag in cpu percentage\n# active-defrag-cycle-min 5\n\n# maximal effort for defrag in cpu percentage\n# active-defrag-cycle-max 75\n\n# maximum number of set/hash/zset/list fields that will be processed from\n# the main dictionary scan\n# active-defrag-max-scan-fields 1000\n\n# it is possible to pin different threads and processes of redis to specific\n# cpus in your system, in order to maximize the performances of the server.\n# this is useful both in order to pin different redis threads in different\n# cpus, but also in order to make sure that multiple redis instances running\n# in the same host will be pinned to different cpus.\n#\n# normally you can do this using the "taskset" command, however it is also\n# possible to this via redis configuration directly, both in linux and freebsd.\n#\n# you can pin the server/io threads, bio threads, aof rewrite child process, and\n# the bgsave child process. the syntax to specify the cpu list is the same as\n# the taskset command:\n#\n# set redis server/io threads to cpu affinity 0,2,4,6:\n# server_cpulist 0-7:2\n#\n# set bio threads to cpu affinity 1,3:\n# bio_cpulist 1,3\n#\n# set aof rewrite child process to cpu affinity 8,9,10,11:\n# aof_rewrite_cpulist 8-11\n#\n# set bgsave child process to cpu affinity 1,10,11\n# bgsave_cpulist 1,10-11\n\n# in some cases redis will emit warnings and even refuse to start if it detects\n# that the system is in bad state, it is possible to suppress these warnings\n# by setting the following config which takes a space delimited list of warnings\n# to suppress\n#\n# ignore-warnings arm64-cow-bug\n\n\n\n\n# deploy.sh\n\nmkdir -p /etc/redis/\n\n\\cp ./redis.conf /etc/redis/redis.conf\ndocker-compose up -d\n',charsets:{cjk:!0},lastUpdated:"2023/09/11, 15:56:39",lastUpdatedTimestamp:1694418999e3},{title:"CentOS7调整磁盘分区",frontmatter:{title:"CentOS7调整磁盘分区",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/2cbf35/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/02.CentOS7%E8%B0%83%E6%95%B4%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA.html",relativePath:"05.工具&部署/02.Linux/02.CentOS7调整磁盘分区.md",key:"v-a0880f96",path:"/pages/2cbf35/",headers:[{level:2,title:"对磁盘进行扩容",slug:"对磁盘进行扩容",normalizedTitle:"对磁盘进行扩容",charIndex:20},{level:2,title:"磁盘分区错误",slug:"磁盘分区错误",normalizedTitle:"磁盘分区错误",charIndex:635},{level:2,title:"创建/home分区",slug:"创建-home分区",normalizedTitle:"创建/home分区",charIndex:1170},{level:2,title:"新增磁盘挂载扩容",slug:"新增磁盘挂载扩容",normalizedTitle:"新增磁盘挂载扩容",charIndex:1376}],headersStr:"对磁盘进行扩容 磁盘分区错误 创建/home分区 新增磁盘挂载扩容",content:"# CentOS7调整磁盘分区\n\n\n# 对磁盘进行扩容\n\n当磁盘空间不足时，需要对磁盘进行扩容。可以在虚拟机选项中直接增加磁盘大小，比如增加100G到300G。\n\n\n\n使用fdisk /dev/sda命令对新加磁盘空间进行分区，先输入m查看帮助。\n\n\n\n输入n选择增加新分区，输入p选择分区格式为主分区。然后直接按两次回车使用默认的起始扇区和结束扇区，这样能充分利用全部扇区。操作后提示100G分区已添加。输入w进行提交操作\n\n\n\n使用fdisk -l查看多出来一个/dev/sda3的磁盘。\n\n\n\n使用partprobe命令用于重读分区表,将磁盘分区表变化信息通知内核,请求操作系统重新加载分区表\n\n使用命令pvcreate /dev/sda3创建物理卷\n\n\n\n使用vgscan查询物理卷，可以查到本机物理卷名称为cl，然后使用vgextend扩展物理卷cl，键入命令vgextend cl /dev/sda3。\n\n\n\n再使用lvextend扩展逻辑卷，命令：lvextend -L +100G /dev/mapper/cl-root。\n\n接着用df -h查看，发现实际容量并没有变化，因为系统还不认识刚添加进来的磁盘文件系统，所以还需要使用xfs_growfs对文件系统进行扩容。命令：\n\nxfs_growfs /dev/mapper/cl-root\n\n\n或者使用resize2fs –f加上要扩展的分区名。\n\n\n\n再使用df -h查看，分区扩展成功。\n\n\n\n\n# 磁盘分区错误\n\n新建虚拟机时，给虚拟机本身分配有200G磁盘空间。\n\n\n\n在分区时，模拟错误分区，对系统的默认分区不作调整。此时/目录只有50G，而/home分区有141GB。\n\n\n\n进入系统后，使用df -h命令查看分区和磁盘使用情况。此时/home目录的磁盘空间需要移除，全部分给/root目录（也就是cl-root）。\n\n\n\n使用fdisk -l查看物理磁盘挂载情况。\n\n\n\n调整分区前正常是要备份数据的，可参考如下操作。但是新装系统没有什么数据的情况，可以不要数据，直接操作。\n\n\n\n卸载/home。\n\n如果/home存在进程，需要使用fuser -m -v -I -k /home终止/home下的进程，然后再使用umount卸载/home。\n\n\n\n然后删除/home所在的lv。\n\nlvremove /dev/mapper/cl-home\n\n\n使用lvextend扩展逻辑卷/root，增加141G（如果增加空间超过可用大小，会报错）。\n\nlvextend -L +141G /dev/mapper/cl-root\n\n\n\n\n使用xfs_growfs对文件系统/root进行扩容。\n\nxfs_growfs /dev/mapper/cl-root\n\n\n\n\n\n# 创建/home分区\n\n如果某些特定场景，需要使用/home分区，而开始没有划分，则可以参照下文进行添加。\n\n使用vgdisplay命令查看剩余分区大小，然后创建一个逻辑卷“home”。\n\n\n\n此时使用fdisk -l已经可以看到新的分区。\n\n\n\n然后使用mkfs.xfs命令格式化分区，分区类型为xfs。\n\n\n\n最后使用mount进行挂载，挂载位置为/home。再使用df -h进行查看，挂载成功。\n\n\n\n\n# 新增磁盘挂载扩容\n\n实际使用中，也有可能当前存储用完了，需要新增其他分区，那么要使用添加硬盘，新增一块硬盘来处理。如下图，新增一块100G硬盘。\n\n\n\n系统中使用fdisk -l查看，多了一块100G的sdb。\n\n\n\n此时并不能直接使用，要使用fdisk进行分区。和前面类似，使用fdisk /dev/sdb对新硬盘进行分区。键入n创建分区，选择p分区类型为主分区，两次回车，最后w写入分区。\n\n\n\n还是一样，使用partprobe通知系统分区表的变化，再使用pvcreate创建物理卷。使用vgscan查询物理卷，然后使用vgextend新增物理卷扩展cl。使用lvextend扩展逻辑卷，最后使用xfs_growfs对文件系统进行扩容。再使用df -h查看，分区扩展成功。\n\n",normalizedContent:"# centos7调整磁盘分区\n\n\n# 对磁盘进行扩容\n\n当磁盘空间不足时，需要对磁盘进行扩容。可以在虚拟机选项中直接增加磁盘大小，比如增加100g到300g。\n\n\n\n使用fdisk /dev/sda命令对新加磁盘空间进行分区，先输入m查看帮助。\n\n\n\n输入n选择增加新分区，输入p选择分区格式为主分区。然后直接按两次回车使用默认的起始扇区和结束扇区，这样能充分利用全部扇区。操作后提示100g分区已添加。输入w进行提交操作\n\n\n\n使用fdisk -l查看多出来一个/dev/sda3的磁盘。\n\n\n\n使用partprobe命令用于重读分区表,将磁盘分区表变化信息通知内核,请求操作系统重新加载分区表\n\n使用命令pvcreate /dev/sda3创建物理卷\n\n\n\n使用vgscan查询物理卷，可以查到本机物理卷名称为cl，然后使用vgextend扩展物理卷cl，键入命令vgextend cl /dev/sda3。\n\n\n\n再使用lvextend扩展逻辑卷，命令：lvextend -l +100g /dev/mapper/cl-root。\n\n接着用df -h查看，发现实际容量并没有变化，因为系统还不认识刚添加进来的磁盘文件系统，所以还需要使用xfs_growfs对文件系统进行扩容。命令：\n\nxfs_growfs /dev/mapper/cl-root\n\n\n或者使用resize2fs –f加上要扩展的分区名。\n\n\n\n再使用df -h查看，分区扩展成功。\n\n\n\n\n# 磁盘分区错误\n\n新建虚拟机时，给虚拟机本身分配有200g磁盘空间。\n\n\n\n在分区时，模拟错误分区，对系统的默认分区不作调整。此时/目录只有50g，而/home分区有141gb。\n\n\n\n进入系统后，使用df -h命令查看分区和磁盘使用情况。此时/home目录的磁盘空间需要移除，全部分给/root目录（也就是cl-root）。\n\n\n\n使用fdisk -l查看物理磁盘挂载情况。\n\n\n\n调整分区前正常是要备份数据的，可参考如下操作。但是新装系统没有什么数据的情况，可以不要数据，直接操作。\n\n\n\n卸载/home。\n\n如果/home存在进程，需要使用fuser -m -v -i -k /home终止/home下的进程，然后再使用umount卸载/home。\n\n\n\n然后删除/home所在的lv。\n\nlvremove /dev/mapper/cl-home\n\n\n使用lvextend扩展逻辑卷/root，增加141g（如果增加空间超过可用大小，会报错）。\n\nlvextend -l +141g /dev/mapper/cl-root\n\n\n\n\n使用xfs_growfs对文件系统/root进行扩容。\n\nxfs_growfs /dev/mapper/cl-root\n\n\n\n\n\n# 创建/home分区\n\n如果某些特定场景，需要使用/home分区，而开始没有划分，则可以参照下文进行添加。\n\n使用vgdisplay命令查看剩余分区大小，然后创建一个逻辑卷“home”。\n\n\n\n此时使用fdisk -l已经可以看到新的分区。\n\n\n\n然后使用mkfs.xfs命令格式化分区，分区类型为xfs。\n\n\n\n最后使用mount进行挂载，挂载位置为/home。再使用df -h进行查看，挂载成功。\n\n\n\n\n# 新增磁盘挂载扩容\n\n实际使用中，也有可能当前存储用完了，需要新增其他分区，那么要使用添加硬盘，新增一块硬盘来处理。如下图，新增一块100g硬盘。\n\n\n\n系统中使用fdisk -l查看，多了一块100g的sdb。\n\n\n\n此时并不能直接使用，要使用fdisk进行分区。和前面类似，使用fdisk /dev/sdb对新硬盘进行分区。键入n创建分区，选择p分区类型为主分区，两次回车，最后w写入分区。\n\n\n\n还是一样，使用partprobe通知系统分区表的变化，再使用pvcreate创建物理卷。使用vgscan查询物理卷，然后使用vgextend新增物理卷扩展cl。使用lvextend扩展逻辑卷，最后使用xfs_growfs对文件系统进行扩容。再使用df -h查看，分区扩展成功。\n\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"IO压测",frontmatter:{title:"IO压测",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/42cda4/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/03.IO%E5%8E%8B%E6%B5%8B.html",relativePath:"05.工具&部署/02.Linux/03.IO压测.md",key:"v-6592916c",path:"/pages/42cda4/",headers:[{level:2,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:20},{level:2,title:"参数解释",slug:"参数解释",normalizedTitle:"参数解释",charIndex:142},{level:2,title:"fio测试场景",slug:"fio测试场景",normalizedTitle:"fio测试场景",charIndex:754},{level:2,title:"结果说明",slug:"结果说明",normalizedTitle:"结果说明",charIndex:1818}],headersStr:"安装 参数解释 fio测试场景 结果说明",content:"# Linux下磁盘I/O测试\n\n\n# 安装\n\n * 方法一：[推荐] 在Linux系统下通过yum安装，yum install -y fio\n\n * 方法二：在fio官网下载fio-2.1.10.tar文件，解压后./configure、make、make install\n\n\n# 参数解释\n\nfilename=/dev/emcpowerb　支持文件系统或者裸设备，-filename=/dev/sda2或-filename=/dev/sdb\ndirect=1 测试过程绕过机器自带的buffer，使测试结果更真实\nrw=randwread 测试随机读的I/O\nrw=randwrite 测试随机写的I/O\nrw=randrw 测试随机混合写和读的I/O\nrw=read 测试顺序读的I/O\nrw=write 测试顺序写的I/O\nrw=rw 测试顺序混合写和读的I/O\nbs=4k 单次io的块文件大小为4k\nbsrange=512-2048 同上，提定数据块的大小范围\nsize=5g 本次的测试文件大小为5g，以每次4k的io进行测试\nnumjobs=30 本次的测试线程为30\nruntime=1000 测试时间为1000秒，如果不写则一直将5g文件分4k每次写完为止\nioengine=psync io引擎使用pync方式，如果要使用libaio引擎，需要yum install libaio-devel包\nrwmixwrite=30 在混合读写的模式下，写占30%\ngroup_reporting 关于显示结果的，汇总每个进程的信息\n\n此外\nlockmem=1g 只使用1g内存进行测试\nzero_buffers 用0初始化系统buffer\nnrfiles=8 每个进程生成文件的数量\n\n\n\n# fio测试场景\n\n> /dev/emcpowerb的地址为fdisk -l获得。部分机器为：/dev/sda、/dev/sda1、/dev/sda2、/dev/sda3\n\n * 100%随机，100%读， 4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=rand_100read_4k\n\n\n * 100%随机，100%写， 4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=rand_100write_4k\n\n\n * 100%顺序，100%读 ，4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=sqe_100read_4k\n\n\n * 100%顺序，100%写 ，4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=sqe_100write_4k\n\n\n * 100%随机，70%读，30%写 4K\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randrw -rwmixread=70 -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=randrw_70read_4k\n\n\n\n# 结果说明\n\nio=执行了多少M的IO\n\nbw=平均IO带宽\niops=IOPS\nrunt=线程运行时间\nslat=提交延迟\nclat=完成延迟\nlat=响应时间\nbw=带宽\ncpu=利用率\nIO depths=io队列\nIO submit=单个IO提交要提交的IO数\nIO complete=Like the above submit number, but for completions instead.\nIO issued=The number of read/write requests issued, and how many of them were short.\nIO latencies=IO完延迟的分布\n\nio=总共执行了多少size的IO\naggrb=group总带宽\nminb=最小.平均带宽.\nmaxb=最大平均带宽.\nmint=group中线程的最短运行时间.\nmaxt=group中线程的最长运行时间.\n\nios=所有group总共执行的IO数.\nmerge=总共发生的IO合并数.\nticks=Number of ticks we kept the disk busy.\nio_queue=花费在队列上的总共时间.\nutil=磁盘利用率\n",normalizedContent:"# linux下磁盘i/o测试\n\n\n# 安装\n\n * 方法一：[推荐] 在linux系统下通过yum安装，yum install -y fio\n\n * 方法二：在fio官网下载fio-2.1.10.tar文件，解压后./configure、make、make install\n\n\n# 参数解释\n\nfilename=/dev/emcpowerb　支持文件系统或者裸设备，-filename=/dev/sda2或-filename=/dev/sdb\ndirect=1 测试过程绕过机器自带的buffer，使测试结果更真实\nrw=randwread 测试随机读的i/o\nrw=randwrite 测试随机写的i/o\nrw=randrw 测试随机混合写和读的i/o\nrw=read 测试顺序读的i/o\nrw=write 测试顺序写的i/o\nrw=rw 测试顺序混合写和读的i/o\nbs=4k 单次io的块文件大小为4k\nbsrange=512-2048 同上，提定数据块的大小范围\nsize=5g 本次的测试文件大小为5g，以每次4k的io进行测试\nnumjobs=30 本次的测试线程为30\nruntime=1000 测试时间为1000秒，如果不写则一直将5g文件分4k每次写完为止\nioengine=psync io引擎使用pync方式，如果要使用libaio引擎，需要yum install libaio-devel包\nrwmixwrite=30 在混合读写的模式下，写占30%\ngroup_reporting 关于显示结果的，汇总每个进程的信息\n\n此外\nlockmem=1g 只使用1g内存进行测试\nzero_buffers 用0初始化系统buffer\nnrfiles=8 每个进程生成文件的数量\n\n\n\n# fio测试场景\n\n> /dev/emcpowerb的地址为fdisk -l获得。部分机器为：/dev/sda、/dev/sda1、/dev/sda2、/dev/sda3\n\n * 100%随机，100%读， 4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=rand_100read_4k\n\n\n * 100%随机，100%写， 4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=rand_100write_4k\n\n\n * 100%顺序，100%读 ，4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=sqe_100read_4k\n\n\n * 100%顺序，100%写 ，4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=sqe_100write_4k\n\n\n * 100%随机，70%读，30%写 4k\n\nfio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randrw -rwmixread=70 -ioengine=psync -bs=4k -size=1000g -numjobs=50 -runtime=180 -group_reporting -name=randrw_70read_4k\n\n\n\n# 结果说明\n\nio=执行了多少m的io\n\nbw=平均io带宽\niops=iops\nrunt=线程运行时间\nslat=提交延迟\nclat=完成延迟\nlat=响应时间\nbw=带宽\ncpu=利用率\nio depths=io队列\nio submit=单个io提交要提交的io数\nio complete=like the above submit number, but for completions instead.\nio issued=the number of read/write requests issued, and how many of them were short.\nio latencies=io完延迟的分布\n\nio=总共执行了多少size的io\naggrb=group总带宽\nminb=最小.平均带宽.\nmaxb=最大平均带宽.\nmint=group中线程的最短运行时间.\nmaxt=group中线程的最长运行时间.\n\nios=所有group总共执行的io数.\nmerge=总共发生的io合并数.\nticks=number of ticks we kept the disk busy.\nio_queue=花费在队列上的总共时间.\nutil=磁盘利用率\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"CentOS7安装mysql5.7",frontmatter:{title:"CentOS7安装mysql5.7",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/6db179/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/05.CentOS7%E5%AE%89%E8%A3%85mysql5.7.html",relativePath:"05.工具&部署/02.Linux/05.CentOS7安装mysql5.7.md",key:"v-778ac29c",path:"/pages/6db179/",headersStr:null,content:"# CentOS7安装mysql5.7\n\n> 文件下载地址：https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.33-1.el7.x86_64.rpm-bundle.tar\n\n * 卸载系统默认mariadb\n\nrpm -qa | grep mariadb;\nrpm -e mariadb-libs-5.5.60-1.el7_5.x86_64 --nodeps\n\n\n * 上传并解压文件\n\nmkdir /usr/local/mysql/\ntar -vxf mysql-5.7.33-1.el7.x86_64.rpm-bundle.tar -C /usr/local/mysql/\n\n\n * 安装\n\ncd /usr/local/mysql/\nrpm -ivh mysql-community-common-5.7.33-1.el7.x86_64.rpm\nrpm -ivh mysql-community-libs-5.7.33-1.el7.x86_64.rpm\nrpm -ivh mysql-community-client-5.7.33-1.el7.x86_64.rpm\nyum -y install perl.x86_64\nrpm -ivh mysql-community-server-5.7.33-1.el7.x86_64.rpm\n\n\n * 删除默认文件\n\nrm -rf /var/lib/mysql/*\n\n\n * 启动服务\n\nservice mysqld start\nsystemctl enable mysqld\n\n\n * 查看初始密码\n\ngrep 'temporary password' /var/log/mysqld.log;\n\n\n * 登录\n\nmysql -u root -p aUuTak1Geg!k\n\n\n * 重新设置密码\n\nset password for 'root'@'localhost' = password('Root123@');\n#修改密码验证强度\nset global validate_password_policy=LOW;\nset global validate_password_length=6;\nset password for 'root'@'localhost' = password('123456');\n#本地授权\ngrant all privileges on *.* to root@\"%\" identified by '123456' with grant option;\n#远程授权\ngrant all privileges on *.* to root@localhost identified by '123456' with grant option;\n#刷新权限\nflush privileges;\n",normalizedContent:"# centos7安装mysql5.7\n\n> 文件下载地址：https://cdn.mysql.com//downloads/mysql-5.7/mysql-5.7.33-1.el7.x86_64.rpm-bundle.tar\n\n * 卸载系统默认mariadb\n\nrpm -qa | grep mariadb;\nrpm -e mariadb-libs-5.5.60-1.el7_5.x86_64 --nodeps\n\n\n * 上传并解压文件\n\nmkdir /usr/local/mysql/\ntar -vxf mysql-5.7.33-1.el7.x86_64.rpm-bundle.tar -c /usr/local/mysql/\n\n\n * 安装\n\ncd /usr/local/mysql/\nrpm -ivh mysql-community-common-5.7.33-1.el7.x86_64.rpm\nrpm -ivh mysql-community-libs-5.7.33-1.el7.x86_64.rpm\nrpm -ivh mysql-community-client-5.7.33-1.el7.x86_64.rpm\nyum -y install perl.x86_64\nrpm -ivh mysql-community-server-5.7.33-1.el7.x86_64.rpm\n\n\n * 删除默认文件\n\nrm -rf /var/lib/mysql/*\n\n\n * 启动服务\n\nservice mysqld start\nsystemctl enable mysqld\n\n\n * 查看初始密码\n\ngrep 'temporary password' /var/log/mysqld.log;\n\n\n * 登录\n\nmysql -u root -p auutak1geg!k\n\n\n * 重新设置密码\n\nset password for 'root'@'localhost' = password('root123@');\n#修改密码验证强度\nset global validate_password_policy=low;\nset global validate_password_length=6;\nset password for 'root'@'localhost' = password('123456');\n#本地授权\ngrant all privileges on *.* to root@\"%\" identified by '123456' with grant option;\n#远程授权\ngrant all privileges on *.* to root@localhost identified by '123456' with grant option;\n#刷新权限\nflush privileges;\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"Linux图形化监控工具Cockpit",frontmatter:{title:"Linux图形化监控工具Cockpit",date:"2023-09-05T20:21:18.000Z",permalink:"/pages/71dd10/",article:!1},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/04.Linux%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7Cockpit.html",relativePath:"05.工具&部署/02.Linux/04.Linux图形化监控工具Cockpit.md",key:"v-6c528997",path:"/pages/71dd10/",headers:[{level:2,title:"介绍",slug:"介绍",normalizedTitle:"介绍",charIndex:26},{level:2,title:"安装：",slug:"安装",normalizedTitle:"安装：",charIndex:274},{level:2,title:"访问",slug:"访问",normalizedTitle:"访问",charIndex:486}],headersStr:"介绍 安装： 访问",content:"# Cockpit网页版图像化服务管理工具\n\n\n# 介绍\n\n优点是无需中间层，且可以管理多种服务。\n\n根据其项目主站描述，Cockpit 有如下特点：\n\n * 从易用性考虑设计，方便管理人员使用，而不是仅仅的终端命令按钮化。\n * 不会打乱已有终端或脚本服务配置，通过 Cockpit 启用的服务可以在终端停止，脚本运行的错误亦会被 Cockpit 捕获。\n * 支持一次性管理多个服务，实现自动化和批处理。\n * 系统存储信息查看。\n * docker容器监控。\n * 系统网络监控。\n * web命令行终端。\n * 界面友好的仪表盘。\n\n\n# 安装：\n\n```\n# 安装cockpit\nyum -y install cockpit\n# 安装cockpit所有模块\nyum -y install cockpit-*\n# 启动及开机自启\n# rpm -ivh cockpit-195.6-1.el7.centos.x86_64.rpm\nsystemctl start cockpit && systemctl enable cockpit.socket\n```\n\n\n\n# 访问\n\n# web ui\nhttps://127.0.0.1:9090\n",normalizedContent:"# cockpit网页版图像化服务管理工具\n\n\n# 介绍\n\n优点是无需中间层，且可以管理多种服务。\n\n根据其项目主站描述，cockpit 有如下特点：\n\n * 从易用性考虑设计，方便管理人员使用，而不是仅仅的终端命令按钮化。\n * 不会打乱已有终端或脚本服务配置，通过 cockpit 启用的服务可以在终端停止，脚本运行的错误亦会被 cockpit 捕获。\n * 支持一次性管理多个服务，实现自动化和批处理。\n * 系统存储信息查看。\n * docker容器监控。\n * 系统网络监控。\n * web命令行终端。\n * 界面友好的仪表盘。\n\n\n# 安装：\n\n```\n# 安装cockpit\nyum -y install cockpit\n# 安装cockpit所有模块\nyum -y install cockpit-*\n# 启动及开机自启\n# rpm -ivh cockpit-195.6-1.el7.centos.x86_64.rpm\nsystemctl start cockpit && systemctl enable cockpit.socket\n```\n\n\n\n# 访问\n\n# web ui\nhttps://127.0.0.1:9090\n",charsets:{cjk:!0},lastUpdated:"2023/09/05, 21:16:45",lastUpdatedTimestamp:1693919805e3},{title:"在线Linux命令查询",frontmatter:{title:"在线Linux命令查询",date:"2024-08-23T06:39:16.000Z",permalink:"/pages/518cfa/"},regularPath:"/05.%E5%B7%A5%E5%85%B7&%E9%83%A8%E7%BD%B2/02.Linux/06.%E5%9C%A8%E7%BA%BFLinux%E5%91%BD%E4%BB%A4%E6%9F%A5%E8%AF%A2.html",relativePath:"05.工具&部署/02.Linux/06.在线Linux命令查询.md",key:"v-b6061afe",path:"/pages/518cfa/",headersStr:null,content:"Linux 在线命令",normalizedContent:"linux 在线命令",charsets:{cjk:!0}},{title:"AspNetCore面试题",frontmatter:{title:"AspNetCore面试题",date:"2023-04-20T15:56:28.000Z",permalink:"/pages/86a4e2/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/01.AspNetCore%E9%9D%A2%E8%AF%95%E9%A2%98/01.AspNetCore%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/01.AspNetCore面试题/01.AspNetCore面试题.md",key:"v-4c28040b",path:"/pages/86a4e2/",headersStr:null,content:"# AspNetCore面试题\n\n1、什么是dot net core的startup class?\n\n答：Startup class是dot net core应用的入口。所有的dot net core应用必须有这个class 这个类用来配置应用。\n\n这个类的调用是在program main函数里面进行配置的。类的名字可以自己定义。\n\n2、什么是中间件?\n\n答：中间件在这里是指注入到应用中处理请求和响应的组件。\n\n3、application builder的use和run方法有什么区别?\n\n答：这两个方法都在start up class的configure方法里面调用。都是用来向应用请求管道里面添加中间件的。Use方法可以调用下一个中间件的添加，而run不会。\n\n4、dot net core 管道里面的map拓展有什么作用?\n\n答：可以针对不同的路径添加不同的中间件。\n\n5、dot net core里面的路径是如何处理的?\n\n答：路径处理是用来为进入的请求寻找处理函数的机制。所有的路径在函数运行开始时进行注册。\n\n主要有两种路径处理方式，常规路径处理和属性路径处理。常规路径处理就是用MapRoute的方式设定调用路径，属性路径处理是指在调用函数的上方设定一个路径属性。\n\n6、如何在dot net core中激活session功能?\n\n答：首先要添加session包. 其次要在config service方法里面添加session。然后又在configure方法里面调用usesession。\n\n7、描述一下依赖注入后的服务生命周期?\n\n答：asp.net core主要提供了三种依赖注入的方式\n\n其中AddTransient与AddSingleton比较好区别\n\nAddTransient瞬时模式：每次都获取一个新的实例\n\nAddSingleton单例模式：每次都获取同一个实例\n\n而AddTransient与AddScoped的区别更不容易区别一点\n\n首先这两种方式每次请求得到的都不是同一个对象，从这点看会发现这两个都一样。\n\n但是我们可以继续分细一点，虽然不同的请求得到的结果不同，但是我们可以在同一次请求中去获取多次实例测试。\n\n小总结:\n\nAddTransient瞬时模式：每次请求，都获取一个新的实例。即使同一个请求获取多次也会是不同的实例\n\nAddScoped：每次请求，都获取一个新的实例。同一个请求获取多次会得到相同的实例\n\nAddSingleton单例模式：每次都获取同一个实例\n\n8、dot net core跟dot net比较有哪些更好的地方?\n\n答：第一是跨平台，它可以运行在三大操作系统上面，windows， Linux和MAC。\n\n第二是对架构本身安装没有依赖，因为所有的依赖都跟程序本身在一起。\n\n第三是dot net core处理请求的效率更高，能够处理更多的请求。\n\n第四是dot net core有更多的安装配置方法。\n\n9、asp dot core有哪些好的功能？\n\n答：第一是依赖注入。\n\n第二是日志系统架构。\n\n第三是引入了一个跨平台的网络服务器，kestrel。可以没有iis, apache和nginx就可以单独运行。\n\n第四是可以使用命令行创建应用。\n\n第五是使用APP settings json file来配置工程。\n\n第六是使用start up来注册服务。\n\n第七是更好的支持异步编程。\n\n第八是支持web socket和signal IR。\n\n第九是对于跨网站的请求的预防和保护机制。",normalizedContent:"# aspnetcore面试题\n\n1、什么是dot net core的startup class?\n\n答：startup class是dot net core应用的入口。所有的dot net core应用必须有这个class 这个类用来配置应用。\n\n这个类的调用是在program main函数里面进行配置的。类的名字可以自己定义。\n\n2、什么是中间件?\n\n答：中间件在这里是指注入到应用中处理请求和响应的组件。\n\n3、application builder的use和run方法有什么区别?\n\n答：这两个方法都在start up class的configure方法里面调用。都是用来向应用请求管道里面添加中间件的。use方法可以调用下一个中间件的添加，而run不会。\n\n4、dot net core 管道里面的map拓展有什么作用?\n\n答：可以针对不同的路径添加不同的中间件。\n\n5、dot net core里面的路径是如何处理的?\n\n答：路径处理是用来为进入的请求寻找处理函数的机制。所有的路径在函数运行开始时进行注册。\n\n主要有两种路径处理方式，常规路径处理和属性路径处理。常规路径处理就是用maproute的方式设定调用路径，属性路径处理是指在调用函数的上方设定一个路径属性。\n\n6、如何在dot net core中激活session功能?\n\n答：首先要添加session包. 其次要在config service方法里面添加session。然后又在configure方法里面调用usesession。\n\n7、描述一下依赖注入后的服务生命周期?\n\n答：asp.net core主要提供了三种依赖注入的方式\n\n其中addtransient与addsingleton比较好区别\n\naddtransient瞬时模式：每次都获取一个新的实例\n\naddsingleton单例模式：每次都获取同一个实例\n\n而addtransient与addscoped的区别更不容易区别一点\n\n首先这两种方式每次请求得到的都不是同一个对象，从这点看会发现这两个都一样。\n\n但是我们可以继续分细一点，虽然不同的请求得到的结果不同，但是我们可以在同一次请求中去获取多次实例测试。\n\n小总结:\n\naddtransient瞬时模式：每次请求，都获取一个新的实例。即使同一个请求获取多次也会是不同的实例\n\naddscoped：每次请求，都获取一个新的实例。同一个请求获取多次会得到相同的实例\n\naddsingleton单例模式：每次都获取同一个实例\n\n8、dot net core跟dot net比较有哪些更好的地方?\n\n答：第一是跨平台，它可以运行在三大操作系统上面，windows， linux和mac。\n\n第二是对架构本身安装没有依赖，因为所有的依赖都跟程序本身在一起。\n\n第三是dot net core处理请求的效率更高，能够处理更多的请求。\n\n第四是dot net core有更多的安装配置方法。\n\n9、asp dot core有哪些好的功能？\n\n答：第一是依赖注入。\n\n第二是日志系统架构。\n\n第三是引入了一个跨平台的网络服务器，kestrel。可以没有iis, apache和nginx就可以单独运行。\n\n第四是可以使用命令行创建应用。\n\n第五是使用app settings json file来配置工程。\n\n第六是使用start up来注册服务。\n\n第七是更好的支持异步编程。\n\n第八是支持web socket和signal ir。\n\n第九是对于跨网站的请求的预防和保护机制。",charsets:{cjk:!0}},{title:"Net面试题",frontmatter:{title:"Net面试题",date:"2023-04-20T15:58:28.000Z",permalink:"/pages/868a19/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/01.AspNetCore%E9%9D%A2%E8%AF%95%E9%A2%98/02.Net%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/01.AspNetCore面试题/02.Net面试题.md",key:"v-7280ffb2",path:"/pages/868a19/",headersStr:null,content:"# Net面试题\n\n1、JIT是如何工作的\n\n答：JIT 引擎在编译中间代码之前，会寻找方法的本机机器代码缓存并且判断其是否可用，如果可用则直接加载，如果不可用，JIT 引擎会查找类型中的方法存根，找到该中间代码并且进行编译。\n\n2、值类型和引用类型的区别\n\n答：所有继承自System.ValueType 的类型是值类型，而其他类型都是引用类型。值类型的赋值会产生一个新的数据副本，所以每个值类型都拥有一个数据副本，而引用类型的赋值则是赋值引用。值类型的对象分配在堆栈上，而引用类型的对象分配在堆上。当比较两个值类型时，进行的是内容比较，而比较两个引用类型时，进行的是引用比较。\n\n3、解释泛型的基本原理\n\n答：泛型类似C++中的模板，允许程序员定义更通用的类型和算法，并且在具体使用时再生成具体的封闭类型。所有带泛型参数的类型都是一个开放式类型，它不能被实例化，但具备所有封闭类型的其他特性，本质上，它和封闭类型没有区别。\n\n4、如何自定义序列化和反序列化的过程\n\n答：通过实现 ISerializable 接口中的 GetObjectData 方法可以实现自定义的序列化，而通过添加带有SerializationInfo 和StreamingContext的参数的构造方法可以自定义反序列化的过程。\n\n5、如何使用 IFormattable 接口实现格式化输出\n\n答：IFormattable接口帮助类型实现了多样式的格式化输出。IFormattable 的ToString方法接受一个代表格式的字符串参数，通过对这个参数的分析来进行格式化输出。另外，IFormattable.ToString方法接受一个IFormatProvider类型的参数，以允许类型的使用者提供格式化的方法。\n\n6、请解释委托的基本原理\n\n答：委托是一类继承自System.Delegate 的类型，每个委托对象至少包含了一个指向某个方法的指针，该方法可以是实例方法，也可以是静态方法。委托实现了回调方法的机制，能够帮助程序员设计更加简洁优美的面向对象程序。\n\n7、什么是链式委托\n\n答：链式委托是指一个由委托串成的链表，当链表上的一个委托被回调时，所有链表上该委托的后续委托将会被顺序执行。\n\n8、请解释反射的基本原理和其实现的基石\n\n答：反射是一种动态分析程序集、模块、类型、字段等目标对象的机制，它的实现依托于元数据。元数据是存储在PE 文件中的数据块，它详细记录了程序集或模块内部的结构、引用的类型和程序集和清单\n\n9、如何利用反射来实现工厂模式\n\n答：使用反射可以实现灵活性较高的工厂模式，其关键在于动态地查找产品所包含的所有零件，而不需要通过代码来逐一分析使用者的需求。反射工厂模式具有灵活性高，运行效率相对较低的特点。\n\n10、如何以较小的内存代价保存 Type、Field 和 Method 信息\n\n答：System.RuntimeTypeHandle、System.RuntimeMethodHandle 和 System.RuntimeFieldHandle 三个类型，分别包含了一个指向类型、方法和字段描述的指针，用保存指针的方式来代替保存整个类型、方法和字段的信息描述对象，可以有效地减少内存的消耗。而在实际需要用到这些信息时，又可以通过这三个句柄类型对象，分别得到System.Type、System.Reflection.MethodInfo 和System.Reflection.FieldInfo 类型对象。\n\n11、如何防止 SQL注入式攻击\n\n答：SQL 注入式攻击时常见的一种攻击方法，主要利用的是系统设计的弊端。程序员在设计时需要考虑到注入式攻击的问题，避免直接使用用户输入拼接 SQL 语句，适当使用加密数据进行存储，并且在合适的场合使用存储过程。\n\n12、请简要叙述数据库连接池的机制\n\n答：ADO.NET 对上层用户提供了数据库连接池的服务，使用完的数据库连接将被有选择的保持在数据库连接池中，以供下次使用。当用户以某个连接字符串申请数据库连接时，数据库连接池将尝试寻找在池中寻找具有相同的连接字符串的连接，并直接提供给用户。\n\n13、如何提高连接池内连接的重用率\n\n答：为了提高数据库连接池的重用率，唯一的方法就是尽量保证系统访问数据库所使用的连接字符串不变。例如建立跳板数据库，使所有连接都首先尝试访问跳板数据库。另外，统一使用超级用户帐号可以进一步统一连接字符串，但这为系统带来了安全上的隐患。\n\n14、哈希表和数组列表有什么区别？\n\n答：哈希表以值对和名称的形式存储数据, 而数组列表仅存储值。\n\n你需要将名称传递给哈希表中的值, 而在数组中, 则需要传递索引号来访问值。\n\n在数组中, 你只能存储类似类型的数据类型, 而在哈希表中, 你可以存储不同类型的数据类型。例如整数, 字符串等\n\n15、什么是内存映射文件？\n\n答：内存映射文件用于将文件内容映射到应用程序的逻辑地址。它使你能够在同一台计算机上运行多个进程以彼此共享数据。要获得一个内存映射文件对象, 可以使用MemoryMappedFile.CreateFromFiles()方法。它表示磁盘上文件中的持久性内存映射文件。\n\n16、使用哪种方法在.NET中实施垃圾收集？\n\nSystem.GC.Collect()方法。\n\n17、.Net中有哪些不同类型的索引？\n\n答：.Net中有两种类型的索引：\n\n聚集索引和非聚集索引\n\n18、.Net中有几种类型的内存？\n\n答：.Net中有两种类型的内存\n\n * 堆栈内存\n * 堆内存\n\n19、元组可以容纳多少个元素？\n\n答：一个元组可以容纳1到8个元素。如果元素多于8个, 则可以将第8个元素定义为另一个元组。元组可以指定为参数或方法的返回类型。",normalizedContent:"# net面试题\n\n1、jit是如何工作的\n\n答：jit 引擎在编译中间代码之前，会寻找方法的本机机器代码缓存并且判断其是否可用，如果可用则直接加载，如果不可用，jit 引擎会查找类型中的方法存根，找到该中间代码并且进行编译。\n\n2、值类型和引用类型的区别\n\n答：所有继承自system.valuetype 的类型是值类型，而其他类型都是引用类型。值类型的赋值会产生一个新的数据副本，所以每个值类型都拥有一个数据副本，而引用类型的赋值则是赋值引用。值类型的对象分配在堆栈上，而引用类型的对象分配在堆上。当比较两个值类型时，进行的是内容比较，而比较两个引用类型时，进行的是引用比较。\n\n3、解释泛型的基本原理\n\n答：泛型类似c++中的模板，允许程序员定义更通用的类型和算法，并且在具体使用时再生成具体的封闭类型。所有带泛型参数的类型都是一个开放式类型，它不能被实例化，但具备所有封闭类型的其他特性，本质上，它和封闭类型没有区别。\n\n4、如何自定义序列化和反序列化的过程\n\n答：通过实现 iserializable 接口中的 getobjectdata 方法可以实现自定义的序列化，而通过添加带有serializationinfo 和streamingcontext的参数的构造方法可以自定义反序列化的过程。\n\n5、如何使用 iformattable 接口实现格式化输出\n\n答：iformattable接口帮助类型实现了多样式的格式化输出。iformattable 的tostring方法接受一个代表格式的字符串参数，通过对这个参数的分析来进行格式化输出。另外，iformattable.tostring方法接受一个iformatprovider类型的参数，以允许类型的使用者提供格式化的方法。\n\n6、请解释委托的基本原理\n\n答：委托是一类继承自system.delegate 的类型，每个委托对象至少包含了一个指向某个方法的指针，该方法可以是实例方法，也可以是静态方法。委托实现了回调方法的机制，能够帮助程序员设计更加简洁优美的面向对象程序。\n\n7、什么是链式委托\n\n答：链式委托是指一个由委托串成的链表，当链表上的一个委托被回调时，所有链表上该委托的后续委托将会被顺序执行。\n\n8、请解释反射的基本原理和其实现的基石\n\n答：反射是一种动态分析程序集、模块、类型、字段等目标对象的机制，它的实现依托于元数据。元数据是存储在pe 文件中的数据块，它详细记录了程序集或模块内部的结构、引用的类型和程序集和清单\n\n9、如何利用反射来实现工厂模式\n\n答：使用反射可以实现灵活性较高的工厂模式，其关键在于动态地查找产品所包含的所有零件，而不需要通过代码来逐一分析使用者的需求。反射工厂模式具有灵活性高，运行效率相对较低的特点。\n\n10、如何以较小的内存代价保存 type、field 和 method 信息\n\n答：system.runtimetypehandle、system.runtimemethodhandle 和 system.runtimefieldhandle 三个类型，分别包含了一个指向类型、方法和字段描述的指针，用保存指针的方式来代替保存整个类型、方法和字段的信息描述对象，可以有效地减少内存的消耗。而在实际需要用到这些信息时，又可以通过这三个句柄类型对象，分别得到system.type、system.reflection.methodinfo 和system.reflection.fieldinfo 类型对象。\n\n11、如何防止 sql注入式攻击\n\n答：sql 注入式攻击时常见的一种攻击方法，主要利用的是系统设计的弊端。程序员在设计时需要考虑到注入式攻击的问题，避免直接使用用户输入拼接 sql 语句，适当使用加密数据进行存储，并且在合适的场合使用存储过程。\n\n12、请简要叙述数据库连接池的机制\n\n答：ado.net 对上层用户提供了数据库连接池的服务，使用完的数据库连接将被有选择的保持在数据库连接池中，以供下次使用。当用户以某个连接字符串申请数据库连接时，数据库连接池将尝试寻找在池中寻找具有相同的连接字符串的连接，并直接提供给用户。\n\n13、如何提高连接池内连接的重用率\n\n答：为了提高数据库连接池的重用率，唯一的方法就是尽量保证系统访问数据库所使用的连接字符串不变。例如建立跳板数据库，使所有连接都首先尝试访问跳板数据库。另外，统一使用超级用户帐号可以进一步统一连接字符串，但这为系统带来了安全上的隐患。\n\n14、哈希表和数组列表有什么区别？\n\n答：哈希表以值对和名称的形式存储数据, 而数组列表仅存储值。\n\n你需要将名称传递给哈希表中的值, 而在数组中, 则需要传递索引号来访问值。\n\n在数组中, 你只能存储类似类型的数据类型, 而在哈希表中, 你可以存储不同类型的数据类型。例如整数, 字符串等\n\n15、什么是内存映射文件？\n\n答：内存映射文件用于将文件内容映射到应用程序的逻辑地址。它使你能够在同一台计算机上运行多个进程以彼此共享数据。要获得一个内存映射文件对象, 可以使用memorymappedfile.createfromfiles()方法。它表示磁盘上文件中的持久性内存映射文件。\n\n16、使用哪种方法在.net中实施垃圾收集？\n\nsystem.gc.collect()方法。\n\n17、.net中有哪些不同类型的索引？\n\n答：.net中有两种类型的索引：\n\n聚集索引和非聚集索引\n\n18、.net中有几种类型的内存？\n\n答：.net中有两种类型的内存\n\n * 堆栈内存\n * 堆内存\n\n19、元组可以容纳多少个元素？\n\n答：一个元组可以容纳1到8个元素。如果元素多于8个, 则可以将第8个元素定义为另一个元组。元组可以指定为参数或方法的返回类型。",charsets:{cjk:!0}},{title:"Elasticsearch面试题",frontmatter:{title:"Elasticsearch面试题",date:"2023-04-20T15:57:15.000Z",permalink:"/pages/a567cd/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/02.Elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98/01.Elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/02.Elasticsearch面试题/01.Elasticsearch面试题.md",key:"v-01725947",path:"/pages/a567cd/",headersStr:null,content:"# Elasticsearch面试题\n\n1、ES中的倒排索引是什么？\n\n答：传统的检索方式是通过文章，逐个遍历找到对应关键词的位置。 倒排索引，是通过分词策略，形成了词和文章的映射关系表，也称倒排表，这种词典 + 映射表即为倒排索引。\n\n其中词典中存储词元，倒排表中存储该词元在哪些文中出现的位置。 有了倒排索引，就能实现 O(1) 时间复杂度的效率检索文章了，极大的提高了检索效率。\n\n加分项： 倒排索引的底层实现是基于：FST（Finite State Transducer）数据结构。\n\nLucene 从 4+ 版本后开始大量使用的数据结构是 FST。FST 有两个优点： 1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间； 2）查询速度快。O(len(str)) 的查询时间复杂度。\n\n2、ES是如何实现master选举的？\n\n答：\n\n前置条件： 1）只有是候选主节点（master：true）的节点才能成为主节点。 2）最小主节点数（min_master_nodes）的目的是防止脑裂。\n\nElasticsearch 的选主是 ZenDiscovery 模块负责的，主要包含 Ping（节点之间通过这个RPC来发现彼此）和 Unicast（单播模块包含一个主机列表以控制哪些节点需要 ping 通）这两部分； 获取主节点的核心入口为 findMaster，选择主节点成功返回对应 Master，否则返回 null。\n\n选举流程大致描述如下： 第一步：确认候选主节点数达标，elasticsearch.yml 设置的值 discovery.zen.minimum_master_nodes; 第二步：对所有候选主节点根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。 第三步：如果对某个节点的投票数达到一定的值（候选主节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。\n\n * 补充：\n   * 这里的 id 为 string 类型。\n   * master 节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data 节点可以关闭 http 功能。\n\n3、如何解决ES集群的脑裂问题\n\n答：所谓集群脑裂，是指 Elasticsearch 集群中的节点（比如共 20 个），其中的 10 个选了一个 master，另外 10 个选了另一个 master 的情况。\n\n当集群 master 候选数量不小于 3 个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题； 当候选数量为两个时，只能修改为唯一的一个 master 候选，其他作为 data 节点，避免脑裂问题\n\n4、详细描述一下ES索引文档的过程？\n\n答：这里的索引文档应该理解为文档写入 ES，创建索引的过程。\n\n第一步：客户端向集群某节点写入数据，发送请求。（如果没有指定路由/协调节点，请求的节点扮演协调节点的角色。） 第二步：协调节点接受到请求后，默认使用文档 ID 参与计算（也支持通过 routing），得到该文档属于哪个分片。随后请求会被转到另外的节点。\n\n第三步：当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 Memory Buffer，然后定时（默认是每隔 1 秒）写入到F ilesystem Cache，这个从 Momery Buffer 到 Filesystem Cache 的过程就叫做 refresh； 第四步：当然在某些情况下，存在 Memery Buffer 和 Filesystem Cache 的数据可能会丢失，ES 是通过 translog 的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到 translog 中，当 Filesystem cache 中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush； 第五步：在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的 fsync 将创建一个新的提交点，并将内容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。 第六步：flush 触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512 M）时。\n\n补充：关于 Lucene 的 Segement\n\n * Lucene 索引是由多个段组成，段本身是一个功能齐全的倒排索引。\n * 段是不可变的，允许 Lucene 将新的文档增量地添加到索引中，而不用从头重建索引。\n * 对于每一个搜索请求而言，索引中的所有段都会被搜索，并且每个段会消耗 CPU 的时钟周、文件句柄和内存。这意味着段的数量越多，搜索性能会越低。\n * 为了解决这个问题，Elasticsearch 会合并小段到一个较大的段，提交新的合并段到磁盘，并删除那些旧的小段。（段合并）\n\n5、详细描述一下ES更新和删除文档的过程？\n\n答：删除和更新也都是写操作，但是 Elasticsearch 中的文档是不可变的，因此不能被删除或者改动以展示其变更。\n\n磁盘上的每个段都有一个相应的 .del 文件。当删除请求发送后，文档并没有真的被删除，而是在 .del 文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在 .del 文件中被标记为删除的文档将不会被写入新段。\n\n在新的文档被创建时，Elasticsearch 会为该文档指定一个版本号，当执行更新时，旧版本的文档在 .del 文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。\n\n6、详细描述一下ES搜索的过程？\n\n答：搜索被执行成一个两阶段过程，即 Query Then Fetch； Query阶段： 查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。 Fetch阶段： 协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。\n\n7、在并发情况下，ES如果保证读写一致？\n\n答：可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突； 另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。 对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。\n\n8、 ES对于大数据量（上亿量级）的聚合如何实现？\n\n答：Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关\n\n9、对于GC方面，在使用ES时要注意什么？\n\n答：1）倒排词典的索引需要常驻内存，无法GC，需要监控data node上segment memory增长趋势。 2）各类缓存，field cache, filter cache, indexing cache, bulk queue等等，要设置合理的大小，并且要应该根据最坏的情况来看heap是否够用，也就是各类缓存全部占满的时候，还有heap空间可以分配给其他任务吗？避免采用clear cache等“自欺欺人”的方式来释放内存。 3）避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用scan & scroll api来实现。 4）cluster stats驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过tribe node连接。 5）想知道heap够不够，必须结合实际应用场景，并对集群的heap使用情况做持续的监控。\n\n10、说说你们公司ES的集群架构，索引数据大小，分片有多少，以及一些调优手段？\n\n答：根据实际情况回答即可，如果是我的话会这么回答： 我司有多个ES集群，下面列举其中一个。该集群有20个节点，根据数据类型和日期分库，每个索引根据数据量分片，比如日均1亿+数据的，控制单索引大小在200GB以内。　 下面重点列举一些调优策略，仅是我做过的，不一定全面，如有其它建议或者补充欢迎留言。 部署层面： 1）最好是64GB内存的物理机器，但实际上32GB和16GB机器用的比较多，但绝对不能少于8G，除非数据量特别少，这点需要和客户方面沟通并合理说服对方。 2）多个内核提供的额外并发远胜过稍微快一点点的时钟频率。 3）尽量使用SSD，因为查询和索引性能将会得到显著提升。 4）避免集群跨越大的地理距离，一般一个集群的所有节点位于一个数据中心中。 5）设置堆内存：节点内存/2，不要超过32GB。一般来说设置export ES_HEAP_SIZE=32g环境变量，比直接写-Xmx32g -Xms32g更好一点。 6）关闭缓存swap。内存交换到磁盘对服务器性能来说是致命的。如果内存交换到磁盘上，一个100微秒的操作可能变成10毫秒。 再想想那么多10微秒的操作时延累加起来。不难看出swapping对于性能是多么可怕。 7）增加文件描述符，设置一个很大的值，如65535。Lucene使用了大量的文件，同时，Elasticsearch在节点和HTTP客户端之间进行通信也使用了大量的套接字。所有这一切都需要足够的文件描述符。 8）不要随意修改垃圾回收器（CMS）和各个线程池的大小。 9）通过设置gateway.recover_after_nodes、gateway.expected_nodes、gateway.recover_after_time可以在集群重启的时候避免过多的分片交换，这可能会让数据恢复从数个小时缩短为几秒钟。 索引层面： 1）使用批量请求并调整其大小：每次批量数据 5–15 MB 大是个不错的起始点。 2）段合并：Elasticsearch默认值是20MB/s，对机械磁盘应该是个不错的设置。如果你用的是SSD，可以考虑提高到100-200MB/s。如果你在做批量导入，完全不在意搜索，你可以彻底关掉合并限流。另外还可以增加 index.translog.flush_threshold_size 设置，从默认的512MB到更大一些的值，比如1GB，这可以在一次清空触发的时候在事务日志里积累出更大的段。 3）如果你的搜索结果不需要近实时的准确度，考虑把每个索引的index.refresh_interval 改到30s。 4）如果你在做大批量导入，考虑通过设置index.number_of_replicas: 0 关闭副本。 5）需要大量拉取数据的场景，可以采用scan & scroll api来实现，而不是from/size一个大范围。 存储层面： 1）基于数据+时间滚动创建索引，每天递增数据。控制单个索引的量，一旦单个索引很大，存储等各种风险也随之而来，所以要提前考虑+及早避免。 2）冷热数据分离存储，热数据（比如最近3天或者一周的数据），其余为冷数据。对于冷数据不会再写入新数据，可以考虑定期force_merge加shrink压缩操作，节省存储空间和检索效率。",normalizedContent:"# elasticsearch面试题\n\n1、es中的倒排索引是什么？\n\n答：传统的检索方式是通过文章，逐个遍历找到对应关键词的位置。 倒排索引，是通过分词策略，形成了词和文章的映射关系表，也称倒排表，这种词典 + 映射表即为倒排索引。\n\n其中词典中存储词元，倒排表中存储该词元在哪些文中出现的位置。 有了倒排索引，就能实现 o(1) 时间复杂度的效率检索文章了，极大的提高了检索效率。\n\n加分项： 倒排索引的底层实现是基于：fst（finite state transducer）数据结构。\n\nlucene 从 4+ 版本后开始大量使用的数据结构是 fst。fst 有两个优点： 1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间； 2）查询速度快。o(len(str)) 的查询时间复杂度。\n\n2、es是如何实现master选举的？\n\n答：\n\n前置条件： 1）只有是候选主节点（master：true）的节点才能成为主节点。 2）最小主节点数（min_master_nodes）的目的是防止脑裂。\n\nelasticsearch 的选主是 zendiscovery 模块负责的，主要包含 ping（节点之间通过这个rpc来发现彼此）和 unicast（单播模块包含一个主机列表以控制哪些节点需要 ping 通）这两部分； 获取主节点的核心入口为 findmaster，选择主节点成功返回对应 master，否则返回 null。\n\n选举流程大致描述如下： 第一步：确认候选主节点数达标，elasticsearch.yml 设置的值 discovery.zen.minimum_master_nodes; 第二步：对所有候选主节点根据nodeid字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。 第三步：如果对某个节点的投票数达到一定的值（候选主节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。\n\n * 补充：\n   * 这里的 id 为 string 类型。\n   * master 节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data 节点可以关闭 http 功能。\n\n3、如何解决es集群的脑裂问题\n\n答：所谓集群脑裂，是指 elasticsearch 集群中的节点（比如共 20 个），其中的 10 个选了一个 master，另外 10 个选了另一个 master 的情况。\n\n当集群 master 候选数量不小于 3 个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题； 当候选数量为两个时，只能修改为唯一的一个 master 候选，其他作为 data 节点，避免脑裂问题\n\n4、详细描述一下es索引文档的过程？\n\n答：这里的索引文档应该理解为文档写入 es，创建索引的过程。\n\n第一步：客户端向集群某节点写入数据，发送请求。（如果没有指定路由/协调节点，请求的节点扮演协调节点的角色。） 第二步：协调节点接受到请求后，默认使用文档 id 参与计算（也支持通过 routing），得到该文档属于哪个分片。随后请求会被转到另外的节点。\n\n第三步：当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 memory buffer，然后定时（默认是每隔 1 秒）写入到f ilesystem cache，这个从 momery buffer 到 filesystem cache 的过程就叫做 refresh； 第四步：当然在某些情况下，存在 memery buffer 和 filesystem cache 的数据可能会丢失，es 是通过 translog 的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到 translog 中，当 filesystem cache 中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush； 第五步：在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的 fsync 将创建一个新的提交点，并将内容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。 第六步：flush 触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512 m）时。\n\n补充：关于 lucene 的 segement\n\n * lucene 索引是由多个段组成，段本身是一个功能齐全的倒排索引。\n * 段是不可变的，允许 lucene 将新的文档增量地添加到索引中，而不用从头重建索引。\n * 对于每一个搜索请求而言，索引中的所有段都会被搜索，并且每个段会消耗 cpu 的时钟周、文件句柄和内存。这意味着段的数量越多，搜索性能会越低。\n * 为了解决这个问题，elasticsearch 会合并小段到一个较大的段，提交新的合并段到磁盘，并删除那些旧的小段。（段合并）\n\n5、详细描述一下es更新和删除文档的过程？\n\n答：删除和更新也都是写操作，但是 elasticsearch 中的文档是不可变的，因此不能被删除或者改动以展示其变更。\n\n磁盘上的每个段都有一个相应的 .del 文件。当删除请求发送后，文档并没有真的被删除，而是在 .del 文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在 .del 文件中被标记为删除的文档将不会被写入新段。\n\n在新的文档被创建时，elasticsearch 会为该文档指定一个版本号，当执行更新时，旧版本的文档在 .del 文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。\n\n6、详细描述一下es搜索的过程？\n\n答：搜索被执行成一个两阶段过程，即 query then fetch； query阶段： 查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。ps：在搜索的时候是会查询filesystem cache的，但是有部分数据还在memory buffer，所以搜索是近实时的。 每个分片返回各自优先队列中 所有文档的 id 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。 fetch阶段： 协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 get 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。\n\n7、在并发情况下，es如果保证读写一致？\n\n答：可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突； 另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。 对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。\n\n8、 es对于大数据量（上亿量级）的聚合如何实现？\n\n答：elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于hll算法的。hll 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关\n\n9、对于gc方面，在使用es时要注意什么？\n\n答：1）倒排词典的索引需要常驻内存，无法gc，需要监控data node上segment memory增长趋势。 2）各类缓存，field cache, filter cache, indexing cache, bulk queue等等，要设置合理的大小，并且要应该根据最坏的情况来看heap是否够用，也就是各类缓存全部占满的时候，还有heap空间可以分配给其他任务吗？避免采用clear cache等“自欺欺人”的方式来释放内存。 3）避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用scan & scroll api来实现。 4）cluster stats驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过tribe node连接。 5）想知道heap够不够，必须结合实际应用场景，并对集群的heap使用情况做持续的监控。\n\n10、说说你们公司es的集群架构，索引数据大小，分片有多少，以及一些调优手段？\n\n答：根据实际情况回答即可，如果是我的话会这么回答： 我司有多个es集群，下面列举其中一个。该集群有20个节点，根据数据类型和日期分库，每个索引根据数据量分片，比如日均1亿+数据的，控制单索引大小在200gb以内。　 下面重点列举一些调优策略，仅是我做过的，不一定全面，如有其它建议或者补充欢迎留言。 部署层面： 1）最好是64gb内存的物理机器，但实际上32gb和16gb机器用的比较多，但绝对不能少于8g，除非数据量特别少，这点需要和客户方面沟通并合理说服对方。 2）多个内核提供的额外并发远胜过稍微快一点点的时钟频率。 3）尽量使用ssd，因为查询和索引性能将会得到显著提升。 4）避免集群跨越大的地理距离，一般一个集群的所有节点位于一个数据中心中。 5）设置堆内存：节点内存/2，不要超过32gb。一般来说设置export es_heap_size=32g环境变量，比直接写-xmx32g -xms32g更好一点。 6）关闭缓存swap。内存交换到磁盘对服务器性能来说是致命的。如果内存交换到磁盘上，一个100微秒的操作可能变成10毫秒。 再想想那么多10微秒的操作时延累加起来。不难看出swapping对于性能是多么可怕。 7）增加文件描述符，设置一个很大的值，如65535。lucene使用了大量的文件，同时，elasticsearch在节点和http客户端之间进行通信也使用了大量的套接字。所有这一切都需要足够的文件描述符。 8）不要随意修改垃圾回收器（cms）和各个线程池的大小。 9）通过设置gateway.recover_after_nodes、gateway.expected_nodes、gateway.recover_after_time可以在集群重启的时候避免过多的分片交换，这可能会让数据恢复从数个小时缩短为几秒钟。 索引层面： 1）使用批量请求并调整其大小：每次批量数据 5–15 mb 大是个不错的起始点。 2）段合并：elasticsearch默认值是20mb/s，对机械磁盘应该是个不错的设置。如果你用的是ssd，可以考虑提高到100-200mb/s。如果你在做批量导入，完全不在意搜索，你可以彻底关掉合并限流。另外还可以增加 index.translog.flush_threshold_size 设置，从默认的512mb到更大一些的值，比如1gb，这可以在一次清空触发的时候在事务日志里积累出更大的段。 3）如果你的搜索结果不需要近实时的准确度，考虑把每个索引的index.refresh_interval 改到30s。 4）如果你在做大批量导入，考虑通过设置index.number_of_replicas: 0 关闭副本。 5）需要大量拉取数据的场景，可以采用scan & scroll api来实现，而不是from/size一个大范围。 存储层面： 1）基于数据+时间滚动创建索引，每天递增数据。控制单个索引的量，一旦单个索引很大，存储等各种风险也随之而来，所以要提前考虑+及早避免。 2）冷热数据分离存储，热数据（比如最近3天或者一周的数据），其余为冷数据。对于冷数据不会再写入新数据，可以考虑定期force_merge加shrink压缩操作，节省存储空间和检索效率。",charsets:{cjk:!0}},{title:"MongoDB面试题",frontmatter:{title:"MongoDB面试题",date:"2023-04-20T15:57:37.000Z",permalink:"/pages/5201b9/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/03.MongoDB%E9%9D%A2%E8%AF%95%E9%A2%98/01.MongoDB%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/03.MongoDB面试题/01.MongoDB面试题.md",key:"v-3f973327",path:"/pages/5201b9/",headersStr:null,content:"# MongoDB面试题\n\n1、MySQL与MongoDB之间最基本的差别是什么?\n\n答：MySQL和MongoDB两者都是免费开源的数据库。MySQL和MongoDB有许多基本差别包括数据的表示(data representation)，查询，关系，事务，schema的设计和定义，标准化(normalization)，速度和性能。\n\n通过比较MySQL和MongoDB，实际上我们是在比较关系型和非关系型数据库，即数据存储结构不同。详细阅读\n\n2、MongoDB成为最好NoSQL数据库的原因是什么?\n\n答：以下特点使得MongoDB成为最好的NoSQL数据库：\n\n * 面向文件的\n * 高性能\n * 高可用性\n * 易扩展性\n * 丰富的查询语言\n\n3、分析器在MongoDB中的作用是什么?\n\n答：MongoDB中包括了一个可以显示数据库中每个操作性能特点的数据库分析器。通过这个分析器你可以找到比预期慢的查询(或写操作);利用这一信息，比如，可以确定是否需要添加索引。\n\n4、如果用户移除对象的属性，该属性是否从存储层中删除?\n\n答：是的，用户移除属性然后对象会重新保存(re-save())。\n\n5、更新操作立刻fsync到磁盘?\n\n答：不会，磁盘写操作默认是延迟执行的。写操作可能在两三秒(默认在60秒内)后到达磁盘。例如，如果一秒内数据库收到一千个对一个对象递增的操作，仅刷新磁盘一次。\n\n6、什么是master或primary?\n\n答：它是当前备份集群(replica set)中负责处理所有写入操作的主要节点/成员。在一个备份集群中，当失效备援(failover)事件发生时，一个另外的成员会变成primary。\n\n7、 数据在什么时候才会扩展到多个分片(shard)里?\n\n答：MongoDB 分片是基于区域(range)的。所以一个集合(collection)中的所有的对象都被存放到一个块(chunk)中。只有当存在多余一个块的时候，才会有多个分片获取数据的选项。现在，每个默认块的大小是 64Mb，所以你需要至少 64 Mb 空间才可以实施一个迁移。\n\n8、分片(sharding)和复制(replication)是怎样工作的?\n\n答：每一个分片(shard)是一个分区数据的逻辑集合。分片可能由单一服务器或者集群组成，我们推荐为每一个分片(shard)使用集群。\n\n9、如果块移动操作(moveChunk)失败了，我需要手动清除部分转移的文档吗?\n\n答：不需要，移动操作是一致(consistent)并且是确定性的(deterministic);一次失败后，移动操作会不断重试;当完成后，数据只会出现在新的分片里(shard)。\n\n10、如果一个分片（Shard）停止或很慢的时候，发起一个查询会怎样？\n\n答：如果一个分片停止了，除非查询设置了“Partial”选项，否则查询会返回一个错误。如果一个分片响应很慢，MongoDB会等待它的响应。\n\n11、如何理解MongoDB中的GridFS机制，MongoDB为何使用GridFS来存储文件？\n\n答：GridFS是一种将大型文件存储在MongoDB中的文件规范。使用GridFS可以将大文件分隔成多个小文档存放，这样我们能够有效的保存大文档，而且解决了BSON对象有限制的问题。\n\n12、MongoDB支持存储过程吗？如果支持的话，怎么用？\n\n答：MongoDB支持存储过程，它是javascript写的，保存在db.system.js表中。\n\n13、当更新一个正在被迁移的块（Chunk）上的文档时会发生什么？\n\n答：更新操作会立即发生在旧的块（Chunk）上，然后更改才会在所有权转移前复制到新的分片上。",normalizedContent:"# mongodb面试题\n\n1、mysql与mongodb之间最基本的差别是什么?\n\n答：mysql和mongodb两者都是免费开源的数据库。mysql和mongodb有许多基本差别包括数据的表示(data representation)，查询，关系，事务，schema的设计和定义，标准化(normalization)，速度和性能。\n\n通过比较mysql和mongodb，实际上我们是在比较关系型和非关系型数据库，即数据存储结构不同。详细阅读\n\n2、mongodb成为最好nosql数据库的原因是什么?\n\n答：以下特点使得mongodb成为最好的nosql数据库：\n\n * 面向文件的\n * 高性能\n * 高可用性\n * 易扩展性\n * 丰富的查询语言\n\n3、分析器在mongodb中的作用是什么?\n\n答：mongodb中包括了一个可以显示数据库中每个操作性能特点的数据库分析器。通过这个分析器你可以找到比预期慢的查询(或写操作);利用这一信息，比如，可以确定是否需要添加索引。\n\n4、如果用户移除对象的属性，该属性是否从存储层中删除?\n\n答：是的，用户移除属性然后对象会重新保存(re-save())。\n\n5、更新操作立刻fsync到磁盘?\n\n答：不会，磁盘写操作默认是延迟执行的。写操作可能在两三秒(默认在60秒内)后到达磁盘。例如，如果一秒内数据库收到一千个对一个对象递增的操作，仅刷新磁盘一次。\n\n6、什么是master或primary?\n\n答：它是当前备份集群(replica set)中负责处理所有写入操作的主要节点/成员。在一个备份集群中，当失效备援(failover)事件发生时，一个另外的成员会变成primary。\n\n7、 数据在什么时候才会扩展到多个分片(shard)里?\n\n答：mongodb 分片是基于区域(range)的。所以一个集合(collection)中的所有的对象都被存放到一个块(chunk)中。只有当存在多余一个块的时候，才会有多个分片获取数据的选项。现在，每个默认块的大小是 64mb，所以你需要至少 64 mb 空间才可以实施一个迁移。\n\n8、分片(sharding)和复制(replication)是怎样工作的?\n\n答：每一个分片(shard)是一个分区数据的逻辑集合。分片可能由单一服务器或者集群组成，我们推荐为每一个分片(shard)使用集群。\n\n9、如果块移动操作(movechunk)失败了，我需要手动清除部分转移的文档吗?\n\n答：不需要，移动操作是一致(consistent)并且是确定性的(deterministic);一次失败后，移动操作会不断重试;当完成后，数据只会出现在新的分片里(shard)。\n\n10、如果一个分片（shard）停止或很慢的时候，发起一个查询会怎样？\n\n答：如果一个分片停止了，除非查询设置了“partial”选项，否则查询会返回一个错误。如果一个分片响应很慢，mongodb会等待它的响应。\n\n11、如何理解mongodb中的gridfs机制，mongodb为何使用gridfs来存储文件？\n\n答：gridfs是一种将大型文件存储在mongodb中的文件规范。使用gridfs可以将大文件分隔成多个小文档存放，这样我们能够有效的保存大文档，而且解决了bson对象有限制的问题。\n\n12、mongodb支持存储过程吗？如果支持的话，怎么用？\n\n答：mongodb支持存储过程，它是javascript写的，保存在db.system.js表中。\n\n13、当更新一个正在被迁移的块（chunk）上的文档时会发生什么？\n\n答：更新操作会立即发生在旧的块（chunk）上，然后更改才会在所有权转移前复制到新的分片上。",charsets:{cjk:!0}},{title:"MySql面试题",frontmatter:{title:"MySql面试题",date:"2023-04-20T15:57:56.000Z",permalink:"/pages/43b4dd/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/04.MySql%E9%9D%A2%E8%AF%95%E9%A2%98/01.MySql%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/04.MySql面试题/01.MySql面试题.md",key:"v-30230c72",path:"/pages/43b4dd/",headersStr:null,content:"# MySql面试题\n\n1、Mysql 的存储引擎,myisam和innodb的区别。\n\n答：\n\n1.MyISAM 是非事务的存储引擎，适合用于频繁查询的应用。表锁，不会出现死锁，适合小数据，小并发。\n\n2.innodb是支持事务的存储引擎，合于插入和更新操作比较多的应用，设计合理的话是行锁（最大区别就在锁的级别上），适合大数据，大并发。\n\n2、MySQL数据库作发布系统的存储，一天五万条以上的增量，预计运维三年,怎么优化？\n\n答：a. 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率。 b. 选择合适的表字段数据类型和存储引擎，适当的添加索引。 c. mysql库主从读写分离。 d. 找规律分表，减少单表中的数据量提高查询速度。 e。添加缓存机制，比如memcached，apc等。 f. 不经常改动的页面，生成静态页面。 g. 书写高效率的SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE.\n\n3、对于大流量的网站,您采用什么样的方法来解决各页面访问量统计问题？\n\n答：a. 确认服务器是否能支撑当前访问量。 b. 优化数据库访问。 c. 禁止外部访问链接（盗链）, 比如图片盗链。 d. 控制文件下载。 e. 使用不同主机分流。 f. 使用浏览统计软件，了解访问量，有针对性的进行优化。\n\n4、锁的优化策略\n\n答：① 读写分离\n\n② 分段加锁\n\n③ 减少锁持有的时间\n\n④ 多个线程尽量以相同的顺序去获取资源\n\n5、索引的底层实现原理和优化\n\n答：B+树，经过优化的B+树\n\n主要是在所有的叶子结点中增加了指向下一个叶子节点的指针，因此InnoDB建议为大部分表使用默认自增的主键作为主索引。\n\n6、 什么情况下设置了索引但无法使用\n\n答：① 以“%”开头的LIKE语句，模糊匹配\n\n② OR语句前后没有同时使用索引\n\n③ 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）\n\n7、实践中如何优化MySQL\n\n答：① SQL语句及索引的优化\n\n② 数据库表结构的优化\n\n③ 系统配置的优化\n\n④ 硬件的优化\n\n8、SQL注入漏洞产生的原因？如何防止？\n\n答：SQL注入产生的原因：程序开发过程中不注意规范书写sql语句和对特殊字符进行过滤，导致客户端可以通过全局变量POST和GET提交一些sql语句正常执行。\n\n防止SQL注入的方式： 开启配置文件中的magic_quotes_gpc 和 magic_quotes_runtime设置\n\n执行sql语句时使用addslashes进行sql语句转换\n\nSql语句书写尽量不要省略双引号和单引号。\n\n过滤掉sql语句中的一些关键词：update、insert、delete、select、 * 。\n\n提高数据库表和字段的命名技巧，对一些重要的字段根据程序的特点命名，取不易被猜到的。\n\nPhp配置文件中设置register_globals为off,关闭全局变量注册\n\n控制错误信息，不要在浏览器上输出错误信息，将错误信息写到日志文件中。\n\n9、索引的目的是什么？\n\n答：快速访问数据表中的特定信息，提高检索速度\n\n创建唯一性索引，保证数据库表中每一行数据的唯一性。\n\n加速表和表之间的连接\n\n使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间\n\n10、索引对数据库系统的负面影响是什么？\n\n答：负面影响： 创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加；索引需要占用物理空间，不光是表需要占用数据空间，每个索引也需要占用物理空间；当对表进行增、删、改、的时候索引也要动态维护，这样就降低了数据的维护速度。\n\n11、为数据表建立索引的原则有哪些？\n\n答：在最频繁使用的、用以缩小查询范围的字段上建立索引。\n\n在频繁使用的、需要排序的字段上建立索引\n\n12、什么情况下不宜建立索引？\n\n答：对于查询中很少涉及的列或者重复值比较多的列，不宜建立索引。\n\n对于一些特殊的数据类型，不宜建立索引，比如文本字段（text）等\n\n13、主键、外键和索引的区别？\n\n答：主键、外键和索引的区别\n\n定义：\n\n主键–唯一标识一条记录，不能有重复的，不允许为空\n\n外键–表的外键是另一表的主键, 外键可以有重复的, 可以是空值\n\n索引–该字段没有重复值，但可以有一个空值\n\n作用：\n\n主键–用来保证数据完整性\n\n外键–用来和其他表建立联系用的\n\n索引–是提高查询排序的速度\n\n个数：\n\n主键–主键只能有一个\n\n外键–一个表可以有多个外键\n\n索引–一个表可以有多个唯一索引",normalizedContent:"# mysql面试题\n\n1、mysql 的存储引擎,myisam和innodb的区别。\n\n答：\n\n1.myisam 是非事务的存储引擎，适合用于频繁查询的应用。表锁，不会出现死锁，适合小数据，小并发。\n\n2.innodb是支持事务的存储引擎，合于插入和更新操作比较多的应用，设计合理的话是行锁（最大区别就在锁的级别上），适合大数据，大并发。\n\n2、mysql数据库作发布系统的存储，一天五万条以上的增量，预计运维三年,怎么优化？\n\n答：a. 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率。 b. 选择合适的表字段数据类型和存储引擎，适当的添加索引。 c. mysql库主从读写分离。 d. 找规律分表，减少单表中的数据量提高查询速度。 e。添加缓存机制，比如memcached，apc等。 f. 不经常改动的页面，生成静态页面。 g. 书写高效率的sql。比如 select * from tabel 改为 select field_1, field_2, field_3 from table.\n\n3、对于大流量的网站,您采用什么样的方法来解决各页面访问量统计问题？\n\n答：a. 确认服务器是否能支撑当前访问量。 b. 优化数据库访问。 c. 禁止外部访问链接（盗链）, 比如图片盗链。 d. 控制文件下载。 e. 使用不同主机分流。 f. 使用浏览统计软件，了解访问量，有针对性的进行优化。\n\n4、锁的优化策略\n\n答：① 读写分离\n\n② 分段加锁\n\n③ 减少锁持有的时间\n\n④ 多个线程尽量以相同的顺序去获取资源\n\n5、索引的底层实现原理和优化\n\n答：b+树，经过优化的b+树\n\n主要是在所有的叶子结点中增加了指向下一个叶子节点的指针，因此innodb建议为大部分表使用默认自增的主键作为主索引。\n\n6、 什么情况下设置了索引但无法使用\n\n答：① 以“%”开头的like语句，模糊匹配\n\n② or语句前后没有同时使用索引\n\n③ 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）\n\n7、实践中如何优化mysql\n\n答：① sql语句及索引的优化\n\n② 数据库表结构的优化\n\n③ 系统配置的优化\n\n④ 硬件的优化\n\n8、sql注入漏洞产生的原因？如何防止？\n\n答：sql注入产生的原因：程序开发过程中不注意规范书写sql语句和对特殊字符进行过滤，导致客户端可以通过全局变量post和get提交一些sql语句正常执行。\n\n防止sql注入的方式： 开启配置文件中的magic_quotes_gpc 和 magic_quotes_runtime设置\n\n执行sql语句时使用addslashes进行sql语句转换\n\nsql语句书写尽量不要省略双引号和单引号。\n\n过滤掉sql语句中的一些关键词：update、insert、delete、select、 * 。\n\n提高数据库表和字段的命名技巧，对一些重要的字段根据程序的特点命名，取不易被猜到的。\n\nphp配置文件中设置register_globals为off,关闭全局变量注册\n\n控制错误信息，不要在浏览器上输出错误信息，将错误信息写到日志文件中。\n\n9、索引的目的是什么？\n\n答：快速访问数据表中的特定信息，提高检索速度\n\n创建唯一性索引，保证数据库表中每一行数据的唯一性。\n\n加速表和表之间的连接\n\n使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间\n\n10、索引对数据库系统的负面影响是什么？\n\n答：负面影响： 创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加；索引需要占用物理空间，不光是表需要占用数据空间，每个索引也需要占用物理空间；当对表进行增、删、改、的时候索引也要动态维护，这样就降低了数据的维护速度。\n\n11、为数据表建立索引的原则有哪些？\n\n答：在最频繁使用的、用以缩小查询范围的字段上建立索引。\n\n在频繁使用的、需要排序的字段上建立索引\n\n12、什么情况下不宜建立索引？\n\n答：对于查询中很少涉及的列或者重复值比较多的列，不宜建立索引。\n\n对于一些特殊的数据类型，不宜建立索引，比如文本字段（text）等\n\n13、主键、外键和索引的区别？\n\n答：主键、外键和索引的区别\n\n定义：\n\n主键–唯一标识一条记录，不能有重复的，不允许为空\n\n外键–表的外键是另一表的主键, 外键可以有重复的, 可以是空值\n\n索引–该字段没有重复值，但可以有一个空值\n\n作用：\n\n主键–用来保证数据完整性\n\n外键–用来和其他表建立联系用的\n\n索引–是提高查询排序的速度\n\n个数：\n\n主键–主键只能有一个\n\n外键–一个表可以有多个外键\n\n索引–一个表可以有多个唯一索引",charsets:{cjk:!0}},{title:"RabbitMQ面试题",frontmatter:{title:"RabbitMQ面试题",date:"2023-04-20T15:59:14.000Z",permalink:"/pages/d74e41/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/06.RabbitMQ%E9%9D%A2%E8%AF%95%E9%A2%98/01.RabbitMQ%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/06.RabbitMQ面试题/01.RabbitMQ面试题.md",key:"v-26d51feb",path:"/pages/d74e41/",headersStr:null,content:"# RabbitMQ面试题\n\n1、如何保证RabbitMQ消息的顺序性？\n\n答：\n\n * 拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点；\n * 或者就一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理。\n\n2、消息如何分发？\n\n答：\n\n * 若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。通过路由可实现多消费的功能\n\n3、消息基于什么传输？\n\n答：\n\n * 由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。\n\n4、如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？\n\n答：\n\n * 先说为什么会重复消费：正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；\n * 但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。\n * 针对以上问题，一个解决思路是：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；\n   * 比如：在写入消息队列的数据做唯一标示，消费消息时，根据唯一标识判断是否消费过；\n   * 假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。\n\n5、如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？\n\n答：发送方确认模式\n\n * 将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。\n * 一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。\n * 如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。\n * 发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。\n\n接收方确认机制\n\n * 消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。\n * 这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；\n\n下面罗列几种特殊情况\n\n * 如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）\n * 如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。\n\n6、如何保证RabbitMQ消息的可靠传输？\n\n答：\n\n * 消息不可靠的情况可能是消息丢失，劫持等原因；\n * 丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；\n\n产者丢失消息\n\n 1. 生产者丢失消息：从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；\n    \n    transaction机制就是说：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；\n    \n    confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；\n    \n    rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；\n    \n    如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。\n\n消息队列丢数据\n\n 1. 消息队列丢数据：消息持久化。\n    \n    处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。\n    \n    这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。\n    \n    这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。\n    \n    那么如何持久化呢？\n    \n    这里顺便说一下吧，其实也很容易，就下面两步\n    \n    1. 将queue的持久化标识durable设置为true,则代表是一个持久的队列\n    2. 发送消息的时候将deliveryMode=2\n    \n    这样设置以后，即使rabbitMQ挂了，重启后也能恢复数据\n\n消费者丢失消息\n\n 1. 消费者丢失消息：消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！\n    \n    消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；\n    \n    如果这时处理消息失败，就会丢失该消息；\n    \n    解决方案：处理消息成功后，手动回复确认消息。\n\n7、为什么不应该对所有的 message 都使用持久化机制？\n\n答：\n\n * 首先，必然导致性能的下降，因为写磁盘比写 RAM 慢的多，message 的吞吐量可能有 10 倍的差距。\n * 其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。矛盾点在于，若 message 设置了 persistent 属性，但 queue 未设置 durable 属性，那么当该 queue 的 owner node 出现异常后，在未重建该 queue 前，发往该 queue 的 message 将被 blackholed ；若 message 设置了 persistent 属性，同时 queue 也设置了 durable 属性，那么当 queue 的 owner node 异常且无法重启的情况下，则该 queue 无法在其他 node 上重建，只能等待其 owner node 重启后，才能恢复该 queue 的使用，而在这段时间内发送给该 queue 的 message 将被 blackholed 。\n * 所以，是否要对 message 进行持久化，需要综合考虑性能需要，以及可能遇到的问题。若想达到 100,000 条/秒以上的消息吞吐量（单 RabbitMQ 服务器），则要么使用其他的方式来确保 message 的可靠 delivery ，要么使用非常快速的存储系统以支持全持久化（例如使用 SSD）。另外一种处理原则是：仅对关键消息作持久化处理（根据业务重要程度），且应该保证关键消息的量不会导致性能瓶颈。\n\n8、如何保证高可用的？RabbitMQ 的集群\n\n答：\n\n * RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。\n\n单机模式\n\n 1. 单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的?，没人生产用单机模式\n\n普通集群模式\n\n 1. 普通集群模式\n    \n    ：\n    \n    * 意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。\n    * 你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。\n\n像集群模式\n\n 1. 镜像集群模式：\n    * 这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。\n    * 这样的好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。\n\n8、如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？\n\n答：\n\n * 消息积压处理办法：临时紧急扩容：\n * 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 cnosumer 都停掉。 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。 MQ中消息失效：假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。\n * mq消息队列块满了：如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。\n\n9、消息的重复问题\n\n答：\n\n * 造成消息重复的根本原因是：网络不可达。\n * 所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？\n * 消费端处理消息的业务逻辑保持幂等性。只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。利用一张日志表来记录已经处理成功的消息的 ID，如果新到的消息 ID 已经在日志表中，那么就不再处理这条消息。\n\n10、rabbitmq 的使用场景\n\n答：\n\n（1）服务间异步通信\n\n（2）顺序消费\n\n（3）定时任务\n\n（4）请求削峰\n\n11、消息队列有什么优缺点？RabbitMQ有什么优缺点？\n\n答：\n\n * 优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。\n * 缺点有以下几个：\n\n 1. 系统可用性降低 本来系统运行好好的，现在你非要加入个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性会降低；\n 2. 系统复杂度提高 加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂性增大。\n 3. 一致性问题 A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。",normalizedContent:"# rabbitmq面试题\n\n1、如何保证rabbitmq消息的顺序性？\n\n答：\n\n * 拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点；\n * 或者就一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理。\n\n2、消息如何分发？\n\n答：\n\n * 若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。通过路由可实现多消费的功能\n\n3、消息基于什么传输？\n\n答：\n\n * 由于 tcp 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。rabbitmq 使用信道的方式来传输数据。信道是建立在真实的 tcp 连接内的虚拟连接，且每条 tcp 连接上的信道数量没有限制。\n\n4、如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？\n\n答：\n\n * 先说为什么会重复消费：正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；\n * 但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。\n * 针对以上问题，一个解决思路是：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；\n   * 比如：在写入消息队列的数据做唯一标示，消费消息时，根据唯一标识判断是否消费过；\n   * 假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。\n\n5、如何确保消息正确地发送至 rabbitmq？ 如何确保消息接收方消费了消息？\n\n答：发送方确认模式\n\n * 将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 id。\n * 一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 id）。\n * 如果 rabbitmq 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。\n * 发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。\n\n接收方确认机制\n\n * 消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，rabbitmq 才能安全地把消息从队列中删除。\n * 这里并没有用到超时机制，rabbitmq 仅通过 consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，rabbitmq 给了 consumer 足够长的时间来处理消息。保证数据的最终一致性；\n\n下面罗列几种特殊情况\n\n * 如果消费者接收到消息，在确认之前断开了连接或取消订阅，rabbitmq 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）\n * 如果消费者接收到消息却没有确认消息，连接也未断开，则 rabbitmq 认为该消费者繁忙，将不会给该消费者分发更多的消息。\n\n6、如何保证rabbitmq消息的可靠传输？\n\n答：\n\n * 消息不可靠的情况可能是消息丢失，劫持等原因；\n * 丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；\n\n产者丢失消息\n\n 1. 生产者丢失消息：从生产者弄丢数据这个角度来看，rabbitmq提供transaction和confirm模式来确保生产者不丢消息；\n    \n    transaction机制就是说：发送消息前，开启事务（channel.txselect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txrollback()）,如果发送成功则提交事务（channel.txcommit()）。然而，这种方式有个缺点：吞吐量下降；\n    \n    confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的id（从1开始），一旦消息被投递到所有匹配的队列之后；\n    \n    rabbitmq就会发送一个ack给生产者（包含消息的唯一id），这就使得生产者知道消息已经正确到达目的队列了；\n    \n    如果rabbitmq没能处理该消息，则会发送一个nack消息给你，你可以进行重试操作。\n\n消息队列丢数据\n\n 1. 消息队列丢数据：消息持久化。\n    \n    处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。\n    \n    这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个ack信号。\n    \n    这样，如果消息持久化磁盘之前，rabbitmq阵亡了，那么生产者收不到ack信号，生产者会自动重发。\n    \n    那么如何持久化呢？\n    \n    这里顺便说一下吧，其实也很容易，就下面两步\n    \n    1. 将queue的持久化标识durable设置为true,则代表是一个持久的队列\n    2. 发送消息的时候将deliverymode=2\n    \n    这样设置以后，即使rabbitmq挂了，重启后也能恢复数据\n\n消费者丢失消息\n\n 1. 消费者丢失消息：消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！\n    \n    消费者在收到消息之后，处理消息之前，会自动回复rabbitmq已收到消息；\n    \n    如果这时处理消息失败，就会丢失该消息；\n    \n    解决方案：处理消息成功后，手动回复确认消息。\n\n7、为什么不应该对所有的 message 都使用持久化机制？\n\n答：\n\n * 首先，必然导致性能的下降，因为写磁盘比写 ram 慢的多，message 的吞吐量可能有 10 倍的差距。\n * 其次，message 的持久化机制用在 rabbitmq 的内置 cluster 方案时会出现“坑爹”问题。矛盾点在于，若 message 设置了 persistent 属性，但 queue 未设置 durable 属性，那么当该 queue 的 owner node 出现异常后，在未重建该 queue 前，发往该 queue 的 message 将被 blackholed ；若 message 设置了 persistent 属性，同时 queue 也设置了 durable 属性，那么当 queue 的 owner node 异常且无法重启的情况下，则该 queue 无法在其他 node 上重建，只能等待其 owner node 重启后，才能恢复该 queue 的使用，而在这段时间内发送给该 queue 的 message 将被 blackholed 。\n * 所以，是否要对 message 进行持久化，需要综合考虑性能需要，以及可能遇到的问题。若想达到 100,000 条/秒以上的消息吞吐量（单 rabbitmq 服务器），则要么使用其他的方式来确保 message 的可靠 delivery ，要么使用非常快速的存储系统以支持全持久化（例如使用 ssd）。另外一种处理原则是：仅对关键消息作持久化处理（根据业务重要程度），且应该保证关键消息的量不会导致性能瓶颈。\n\n8、如何保证高可用的？rabbitmq 的集群\n\n答：\n\n * rabbitmq 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 rabbitmq 为例子讲解第一种 mq 的高可用性怎么实现。rabbitmq 有三种模式：单机模式、普通集群模式、镜像集群模式。\n\n单机模式\n\n 1. 单机模式，就是 demo 级别的，一般就是你本地启动了玩玩儿的?，没人生产用单机模式\n\n普通集群模式\n\n 1. 普通集群模式\n    \n    ：\n    \n    * 意思就是在多台机器上启动多个 rabbitmq 实例，每个机器启动一个。\n    * 你创建的 queue，只会放在一个 rabbitmq 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。\n\n像集群模式\n\n 1. 镜像集群模式：\n    * 这种模式，才是所谓的 rabbitmq 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 rabbitmq 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。rabbitmq 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。\n    * 这样的好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！rabbitmq 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。\n\n8、如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？\n\n答：\n\n * 消息积压处理办法：临时紧急扩容：\n * 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 cnosumer 都停掉。 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。 mq中消息失效：假设你用的是 rabbitmq，rabbtimq 是可以设置过期时间的，也就是 ttl。如果消息在 queue 中积压超过一定的时间就会被 rabbitmq 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。\n * mq消息队列块满了：如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。\n\n9、消息的重复问题\n\n答：\n\n * 造成消息重复的根本原因是：网络不可达。\n * 所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？\n * 消费端处理消息的业务逻辑保持幂等性。只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。利用一张日志表来记录已经处理成功的消息的 id，如果新到的消息 id 已经在日志表中，那么就不再处理这条消息。\n\n10、rabbitmq 的使用场景\n\n答：\n\n（1）服务间异步通信\n\n（2）顺序消费\n\n（3）定时任务\n\n（4）请求削峰\n\n11、消息队列有什么优缺点？rabbitmq有什么优缺点？\n\n答：\n\n * 优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。\n * 缺点有以下几个：\n\n 1. 系统可用性降低 本来系统运行好好的，现在你非要加入个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性会降低；\n 2. 系统复杂度提高 加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂性增大。\n 3. 一致性问题 a 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 bcd 三个系统那里，bd 两个系统写库成功了，结果 c 系统写库失败了，咋整？你这数据就不一致了。",charsets:{cjk:!0}},{title:"Nginx面试题",frontmatter:{title:"Nginx面试题",date:"2023-04-20T15:58:51.000Z",permalink:"/pages/27153d/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/05.Nginx%E9%9D%A2%E8%AF%95%E9%A2%98/01.Nginx%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/05.Nginx面试题/01.Nginx面试题.md",key:"v-03d9b432",path:"/pages/27153d/",headersStr:null,content:"# Nginx面试题\n\n1、nginx是如何实现高并发的？\n\n答：一个主进程，多个工作进程，每个工作进程可以处理多个请求，每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到可能发生阻塞的地方，比如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理的worker继续处理其他请求，而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往下走。由于web server的工作性质决定了每个request的大部份生命都是在网络传输中，实际上花费在server机器上的时间片不多。这是几个进程就解决高并发的秘密所在。即@skoo所说的webserver刚好属于网络io密集型应用，不算是计算密集型。\n\n2、Nginx如何处理HTTP请求？\n\n答：Nginx使用反应器模式。主事件循环等待操作系统发出准备事件的信号，这样数据就可以从套接字读取，在该实例中读取到缓冲区并进行处理。单个线程可以提供数万个并发连接。\n\n3、使用“反向代理服务器”的优点是什么?\n\n答：反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时。\n\n4、列举Nginx服务器的最佳用途。\n\n答：Nginx服务器的最佳用法是在网络上部署动态HTTP内容，使用SCGI、WSGI应用程序服务器、用于脚本的FastCGI处理程序。它还可以作为负载均衡器。\n\n5、Nginx服务器上的Master和Worker进程分别是什么?\n\n答：Master进程：读取及评估配置和维持 ；Worker进程：处理请求。\n\n6、什么是C10K问题?\n\n答：C10K问题是指无法同时处理大量客户端(10,000)的网络套接字。\n\n7、请陈述stub_status和sub_filter指令的作用是什么?\n\n答：（1）Stub_status指令：该指令用于了解Nginx当前状态的当前状态，如当前的活动连接，接受和处理当前读/写/等待连接的总数 ；（2）Sub_filter指令：它用于搜索和替换响应中的内容，并快速修复陈旧的数据\n\n8、为什么不使用多线程？\n\n答：Nginx:采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量），不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换，所以才使得Nginx支持更高的并发。\n\n9、为什么要做动、静分离？\n\n答：在我们的软件开发中，有些请求是需要后台处理的（如：.jsp,.do等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js等等），这些不需要经过后台处理的文件称为静态文件，否则动态文件。因此我们后台处理忽略静态文件，但是如果直接忽略静态文件的话，后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，应该使用这种动静分离的策略去解决动、静分离将网站静态资源（HTML，JavaScript，CSS等）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问。这里将静态资源放到nginx中，动态资源转发到tomcat服务器中,毕竟Tomcat的优势是处理动态请求。\n\n10、ngx_http_upstream_module的作用是什么?\n\n答：要在URL中保留双斜线，就必须使用merge_slashes_off；语法:merge_slashes [on/off] ； 默认值: merge_slashes on ；环境: http，server",normalizedContent:"# nginx面试题\n\n1、nginx是如何实现高并发的？\n\n答：一个主进程，多个工作进程，每个工作进程可以处理多个请求，每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到可能发生阻塞的地方，比如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理的worker继续处理其他请求，而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往下走。由于web server的工作性质决定了每个request的大部份生命都是在网络传输中，实际上花费在server机器上的时间片不多。这是几个进程就解决高并发的秘密所在。即@skoo所说的webserver刚好属于网络io密集型应用，不算是计算密集型。\n\n2、nginx如何处理http请求？\n\n答：nginx使用反应器模式。主事件循环等待操作系统发出准备事件的信号，这样数据就可以从套接字读取，在该实例中读取到缓冲区并进行处理。单个线程可以提供数万个并发连接。\n\n3、使用“反向代理服务器”的优点是什么?\n\n答：反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时。\n\n4、列举nginx服务器的最佳用途。\n\n答：nginx服务器的最佳用法是在网络上部署动态http内容，使用scgi、wsgi应用程序服务器、用于脚本的fastcgi处理程序。它还可以作为负载均衡器。\n\n5、nginx服务器上的master和worker进程分别是什么?\n\n答：master进程：读取及评估配置和维持 ；worker进程：处理请求。\n\n6、什么是c10k问题?\n\n答：c10k问题是指无法同时处理大量客户端(10,000)的网络套接字。\n\n7、请陈述stub_status和sub_filter指令的作用是什么?\n\n答：（1）stub_status指令：该指令用于了解nginx当前状态的当前状态，如当前的活动连接，接受和处理当前读/写/等待连接的总数 ；（2）sub_filter指令：它用于搜索和替换响应中的内容，并快速修复陈旧的数据\n\n8、为什么不使用多线程？\n\n答：nginx:采用单线程来异步非阻塞处理请求（管理员可以配置nginx主进程的工作进程的数量），不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的cpu的上下文切换，所以才使得nginx支持更高的并发。\n\n9、为什么要做动、静分离？\n\n答：在我们的软件开发中，有些请求是需要后台处理的（如：.jsp,.do等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js等等），这些不需要经过后台处理的文件称为静态文件，否则动态文件。因此我们后台处理忽略静态文件，但是如果直接忽略静态文件的话，后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，应该使用这种动静分离的策略去解决动、静分离将网站静态资源（html，javascript，css等）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问。这里将静态资源放到nginx中，动态资源转发到tomcat服务器中,毕竟tomcat的优势是处理动态请求。\n\n10、ngx_http_upstream_module的作用是什么?\n\n答：要在url中保留双斜线，就必须使用merge_slashes_off；语法:merge_slashes [on/off] ； 默认值: merge_slashes on ；环境: http，server",charsets:{cjk:!0}},{title:"Redis面试题",frontmatter:{title:"Redis面试题",date:"2023-04-20T15:59:40.000Z",permalink:"/pages/97e5f1/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/07.Redis%E9%9D%A2%E8%AF%95%E9%A2%98/01.Redis%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/07.Redis面试题/01.Redis面试题.md",key:"v-d6f86d32",path:"/pages/97e5f1/",headersStr:null,content:"# Redis面试题\n\n1、Redis 有哪几种数据淘汰策略？\n\n答：\n\n * noeviction:返回错误当内存限制达到，并且客户端尝试执行会让更多内存被使用的命令。\n * allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。\n * volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。\n * allkeys-random: 回收随机的键使得新添加的数据有空间存放。\n * volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。\n * volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。\n\n2、Redis 一个字符串类型的值能存储最大容量是多少？\n\n512M\n\n3、为什么 Redis 需要把所有数据放到内存中？\n\n答：Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。\n\n所以 redis 具有快速和数据持久化的特征，如果不将数据放在内存中，磁盘 I/O 速度为严重影响 redis 的性能。\n\n在内存越来越便宜的今天，redis 将会越来越受欢迎， 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。\n\n4、Redis 集群方案应该怎么做？都有哪些方案？\n\n * codis\n * 目前用的最多的集群方案，基本和 twemproxy 一致的效果，但它支持在节点数量改变情况下，旧节点数据可恢复到新 hash 节点。\n * redis cluster3.0 自带的集群，特点在于他的分布式算法不是一致性 hash，而是 hash 槽的概念，以及自身支持节点设置从节点。\n * 在业务代码层实现，起几个毫无关联的 redis 实例，在代码层，对 key 进行 hash 计算，然后去对应的redis 实例操作数据。这种方式对 hash 层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。\n\n5、Redis 集群方案什么情况下会导致整个集群不可用？\n\n答：有 A，B，C 三个节点的集群,在没有复制模型的情况下,如果节点 B 失败了，那么整个集群就会以为缺少5501-11000 这个范围的槽而不可用。\n\n6、MySQL 里有 2000w 数据，redis 中只存 20w 的数据，如何保证 redis 中的数据都是热点数据？\n\n答：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。\n\n7、Redis 有哪些适合的场景？\n\n会话缓存（Session Cache）\n\n全页缓存（FPC）\n\n队列\n\n排行榜/计数器\n\n发布/订阅\n\n8、说说 Redis 哈希槽的概念？\n\n答：Redis 集群没有使用一致性 hash,而是引入了哈希槽的概念，Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分 hash 槽。\n\n9、Redis 集群的主从复制模型是怎样的？\n\n答：为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有 N-1 个复制品.\n\n10、Redis 集群会有写操作丢失吗？为什么？\n\n答：Redis 并不能保证数据的强一致性，这意味着在实际中集群在特定的条件下可能会丢失写操作。\n\n11、Redis 集群之间是如何复制的？\n\n答：异步复制\n\n12、Redis 集群最大节点个数是多少？\n\n答：16384 个\n\n13、Redis 集群如何选择数据库？\n\n答：Redis 集群目前无法做数据库选择，默认在 0 数据库。\n\n14、Redis 如何做内存优化？\n\n答：尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。\n\n比如你的 web 系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的 key,而是应该把这个用户的所有信息存储到一张散列表里面。\n\n15、什么是缓存穿透？如何避免？什么是缓存雪崩？何如避免？\n\n缓存穿透\n\n一般的缓存系统，都是按照 key 去缓存查询，如果不存在对应的 value，就应该去后端系统查找（比如DB）。一些恶意的请求会故意查询不存在的 key,请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。\n\n如何避免？\n\n> 1：对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该 key 对应的数据 insert 了之后清理缓存。\n> \n> 2：对一定不存在的 key 进行过滤。可以把所有的可能存在的 key 放到一个大的 Bitmap 中，查询时通过该 bitmap 过滤。\n\n缓存雪崩\n\n当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压力。导致系统崩溃。\n\n如何避免？\n\n> 1：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个 key 只允许一个线程查询数据和写缓存，其他线程等待。\n> \n> 2：做二级缓存，A1 为原始缓存，A2 为拷贝缓存，A1 失效时，可以访问 A2，A1 缓存失效时间设置为短期，A2 设置为长期\n> \n> 3：不同的 key，设置不同的过期时间，让缓存失效的时间点尽量均匀\n\n16、Redis 回收进程如何工作的？\n\n答：一个客户端运行了新的命令，添加了新的数据。Redi 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。一个新的命令被执行，等等。\n\n所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。\n\n如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。\n\n17、使用过 Redis 分布式锁么，它是怎么实现的？\n\n答：先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。\n\n如果在 setnx 之后执行 expire 之前进程意外 crash 或者要重启维护了，那会怎么样？\n\nset 指令有非常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成一条指令来用的！\n\n18、使用过 Redis 做异步队列么，你是怎么用的？有什么缺点？\n\n答：般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep一会再重试。\n\n缺点：\n\n * 在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 rabbitmq 等。\n * 能不能生产一次消费多次呢？\n * 使用 pub/sub 主题订阅者模式，可以实现 1:N 的消息队列。",normalizedContent:"# redis面试题\n\n1、redis 有哪几种数据淘汰策略？\n\n答：\n\n * noeviction:返回错误当内存限制达到，并且客户端尝试执行会让更多内存被使用的命令。\n * allkeys-lru: 尝试回收最少使用的键（lru），使得新添加的数据有空间存放。\n * volatile-lru: 尝试回收最少使用的键（lru），但仅限于在过期集合的键,使得新添加的数据有空间存放。\n * allkeys-random: 回收随机的键使得新添加的数据有空间存放。\n * volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。\n * volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（ttl）较短的键,使得新添加的数据有空间存放。\n\n2、redis 一个字符串类型的值能存储最大容量是多少？\n\n512m\n\n3、为什么 redis 需要把所有数据放到内存中？\n\n答：redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。\n\n所以 redis 具有快速和数据持久化的特征，如果不将数据放在内存中，磁盘 i/o 速度为严重影响 redis 的性能。\n\n在内存越来越便宜的今天，redis 将会越来越受欢迎， 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。\n\n4、redis 集群方案应该怎么做？都有哪些方案？\n\n * codis\n * 目前用的最多的集群方案，基本和 twemproxy 一致的效果，但它支持在节点数量改变情况下，旧节点数据可恢复到新 hash 节点。\n * redis cluster3.0 自带的集群，特点在于他的分布式算法不是一致性 hash，而是 hash 槽的概念，以及自身支持节点设置从节点。\n * 在业务代码层实现，起几个毫无关联的 redis 实例，在代码层，对 key 进行 hash 计算，然后去对应的redis 实例操作数据。这种方式对 hash 层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。\n\n5、redis 集群方案什么情况下会导致整个集群不可用？\n\n答：有 a，b，c 三个节点的集群,在没有复制模型的情况下,如果节点 b 失败了，那么整个集群就会以为缺少5501-11000 这个范围的槽而不可用。\n\n6、mysql 里有 2000w 数据，redis 中只存 20w 的数据，如何保证 redis 中的数据都是热点数据？\n\n答：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。\n\n7、redis 有哪些适合的场景？\n\n会话缓存（session cache）\n\n全页缓存（fpc）\n\n队列\n\n排行榜/计数器\n\n发布/订阅\n\n8、说说 redis 哈希槽的概念？\n\n答：redis 集群没有使用一致性 hash,而是引入了哈希槽的概念，redis 集群有 16384 个哈希槽，每个 key 通过 crc16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分 hash 槽。\n\n9、redis 集群的主从复制模型是怎样的？\n\n答：为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有 n-1 个复制品.\n\n10、redis 集群会有写操作丢失吗？为什么？\n\n答：redis 并不能保证数据的强一致性，这意味着在实际中集群在特定的条件下可能会丢失写操作。\n\n11、redis 集群之间是如何复制的？\n\n答：异步复制\n\n12、redis 集群最大节点个数是多少？\n\n答：16384 个\n\n13、redis 集群如何选择数据库？\n\n答：redis 集群目前无法做数据库选择，默认在 0 数据库。\n\n14、redis 如何做内存优化？\n\n答：尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。\n\n比如你的 web 系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的 key,而是应该把这个用户的所有信息存储到一张散列表里面。\n\n15、什么是缓存穿透？如何避免？什么是缓存雪崩？何如避免？\n\n缓存穿透\n\n一般的缓存系统，都是按照 key 去缓存查询，如果不存在对应的 value，就应该去后端系统查找（比如db）。一些恶意的请求会故意查询不存在的 key,请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。\n\n如何避免？\n\n> 1：对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该 key 对应的数据 insert 了之后清理缓存。\n> \n> 2：对一定不存在的 key 进行过滤。可以把所有的可能存在的 key 放到一个大的 bitmap 中，查询时通过该 bitmap 过滤。\n\n缓存雪崩\n\n当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压力。导致系统崩溃。\n\n如何避免？\n\n> 1：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个 key 只允许一个线程查询数据和写缓存，其他线程等待。\n> \n> 2：做二级缓存，a1 为原始缓存，a2 为拷贝缓存，a1 失效时，可以访问 a2，a1 缓存失效时间设置为短期，a2 设置为长期\n> \n> 3：不同的 key，设置不同的过期时间，让缓存失效的时间点尽量均匀\n\n16、redis 回收进程如何工作的？\n\n答：一个客户端运行了新的命令，添加了新的数据。redi 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。一个新的命令被执行，等等。\n\n所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。\n\n如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。\n\n17、使用过 redis 分布式锁么，它是怎么实现的？\n\n答：先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。\n\n如果在 setnx 之后执行 expire 之前进程意外 crash 或者要重启维护了，那会怎么样？\n\nset 指令有非常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成一条指令来用的！\n\n18、使用过 redis 做异步队列么，你是怎么用的？有什么缺点？\n\n答：般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep一会再重试。\n\n缺点：\n\n * 在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 rabbitmq 等。\n * 能不能生产一次消费多次呢？\n * 使用 pub/sub 主题订阅者模式，可以实现 1:n 的消息队列。",charsets:{cjk:!0}},{title:"设计模式",frontmatter:{title:"设计模式",date:"2023-04-20T16:00:18.000Z",permalink:"/pages/51830e/"},regularPath:"/06.%E9%9D%A2%E8%AF%95/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E9%9D%A2%E8%AF%95%E9%A2%98/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/08.设计模式面试题/01.设计模式面试题.md",key:"v-6ea4444b",path:"/pages/51830e/",headersStr:null,content:"# 设计模式面试题\n\n1、那些地方用到了单例模式\n\n答：\n\n 1. 网站的计数器，一般也是采用单例模式实现，否则难以同步。\n 2. 应用程序的日志应用，一般都是单例模式实现，只有一个实例去操作才好，否则内容不好追加显示。\n 3. 多线程的线程池的设计一般也是采用单例模式，因为线程池要方便对池中的线程进行控制\n 4. Windows的（任务管理器）就是很典型的单例模式，他不能打开俩个\n 5. windows的（回收站）也是典型的单例应用。在整个系统运行过程中，回收站只维护一个实例。\n\n2、举一个用 .Net5中实现的装饰模式(decorator design pattern)？它是作用于对象层次还是类 层次？ 答：装饰模式增加强了单个对象的能力。.Net5 IO 到处都使用了装饰模式，典型例子就是 Buffered 系列类如 BufferedStream 它们增强了 Stream 对象， 以实现提升性能的 Buffer 层次的读取和写入。\n\n3、适配器模式是什么？什么时候使用？**\n\n答：适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。适配器模式提供对接口的转换。如果你的客户端使用某些接口，但是你有另外一些接口，你就可以写一个适配去来连接这些接口。\n\n4、适配器模式与装饰器模式有什么区别？**\n\n答：虽然适配器模式和装饰器模式的结构类似，但是每种模式的出现意图不同。适配器模式被用于桥接两个接口，而装饰模式的目的是在不修改类的情况下给类增加新的功能。\n\n装饰者模式：动态地将责任附加到对象上，若要扩展功能，装饰者模提供了比继承更有弹性的替代方案。\n\n通俗的解释：装饰模式就是给一个对象增加一些新的功能，而且是动态的，要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例。\n\n适配器模式：将一个类的接口，转换成客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间。\n\n适配器模式有三种：类的适配器模式、对象的适配器模式、接口的适配器模式。\n\n通俗的说法：适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。\n\n5、适配器模式和代理模式之间有什么不同？**\n\n答：这个问题与前面的类似，适配器模式和代理模式的区别在于他们的意图不同。由于适配器模式和代理模式都是封装真正执行动作的类，因此结构是一致的，但是适配器模式用于接口之间的转换，而代理模式则是增加一个额外的中间层，以便支持分配、控制或智能访问。\n\n6、使用工厂模式最主要的好处是什么？你在哪里使用？\n\n答：工厂模式的最大好处是增加了创建对象时的封装层次。如果 你使用工厂来创建对象，之后你可以使用更高级和更高性能的实现来替换原始的产品实现或类，这不需要在调用层做任何修改。可以看我的文章工厂模式得更详细的解释和和了解更多的好处。\n\n7、什么时候使用享元模式？\n\n答：享元模式通过共享对象来避免创建太多的对象。为了使用享元模式，你需要确保你的对象是不可变的，这样你才能安全的共享。Net5中 String 池、Integer 池以及 Long 池都是很好的使用了享元模式的例子。\n\n8、什么是责任链设计模式**\n\n答：责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。\n\n9、你可以说出几个在.Net5中使用的设计模式吗？\n\n答：装饰器设计模式（Decorator design pattern）被用于多个.Net5 IO类中。单例模式（Singleton pattern）用于Runtime，Calendar和其他的一些类中。工厂模式（Factory pattern）被用于各种不可变的类如HttpClient，像HttpClientFactory，观察者模式（Observer pattern）被用于DiagnosticSource和很多的事件监听中。",normalizedContent:"# 设计模式面试题\n\n1、那些地方用到了单例模式\n\n答：\n\n 1. 网站的计数器，一般也是采用单例模式实现，否则难以同步。\n 2. 应用程序的日志应用，一般都是单例模式实现，只有一个实例去操作才好，否则内容不好追加显示。\n 3. 多线程的线程池的设计一般也是采用单例模式，因为线程池要方便对池中的线程进行控制\n 4. windows的（任务管理器）就是很典型的单例模式，他不能打开俩个\n 5. windows的（回收站）也是典型的单例应用。在整个系统运行过程中，回收站只维护一个实例。\n\n2、举一个用 .net5中实现的装饰模式(decorator design pattern)？它是作用于对象层次还是类 层次？ 答：装饰模式增加强了单个对象的能力。.net5 io 到处都使用了装饰模式，典型例子就是 buffered 系列类如 bufferedstream 它们增强了 stream 对象， 以实现提升性能的 buffer 层次的读取和写入。\n\n3、适配器模式是什么？什么时候使用？**\n\n答：适配器模式（adapter pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。适配器模式提供对接口的转换。如果你的客户端使用某些接口，但是你有另外一些接口，你就可以写一个适配去来连接这些接口。\n\n4、适配器模式与装饰器模式有什么区别？**\n\n答：虽然适配器模式和装饰器模式的结构类似，但是每种模式的出现意图不同。适配器模式被用于桥接两个接口，而装饰模式的目的是在不修改类的情况下给类增加新的功能。\n\n装饰者模式：动态地将责任附加到对象上，若要扩展功能，装饰者模提供了比继承更有弹性的替代方案。\n\n通俗的解释：装饰模式就是给一个对象增加一些新的功能，而且是动态的，要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例。\n\n适配器模式：将一个类的接口，转换成客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间。\n\n适配器模式有三种：类的适配器模式、对象的适配器模式、接口的适配器模式。\n\n通俗的说法：适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。\n\n5、适配器模式和代理模式之间有什么不同？**\n\n答：这个问题与前面的类似，适配器模式和代理模式的区别在于他们的意图不同。由于适配器模式和代理模式都是封装真正执行动作的类，因此结构是一致的，但是适配器模式用于接口之间的转换，而代理模式则是增加一个额外的中间层，以便支持分配、控制或智能访问。\n\n6、使用工厂模式最主要的好处是什么？你在哪里使用？\n\n答：工厂模式的最大好处是增加了创建对象时的封装层次。如果 你使用工厂来创建对象，之后你可以使用更高级和更高性能的实现来替换原始的产品实现或类，这不需要在调用层做任何修改。可以看我的文章工厂模式得更详细的解释和和了解更多的好处。\n\n7、什么时候使用享元模式？\n\n答：享元模式通过共享对象来避免创建太多的对象。为了使用享元模式，你需要确保你的对象是不可变的，这样你才能安全的共享。net5中 string 池、integer 池以及 long 池都是很好的使用了享元模式的例子。\n\n8、什么是责任链设计模式**\n\n答：责任链模式（chain of responsibility pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。\n\n9、你可以说出几个在.net5中使用的设计模式吗？\n\n答：装饰器设计模式（decorator design pattern）被用于多个.net5 io类中。单例模式（singleton pattern）用于runtime，calendar和其他的一些类中。工厂模式（factory pattern）被用于各种不可变的类如httpclient，像httpclientfactory，观察者模式（observer pattern）被用于diagnosticsource和很多的事件监听中。",charsets:{cjk:!0}},{title:"微服务面试题",frontmatter:{title:"微服务面试题",date:"2023-04-20T16:00:37.000Z",permalink:"/pages/11e99f/",article:!1},regularPath:"/06.%E9%9D%A2%E8%AF%95/09.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%9D%A2%E8%AF%95%E9%A2%98/01.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"06.面试/09.微服务面试题/01.微服务面试题.md",key:"v-a493dd52",path:"/pages/11e99f/",headersStr:null,content:"# 微服务面试题\n\n1、什么是微服务？\n\n答：单个轻量级服务一般为一个单独微服务，微服务讲究的是 专注某个功能的实现，比如登录系统只专注于用户登录方面功能的实现，讲究的是职责单一，开箱即用，可以独立运行。微服务架构系统是一个分布式的系统，按照业务进行划分服务单元模块，解决单个系统的不足，满足越来越复杂的业务需求。\n\n马丁福勒（Martin Fowler）：就目前而言，对于微服务业界并没有一个统一的、标准的定义。但通常而言，微服务架构是一种架构模式或者说是架构风格，它提倡将单一应用程序划分成一组小的服务。每个服务运行在其独立的自己的进程中服务之间相互配合、相互协调，为用户提供最终价值。服务之间采用轻量级通信。每个服务都围绕具体业务进行构建，并能够独立部署到生产环境等。另外应尽量避免统一的、集中的服务管理机制。\n\n通俗的来讲：\n\n微服务就是一个独立的职责单一的服务应用程序。在 intellij idea 工具里面就是用maven开发的一个个独立的module，具体就是使用springboot 开发的一个小的模块，处理单一专业的业务逻辑，一个模块只做一个事情。\n\n微服务强调的是服务大小，关注的是某一个点，具体解决某一个问题/落地对应的一个服务应用，可以看做是idea 里面一个 module。\n\n比如你去医院：你的牙齿不舒服，那么你就去牙科。你的头疼，那么你就去脑科。一个个的科室，就是一个微服务，一个功能就是一个服务。\n\n2、微服务之间如何独立通讯的?\n\n答： 同步通信：.Net5通过 RPC GRPC 远程过程调用或者通过 REST 接口json调用 等。\n\n异步：消息队列，如：RabbitMq、ActiveM、Kafka 等。\n\n3、什么是熔断？什么是服务降级？\n\n答：服务熔断的作用类似于我们家用的保险丝，当某服务出现不可用或响应超时的情况时，为了防止整个系统出现雪崩，暂时停止对该服务的调用。\n\n服务降级是从整个系统的负荷情况出发和考虑的，对某些负荷会比较高的情况，为了预防某些功能（业务场景）出现负荷过载或者响应慢的情况，在其内部暂时舍弃对一些非核心的接口和数据的请求，而直接返回一个提前准备好的fallback（退路）错误处理信息。这样，虽然提供的是一个有损的服务，但却保证了整个系统的稳定性和可用性。\n\n4、微服务的优缺点是什么？说下你在项目中碰到的坑。\n\n答：优点：松耦合，聚焦单一业务功能，无关开发语言，团队规模降低。在开发中，不需要了解多有业务，只专注于当前功能，便利集中，功能小而精。微服务一个功能受损，对其他功能影响并不是太大，可以快速定位问题。微服务只专注于当前业务逻辑代码，不会和 html、css 或其他界面进行混合。可以灵活搭配技术，独立性比较舒服。\n\n缺点：随着服务数量增加，管理复杂，部署复杂，服务器需要增多，服务通信和调用压力增大，运维工程师压力增大，人力资源增多，系统依赖增强，数据一致性，性能监控。\n\n5、你所知道微服务的技术栈有哪些？列举一二。\n\n答：微服务条目 落地技术 服务开发 AspnetCore、.Net5、.Net6 服务配置与管理 携程公司的Apollo、社区的的Consul等 服务注册与发现 Eurka、Consul、Zookeeper等 服务调用 Rest（服务通信）、RPC、GRpc 服务熔断器 Polly、Envoy等 负载均衡 Nginx等 服务接口调用（客户端简化工具） WebAPI等 消息队列 Kafka、RabbitMQ、ActiveMQ等 服务配置中心管理 Apollo、Chef等 服务路由（API网关） Ocelot等 服务监控 Zabbix，Nagios，Skywalking等 全链路追踪 Zipkin，Brave，Skywalking等 服务部署 Docker，OpenStack，Kubernetes等 数据流操作开发包 SpringCloud Stream（封装与Redis，Rabbit，kafka等发送接收消息） 事件消息总线CAP\n\n6、什么是微服务架构？\n\n答：微服务架构 就是 对微服务进行管理整合应用的。微服务架构 依赖于 微服务，是在微服务基础之上的。\n\n例如：上面已经列举了什么是微服务。在医院里，每一个科室都是一个独立的微服务，那么 这个医院 就是 一个大型的微服务架构，就类似 院长 可以 对下面的 科室进行管理。微服务架构主要就是这种功能。\n\n7、设计微服务的最佳实践是什么？\n\n答：\n\n 1. 为每个微服务分开数据存储\n 2. 将代码保持在类似的成熟度等级上\n 3. 为每个微服务进行单独的构建\n 4. 部署到容器中\n 5. 将服务器视为无状态的\n\n8、单体应用、SOA 和微服务架构有什么区别？**\n\n答：\n\n * 单体应用类似于一个大容器，其中程序的所有组件都被组装在一起并紧密包装。\n * SOA是一组相互通信的服务。通信可以涉及简单的数据传送，也可以涉及两个或多个协调某些活动的服务。\n * 微服务架构是一种架构风格，它将应用程序构建为以业务域为模型的小型自治服务集合。\n\n9、在使用微服务架构时，你面临的挑战是什么？**\n\n答：\n\n开发较小的微服务听起来很容易，但在开发时会经常遇到一些挑战。\n\n * 自动化组件：难以自动化，因为有许多较小的组件。对于每个组件，都必须采取构建、发布和监控的步骤。\n * 可感知性：将大量组件维持在一起会带来难以部署、维护、监控和识别的问题。它需要在所有组件周围具有很好的感知能力。\n * 配置管理：有时在各种环境中维护组件的配置会很困难。\n * 调试：很难找到与产生的错误相关的每一项服务。维护一个集中式的日志和控制面板对调试问题至关重要。\n\n10、为什么需要域驱动设计（DDD）？\n\n答：\n\n * 映射领域\n * 降低复杂性\n * 可测试性\n * 可维护性\n * 知识丰富的设计\n * 将业务和服务结合在一起\n * 上下文集中\n * 通用语言\n\n11、你对分布式事务的理解？\n\n答：\n\n分布式事务是单个事件导致两个或多个不能以原子方式提交的单独数据源的突变的情况。在微服务的世界中，它变得更加复杂，因为每个服务都是一个工作单元，并且在大多数情况下，多个服务必须协同工作才能使业务成功。\n\n12、什么是幂等性（Idempotence）及用在那里？\n\n幂等性是能够以同样的方式做两次，而最终结果将保持不变，就好像它只做了一次的特性。\n\n用法：在远程服务或数据源中使用幂等性，以便当它多次接收指令时，只处理一次。\n\n13、什么是有界上下文？\n\n答：有界上下文是领域驱动设计的核心模式。 DDD 战略设计部门的重点是处理大型模型和团队。 DDD 通过将大型模型划分为不同的有界上下文并明确其相互关系来处理大型模型。\n\n14、容器在微服务中的用途是什么？\n\n答：容器是管理基于微服务的程序以便单独开发和部署它们的好方法*。*你可以将微服务封装在容器镜像及其依赖项中，然后可以用它来滚动开发按需实例的微服务而无需任何额外的工作。\n\n15、什么是金丝雀发布（Canary Releasing）？\n\n答：金丝雀发布是一种降低在生产中引入新版本软件风险的技术。通过在将更改传递给整个基础架构之前将更改缓慢地推广到一小部分用户来完成的。",normalizedContent:"# 微服务面试题\n\n1、什么是微服务？\n\n答：单个轻量级服务一般为一个单独微服务，微服务讲究的是 专注某个功能的实现，比如登录系统只专注于用户登录方面功能的实现，讲究的是职责单一，开箱即用，可以独立运行。微服务架构系统是一个分布式的系统，按照业务进行划分服务单元模块，解决单个系统的不足，满足越来越复杂的业务需求。\n\n马丁福勒（martin fowler）：就目前而言，对于微服务业界并没有一个统一的、标准的定义。但通常而言，微服务架构是一种架构模式或者说是架构风格，它提倡将单一应用程序划分成一组小的服务。每个服务运行在其独立的自己的进程中服务之间相互配合、相互协调，为用户提供最终价值。服务之间采用轻量级通信。每个服务都围绕具体业务进行构建，并能够独立部署到生产环境等。另外应尽量避免统一的、集中的服务管理机制。\n\n通俗的来讲：\n\n微服务就是一个独立的职责单一的服务应用程序。在 intellij idea 工具里面就是用maven开发的一个个独立的module，具体就是使用springboot 开发的一个小的模块，处理单一专业的业务逻辑，一个模块只做一个事情。\n\n微服务强调的是服务大小，关注的是某一个点，具体解决某一个问题/落地对应的一个服务应用，可以看做是idea 里面一个 module。\n\n比如你去医院：你的牙齿不舒服，那么你就去牙科。你的头疼，那么你就去脑科。一个个的科室，就是一个微服务，一个功能就是一个服务。\n\n2、微服务之间如何独立通讯的?\n\n答： 同步通信：.net5通过 rpc grpc 远程过程调用或者通过 rest 接口json调用 等。\n\n异步：消息队列，如：rabbitmq、activem、kafka 等。\n\n3、什么是熔断？什么是服务降级？\n\n答：服务熔断的作用类似于我们家用的保险丝，当某服务出现不可用或响应超时的情况时，为了防止整个系统出现雪崩，暂时停止对该服务的调用。\n\n服务降级是从整个系统的负荷情况出发和考虑的，对某些负荷会比较高的情况，为了预防某些功能（业务场景）出现负荷过载或者响应慢的情况，在其内部暂时舍弃对一些非核心的接口和数据的请求，而直接返回一个提前准备好的fallback（退路）错误处理信息。这样，虽然提供的是一个有损的服务，但却保证了整个系统的稳定性和可用性。\n\n4、微服务的优缺点是什么？说下你在项目中碰到的坑。\n\n答：优点：松耦合，聚焦单一业务功能，无关开发语言，团队规模降低。在开发中，不需要了解多有业务，只专注于当前功能，便利集中，功能小而精。微服务一个功能受损，对其他功能影响并不是太大，可以快速定位问题。微服务只专注于当前业务逻辑代码，不会和 html、css 或其他界面进行混合。可以灵活搭配技术，独立性比较舒服。\n\n缺点：随着服务数量增加，管理复杂，部署复杂，服务器需要增多，服务通信和调用压力增大，运维工程师压力增大，人力资源增多，系统依赖增强，数据一致性，性能监控。\n\n5、你所知道微服务的技术栈有哪些？列举一二。\n\n答：微服务条目 落地技术 服务开发 aspnetcore、.net5、.net6 服务配置与管理 携程公司的apollo、社区的的consul等 服务注册与发现 eurka、consul、zookeeper等 服务调用 rest（服务通信）、rpc、grpc 服务熔断器 polly、envoy等 负载均衡 nginx等 服务接口调用（客户端简化工具） webapi等 消息队列 kafka、rabbitmq、activemq等 服务配置中心管理 apollo、chef等 服务路由（api网关） ocelot等 服务监控 zabbix，nagios，skywalking等 全链路追踪 zipkin，brave，skywalking等 服务部署 docker，openstack，kubernetes等 数据流操作开发包 springcloud stream（封装与redis，rabbit，kafka等发送接收消息） 事件消息总线cap\n\n6、什么是微服务架构？\n\n答：微服务架构 就是 对微服务进行管理整合应用的。微服务架构 依赖于 微服务，是在微服务基础之上的。\n\n例如：上面已经列举了什么是微服务。在医院里，每一个科室都是一个独立的微服务，那么 这个医院 就是 一个大型的微服务架构，就类似 院长 可以 对下面的 科室进行管理。微服务架构主要就是这种功能。\n\n7、设计微服务的最佳实践是什么？\n\n答：\n\n 1. 为每个微服务分开数据存储\n 2. 将代码保持在类似的成熟度等级上\n 3. 为每个微服务进行单独的构建\n 4. 部署到容器中\n 5. 将服务器视为无状态的\n\n8、单体应用、soa 和微服务架构有什么区别？**\n\n答：\n\n * 单体应用类似于一个大容器，其中程序的所有组件都被组装在一起并紧密包装。\n * soa是一组相互通信的服务。通信可以涉及简单的数据传送，也可以涉及两个或多个协调某些活动的服务。\n * 微服务架构是一种架构风格，它将应用程序构建为以业务域为模型的小型自治服务集合。\n\n9、在使用微服务架构时，你面临的挑战是什么？**\n\n答：\n\n开发较小的微服务听起来很容易，但在开发时会经常遇到一些挑战。\n\n * 自动化组件：难以自动化，因为有许多较小的组件。对于每个组件，都必须采取构建、发布和监控的步骤。\n * 可感知性：将大量组件维持在一起会带来难以部署、维护、监控和识别的问题。它需要在所有组件周围具有很好的感知能力。\n * 配置管理：有时在各种环境中维护组件的配置会很困难。\n * 调试：很难找到与产生的错误相关的每一项服务。维护一个集中式的日志和控制面板对调试问题至关重要。\n\n10、为什么需要域驱动设计（ddd）？\n\n答：\n\n * 映射领域\n * 降低复杂性\n * 可测试性\n * 可维护性\n * 知识丰富的设计\n * 将业务和服务结合在一起\n * 上下文集中\n * 通用语言\n\n11、你对分布式事务的理解？\n\n答：\n\n分布式事务是单个事件导致两个或多个不能以原子方式提交的单独数据源的突变的情况。在微服务的世界中，它变得更加复杂，因为每个服务都是一个工作单元，并且在大多数情况下，多个服务必须协同工作才能使业务成功。\n\n12、什么是幂等性（idempotence）及用在那里？\n\n幂等性是能够以同样的方式做两次，而最终结果将保持不变，就好像它只做了一次的特性。\n\n用法：在远程服务或数据源中使用幂等性，以便当它多次接收指令时，只处理一次。\n\n13、什么是有界上下文？\n\n答：有界上下文是领域驱动设计的核心模式。 ddd 战略设计部门的重点是处理大型模型和团队。 ddd 通过将大型模型划分为不同的有界上下文并明确其相互关系来处理大型模型。\n\n14、容器在微服务中的用途是什么？\n\n答：容器是管理基于微服务的程序以便单独开发和部署它们的好方法*。*你可以将微服务封装在容器镜像及其依赖项中，然后可以用它来滚动开发按需实例的微服务而无需任何额外的工作。\n\n15、什么是金丝雀发布（canary releasing）？\n\n答：金丝雀发布是一种降低在生产中引入新版本软件风险的技术。通过在将更改传递给整个基础架构之前将更改缓慢地推广到一小部分用户来完成的。",charsets:{cjk:!0}},{title:"博客文章",frontmatter:{archivesPage:!0,title:"博客文章",permalink:"/blog/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-d7570fb0",path:"/blog/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/04/26, 22:10:06",lastUpdatedTimestamp:1682518206e3},{title:"Home",frontmatter:{home:!0,heroImage:"/img/logo.png",heroText:"ZYHCODE的博客",tagline:"🚀后端全栈知识体系。总结、思考、输出",bannerBg:"none",features:[{title:"技术学习",details:"涉及Java、Go、Python等后端技术栈; 大数据集群管理、离线开发、实时开发、BI报表等; 还有其他中间件"},{title:"创业思考",details:"毕业后一直创业、关于在创业过程中的一些对人、事、管理的思考"},{title:"读书笔记",details:"读书笔记、同步Notion里的读书笔记, 涉及文学、历史、传记等"}],postList:"none"},regularPath:"/",relativePath:"index.md",key:"v-49cf9efe",path:"/",headers:[{level:2,title:"🎖快速访问",slug:"🎖快速访问",normalizedTitle:"🎖快速访问",charIndex:6},{level:2,title:"⚡ 反馈与交流",slug:"⚡-反馈与交流",normalizedTitle:"⚡ 反馈与交流",charIndex:692}],headersStr:"🎖快速访问 ⚡ 反馈与交流",content:"\n\n\n\n# 🎖快速访问\n\nJava官网\n\n🚀构建新式应用的免费开放源代码跨平台框架。\n\nJava 文档\n\nJava Platform, Standard Edition Documentation\n\nSpring 官方文档\n\nSpring 学习最好的文档\n\n# - name: OpenHarmony\n#   desc: 开放原子开源基金会\n#   link: https://docs.openharmony.cn/pages/000000/\n#   bgColor: '#f1f1f1'\n#   textColor: '#2A3344'\n- name: Java官网\n  desc: 🚀构建新式应用的免费开放源代码跨平台框架。\n  link: https://www.oracle.com/java/\n  bgColor: '#9415bf'\n  textColor: '#ffffff'\n- name: Java 文档\n  desc: Java Platform, Standard Edition Documentation \n  link: https://docs.oracle.com/en/java/javase/index.html\n  bgColor: '#9415bf'\n  textColor: '#ffffff'\n- name: Spring 官方文档\n  desc: Spring 学习最好的文档\n  link: https://spring.io/\n  bgColor: '#9415bf'\n  textColor: '#ffffff'\n\n\n\n# ⚡ 反馈与交流\n\n在使用过程中有任何问题和想法，请给我提 Issue。 你也可以在Issue查看别人提的问题和给出解决方案。",normalizedContent:"\n\n\n\n# 🎖快速访问\n\njava官网\n\n🚀构建新式应用的免费开放源代码跨平台框架。\n\njava 文档\n\njava platform, standard edition documentation\n\nspring 官方文档\n\nspring 学习最好的文档\n\n# - name: openharmony\n#   desc: 开放原子开源基金会\n#   link: https://docs.openharmony.cn/pages/000000/\n#   bgcolor: '#f1f1f1'\n#   textcolor: '#2a3344'\n- name: java官网\n  desc: 🚀构建新式应用的免费开放源代码跨平台框架。\n  link: https://www.oracle.com/java/\n  bgcolor: '#9415bf'\n  textcolor: '#ffffff'\n- name: java 文档\n  desc: java platform, standard edition documentation \n  link: https://docs.oracle.com/en/java/javase/index.html\n  bgcolor: '#9415bf'\n  textcolor: '#ffffff'\n- name: spring 官方文档\n  desc: spring 学习最好的文档\n  link: https://spring.io/\n  bgcolor: '#9415bf'\n  textcolor: '#ffffff'\n\n\n\n# ⚡ 反馈与交流\n\n在使用过程中有任何问题和想法，请给我提 issue。 你也可以在issue查看别人提的问题和给出解决方案。",charsets:{cjk:!0},lastUpdated:"2023/09/21, 10:51:40",lastUpdatedTimestamp:16952647e5}],themeConfig:{nav:[{text:"🏠首页",link:"/"},{text:"Java基础",link:"/pages/77d4e2/",items:[{text:"集合",link:"/pages/77d4e2/",items:[{text:"IO基础知识",link:"/pages/77d4e2/"},{text:"IO设计模式",link:"/pages/49acab/"},{text:"IO模型总结",link:"/pages/a3d832/"},{text:"NIO核心知识总结",link:"/pages/42be26/"}]},{text:"IO流总结",link:"/pages/77d4e2/",items:[{text:"IO基础知识",link:"/pages/77d4e2/"},{text:"IO设计模式",link:"/pages/49acab/"},{text:"IO模型总结",link:"/pages/a3d832/"},{text:"NIO核心知识总结",link:"/pages/42be26/"}]},{text:"并发编程",link:"/pages/77d4e2/",items:[{text:"IO基础知识",link:"/pages/77d4e2/"},{text:"IO设计模式",link:"/pages/49acab/"},{text:"IO模型总结",link:"/pages/a3d832/"},{text:"NIO核心知识总结",link:"/pages/42be26/"}]},{text:"JVM",link:"/pages/77d4e2/",items:[{text:"IO基础知识",link:"/pages/77d4e2/"},{text:"IO设计模式",link:"/pages/49acab/"},{text:"IO模型总结",link:"/pages/a3d832/"},{text:"NIO核心知识总结",link:"/pages/42be26/"}]},{text:"版本新特性",link:"/pages/cd056d/",items:[{text:"Java8新特性",link:"/pages/cd056d/"},{text:"Java8指南中文翻译",link:"/pages/b610cd/"},{text:"Java9新特性",link:"/pages/1091ad/"},{text:"Java10新特性",link:"/pages/e43406/"},{text:"Java11新特性",link:"/pages/f37c60/"},{text:"Java12-13新特性",link:"/pages/79a5f6/"},{text:"Java14-15新特性",link:"/pages/683a03/"},{text:"Java16新特性",link:"/pages/fa2c73/"},{text:"Java17新特性",link:"/pages/245aa2/"},{text:"Java18新特性",link:"/pages/ce76de/"},{text:"Java19新特性",link:"/pages/42d550/"},{text:"Java20新特性",link:"/pages/d5208b/"},{text:"Java21新特性",link:"/pages/54087b/"}]},{text:"Springboot",link:"/pages/be9ac8/",items:[{text:"IO基础知识",link:"/pages/be9ac8/"},{text:"Cookie、Session、JWT、Token",link:"/pages/c6bced/"}]}]},{text:"微服务",link:"/pages/easytool/",items:[{text:"设计初衷",link:"/pages/easytool/"},{text:"克隆",link:"/pages/dc4434/"},{text:"类型转换",link:"/pages/24d03b/"}]},{text:"大数据",link:"/pages/easytool/",items:[{text:"设计初衷",link:"/pages/easytool/"},{text:"克隆",link:"/pages/dc4434/"},{text:"类型转换",link:"/pages/24d03b/"}]},{text:"🎖人工智能",link:"/pages/easytool/",items:[{text:"机器学习",link:"/pages/e50dff/",items:[{text:"吴恩达课程笔记",link:"/pages/f1d3fb/"}]},{text:"深度学习",link:"/pages/e50dff/",items:[{text:"简介",link:"/pages/e50dff/"},{text:"设计初衷",link:"/pages/easytool/"}]},{text:"大模型",link:"/pages/e50dff/",items:[{text:"简介",link:"/pages/e50dff/"},{text:"设计初衷",link:"/pages/easytool/"}]},{text:"数字人",link:"/pages/e50dff/",items:[{text:"简介",link:"/pages/e50dff/"},{text:"设计初衷",link:"/pages/easytool/"}]}]},{text:"中间件|部署",link:"/pages/e50dff/",items:[{text:"Docker",link:"/pages/e50dff/",items:[{text:"简介",link:"/pages/e50dff/"},{text:"机器学习",link:"/pages/f1d3fb/"},{text:"Apisix",link:"/pages/fbe42b/"},{text:"Apollo",link:"/pages/272684/"},{text:"Cassandra",link:"/pages/01958e/"},{text:"Cerebro",link:"/pages/7e58c5/"},{text:"ClickHouse",link:"/pages/3b4977/"},{text:"Consul",link:"/pages/3d230b/"},{text:"EasyMock",link:"/pages/ca4b88/"},{text:"Elasticsearch",link:"/pages/18fff0/"},{text:"Emqx",link:"/pages/d93c0b/"},{text:"FastDFS",link:"/pages/7bfded/"},{text:"Flink",link:"/pages/53b154/"},{text:"Gitlab",link:"/pages/83a3e2/"},{text:"Jenkins",link:"/pages/f90f99/"},{text:"Jrebel",link:"/pages/8e9d93/"},{text:"MariaDB",link:"/pages/ee069d/"},{text:"MySQL",link:"/pages/cff07b/"},{text:"Percona",link:"/pages/862a97/"},{text:"Phpmyadmin",link:"/pages/a560de/"},{text:"PostgreSQL",link:"/pages/230ca1/"},{text:"Redis",link:"/pages/be7f5d/"}]},{text:"Linux",link:"/pages/aa794b/",items:[{text:"Linux命令查询",link:"/pages/518cfa/"},{text:"查看Linux系统信息",link:"/pages/aa794b/"},{text:"CentOS7调整磁盘分区",link:"/pages/2cbf35/"},{text:"IO压测",link:"/pages/42cda4/"},{text:"图形化监控工具Cockpit",link:"/pages/71dd10/"}]},{text:"Redis",link:"/pages/aa794b/",items:[{text:"查看Linux系统信息",link:"/pages/aa794b/"},{text:"CentOS7调整磁盘分区",link:"/pages/2cbf35/"},{text:"IO压测",link:"/pages/42cda4/"},{text:"图形化监控工具Cockpit",link:"/pages/71dd10/"}]},{text:"Kafka",link:"/pages/aa794b/",items:[{text:"查看Linux系统信息",link:"/pages/aa794b/"},{text:"CentOS7调整磁盘分区",link:"/pages/2cbf35/"},{text:"IO压测",link:"/pages/42cda4/"},{text:"图形化监控工具Cockpit",link:"/pages/71dd10/"}]}]},{text:"面试宝典",link:"/pages/86a4e2/",items:[{text:"AspNetCore面试题",link:"/pages/86a4e2/"},{text:"Elasticsearch面试题",link:"/pages/a567cd/"},{text:"MongoDB面试题",link:"/pages/5201b9/"},{text:"MySql面试题",link:"/pages/43b4dd/"},{text:"Nginx面试题",link:"/pages/27153d/"},{text:"RabbitMQ面试题",link:"/pages/d74e41/"},{text:"Redis面试题",link:"/pages/97e5f1/"},{text:"设计模式",link:"/pages/51830e/"},{text:"微服务",link:"/pages/11e99f/"}]},{text:"在线工具箱",link:"https://debug.group/string-diff.html"}],sidebarDepth:2,logo:"/img/logo.png",repo:"Gresdy",searchMaxSuggestions:10,lastUpdated:"上次更新",sidebar:{"/01.Java基础/":[{title:"集合",collapsable:!1,children:[["01.集合/01.类型转换.md","类型转换","/pages/155b65/"]]},{title:"IO流",collapsable:!1,children:[["02.IO流/01.IO基础知识.md","Java IO 基础知识总结","/pages/77d4e2/"],["02.IO流/02.IO设计模式.md","Java IO 设计模式总结","/pages/49acab/"],["02.IO流/03.IO模型总结.md","Java IO 模型详解","/pages/a3d832/"],["02.IO流/04.NIO核心知识总结.md","Java NIO 核心知识总结","/pages/42be26/"]]},{title:"并发编程",collapsable:!1,children:[]},{title:" JVM",collapsable:!1,children:[]},{title:"版本新特性",collapsable:!1,children:[["05.版本新特性/01.java8-common-new-features.md","Java8 新特性实战","/pages/cd056d/"],["05.版本新特性/02.java8-tutorial-translate.md","java8-tutorial-translate","/pages/b610cd/"],["05.版本新特性/03.java9.md","Java 9 新特性概览","/pages/1091ad/"],["05.版本新特性/04.java10.md","Java 10 新特性概览","/pages/e43406/"],["05.版本新特性/05.java11.md","Java 11 新特性概览","/pages/f37c60/"],["05.版本新特性/06.java12-13.md","Java 12  & 13 新特性概览","/pages/79a5f6/"],["05.版本新特性/07.java14-15.md","Java 14  & 15 新特性概览","/pages/683a03/"],["05.版本新特性/08.java16.md","Java 16 新特性概览","/pages/fa2c73/"],["05.版本新特性/09.java17.md","Java 17 新特性概览（重要）","/pages/245aa2/"],["05.版本新特性/10.java18.md","Java 18 新特性概览","/pages/ce76de/"],["05.版本新特性/11.java19.md","Java 19 新特性概览","/pages/42d550/"],["05.版本新特性/12.java20.md","Java 20 新特性概览","/pages/d5208b/"],["05.版本新特性/13.java21.md","Java 21 新特性概览(重要)","/pages/54087b/"]]},{title:"SpringBoot",collapsable:!1,children:[["06.SpringBoot/01.Spring源码.md","Spring源码","/pages/be9ac8/"],["06.SpringBoot/02.权限模型.md","权限模型","/pages/5b4265/"],["06.SpringBoot/03.Cookie-Session-Token-JWT.md","Cookie-Session-Token-JWT","/pages/c6bced/"]]}],catalogue:{},"/03.人工智能/":[["01.监督学习-吴恩达coursera.md","监督学习-吴恩达coursera","/pages/3c4623/"],["02.吴恩达：机器学习的六个核心算法.md","吴恩达：机器学习的六个核心算法","/pages/cb2190/"]],"/04.知识地图/":[{title:"知识地图",collapsable:!1,children:[["01.知识地图/01.知识地图.md","知识地图","/pages/f8be69/"]]},{title:"源码脑图",collapsable:!1,children:[["02.源码脑图/01.总览.md","总览","/pages/8448ab/"],["02.源码脑图/02.Program入口.md","Program入口","/pages/372b2d/"],["02.源码脑图/03.WebApplication主机.md","WebApplication主机","/pages/cb2fbc/"],["02.源码脑图/04.Host主机.md","Host主机","/pages/78c443/"],["02.源码脑图/05.WebHost主机.md","WebHost主机","/pages/840f86/"],["02.源码脑图/06.依赖注入.md","依赖注入","/pages/0d115d/"],["02.源码脑图/07.Autofac.md","Autofac","/pages/e2d1de/"],["02.源码脑图/08.Middleware中间件.md","Middleware中间件","/pages/899977/"],["02.源码脑图/09.RateLimiter限制速率.md","RateLimiter限制速率","/pages/5991be/"],["02.源码脑图/10.响应缓存请求解压缩.md","响应缓存、请求解压缩","/pages/bacc57/"]]}],"/05.工具&部署/":[{title:"Docker",collapsable:!1,children:[["01.Docker/01.开源简介.md","开源简介","/pages/e50dff/"],["01.Docker/02.监督学习-吴恩达coursera.md","吴恩达机器学习视频","/pages/f1d3fb/"],["01.Docker/03.Apisix.md","Apisix","/pages/fbe42b/"],["01.Docker/04.Apollo.md","Apollo","/pages/272684/"],["01.Docker/05.Cassandra.md","Cassandra","/pages/01958e/"],["01.Docker/06.Cerebro.md","Cerebro","/pages/7e58c5/"],["01.Docker/07.ClickHouse.md","ClickHouse","/pages/3b4977/"],["01.Docker/08.Consul.md","Consul","/pages/3d230b/"],["01.Docker/09.EasyMock.md","EasyMock","/pages/ca4b88/"],["01.Docker/10.Elasticsearch.md","Elasticsearch","/pages/18fff0/"],["01.Docker/11.Emqx.md","Emqx","/pages/d93c0b/"],["01.Docker/12.FastDFS.md","FastDFS","/pages/7bfded/"],["01.Docker/13.Flink.md","Flink","/pages/53b154/"],["01.Docker/14.Gitlab.md","Gitlab","/pages/83a3e2/"],["01.Docker/15.Jenkins.md","Jenkins","/pages/f90f99/"],["01.Docker/16.Jrebel.md","Jrebel","/pages/8e9d93/"],["01.Docker/17.MariaDB.md","MariaDB","/pages/ee069d/"],["01.Docker/18.MySQL.md","MySQL","/pages/cff07b/"],["01.Docker/19.Percona.md","Percona","/pages/862a97/"],["01.Docker/20.Phpmyadmin.md","Phpmyadmin","/pages/a560de/"],["01.Docker/21.PostgreSQL.md","PostgreSQL","/pages/230ca1/"],["01.Docker/22.Redis.md","Redis","/pages/be7f5d/"]]},{title:"Linux",collapsable:!1,children:[["02.Linux/01.查看Linux系统信息.md","查看Linux系统信息","/pages/aa794b/"],["02.Linux/02.CentOS7调整磁盘分区.md","CentOS7调整磁盘分区","/pages/2cbf35/"],["02.Linux/03.IO压测.md","IO压测","/pages/42cda4/"],["02.Linux/04.Linux图形化监控工具Cockpit.md","Linux图形化监控工具Cockpit","/pages/71dd10/"],["02.Linux/05.CentOS7安装mysql5.7.md","CentOS7安装mysql5.7","/pages/6db179/"],["02.Linux/06.在线Linux命令查询.md","在线Linux命令查询","/pages/518cfa/"]]}],"/06.面试/":[{title:"AspNetCore面试题",collapsable:!1,children:[["01.AspNetCore面试题/01.AspNetCore面试题.md","AspNetCore面试题","/pages/86a4e2/"],["01.AspNetCore面试题/02.Net面试题.md","Net面试题","/pages/868a19/"]]},{title:"Elasticsearch面试题",collapsable:!1,children:[["02.Elasticsearch面试题/01.Elasticsearch面试题.md","Elasticsearch面试题","/pages/a567cd/"]]},{title:"MongoDB面试题",collapsable:!1,children:[["03.MongoDB面试题/01.MongoDB面试题.md","MongoDB面试题","/pages/5201b9/"]]},{title:"MySql面试题",collapsable:!1,children:[["04.MySql面试题/01.MySql面试题.md","MySql面试题","/pages/43b4dd/"]]},{title:"Nginx面试题",collapsable:!1,children:[["05.Nginx面试题/01.Nginx面试题.md","Nginx面试题","/pages/27153d/"]]},{title:"RabbitMQ面试题",collapsable:!1,children:[["06.RabbitMQ面试题/01.RabbitMQ面试题.md","RabbitMQ面试题","/pages/d74e41/"]]},{title:"Redis面试题",collapsable:!1,children:[["07.Redis面试题/01.Redis面试题.md","Redis面试题","/pages/97e5f1/"]]},{title:"设计模式面试题",collapsable:!1,children:[["08.设计模式面试题/01.设计模式面试题.md","设计模式","/pages/51830e/"]]},{title:"微服务面试题",collapsable:!1,children:[["09.微服务面试题/01.微服务面试题.md","微服务面试题","/pages/11e99f/"]]}]},updateBar:{showToArticle:!1},pageStyle:"line",category:!1,tag:!1,author:{name:"三更扯谈",href:"https://github.com/Gresdy"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:1248824030@qq.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/Gresdy"},{iconClass:"icon-gitee",title:"Gitee",link:"https://github.com/Gresdy"}]},footer:{createYear:2023,copyrightInfo:"三更扯谈 | MIT License"},htmlModules:{}}};var Tt=t(94),Et=t(95),St=t(12);var It={computed:{$filterPosts(){return this.$site.pages.filter(e=>{const{frontmatter:{pageComponent:n,article:t,home:a}}=e;return!(n||!1===t||!0===a)})},$sortPosts(){return(e=this.$filterPosts).sort((e,n)=>{const t=e.frontmatter.sticky,a=n.frontmatter.sticky;return t&&a?t==a?Object(St.a)(e,n):t-a:t&&!a?-1:!t&&a?1:Object(St.a)(e,n)}),e;var e},$sortPostsByDate(){return(e=this.$filterPosts).sort((e,n)=>Object(St.a)(e,n)),e;var e},$groupPosts(){return function(e){const n={},t={};for(let a=0,r=e.length;a<r;a++){const{frontmatter:{categories:r,tags:i}}=e[a];"array"===Object(St.n)(r)&&r.forEach(t=>{t&&(n[t]||(n[t]=[]),n[t].push(e[a]))}),"array"===Object(St.n)(i)&&i.forEach(n=>{n&&(t[n]||(t[n]=[]),t[n].push(e[a]))})}return{categories:n,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(e){const n=[],t=[];for(let t in e.categories)n.push({key:t,length:e.categories[t].length});for(let n in e.tags)t.push({key:n,length:e.tags[n].length});return{categories:n,tags:t}}(this.$groupPosts)}}};a.default.component(Tt.default),a.default.component(Et.default);function At(e){return e.toString().padStart(2,"0")}t(244);a.default.component("Notice",()=>Promise.all([t.e(0),t.e(2),t.e(5)]).then(t.bind(null,471))),a.default.component("Badge",()=>Promise.all([t.e(0),t.e(6)]).then(t.bind(null,546))),a.default.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,94))),a.default.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,95)));t(245);var Ct=[({Vue:e,options:n,router:t,siteData:a,isServer:r})=>{r||t.afterEach(()=>{var e;e=function(){setTimeout((function(){void 0===window._AdBlockInit&&function(){const e=document.getElementsByClassName("wwads-cn"),n=document.querySelector(".wwads-content");e[0]&&!n&&(e[0].innerHTML="<style>.wwads-horizontal,.wwads-vertical{background-color:#f4f8fa;padding:5px;min-height:120px;margin-top:20px;box-sizing:border-box;border-radius:3px;font-family:sans-serif;display:flex;min-width:150px;position:relative;overflow:hidden;}.wwads-horizontal{flex-wrap:wrap;justify-content:center}.wwads-vertical{flex-direction:column;align-items:center;padding-bottom:32px}.wwads-horizontal a,.wwads-vertical a{text-decoration:none}.wwads-horizontal .wwads-img,.wwads-vertical .wwads-img{margin:5px}.wwads-horizontal .wwads-content,.wwads-vertical .wwads-content{margin:5px}.wwads-horizontal .wwads-content{flex:130px}.wwads-vertical .wwads-content{margin-top:10px}.wwads-horizontal .wwads-text,.wwads-content .wwads-text{font-size:14px;line-height:1.4;color:#0e1011;-webkit-font-smoothing:antialiased}.wwads-horizontal .wwads-poweredby,.wwads-vertical .wwads-poweredby{display:block;font-size:11px;color:#a6b7bf;margin-top:1em}.wwads-vertical .wwads-poweredby{position:absolute;left:10px;bottom:10px}.wwads-horizontal .wwads-poweredby span,.wwads-vertical .wwads-poweredby span{transition:all 0.2s ease-in-out;margin-left:-1em}.wwads-horizontal .wwads-poweredby span:first-child,.wwads-vertical .wwads-poweredby span:first-child{opacity:0}.wwads-horizontal:hover .wwads-poweredby span,.wwads-vertical:hover .wwads-poweredby span{opacity:1;margin-left:0}.wwads-horizontal .wwads-hide,.wwads-vertical .wwads-hide{position:absolute;right:-23px;bottom:-23px;width:46px;height:46px;border-radius:23px;transition:all 0.3s ease-in-out;cursor:pointer;}.wwads-horizontal .wwads-hide:hover,.wwads-vertical .wwads-hide:hover{background:rgb(0 0 0 /0.05)}.wwads-horizontal .wwads-hide svg,.wwads-vertical .wwads-hide svg{position:absolute;left:10px;top:10px;fill:#a6b7bf}.wwads-horizontal .wwads-hide:hover svg,.wwads-vertical .wwads-hide:hover svg{fill:#3E4546}</style><a href='https://wwads.cn/page/whitelist-wwads' class='wwads-img' target='_blank' rel='nofollow'><img src='https://fastly.jsdelivr.net/gh/xugaoyi/image_store@master/blog/wwads.2a3pidhlh4ys.webp' width='130'></a><div class='wwads-content'><a href='https://wwads.cn/page/whitelist-wwads' class='wwads-text' target='_blank' rel='nofollow'>为了本站的长期运营，请将我们的网站加入广告拦截器的白名单，感谢您的支持！<span style='color: #11a8cd'>如何添加白名单?</span></a><a href='https://wwads.cn/page/end-user-privacy' class='wwads-poweredby' title='万维广告 ～ 让广告更优雅，且有用' target='_blank'><span>广告</span></a></div><a class='wwads-hide' onclick='parentNode.remove()' title='隐藏广告'><svg xmlns='http://www.w3.org/2000/svg' width='6' height='7'><path d='M.879.672L3 2.793 5.121.672a.5.5 0 11.707.707L3.708 3.5l2.12 2.121a.5.5 0 11-.707.707l-2.12-2.12-2.122 2.12a.5.5 0 11-.707-.707l2.121-2.12L.172 1.378A.5.5 0 01.879.672z'></path></svg></a>")}()}),3e3)},"complete"===document.readyState||"interactive"===document.readyState?setTimeout(e,1):document.addEventListener("DOMContentLoaded",e),setTimeout(()=>{const e=document.querySelector(".page-wwads");if(!e)return;const n=e.querySelector(".wwads-hide");n&&(n.onclick=()=>{e.style.display="none"}),"none"===e.style.display&&(e.style.display="flex")},900)})},({Vue:e,options:n,router:t,siteData:a})=>{a.pages.map(e=>{const{frontmatter:{date:n,author:t}}=e;"string"==typeof n&&"Z"===n.charAt(n.length-1)&&(e.frontmatter.date=function(e){e instanceof Date||(e=new Date(e));return`${e.getUTCFullYear()}-${At(e.getUTCMonth()+1)}-${At(e.getUTCDate())} ${At(e.getUTCHours())}:${At(e.getUTCMinutes())}:${At(e.getUTCSeconds())}`}(n)),t?e.author=t:a.themeConfig.author&&(e.author=a.themeConfig.author)}),e.mixin(It)},{},({Vue:e})=>{e.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({router:e})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?d9b44aca91c27e070324d5276deedc0a";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)}(),e.afterEach((function(e){_hmt.push(["_trackPageview",e.fullPath])})))}],jt=[];class Ot extends class{constructor(){this.store=new a.default({data:{state:{}}})}$get(e){return this.store.state[e]}$set(e,n){a.default.set(this.store.state,e,n)}$emit(...e){this.store.$emit(...e)}$on(...e){this.store.$on(...e)}}{}Object.assign(Ot.prototype,{getPageAsyncComponent:cn,getLayoutAsyncComponent:dn,getAsyncComponent:un,getVueComponent:pn});var Lt={install(e){const n=new Ot;e.$vuepress=n,e.prototype.$vuepress=n}};function Nt(e,n){const t=n.toLowerCase();return e.options.routes.some(e=>e.path.toLowerCase()===t)}var Dt={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(e){const n=this.pageKey||this.$parent.$page.key;return hn("pageKey",n),a.default.component(n)||a.default.component(n,cn(n)),a.default.component(n)?e(n):e("")}},Pt={functional:!0,props:{slotKey:String,required:!0},render:(e,{props:n,slots:t})=>e("div",{class:["content__"+n.slotKey]},t()[n.slotKey])},Mt={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Rt=(t(246),t(247),Object(wt.a)(Mt,(function(){var e=this._self._c;return e("span",[e("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[e("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),e("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),e("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),zt={functional:!0,render(e,{parent:n,children:t}){if(n._isMounted)return t;n.$once("hook:mounted",()=>{n.$forceUpdate()})}};a.default.config.productionTip=!1,a.default.use(Ge),a.default.use(Lt),a.default.mixin(function(e,n,t=a.default){!function(e){e.locales&&Object.keys(e.locales).forEach(n=>{e.locales[n].path=n});Object.freeze(e)}(n),t.$vuepress.$set("siteData",n);const r=new(e(t.$vuepress.$get("siteData"))),i=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),o={};return Object.keys(i).reduce((e,n)=>(n.startsWith("$")&&(e[n]=i[n].get),e),o),{computed:o}}(e=>class{setPage(e){this.__page=e}get $site(){return e}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:e={}}=this.$site;let n,t;for(const a in e)"/"===a?t=e[a]:0===this.$page.path.indexOf(a)&&(n=e[a]);return n||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:e}=this.$page.frontmatter;return"string"==typeof e&&e}get $title(){const e=this.$page,{metaTitle:n}=this.$page.frontmatter;if("string"==typeof n)return n;const t=this.$siteTitle,a=e.frontmatter.home?null:e.frontmatter.title||e.title;return t?a?a+" | "+t:t:a||"VuePress"}get $description(){const e=function(e){if(e){const n=e.filter(e=>"description"===e.name)[0];if(n)return n.content}}(this.$page.frontmatter.meta);return e||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(e,n){for(let t=0;t<e.length;t++){const a=e[t];if(a.path.toLowerCase()===n.toLowerCase())return a}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},kt)),a.default.component("Content",Dt),a.default.component("ContentSlotsDistributor",Pt),a.default.component("OutboundLink",Rt),a.default.component("ClientOnly",zt),a.default.component("Layout",dn("Layout")),a.default.component("NotFound",dn("NotFound")),a.default.prototype.$withBase=function(e){const n=this.$site.base;return"/"===e.charAt(0)?n+e.slice(1):e},window.__VUEPRESS__={version:"1.9.2",hash:"a5ee89d"},async function(e){const n="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:kt.routerBase||kt.base,t=new Ge({base:n,mode:"history",fallback:!1,routes:xt,scrollBehavior:(e,n,t)=>t||(e.hash?!a.default.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(e.hash)}:{x:0,y:0})});!function(e){e.beforeEach((n,t,a)=>{if(Nt(e,n.path))a();else if(/(\/|\.html)$/.test(n.path))if(/\/$/.test(n.path)){const t=n.path.replace(/\/$/,"")+".html";Nt(e,t)?a(t):a()}else a();else{const t=n.path+"/",r=n.path+".html";Nt(e,r)?a(r):Nt(e,t)?a(t):a()}})}(t);const r={};try{await Promise.all(Ct.filter(e=>"function"==typeof e).map(n=>n({Vue:a.default,options:r,router:t,siteData:kt,isServer:e})))}catch(e){console.error(e)}return{app:new a.default(Object.assign(r,{router:t,render:e=>e("div",{attrs:{id:"app"}},[e("RouterView",{ref:"layout"}),e("div",{class:"global-ui"},jt.map(n=>e(n)))])})),router:t}}(!1).then(({app:e,router:n})=>{n.onReady(()=>{e.$mount("#app")})})}]);